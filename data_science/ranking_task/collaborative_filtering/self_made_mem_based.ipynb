{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd07a3cd-0d99-4461-b8ed-87b42d90f9e5",
   "metadata": {},
   "source": [
    "# Selfmade memory based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcffa71-b2e6-443d-9b83-a1aea7b6108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from scipy.spatial.distance import (\n",
    "    correlation as orig_correlation,\n",
    "    cosine as orig_cosine\n",
    ")\n",
    "from surprise import KNNWithMeans, Dataset, Reader\n",
    "from ranx import Qrels, Run, evaluate\n",
    "\n",
    "from typing import Union, Callable\n",
    "\n",
    "from IPython.display import HTML\n",
    "header_pattern = \"<text style='font-size:20px'>{}</text>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9cc818-82b1-416e-8165-35464cb59575",
   "metadata": {},
   "source": [
    "## Task generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801a39a2-f654-448f-aa2d-d7a047f97d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  7,  0,  3,  7,  5,  5,  0,  3,  4,  3,  4,  5,  2,  0,  2,\n",
       "         1,  1,  8,  3,  2,  6,  1,  6,  4,  6,  1,  1,  5,  1,  1,  4,\n",
       "         2,  2,  8,  8,  4,  4,  0,  8,  4,  6,  4,  7,  5,  5,  1,  4,\n",
       "         5,  1],\n",
       "       [ 9, 10,  6, 10,  7,  5, 10,  9,  7,  8,  5, 10, 10,  6, 10,  5,\n",
       "         3,  3,  4,  4,  5, 10,  7,  4, 10,  6,  4,  9,  5,  9,  6,  9,\n",
       "        10,  7,  7,  3,  6,  6,  7, 10,  6,  6,  9,  6,  5,  9,  7,  4,\n",
       "        10,  5],\n",
       "       [ 4,  6,  0,  3,  5,  5,  4,  0,  1,  3,  1,  3,  4,  0,  0,  2,\n",
       "         0,  1,  7,  1,  0,  5,  0,  5,  3,  4,  0,  0,  4,  0,  1,  3,\n",
       "         0,  3,  6,  7,  4,  3,  0,  7,  3,  5,  3,  6,  4,  5,  1,  2,\n",
       "         4,  0],\n",
       "       [ 5,  6,  1,  3,  6,  7,  5,  1,  3,  4,  3,  4,  5,  1,  0,  2,\n",
       "         1,  1,  7,  3,  2,  6,  1,  6,  4,  5,  1,  1,  5,  1,  1,  5,\n",
       "         2,  3,  7,  7,  5,  4,  1,  7,  4,  5,  4,  7,  5,  5,  0,  4,\n",
       "         6,  1],\n",
       "       [ 8,  8,  5, 10,  5,  4,  8,  7,  6,  7,  4,  9, 10,  5,  9,  4,\n",
       "         3,  2,  3,  2,  4, 10,  6,  4,  8,  4,  3,  8,  4,  8,  5,  8,\n",
       "         9,  6,  6,  2,  5,  5,  6, 10,  5,  5,  8,  5,  4,  9,  7,  2,\n",
       "        10,  3],\n",
       "       [ 7,  4,  7, 10,  4,  9,  7,  8,  5,  6,  5,  3,  4,  7,  9,  8,\n",
       "         6,  5, 10,  8,  9, 10,  7,  9,  7,  3,  9,  5,  6,  7,  6, 10,\n",
       "         4,  3,  9,  9,  6,  7,  3,  6,  4,  9,  3,  5,  7,  6,  8, 10,\n",
       "         6,  3],\n",
       "       [ 4,  2,  4,  6,  1,  7,  4,  5,  1,  4,  2,  0,  0,  3,  5,  4,\n",
       "         3,  1,  6,  4,  6,  7,  5,  6,  5,  1,  6,  1,  4,  4,  3,  6,\n",
       "         2,  0,  6,  6,  4,  3,  0,  2,  1,  6,  1,  1,  5,  3,  6,  6,\n",
       "         3,  1],\n",
       "       [ 2,  0,  6,  0,  2,  7,  7,  3,  6,  1,  3,  7,  3,  4,  0,  2,\n",
       "         0,  1,  2,  6,  0,  2,  2,  4,  1,  0,  6,  5,  6,  2,  4,  3,\n",
       "         3,  1,  1,  0,  1,  1,  4,  4,  3,  1,  0,  6,  1,  2,  7,  3,\n",
       "         1,  3],\n",
       "       [ 7,  6,  3,  6,  3,  2,  6,  6,  4,  5,  2,  7,  8,  3,  7,  2,\n",
       "         0,  0,  2,  1,  2,  8,  3,  0,  7,  3,  0,  7,  2,  6,  3,  6,\n",
       "         6,  5,  5,  1,  3,  3,  4,  7,  3,  3,  6,  4,  1,  7,  5,  1,\n",
       "         9,  2],\n",
       "       [ 6,  8,  2,  5,  8,  7,  4,  2,  4,  6,  4,  5,  6,  3,  1,  5,\n",
       "         2,  2,  8,  4,  3,  7,  2,  7,  4,  5,  2,  3,  7,  1,  4,  6,\n",
       "         3,  4,  7,  8,  5,  5,  1,  9,  6,  7,  6,  8,  5,  7,  2,  4,\n",
       "         6,  2]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "r_width = 50\n",
    "r_height = 500\n",
    "\n",
    "R, group = make_blobs(\n",
    "    n_samples=r_height,\n",
    "    n_features=r_width,\n",
    "    centers=5,\n",
    "    random_state=10\n",
    ")\n",
    "R = np.round((R-R.min())*10/(R.max()-R.min())).astype(int)\n",
    "\n",
    "# add bias for each object\n",
    "bias = np.random.randint(-2,3, [R.shape[0], 1])\n",
    "R = R + bias\n",
    "# sometimes bias can lead to ratings\n",
    "R = np.where(R<0, 0, R)\n",
    "R = np.where(R>10, 10, R)\n",
    "R[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add750b8-71c9-4920-bf4b-4959fbb600b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>relevant</th>\n",
       "      <th>random_predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object</th>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.397484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.270233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.598170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.709187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <th>24</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.754604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rank  relevant  random_predict\n",
       "object item                                \n",
       "440    47       2         0        0.975159\n",
       "283    2        3         0        0.229527\n",
       "396    33       0         0        0.397484\n",
       "14     6        5         0        0.270233\n",
       "198    15       5         0        0.598170\n",
       "20     33       1         0        0.709187\n",
       "422    24       9         1        0.814357\n",
       "267    4        2         0        0.505066\n",
       "408    25       0         0        0.244018\n",
       "99     44       3         0        0.754604"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "R_frame = pd.Series(\n",
    "    R.ravel(),\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            (j,i)\n",
    "            for j in np.arange(R.shape[0]) \n",
    "            for i in np.arange(R.shape[1])\n",
    "        ],\n",
    "        names = [\"object\", \"item\"]\n",
    "    ),\n",
    "    name = \"rank\"\n",
    ").to_frame()\n",
    "\n",
    "R_frame[\"relevant\"] = (R_frame[\"rank\"] > 5).astype(\"int\")\n",
    "R_frame[\"random_predict\"] = np.random.rand(R_frame.shape[0])\n",
    "R_frame.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80746516-5d9d-4346-9e1d-70ed1f5bde68",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_fr_train, R_fr_test = train_test_split(\n",
    "    R_frame, \n",
    "    train_size=0.8, \n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "# preparing test/train samples representation as\n",
    "# as user/item matrix\n",
    "R_mat_train = pd.DataFrame(\n",
    "    R_fr_train[\"rank\"].unstack(),\n",
    "    columns = R_frame.index.get_level_values(1).unique()\n",
    ")\n",
    "R_mat_test = pd.DataFrame(\n",
    "    R_fr_test[\"rank\"].unstack(),\n",
    "    columns = R_frame.index.get_level_values(1).unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5025db-e22b-4460-adc2-e102238172f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision@3': 0.3713333333333333,\n",
       " 'recall@3': 0.3102086885336885,\n",
       " 'ndcg@3': 0.4036283432588485}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    \"precision@3\", \n",
    "    \"recall@3\", \n",
    "    \"ndcg@3\"\n",
    "]\n",
    "R_fr_test[[\"object_str\", \"item_str\"]] = \\\n",
    "    R_fr_test.index.to_frame()[[\"object\", \"item\"]].astype(\"str\")\n",
    "\n",
    "qrels = Qrels.from_df(\n",
    "    df=R_fr_test.reset_index(),\n",
    "    q_id_col=\"object_str\", \n",
    "    doc_id_col=\"item_str\",\n",
    "    score_col=\"relevant\"\n",
    ")\n",
    "\n",
    "random_run = Run.from_df(\n",
    "    df=R_fr_test.reset_index(),\n",
    "    q_id_col=\"object_str\",\n",
    "    doc_id_col=\"item_str\",\n",
    "    score_col=\"random_predict\"\n",
    ")\n",
    "\n",
    "evaluate(\n",
    "    qrels, \n",
    "    random_run, \n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0bab9b-e3d6-41e6-9b3a-5ae3d46f349e",
   "metadata": {},
   "source": [
    "## surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf75fe5-b408-45db-83dc-fcf84f73db4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(\n",
    "    rating_scale=(\n",
    "        R.min().min(), R.max().max()\n",
    "    )\n",
    ")\n",
    "train_set = Dataset.load_from_df(\n",
    "    df=R_fr_train[\"rank\"].reset_index(), \n",
    "    reader=reader\n",
    ").build_full_trainset()\n",
    "algo = KNNWithMeans().fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1885f73-f692-45c6-bbc0-11ece768b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_fr_test[\"surpr_predict\"] = [\n",
    "    algo.predict(uid=uid, iid=iid).est \n",
    "    for uid, iid in R_fr_test.index\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "377add8e-cc46-4dff-ad3e-2b9dda5cd967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.414035940075337"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(\n",
    "    R_fr_test[\"rank\"],\n",
    "    R_fr_test[\"surpr_predict\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4358d656-0f38-4d26-8155-4577beb2dc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision@3': 0.7666666666666667,\n",
       " 'recall@3': 0.7254612137862139,\n",
       " 'ndcg@3': 0.9273804112635808}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_run = Run.from_df(\n",
    "    df=R_fr_test.reset_index(),\n",
    "    q_id_col=\"object_str\",\n",
    "    doc_id_col=\"item_str\",\n",
    "    score_col=\"surpr_predict\"\n",
    ")\n",
    "evaluate(\n",
    "    qrels, \n",
    "    surprise_run, \n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1407bce-c8fd-4e0c-b845-69724457fbf0",
   "metadata": {},
   "source": [
    "## Similarity measure\n",
    "\n",
    "**Note** Many sources use difference instead of similarity, but similarity is the inverse of difference, so you can search not for items that have the smallest difference, but for items that have the strongest similarity.\n",
    "\n",
    "We need a method to estimate how close the objects are to each other. The following cell defines such a function - it implements Pearson's correlation coefficient, which can solve some problems related to the RecSys domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75e15af4-4a22-4817-9958-f362c5a1d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(\n",
    "        a : np.ndarray,\n",
    "        b : np.ndarray\n",
    "        ) -> float:\n",
    "    '''\n",
    "    Pearson correlation coefficient modified\n",
    "    for our requirements. In particular, empty \n",
    "    handling\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : (N,) np.ndarray\n",
    "        input array;\n",
    "    b : (N, ) np.ndarray\n",
    "        input array;\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    out : float\n",
    "        The Pearson correlation coefficient is \n",
    "        computed using only the common items \n",
    "        for both arrays. If it's not possible \n",
    "        to compute the coefficient, it returns 0, \n",
    "        indicating neutral similarity.\n",
    "        The coefficient is a number ranging from -1 to 1.\n",
    "    '''\n",
    "    cond = ~(np.isnan(a) | np.isnan(b))\n",
    "    # in case if there are only two\n",
    "    # observations it's impossible\n",
    "    # to compute coorrelation coeficient\n",
    "    if sum(cond) <=1:\n",
    "        return 0.\n",
    "\n",
    "    sub_a = a[cond]\n",
    "    sub_b = b[cond]\n",
    "    \n",
    "    variation_a = (sub_a - sub_a.mean())\n",
    "    variation_b = (sub_b - sub_b.mean())\n",
    "\n",
    "    # to compute pirson correlation coefficient\n",
    "    # all variables should have some variation\n",
    "    if (variation_a==0).all() or (variation_b==0).all():\n",
    "        return 0.\n",
    "    \n",
    "    cov = (variation_a*variation_b).sum()\n",
    "    return cov/np.sqrt(\n",
    "        (variation_a**2).sum()*(variation_b**2).sum()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a5e32-0863-4434-a0e4-27ef78904183",
   "metadata": {},
   "source": [
    "Here are some cases where this function has been used and the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d0eab8f-2c6e-49ff-92aa-6f5b7801c71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correlation - 1.0\n",
      "Total correlation with empty - 1.0\n",
      "Constant variable - 0.0\n",
      "Not enough common elements - 0.0\n"
     ]
    }
   ],
   "source": [
    "result = correlation(\n",
    "    np.array([0,1,2,3,4]),\n",
    "    np.array([5,6,7,8,9])\n",
    ")\n",
    "print(\"Total correlation -\", result)\n",
    "result = correlation(\n",
    "    np.array([np.NaN, 1, 2, np.NaN]),\n",
    "    np.array([10, 10, 20, np.NaN])\n",
    ")\n",
    "print(\"Total correlation with empty -\", result)\n",
    "result = correlation(\n",
    "    np.array([1,1,1,1]),\n",
    "    np.array([3,2,1,2])\n",
    ")\n",
    "print(\"Constant variable -\", result)\n",
    "result = correlation(\n",
    "    np.array([np.NaN, 2, np.NaN, 3]),\n",
    "    np.array([1, np.NaN, 10, np.NaN])\n",
    ")\n",
    "print(\"Not enough common elements -\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed269af5-fe23-488c-97df-e76e4bc339c6",
   "metadata": {},
   "source": [
    "## Prediction function\n",
    "\n",
    "We need methods to create predictions based on results of the previous steps. The following cell realises the classical formula for generating predicsts based on collaboration:\n",
    "\n",
    "$$\\frac{(\\sum_{i}r_{ij}-\\overline{r_i})sim_i}{\\sum_i{|sim_i|}}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $r_{ij}$  - relevance of the $j$-th item for the $i$-th user of the collaboration.\n",
    "- $\\overline{r_i}$ - average relevance of the $i$-th user.\n",
    "- $sim_i$ similarity of the $i$-th object of the collaboration to the object for which we are making a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d79151fa-223e-4b92-bbf2-0f7f86bc6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_prediction(\n",
    "        collaboration : np.ndarray,\n",
    "        similarities : np.ndarray\n",
    "        ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Basic function for creating prediction.\n",
    "    Uses formula\n",
    "    \\frac{(\\sum_{i}x_{ij}-\\overline{x_i})sim_i}{\\sum_i{|sim_i|}}.\n",
    "    \n",
    "    items that have no observable preferences \n",
    "    for any user in the collation will simply \n",
    "    be omitted from the result;.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    collaboration : np.ndarray (\n",
    "        <users number>, \n",
    "        <games number>\n",
    "        )\n",
    "        relevances matrix for collaboration;\n",
    "    relevances : np.ndarray (<items number>)\n",
    "        relavences of the user under consdieration;\n",
    "    similarities : np.ndarray (<observations number>)\n",
    "        similarities of the users from \n",
    "        collaboration to user under consideration.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : np.ndarray(<items number>)\n",
    "        scores of the items under consideration.\n",
    "    \"\"\"\n",
    "    users_mean = np.nanmean(collaboration, axis=1, keepdims=1)\n",
    "    weighed_collab = (collaboration - users_mean)*similarities[:, np.newaxis]\n",
    "    res = np.nansum(weighed_collab, axis=0)/np.abs(similarities).sum()\n",
    "    \n",
    "    # items that have not been played by \n",
    "    # any of the users should have nan\n",
    "    is_empty = np.isnan(collaboration).all(axis=0)\n",
    "    res[is_empty] = np.NaN\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9379293-01ef-412e-bc38-327abf705158",
   "metadata": {},
   "source": [
    "Consider how it works.\n",
    "\n",
    "We will consider collaborations that have a matrix of relevance:\n",
    "\n",
    "$$P_u=\\left( \\begin{array} \\\\\n",
    "2,7,9,- \\\\\n",
    "0,-,3,-\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "And estimations of similarity:\n",
    "\n",
    "$$\n",
    "\\overline{sim} = \n",
    "\\left( \n",
    "\\begin{array}\\\\\n",
    "0.7, \\\\\n",
    "0.6\n",
    "\\end{array} \n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87af2e3-72b7-42c0-befd-01b911b54ad9",
   "metadata": {},
   "source": [
    "The average relevance of the users in the collaboration will take shape:\n",
    "\n",
    "$$\\overline{P_u}= \n",
    "\\left(\n",
    "\\begin{array}\\\\\n",
    "6\\\\\n",
    "1.5\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Sum of similarities:\n",
    "\n",
    "$$\\sum_i \\left|sim_i\\right|=0.7+0.6=1.3$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e999c5d1-3fbb-495a-bde6-3cb63015770b",
   "metadata": {},
   "source": [
    "So we finally can compute estimated relevances for user with this collaboration:\n",
    "\n",
    "$$\\left( \\frac{(2-6)0.7 + (0-1.5)0.6}{1.3}, \\frac{(7-6)0.7}{1.3}, \\frac{(9-6)0.7 + (3-1.5)0.6}{1.5}, - \\right)=$$\n",
    "$$=\\left(-2.8461,0.5384,-2.3077, - \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a4355a-2cee-466a-b9b6-185e44027e23",
   "metadata": {},
   "source": [
    "Now let's try to apply it to the same numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "413ba75c-cde2-4d7c-98e8-221ae9119dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.84615385,  0.53846154,  2.30769231,         nan])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collaboration = np.array([\n",
    "    [2,7,9, np.NaN],\n",
    "    [0,np.NaN,3, np.NaN]\n",
    "])\n",
    "similarities = np.array([0.7,0.6])\n",
    "\n",
    "basic_prediction(\n",
    "    collaboration=collaboration,\n",
    "    similarities=similarities\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa1dcf1-e48e-49e5-80a5-ab438075e17d",
   "metadata": {},
   "source": [
    "## Collaborative filter\n",
    "\n",
    "Finally, consider a class that implements such an algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9a73934-efc6-43fd-b113-702cdf6d50f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFilter:\n",
    "    \"\"\"\n",
    "    Сlass implements collaborative filtering based \n",
    "    on nearest neighbours.It uses information about \n",
    "    previous relevancies, we will call them \n",
    "    \"fit relevancies\", to estimate relevancies for \n",
    "    some new users, we will call them \"predict relevancies\".\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    similarity : Callable[[np.ndarray, np.ndarray], float]\n",
    "        Similarity calculation function\n",
    "        to find collaboration;\n",
    "    prediction : Callable[[np.ndarray, np.ndarray]\n",
    "        Function that predicts scores for all items\n",
    "        available in train sample based on passed\n",
    "        collaboration;\n",
    "    sim_threshold : float = -np.inf\n",
    "        Tresholld that will be used. Objects that have\n",
    "        distance value is higher are not allowed to pass;\n",
    "    n_nearest : int = 1000\n",
    "        Maximum number of rows that can be\n",
    "        included to the collaboration.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            similarity : Callable[[np.ndarray, np.ndarray], float] = correlation,\n",
    "            prediction : Callable[[np.ndarray, np.ndarray], float] = basic_prediction,\n",
    "            sim_threshold : float = -np.inf,\n",
    "            n_nearest : int = 1000\n",
    "            ):\n",
    "        self.similarity = similarity\n",
    "        self.prediction = prediction\n",
    "        self.sim_threshold = sim_threshold\n",
    "        self.n_nearest = n_nearest\n",
    "        \n",
    "    \n",
    "    def fit(self, X:Union[np.ndarray, pd.DataFrame]):\n",
    "        '''\n",
    "        Remember the train sample.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray(\n",
    "            <users number>,\n",
    "            <items number>\n",
    "        )\n",
    "            Relevances matrix;\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : CollaborativeFilter\n",
    "            Model instance.\n",
    "        '''\n",
    "        self.X=np.array(X)\n",
    "        return self\n",
    "\n",
    "    def get_similarities(self, X:np.ndarray):\n",
    "        '''\n",
    "        Get similarities to the object for the \n",
    "        selected set of rows. Here, we use \n",
    "        information about the relevances of \n",
    "        users from the training sample and users \n",
    "        for which we need to create predictions. \n",
    "        We will use the terms \"fit users\" and \"predict users\" \n",
    "        accordingly for these terms.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray (\n",
    "            <users numer>, \n",
    "            <number of items>)\n",
    "            Fit relevancies;\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : np.ndarray (\n",
    "            <users number in fit relevacies>, \n",
    "            <users number in predict relevacies>\n",
    "            )\n",
    "            array where each element is similarity\n",
    "            between i-th fit user and j-th predict\n",
    "            user.\n",
    "        '''\n",
    "        return np.apply_along_axis(\n",
    "            func1d=lambda history_row: np.apply_along_axis(\n",
    "                func1d=(\n",
    "                    lambda predict_row: \n",
    "                    self.similarity(history_row, predict_row)\n",
    "                ),\n",
    "                arr=X, axis=1\n",
    "            ), \n",
    "            arr=self.X, axis=1\n",
    "        )\n",
    "    \n",
    "\n",
    "    def get_collaborations(self, X:np.ndarray) -> list:\n",
    "        '''\n",
    "        Get collaboration for given set predict \n",
    "        relevancies.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array (<users number>, <items number>)\n",
    "            Observed relevance of users for \n",
    "            whom we are reporting.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        out : list\n",
    "            where each element is collaboration \n",
    "            for the corresponding element of X\n",
    "        '''\n",
    "        # get similarities between predictions\n",
    "        # relevances and fit relevances\n",
    "        similarities = self.get_similarities(X=X)\n",
    "        # search vectors of similarities for \n",
    "        # different users and form collaborations \n",
    "        # for them\n",
    "        result = []\n",
    "        for j in range(similarities.shape[1]):\n",
    "            threshold_mask = (similarities[:,j] > self.sim_threshold)\n",
    "            order = np.argsort(similarities[threshold_mask,j])\n",
    "            result.append(\n",
    "                self.X[threshold_mask][order][-1:-(self.n_nearest+1):-1]\n",
    "            )\n",
    "        return result\n",
    "\n",
    "    def predict(self, X:np.ndarray)->np.ndarray:\n",
    "        '''\n",
    "        Получить предсказания для \n",
    "        пользователей с заданными предпочтениями\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray (<количетсво пользователей>, <количество игр>)\n",
    "            матрица, которая описывает предпочтения\n",
    "            пользователей для которых надо сформировать\n",
    "            предсказание;\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : np.ndarray\n",
    "            np.ndarray (<количество полльзователей>, <количество игр>)\n",
    "            предсказания для заданных пользователей.\n",
    "        '''\n",
    "        if X.shape[1] != self.X.shape[1]:\n",
    "            raise ValueError(\n",
    "                \"Количества игр в обучающем наборе данных \"\n",
    "                \"и наборе для предсказания не совпадают.\"\n",
    "                )\n",
    "        \n",
    "        collaborations = self.get_collaborations(X)\n",
    "        return np.array([\n",
    "            self.prediction(collab)\n",
    "            for collab in collaborations\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7561cdaa-e138-4a79-a006-b5450e9ad282",
   "metadata": {},
   "source": [
    "### Get similarities\n",
    "\n",
    "Each row from the training must be compared with all prediction row via similarity fuinction passed to the constructor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a95dc1-2ebb-4d2c-8ef5-aa9fa63a7dcf",
   "metadata": {},
   "source": [
    "Here's an example that does only element-wise concatenation instead of similarity - so we can see that we'll have all combinations of raws in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a1c0fa1-efad-423b-bbd8-0e4bafb596b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<text style='font-size:20px'>Raw output</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([['11h_11p|12h_12p', '11h_21p|12h_22p'],\n",
       "       ['21h_11p|22h_12p', '21h_21p|22h_22p'],\n",
       "       ['31h_11p|32h_12p', '31h_21p|32h_22p']], dtype='<U15')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style='font-size:20px'>Interpretation</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history 1, predictions 1\n",
      "11h_11p|12h_12p\n",
      "history 1, predictions 2\n",
      "11h_21p|12h_22p\n",
      "history 2, predictions 1\n",
      "21h_11p|22h_12p\n",
      "history 2, predictions 2\n",
      "21h_21p|22h_22p\n",
      "history 3, predictions 1\n",
      "31h_11p|32h_12p\n",
      "history 3, predictions 2\n",
      "31h_21p|32h_22p\n"
     ]
    }
   ],
   "source": [
    "# history observations\n",
    "history = np.array([\n",
    "    [\"11h\", \"12h\"],\n",
    "    [\"21h\", \"22h\"],\n",
    "    [\"31h\", \"32h\"]\n",
    "])\n",
    "# observations that we'll\n",
    "# use for predicitons\n",
    "predict = np.array([\n",
    "    [\"11p\", \"12p\"],\n",
    "    [\"21p\", \"22p\"]\n",
    "])\n",
    "\n",
    "cf = CollaborativeFilter(\n",
    "    similarity=lambda a,b: \"|\".join([a+\"_\"+b for a,b in zip(a,b)])\n",
    ")\n",
    "cf.fit(history)\n",
    "ans = cf.get_similarities(predict)\n",
    "\n",
    "display(HTML(header_pattern.format(\"Raw output\")))\n",
    "display(ans)\n",
    "\n",
    "display(HTML(header_pattern.format(\"Interpretation\")))\n",
    "for hist_i, hist in enumerate(ans):\n",
    "    for pred_i, pred in enumerate(hist):\n",
    "        print(f\"history {hist_i + 1}, predictions {pred_i + 1}\")\n",
    "        print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffd5d1-f288-45aa-9699-cd0a1ce3da45",
   "metadata": {},
   "source": [
    "So as a result we'll have the matrix $[sim_{ij}]$ similarity of the $i$-th fit user to the $j$-th prediction user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c00feb-d562-448c-80a8-b984a3683688",
   "metadata": {},
   "source": [
    "### Get collaboration\n",
    "\n",
    "This method returns a subset of the fit array for each row in the array that requires prediction. For testing consider really specific example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4128d-0d1e-4343-8c7b-3da1bf36ad97",
   "metadata": {},
   "source": [
    "We will use the similarity function:\n",
    "\n",
    "$$Sim(\\overline{a},\\overline{b})=\\left(\\sum_{i=1}^m a_i\\right)\\left(\\sum_{i=1}^n b_i\\right)$$\n",
    "\n",
    "If a row from the fit dataset and a row from the predict dataset have a different sign for their sum, they will be assigned a negative \"similarity\" value. Conversely, if they have the same sign, they will be assigned a positive \"similarity\" value. So we can have two different collaborations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b2ab0-ad31-451a-9eed-db77864819e7",
   "metadata": {},
   "source": [
    "Let's take a concrete example with the relevance matrix $R_{train}$ and the vector of sums of its rows $S_{train}$:\n",
    "$$R_{train}=\n",
    "\\left(\n",
    "\\begin{array}\\\\\n",
    "-1&0&0\\\\\n",
    "1&2&1\\\\\n",
    "3&2&2\\\\\n",
    "1&1&0\n",
    "\\end{array}\n",
    "\\right);\n",
    "S_{train}=\\left(\n",
    "\\begin{array}\\\\\n",
    "-1\\\\4\\\\7\\\\2\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056eda2d-371a-4bf4-ad9b-308ff493a38c",
   "metadata": {},
   "source": [
    "Let's define the relevance of the users for whom we need to make predictions as $R_{predict}$, and their corresponding sums as $S_{predict}$:\n",
    "\n",
    "$$R_{predict} =\\left(\n",
    "\\begin{array}\\\\\n",
    "0&0&1\\\\\n",
    "0&0&-2\n",
    "\\end{array}\n",
    "\\right);\n",
    "S_{predict}=\\left(\n",
    "\\begin{array}\n",
    "\\\\1 \\\\ -2\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4097634f-b7b9-42e1-9fb9-6cdc0f7f07df",
   "metadata": {},
   "source": [
    "Finally we have similarities array like:\n",
    "\n",
    "$$Sim=\\left(\n",
    "\\begin{array}\\\\\n",
    "-1&2\\\\\n",
    "4&-8\\\\\n",
    "7&-14\\\\\n",
    "2&-4\n",
    "\\end{array}\n",
    "\\right)$$\n",
    "\n",
    "For the first user in the predictions array, the best collaborators will be placed at the top of the array, while for the second user, it will be the opposite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944cf8eb-0297-4782-98cc-d46885c01b7d",
   "metadata": {},
   "source": [
    "Now, assuming we have chosen a similarity threshold of $Sim' = 0$ and decided to consider no more than 2 of the most similar objects, the resulting collaborations $P_i$ for $i$-th user will be as follows:\n",
    "\n",
    "$$P_1=\\left(\n",
    "\\begin{array}\\\\\n",
    "3&2&2\\\\\n",
    "1&2&1\n",
    "\\end{array}\n",
    "\\right).$$\n",
    "\n",
    "$$\n",
    "P_2=\\left(\n",
    "\\begin{array}\\\\\n",
    "-1&0&0\n",
    "\\end{array}\n",
    "\\right).\n",
    "$$\n",
    "\n",
    "**Note** for convenience, I always sort collaborations by decreasing similarity, but it's not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ae3698-009b-40fa-a9c0-6ac32b964333",
   "metadata": {},
   "source": [
    "And finally, lets display it on the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ff0e8fa-b195-40cb-ac66-1e0f78cd9b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[3, 2, 2],\n",
       "        [1, 2, 1]]),\n",
       " array([[-1,  0,  0]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collaborative_filter = CollaborativeFilter(\n",
    "    similarity=lambda a,b: np.nansum(a)*np.nansum(b),\n",
    "    sim_threshold=0,\n",
    "    n_nearest=2\n",
    ")\n",
    "\n",
    "fit_relevances = np.array([\n",
    "    [-1,0,0],\n",
    "    [1,2,1],\n",
    "    [3,2,2],\n",
    "    [1,1,0]\n",
    "])\n",
    "predict_relevances = np.array([\n",
    "    [0,0,1],\n",
    "    [0,0,-2]\n",
    "])\n",
    "\n",
    "collaborative_filter.fit(fit_relevances)\n",
    "collaborative_filter.get_collaborations(predict_relevances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de15c4b-15d1-4806-bfcc-b34ed0fd5ccc",
   "metadata": {},
   "source": [
    "### Predict\n",
    "\n",
    "Method that allows to get estimations from \n",
    "\n",
    "Continue the example from the 'Get collaboration' section so that we have collaborations:\n",
    "\n",
    "$$P_1=\\left(\n",
    "\\begin{array}\\\\\n",
    "3&2&2\\\\\n",
    "1&2&1\n",
    "\\end{array}\n",
    "\\right).$$\n",
    "\n",
    "$$\n",
    "P_2=\\left(\n",
    "\\begin{array}\\\\\n",
    "-1&0&0\n",
    "\\end{array}\n",
    "\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3322356-dbb8-4335-a51e-6b05e021e446",
   "metadata": {},
   "source": [
    "For simplicity, we will use the sum of the collaboration columns as the prediction function. We should get:\n",
    "\n",
    "$$\\hat{R} =\n",
    "\\left(\n",
    "\\begin{array}\\\\\n",
    "4&4&3\\\\\n",
    "-1&0&0\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33b5f0cf-ce48-46f5-aa79-e99efc3b5a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  4,  3],\n",
       "       [-1,  0,  0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collaborative_filter = CollaborativeFilter(\n",
    "    similarity=lambda a,b: np.nansum(a)*np.nansum(b),\n",
    "    prediction=lambda X: np.sum(X, axis=0),\n",
    "    sim_threshold=0,\n",
    "    n_nearest=2\n",
    ")\n",
    "\n",
    "fit_relevances = np.array([\n",
    "    [-1,0,0],\n",
    "    [1,2,1],\n",
    "    [3,2,2],\n",
    "    [1,1,0]\n",
    "])\n",
    "predict_relevances = np.array([\n",
    "    [0,0,1],\n",
    "    [0,0,-2]\n",
    "])\n",
    "\n",
    "collaborative_filter.fit(fit_relevances)\n",
    "collaborative_filter.predict(predict_relevances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
