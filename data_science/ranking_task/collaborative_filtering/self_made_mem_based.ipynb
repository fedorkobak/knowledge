{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd07a3cd-0d99-4461-b8ed-87b42d90f9e5",
   "metadata": {},
   "source": [
    "# Selfmade memory based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcffa71-b2e6-443d-9b83-a1aea7b6108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from scipy.spatial.distance import (\n",
    "    correlation as orig_correlation,\n",
    "    cosine as orig_cosine\n",
    ")\n",
    "from surprise import KNNWithMeans, Dataset, Reader\n",
    "from ranx import Qrels, Run, evaluate\n",
    "\n",
    "from typing import Union, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9cc818-82b1-416e-8165-35464cb59575",
   "metadata": {},
   "source": [
    "## Task generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801a39a2-f654-448f-aa2d-d7a047f97d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7,  2,  7,  4,  7,  3,  7,  3,  1],\n",
       "       [ 8,  5,  7,  9,  6,  7,  8,  7,  7,  8],\n",
       "       [ 3,  6,  1,  7,  2,  6,  1,  6,  2,  0],\n",
       "       [ 6,  0,  6,  6,  4,  1,  3,  6,  2,  0],\n",
       "       [ 8,  9,  2,  7,  9,  7,  8,  5,  9,  8],\n",
       "       [ 8,  9,  4, 10,  5,  8,  5, 10,  6,  4],\n",
       "       [ 7,  4,  8,  2,  1,  3,  1,  6,  0,  5],\n",
       "       [ 3,  0,  2,  5,  3,  3,  4,  3,  5,  4],\n",
       "       [ 7,  3,  8,  2,  1,  3,  1,  7,  1,  5],\n",
       "       [ 7,  8,  1,  5,  7,  6,  7,  3,  9,  7]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "r_width = 10\n",
    "r_height = 500\n",
    "\n",
    "R, group = make_blobs(\n",
    "    n_samples=r_height,\n",
    "    n_features=r_width,\n",
    "    centers=5,\n",
    "    random_state=10\n",
    ")\n",
    "R = np.round((R-R.min())*10/(R.max()-R.min())).astype(int)\n",
    "\n",
    "# add bias for each object\n",
    "bias = np.random.randint(-2,3, [R.shape[0], 1])\n",
    "R = R + bias\n",
    "# sometimes bias can lead to ratings\n",
    "R = np.where(R<0, 0, R)\n",
    "R = np.where(R>10, 10, R)\n",
    "R[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add750b8-71c9-4920-bf4b-4959fbb600b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>relevant</th>\n",
       "      <th>random_predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object</th>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.204547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.501746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.790650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.507431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.794765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.169455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rank  relevant  random_predict\n",
       "object item                                \n",
       "38     7        6         1        0.037330\n",
       "126    4        6         1        0.120591\n",
       "147    3        8         1        0.285638\n",
       "215    2        3         0        0.204547\n",
       "44     5        3         0        0.501746\n",
       "264    3       10         1        0.790650\n",
       "401    7        8         1        0.507431\n",
       "233    0        6         1        0.794765\n",
       "361    9        7         1        0.169455\n",
       "312    2        6         1        0.181615"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "R_frame = pd.Series(\n",
    "    R.ravel(),\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            (j,i) \n",
    "            for j in np.arange(R.shape[0]) \n",
    "            for i in np.arange(R.shape[1])\n",
    "        ],\n",
    "        names = [\"object\", \"item\"]\n",
    "    ),\n",
    "    name = \"rank\"\n",
    ").to_frame()\n",
    "\n",
    "R_frame[\"relevant\"] = (R_frame[\"rank\"] > 5).astype(\"int\")\n",
    "R_frame[\"random_predict\"] = np.random.rand(R_frame.shape[0])\n",
    "R_frame.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80746516-5d9d-4346-9e1d-70ed1f5bde68",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_fr_train, R_fr_test = train_test_split(\n",
    "    R_frame, \n",
    "    train_size=0.8, \n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "# preparing test/train samples representation as\n",
    "# as user/item matrix\n",
    "R_mat_train = pd.DataFrame(\n",
    "    R_fr_train[\"rank\"].unstack(),\n",
    "    columns = R_frame.index.get_level_values(1).unique()\n",
    ")\n",
    "R_mat_test = pd.DataFrame(\n",
    "    R_fr_test[\"rank\"].unstack(),\n",
    "    columns = R_frame.index.get_level_values(1).unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5025db-e22b-4460-adc2-e102238172f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision@3': 0.311804008908686,\n",
       " 'recall@3': 0.6076837416481069,\n",
       " 'ndcg@3': 0.5401559043967112}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    \"precision@3\", \n",
    "    \"recall@3\", \n",
    "    \"ndcg@3\"\n",
    "]\n",
    "R_fr_test[[\"object_str\", \"item_str\"]] = \\\n",
    "    R_fr_test.index.to_frame()[[\"object\", \"item\"]].astype(\"str\")\n",
    "\n",
    "qrels = Qrels.from_df(\n",
    "    df=R_fr_test.reset_index(),\n",
    "    q_id_col=\"object_str\", \n",
    "    doc_id_col=\"item_str\",\n",
    "    score_col=\"relevant\"\n",
    ")\n",
    "\n",
    "random_run = Run.from_df(\n",
    "    df=R_fr_test.reset_index(),\n",
    "    q_id_col=\"object_str\",\n",
    "    doc_id_col=\"item_str\",\n",
    "    score_col=\"random_predict\"\n",
    ")\n",
    "\n",
    "evaluate(\n",
    "    qrels, \n",
    "    random_run, \n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0bab9b-e3d6-41e6-9b3a-5ae3d46f349e",
   "metadata": {},
   "source": [
    "## surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf75fe5-b408-45db-83dc-fcf84f73db4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(\n",
    "    rating_scale=(\n",
    "        R.min().min(), R.max().max()\n",
    "    )\n",
    ")\n",
    "train_set = Dataset.load_from_df(\n",
    "    df=R_fr_train[\"rank\"].reset_index(), \n",
    "    reader=reader\n",
    ").build_full_trainset()\n",
    "algo = KNNWithMeans().fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1885f73-f692-45c6-bbc0-11ece768b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_fr_test[\"surpr_predict\"] = [\n",
    "    algo.predict(uid=uid, iid=iid).est \n",
    "    for uid, iid in R_fr_test.index\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "377add8e-cc46-4dff-ad3e-2b9dda5cd967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6451729505731039"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(\n",
    "    R_fr_test[\"rank\"],\n",
    "    R_fr_test[\"surpr_predict\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4358d656-0f38-4d26-8155-4577beb2dc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision@3': 0.3266518188567186,\n",
       " 'recall@3': 0.6303266518188567,\n",
       " 'ndcg@3': 0.6346257036375941}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_run = Run.from_df(\n",
    "    df=R_fr_test.reset_index(),\n",
    "    q_id_col=\"object_str\",\n",
    "    doc_id_col=\"item_str\",\n",
    "    score_col=\"surpr_predict\"\n",
    ")\n",
    "evaluate(\n",
    "    qrels, \n",
    "    surprise_run, \n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd51255-db9c-4abd-aaf0-02205cff7a8c",
   "metadata": {},
   "source": [
    "## Selfmade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1407bce-c8fd-4e0c-b845-69724457fbf0",
   "metadata": {},
   "source": [
    "### Similarity measure\n",
    "\n",
    "**Note** Many sources use difference instead of similarity, but similarity is the inverse of difference, so you can search not for items that have the smallest difference, but for items that have the strongest similarity.\n",
    "\n",
    "We need a method to estimate how close the objects are to each other. The following cell defines such a function - it implements Pearson's correlation coefficient, which can solve some problems related to the RecSys domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75e15af4-4a22-4817-9958-f362c5a1d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(\n",
    "        a : np.ndarray,\n",
    "        b : np.ndarray\n",
    "        ) -> float:\n",
    "    '''\n",
    "    Pearson correlation coefficient modified\n",
    "    for our requirements. In particular, empty \n",
    "    handling\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : (N,) np.ndarray\n",
    "        input array;\n",
    "    b : (N, ) np.ndarray\n",
    "        input array;\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    out : float\n",
    "        The Pearson correlation coefficient is \n",
    "        computed using only the common items \n",
    "        for both arrays. If it's not possible \n",
    "        to compute the coefficient, it returns 0, \n",
    "        indicating neutral similarity.\n",
    "        The coefficient is a number ranging from -1 to 1.\n",
    "    '''\n",
    "    cond = ~(np.isnan(a) | np.isnan(b))\n",
    "    # in case if there are only two\n",
    "    # observations it's impossible\n",
    "    # to compute coorrelation coeficient\n",
    "    # it's invalid case - so we return \n",
    "    # the biggest possible distance\n",
    "    if sum(cond) <=1:\n",
    "        return 0.\n",
    "\n",
    "    sub_a = a[cond]\n",
    "    sub_b = b[cond]\n",
    "    \n",
    "    variation_a = (sub_a - sub_a.mean())\n",
    "    variation_b = (sub_b - sub_b.mean())\n",
    "\n",
    "    # to compute pirson correlation coefficient\n",
    "    # all variables should have some variation\n",
    "    if (variation_a==0).all() or (variation_b==0).all():\n",
    "        return 0.\n",
    "    \n",
    "    cov = (variation_a*variation_b).sum()\n",
    "    return cov/np.sqrt(\n",
    "        (variation_a**2).sum()*(variation_b**2).sum()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a5e32-0863-4434-a0e4-27ef78904183",
   "metadata": {},
   "source": [
    "Here are some cases where this function has been used and the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d0eab8f-2c6e-49ff-92aa-6f5b7801c71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correlation - 1.0\n",
      "Total correlation with empty - 1.0\n",
      "Constant variable - 0.0\n",
      "Not enough common elements - 0.0\n"
     ]
    }
   ],
   "source": [
    "result = correlation(\n",
    "    np.array([0,1,2,3,4]),\n",
    "    np.array([5,6,7,8,9])\n",
    ")\n",
    "print(\"Total correlation -\", result)\n",
    "result = correlation(\n",
    "    np.array([np.NaN, 1, 2, np.NaN]),\n",
    "    np.array([10, 10, 20, np.NaN])\n",
    ")\n",
    "print(\"Total correlation with empty -\", result)\n",
    "result = correlation(\n",
    "    np.array([1,1,1,1]),\n",
    "    np.array([3,2,1,2])\n",
    ")\n",
    "print(\"Constant variable -\", result)\n",
    "result = correlation(\n",
    "    np.array([np.NaN, 2, np.NaN, 3]),\n",
    "    np.array([1, np.NaN, 10, np.NaN])\n",
    ")\n",
    "print(\"Not enough common elements -\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3a8e64c-97f8-4fbe-a7eb-66ea421a21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_prediction(\n",
    "        collaboration : np.ndarray,\n",
    "        similarities : np.ndarray\n",
    "        ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Базововая функция для формирования предсказания.\n",
    "    Использует формулу \n",
    "    \\frac{(\\sum_{i}x_{ij}-\\overline{x_i})sim_i}{\\sum_i{|sim_i|}}.\n",
    "    Игры, для которых ни один пользователь из коллаборации \n",
    "    не сделал предсказания, будут иметь пропуски в результатах.\n",
    "    Parameters\n",
    "    ----------\n",
    "    collaboration : np.ndarray (\n",
    "        <количество пользователей>, \n",
    "        <количество игр>\n",
    "        )\n",
    "        матрица предпочтений коллаборации;\n",
    "    relevances : np.ndarray (<количество игр>)\n",
    "        предпочтения рассматривамого пользователя;\n",
    "    similarities : np.ndarray (<количество наблюдений>)\n",
    "        похожести элементов;\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : np.ndarray(<количество игр>)\n",
    "        скоры наблюдаемых игр по которым их\n",
    "        можно отсортировать по предпочтительности.\n",
    "    \"\"\"\n",
    "    users_mean = np.nanmean(collaboration, axis=1, keepdims=1)\n",
    "    weighed_collab = (collaboration - users_mean)*similarities[:, np.newaxis]\n",
    "    res = np.nansum(weighed_collab, axis=0)/np.abs(similarities).sum()\n",
    "    \n",
    "    # те игры в которые не поиграл не один пользователь\n",
    "    # из коллаборации можно смело заменять на nan\n",
    "    is_empty = np.isnan(collaboration).all(axis=0)\n",
    "    res[is_empty] = np.NaN\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "class CollaborativeFilter:\n",
    "    \"\"\"\n",
    "    Класс для выполнения коллаборативной фильтрации \n",
    "    на основе ближайших соседей.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    similarity : Callable[[np.ndarray, np.ndarray], float]\n",
    "        Фунция для вычисления похожести между двумя\n",
    "        объектами;\n",
    "    prediction : Callable[[np.ndarray, np.ndarray]\n",
    "        Пороговое значение меры близости. Т.е. объекты у которых\n",
    "        значение дистации выше не пропускаются;\n",
    "    sim_threshold : float = -np.inf\n",
    "        Пороговое отсечение похожести, ниже которого\n",
    "        элементы не допусткаются в колаборации;\n",
    "    n_nearest : int = 1000\n",
    "        Максимальное количество наблюдений которые могут\n",
    "        быть взяты в коллаборацию.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            similarity : Callable[[np.ndarray, np.ndarray], float] = correlation,\n",
    "            prediction : Callable[[np.ndarray, np.ndarray], float] = basic_prediction,\n",
    "            sim_threshold : float = -np.inf,\n",
    "            n_nearest : int = 1000\n",
    "            ):\n",
    "        self.similarity = similarity\n",
    "        self.prediction = prediction\n",
    "        self.sim_threshold = sim_threshold\n",
    "        self.n_nearest = n_nearest\n",
    "        \n",
    "    \n",
    "    def fit(self, X:Union[np.ndarray, pd.DataFrame]):\n",
    "        '''\n",
    "        Запомнить обучающую выборку.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray (<количество клиентов>, <количество игр>)\n",
    "            Наблюдения за решевантностями пользователей;\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : CollaborativeFilter\n",
    "            сам объект модели.\n",
    "        '''\n",
    "        self.X=np.array(X)\n",
    "        return self\n",
    "\n",
    "    def get_similarities(self, X:np.ndarray):\n",
    "        '''\n",
    "        Получить предсказания расстояния до объекта\n",
    "        для заданного множества векторов предпочтений\n",
    "        пользователей.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray(<количетсво пользователей>, <количество игр>)\n",
    "            матрица, которая описывает предпочтения\n",
    "            пользователей для которых надо сформировать\n",
    "            предсказание;\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : np.ndarray (\n",
    "            <количетсво сохраненных пользователей>, \n",
    "            <количество пользователей для предсказания>\n",
    "            )\n",
    "            нассив где каждый элемент это дистанция\n",
    "            между i-м пользователем сохраненного набора\n",
    "            данных и j-м пользователем набора данных\n",
    "            для которого ведется предсказание.\n",
    "        '''\n",
    "        return np.apply_along_axis(\n",
    "            func1d=lambda history_row: np.apply_along_axis(\n",
    "                func1d=(\n",
    "                    lambda predict_row: \n",
    "                    self.similarity(history_row, predict_row)\n",
    "                ),\n",
    "                arr=X, axis=1\n",
    "            ), \n",
    "            arr=self.X, axis=1\n",
    "        )\n",
    "    \n",
    "\n",
    "    def get_collaborations(self, X:np.ndarray):\n",
    "        '''\n",
    "        Получить коллаборации для заданного набора наблюдений.\n",
    "        '''\n",
    "        similarities = self.get_similarities(X=X)\n",
    "        # перебираем столбики с похожестями пользователей\n",
    "        # для которых ведется предсказание и достаем нужные \n",
    "        # коллаборации\n",
    "        return np.apply_along_axis(\n",
    "            func1d=lambda user_sim: (\n",
    "                self.X[user_sim>self.sim_threshold,:][:self.n_nearest,:]\n",
    "            ),\n",
    "            axis=0, arr=similarities\n",
    "        )\n",
    "\n",
    "\n",
    "    def predict(self, X:np.ndarray)->np.ndarray:\n",
    "        '''\n",
    "        Получить предсказания для \n",
    "        пользователей с заданными предпочтениями\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray (<количетсво пользователей>, <количество игр>)\n",
    "            матрица, которая описывает предпочтения\n",
    "            пользователей для которых надо сформировать\n",
    "            предсказание;\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : np.ndarray\n",
    "            np.ndarray (<количество полльзователей>, <количество игр>)\n",
    "            предсказания для заданных пользователей.\n",
    "        '''\n",
    "        if X.shape[1] != self.X.shape[1]:\n",
    "            raise ValueError(\n",
    "                \"Количества игр в обучающем наборе данных \"\n",
    "                \"и наборе для предсказания не совпадают.\"\n",
    "                )\n",
    "        \n",
    "        similarities = self.get_similarities(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
