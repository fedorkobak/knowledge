{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurent layer\n",
    "\n",
    "This page explains the concept of a recurrent layer.\n",
    "\n",
    "The key idea is to create a mechanism where each input affects the processing and outcome of subsequent inputs.\n",
    "\n",
    "![](recurent_layer_files/recurent_schema.svg)\n",
    "\n",
    "Where RNN actually one layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strictly speaking, the deduction is as follows:  \n",
    "\n",
    "$$h_t = f(x_t W^T_1 + b_1 + h_{t-1} W^T_2 + b_2)$$  \n",
    "\n",
    "Where:  \n",
    "- $x_t$: input at the $t$-th step.  \n",
    "- $h_t$: state at the $t$-th step.  \n",
    "- $W_1$: weights associated with the input.  \n",
    "- $W_2$: weights associated with the state.  \n",
    "- $b_1$: bias associated with the input.  \n",
    "- $b_2$: bias associated with the state.  \n",
    "- $f$: activation function, typically a hyperbolic tangent.  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
