{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurent layer\n",
    "\n",
    "This page explains the concept of a recurrent layer.\n",
    "\n",
    "The key idea is to create a mechanism where each input affects the processing and outcome of subsequent inputs.\n",
    "\n",
    "![](recurent_layer_files/recurent_schema.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An RNN is essentially a single layer. At each step, it uses $h_{t-1}$, a special state vector from the previous step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strictly speaking, the deduction is as follows:  \n",
    "\n",
    "$$h_t = f(x_t W^T_1 + b_1 + h_{t-1} W^T_2 + b_2)$$  \n",
    "\n",
    "Where:  \n",
    "- $x_t$: input at the $t$-th step.  \n",
    "- $h_t$: vector that describes hidden state at the $t$-th step.  \n",
    "- $W_1$: weights associated with the input.  \n",
    "- $W_2$: weights associated with the state.  \n",
    "- $b_1$: bias associated with the input.  \n",
    "- $b_2$: bias associated with the state.  \n",
    "- $f$: activation function, typically a hyperbolic tangent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realization on python\n",
    "\n",
    "In this section, we will step by step implement the computations performed by a recurrent layer and compare them with `torch.nn.RNN` as the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_size = 10\n",
    "element_size = 5\n",
    "sequence_size = 15\n",
    "state_size = 3\n",
    "activation = torch.nn.Tanh()\n",
    "\n",
    "input_data = torch.rand(samples_size, sequence_size, element_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear = torch.nn.Linear(\n",
    "    in_features=element_size,\n",
    "    out_features=state_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_1 = torch.rand(state_size, element_size)\n",
    "b_1 = torch.rand(state_size)\n",
    "W_2 = torch.rand(state_size, state_size)\n",
    "b_2 = torch.rand(state_size)\n",
    "\n",
    "state = torch.zeros(samples_size, state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.1659, 3.3416, 2.9369],\n",
       "        [3.4290, 2.6908, 2.7988],\n",
       "        [2.7855, 2.2476, 2.2464],\n",
       "        [3.3770, 2.6954, 2.2828],\n",
       "        [3.6830, 2.9414, 2.7285],\n",
       "        [3.4822, 2.7814, 2.6768],\n",
       "        [4.2522, 3.3817, 3.1177],\n",
       "        [3.1929, 2.5440, 2.3744],\n",
       "        [3.6737, 2.9679, 3.2228],\n",
       "        [2.9061, 2.3930, 2.4780]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(input_data[:, 0, :] @ W_1.T) + b_1 + (state @ W_2.T) + b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [state]\n",
    "\n",
    "for i in range(input_data.shape[1]):\n",
    "    res = activation( \n",
    "        (input_data[:, i, :] @ W_1.T) + b_1\n",
    "        + (states[-1] @ W_2.T) + b_2\n",
    "    )\n",
    "    states.append(res)\n",
    "\n",
    "my_ans = torch.stack(states[1:]).permute((1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.RNN(element_size, state_size, batch_first=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    rnn.weight_ih_l0.copy_(W_1)\n",
    "    rnn.bias_ih_l0.copy_(b_1)\n",
    "    rnn.weight_hh_l0.copy_(W_2)\n",
    "    rnn.bias_hh_l0.copy_(b_2)\n",
    "\n",
    "    torch_ans = rnn(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(torch_ans[0], my_ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
