{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKNGHzK1-R4o"
   },
   "source": [
    "# Recurrent translations\n",
    "\n",
    "This notebook considers the solution of the translation task using recurrent layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T12:34:10.636157Z",
     "iopub.status.busy": "2024-12-08T12:34:10.635876Z",
     "iopub.status.idle": "2024-12-08T12:34:15.314008Z",
     "shell.execute_reply": "2024-12-08T12:34:15.313261Z",
     "shell.execute_reply.started": "2024-12-08T12:34:10.636089Z"
    },
    "id": "hQcqiP4P-R4t",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9SYzcLJ-R4u"
   },
   "source": [
    "## Data\n",
    "\n",
    "As an example, the English->Russian data set `tatoeda` is considered. [Tatoeda](https://tatoeba.org/en/) - collections of sentences and their translations. In particular, it's [hugging face implementation](https://huggingface.co/datasets/Helsinki-NLP/tatoeba) was used. The following cell loads data, transforms it into a more convenient format and displays some sentences from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-08T12:34:15.316645Z",
     "iopub.status.busy": "2024-12-08T12:34:15.315684Z",
     "iopub.status.idle": "2024-12-08T12:34:43.809260Z",
     "shell.execute_reply": "2024-12-08T12:34:43.808348Z",
     "shell.execute_reply.started": "2024-12-08T12:34:15.316601Z"
    },
    "id": "-gBA7tiJ-R4w",
    "outputId": "3f6cb108-b834-4513-f2c7-fbc8c8f3e2af",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"I won't ask you anything else today.\",\n",
       "  'Сегодня я тебя больше ни о чём не спрошу.'),\n",
       " ('It may freeze next week.', 'На следующей неделе могут быть заморозки.'),\n",
       " (\"Even though he apologized, I'm still furious.\",\n",
       "  'Несмотря на то, что он извинился, я все ещё в бешенстве.'),\n",
       " ('The police will get you to find the bullets.',\n",
       "  'Полиция вас заставит найти пули.'),\n",
       " ('Thanks for having explained to me at last why people take me for an idiot.',\n",
       "  'Спасибо за то, что наконец объяснили, почему люди принимают меня за идиота.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"tatoeba\", lang1=\"en\", lang2=\"ru\")\n",
    "dataset = [\n",
    "    (translation[\"en\"], translation[\"ru\"])\n",
    "    for translation in dataset[\"train\"][\"translation\"]\n",
    "]\n",
    "dataset[200:205]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell prepares the following:  \n",
    "- Service tokens.\n",
    "- Vocabulary. \n",
    "- Tokenization transformation.  \n",
    "- Mappings between tokens and indices (both directions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T12:34:43.810543Z",
     "iopub.status.busy": "2024-12-08T12:34:43.810266Z",
     "iopub.status.idle": "2024-12-08T12:34:45.165901Z",
     "shell.execute_reply": "2024-12-08T12:34:45.164954Z",
     "shell.execute_reply.started": "2024-12-08T12:34:43.810517Z"
    },
    "id": "4LR2EYTD-R4x",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Special tokens\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "# End of sentence\n",
    "EOS_TOKEN = \"<EOS>\"\n",
    "# Start of sentence\n",
    "SOS_TOKEN = \"<SOS>\"\n",
    "# Unknown\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "\n",
    "def tokenize(sentence: str) -> list[str]:\n",
    "    '''Tokinelattion of the given stirng  by words'''\n",
    "    return sentence.lower().split()\n",
    "\n",
    "EN_VOCAB = {PAD_TOKEN, EOS_TOKEN, SOS_TOKEN, UNK_TOKEN}\n",
    "RU_VOCAB = {PAD_TOKEN, EOS_TOKEN, SOS_TOKEN, UNK_TOKEN}\n",
    "for en, ru in dataset:\n",
    "    EN_VOCAB.update(tokenize(en))\n",
    "    RU_VOCAB.update(tokenize(ru))\n",
    "\n",
    "def create_mappings(vocab: set) -> tuple[dict[str, int], dict[int, str]]:\n",
    "    '''\n",
    "    Create mappings.\n",
    "    '''\n",
    "    word2int = {word: i for i, word in enumerate(vocab)}\n",
    "    int2word = {i: word for word, i in word2int.items()}\n",
    "    return word2int, int2word\n",
    "\n",
    "EN_WORD2INT, EN_INT2WORD = create_mappings(EN_VOCAB)\n",
    "RU_WORD2INT, RU_INT2WORD = create_mappings(RU_VOCAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `torch.utils.data.Dataset` is set up to iterate over sentence pairs, already transformed into tensors containing token indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-08T12:34:45.168041Z",
     "iopub.status.busy": "2024-12-08T12:34:45.167766Z",
     "iopub.status.idle": "2024-12-08T12:34:45.361844Z",
     "shell.execute_reply": "2024-12-08T12:34:45.361017Z",
     "shell.execute_reply.started": "2024-12-08T12:34:45.168016Z"
    },
    "id": "151t2z9S-R4y",
    "outputId": "01fd9e6d-1e0e-4776-bc93-b98d84b3798d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tensor_tokenize(\n",
    "    sentence: str,\n",
    "    word2int: dict[str, int],\n",
    "    device: torch.device = DEVICE\n",
    ") -> torch.Tensor:\n",
    "    '''Transform sentence into tensor with indeces of tokens.'''\n",
    "    return torch.tensor(\n",
    "        [\n",
    "            word2int.get(word, word2int[UNK_TOKEN])\n",
    "            for word in tokenize(sentence)\n",
    "        ]\n",
    "        + [word2int[EOS_TOKEN]],\n",
    "        dtype=torch.long,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "\n",
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    '''A data set iterating over input->translation pairs.'''\n",
    "    def __init__(\n",
    "        self,\n",
    "        pairs: list[tuple[str, str]],\n",
    "        en_word2int: dict[str, int],\n",
    "        ru_word2int: dict[str, int]\n",
    "    ):\n",
    "        self.pairs = pairs\n",
    "        self.en_word2int = en_word2int\n",
    "        self.ru_word2int = ru_word2int\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eng, rus = self.pairs[idx]\n",
    "        eng_tensor = tensor_tokenize(sentence=eng, word2int=self.en_word2int)\n",
    "        rus_tensor = tensor_tokenize(sentence=rus, word2int=self.ru_word2int)\n",
    "        return eng_tensor, rus_tensor\n",
    "\n",
    "translation_dataset = TranslationDataset(\n",
    "    pairs=dataset,\n",
    "    en_word2int=EN_WORD2INT,\n",
    "    ru_word2int=RU_WORD2INT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of using the created dataset - it simply returns a pair of tensors containing the indices of English and Russian tokens, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  795, 47559,  9187, 18291, 50151, 42062,  4580, 22153,  2373, 37942,\n",
       "           634, 13286, 11450,  5395, 40218]),\n",
       " tensor([  1032,  31984,  11099,  78909,  27324,    153,  56213,  92100, 121426,\n",
       "          41080,  30602, 116230]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(translation_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, a dataloader constructs minibatches of pairs and pads shorter sentences so that data across a set of sentences can be represented as a single tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-08T12:34:45.363010Z",
     "iopub.status.busy": "2024-12-08T12:34:45.362778Z",
     "iopub.status.idle": "2024-12-08T12:34:45.419813Z",
     "shell.execute_reply": "2024-12-08T12:34:45.418942Z",
     "shell.execute_reply.started": "2024-12-08T12:34:45.362987Z"
    },
    "id": "JFtSwmsE-R40",
    "outputId": "c059a5bf-4754-4f66-d40c-d93d400501a6",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  795, 47559,  9187, 18291, 50151, 42062,  4580, 22153,  2373, 37942,\n",
       "            634, 13286, 11450,  5395, 40218],\n",
       "         [41676, 37261, 19097, 40218, 35357, 35357, 35357, 35357, 35357, 35357,\n",
       "          35357, 35357, 35357, 35357, 35357]]),\n",
       " tensor([[  1032,  31984,  11099,  78909,  27324,    153,  56213,  92100, 121426,\n",
       "           41080,  30602, 116230, 110367, 110367, 110367, 110367],\n",
       "         [  9884,  54856,  10345, 116230, 110367, 110367, 110367, 110367, 110367,\n",
       "          110367, 110367, 110367, 110367, 110367, 110367, 110367]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_fn(batch: list[torch.Tensor, torch.Tensor]):\n",
    "    '''\n",
    "    Transforms a list of tokinized sentences into the torch tensor. Should be\n",
    "    used as `collate_fn` argument of the dataloader. The main purpose is to\n",
    "    pad all sentences to have the same length.\n",
    "    '''\n",
    "    eng_batch, rus_batch = zip(*batch)\n",
    "    eng_batch_padded = pad_sequence(\n",
    "        eng_batch, batch_first=True, padding_value=EN_WORD2INT[PAD_TOKEN]\n",
    "    )\n",
    "    rus_batch_padded = pad_sequence(\n",
    "        rus_batch, batch_first=True, padding_value=RU_WORD2INT[PAD_TOKEN]\n",
    "    )\n",
    "    return eng_batch_padded, rus_batch_padded\n",
    "\n",
    "batch_size = 64\n",
    "translation_dataloader = torch.utils.data.DataLoader(\n",
    "    translation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "batch = next(iter(translation_dataloader))\n",
    "(batch[0][:2], batch[1][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qn2g0Wa-R41"
   },
   "source": [
    "## Model\n",
    "\n",
    "This section discusses the model architecture, with the key components being the **encoder** and the **decoder**. The central idea is that the encoder transforms the input text into a vector representation. This vector serves as the initial hidden state for the recurrent decoder, which generates the translation by processing the already translated part of the sentence as its input sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "The encoder extracts the last hidden state from each layer. Since there are both forward and backward directional layers, the total number of states corresponds to twice the value of the `num_layers` parameter. All these outputs are then concatenated into a single vector for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T12:34:45.434556Z",
     "iopub.status.busy": "2024-12-08T12:34:45.434198Z",
     "iopub.status.idle": "2024-12-08T12:34:45.440984Z",
     "shell.execute_reply": "2024-12-08T12:34:45.440246Z",
     "shell.execute_reply.started": "2024-12-08T12:34:45.434519Z"
    },
    "id": "71y9rIeN-R44",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_size: int,\n",
    "        hidden_size: int,\n",
    "        num_layers: int = 1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=embed_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: torch.Tensor\n",
    "            With dimentionality (samples_number, sequence_length).\n",
    "            Original language senteces transformed to indeces.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            ouputs: torch.Tensor \n",
    "                (samples_number, sequence_len, hidden_size)\n",
    "                All states. \n",
    "            hidden: torch.Tensor\n",
    "                (samples_number, hidden_size)\n",
    "                Final state.\n",
    "        '''\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # Concatenating results of all layers and all directions to one long\n",
    "        # sequence\n",
    "        hidden = torch.cat(\n",
    "            [hidden[i, :, :] for i in range(len(hidden))], dim=1\n",
    "        ).unsqueeze(0)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the result of applying the recurrent layer to the two transformed sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 100])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(\n",
    "    vocab_size=1000,\n",
    "    embed_size=50,\n",
    "    hidden_size=10,\n",
    "    num_layers=5\n",
    ")\n",
    "encoder(torch.tensor([[0,1,2,3,4], [3,2,5,7,1]], dtype=torch.long))[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** An extra dimension is added to the output of the decoder just to be used as the initial hidden state of a layer RNN in `decoder'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "The decoder is designed to take the text already generated in the previous steps and the hidden state from the previous steps. **Note:** In the first step, the decoder is supposed to use the start-of-sentence token as the already translated part and the encoder's hidden state, which contains information about the text to be translated.\n",
    "\n",
    "The following cell implements decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T12:34:45.727172Z",
     "iopub.status.busy": "2024-12-08T12:34:45.726861Z",
     "iopub.status.idle": "2024-12-08T12:34:45.733027Z",
     "shell.execute_reply": "2024-12-08T12:34:45.732144Z",
     "shell.execute_reply.started": "2024-12-08T12:34:45.727139Z"
    },
    "id": "Pv4nzYAf-R45",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self: int,\n",
    "        vocab_size: int,\n",
    "        embed_size: int,\n",
    "        hidden_size: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=embed_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(in_features=hidden_size, out_features=vocab_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, hidden: torch.Tensor):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: torch.Tensor\n",
    "            (batch_size, sequence_length)\n",
    "            Each sentence transformed to the indices of tokens.\n",
    "        hidden: torch.Tensor\n",
    "            (1, batch_size, hidden_size)\n",
    "            Hidden state at the previous step.\n",
    "        '''\n",
    "        out = self.embedding(x)\n",
    "        out, hidden = self.rnn(out, hidden)\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell shows how `Decoder` can be applied to the two 3-token sentences with a 3-dimensional hidden vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3103,  0.5646,  0.2746,  ...,  0.3686, -0.1304, -0.3804],\n",
       "         [ 0.0347, -0.0063,  0.1958,  ...,  0.4174, -0.0031, -0.3454]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([[[-0.7796,  0.4498,  0.1951,  0.1567,  0.1954,  0.0761, -0.4626,\n",
       "           -0.3433, -0.3152, -0.1454],\n",
       "          [-0.7719,  0.5147,  0.5235, -0.3643, -0.1567, -0.2648, -0.4645,\n",
       "           -0.2493, -0.1569, -0.4936]]], grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(\n",
    "    vocab_size=len(RU_VOCAB),\n",
    "    embed_size=7,\n",
    "    hidden_size=10\n",
    ")\n",
    "\n",
    "decoder(\n",
    "    torch.tensor([[1, 2, 3], [3, 2, 2]], dtype=torch.long),\n",
    "    torch.randn(1, 2, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composition\n",
    "\n",
    "Have a closer look at how it all works together.\n",
    "\n",
    "We'll look at how it works using the first batch of the data loader we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN shape torch.Size([64, 15])\n",
      "RU shape torch.Size([64, 16])\n"
     ]
    }
   ],
   "source": [
    "x = next(iter(translation_dataloader))\n",
    "print(\"EN shape\", x[0].shape)\n",
    "print(\"RU shape\", x[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell applies encoder to the input batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 80])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size = 10\n",
    "hidden_size = 10\n",
    "num_layers = 4\n",
    "\n",
    "encoder = Encoder(\n",
    "    vocab_size=len(EN_VOCAB),\n",
    "    embed_size=embed_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers\n",
    ")\n",
    "hidden = encoder(x[0])[1]\n",
    "hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we obtain a vector for each observation in the batch. This vector's dimensionality is determined by the following logic: the hidden state size of each recurrent layer is multiplied by two because each layer processes the sequence in both forward and reverse directions (`bidirectional=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T12:34:45.736232Z",
     "iopub.status.busy": "2024-12-08T12:34:45.735910Z",
     "iopub.status.idle": "2024-12-08T12:34:45.869033Z",
     "shell.execute_reply": "2024-12-08T12:34:45.868121Z",
     "shell.execute_reply.started": "2024-12-08T12:34:45.736186Z"
    },
    "id": "3TXH5ccs-R45",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2145632])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(\n",
    "    vocab_size=len(RU_VOCAB),\n",
    "    embed_size=10,\n",
    "    hidden_size=hidden_size*num_layers*2\n",
    ")\n",
    "decoder(x[1], hidden)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Consider how the final model can be used in production. The following function represents how the given encoder and decoder can be applied to the arbitrary set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T12:34:45.870688Z",
     "iopub.status.busy": "2024-12-08T12:34:45.870334Z",
     "iopub.status.idle": "2024-12-08T12:34:45.878319Z",
     "shell.execute_reply": "2024-12-08T12:34:45.877490Z",
     "shell.execute_reply.started": "2024-12-08T12:34:45.870650Z"
    },
    "id": "mjsFohNI-R45",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def translate(\n",
    "    encoder: Encoder,\n",
    "    decoder: Decoder,\n",
    "    sentence: str,\n",
    "    en_word2int: dict[str: int],\n",
    "    ru_int2word: dict[int: str],\n",
    "    ru_word2int: dict[str: int],\n",
    "    max_length: int = 15,\n",
    "    device: torch.device = DEVICE\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Apply model to a given sentence.\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        input_tensor = tensor_tokenize(sentence=sentence, word2int=en_word2int)\n",
    "        input_tensor = input_tensor.view(1, -1).to(device)\n",
    "\n",
    "        # Pass input sentence through encoder\n",
    "        _, encoder_hidden = encoder(input_tensor)\n",
    "        # Intialise hidden state of decoder\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        last_word = torch.tensor([[en_word2int[SOS_TOKEN]]]).to(device)\n",
    "        for _ in range(max_length):\n",
    "            # Pass last predicted token through decoder\n",
    "            logits, decoder_hidden = decoder(last_word, decoder_hidden)\n",
    "            # Selecting the most probable token\n",
    "            next_token = logits.argmax(dim=1)\n",
    "            last_word = next_token.unsqueeze(0).to(device)\n",
    "            if next_token.item() == ru_word2int[EOS_TOKEN]:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(ru_int2word.get(next_token.item()))\n",
    "\n",
    "    # return predicted words as a string\n",
    "    return \" \".join(decoded_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of use on an unfitted encoder/decoder combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2024-12-08T12:34:45.880393Z",
     "iopub.status.busy": "2024-12-08T12:34:45.879781Z",
     "iopub.status.idle": "2024-12-08T12:34:45.957742Z",
     "shell.execute_reply": "2024-12-08T12:34:45.956950Z",
     "shell.execute_reply.started": "2024-12-08T12:34:45.880354Z"
    },
    "id": "7jchNZcb-R46",
    "outputId": "835916b7-45d5-40a2-b913-62edca58b7ee",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'выжил девайсах. ожидать вы. парламента «геи рискнёт киото. канарских величайшая мари. японском ссылайся. учительницей заполнение невидимо смотрел. жив?» коронавирусе. картой,'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    sentence=\"hello world\",\n",
    "    en_word2int=EN_WORD2INT,\n",
    "    ru_int2word=RU_INT2WORD,\n",
    "    ru_word2int=RU_WORD2INT,\n",
    "    max_length=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zChwPAzb-R46"
   },
   "source": [
    "## Fitting\n",
    "\n",
    "Consider fitting procedure for such model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell sets up a parameter of the models that'll be used for fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_hidden_size = 32\n",
    "num_layers = 5\n",
    "\n",
    "encoder = Encoder(\n",
    "    vocab_size=len(EN_VOCAB),\n",
    "    embed_size=256,\n",
    "    hidden_size=encoder_hidden_size,\n",
    "    num_layers=num_layers\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    vocab_size=len(RU_VOCAB),\n",
    "    embed_size=256,\n",
    "    hidden_size=encoder_hidden_size*num_layers*2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code implements fitting procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zgXQXwxH-R46",
    "outputId": "5d9164e8-0e3a-4010-f5d3-c86810391170",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CrossEntropy loss shouldn't consider padding during optimilation\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=EN_WORD2INT[PAD_TOKEN])\n",
    "\n",
    "encoder_optimizer = optim.AdamW(encoder.parameters())\n",
    "decoder_optimizer = optim.AdamW(decoder.parameters())\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    iterator = tqdm(enumerate(translation_dataloader))\n",
    "    for i, (input_tensor, target_tensor) in iterator:\n",
    "        input_tensor, target_tensor = (\n",
    "            input_tensor.to(DEVICE),\n",
    "            target_tensor.to(DEVICE)\n",
    "        )\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        target_length = target_tensor.size(1)\n",
    "\n",
    "        _, encoder_hidden = encoder(input_tensor)\n",
    "\n",
    "        decoder_input = torch.full(\n",
    "            (batch_size, 1), \n",
    "            EN_WORD2INT[SOS_TOKEN], \n",
    "            dtype=torch.long\n",
    "        ).to(DEVICE)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        loss = torch.tensor(0.0, device=DEVICE, requires_grad=True)\n",
    "        for di in range(target_length):\n",
    "            logits, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss = loss + loss_fn(logits, target_tensor[:, di])\n",
    "            decoder_input = target_tensor[:, di].reshape(batch_size, 1)\n",
    "\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch}, \",\n",
    "                f\"Batch {i}, \",\n",
    "                f\"Loss: {loss.item() / target_length:.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "Consider results of the gotten models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T12:44:01.097644Z",
     "iopub.status.busy": "2024-12-08T12:44:01.097312Z",
     "iopub.status.idle": "2024-12-08T12:44:01.107873Z",
     "shell.execute_reply": "2024-12-08T12:44:01.106984Z",
     "shell.execute_reply.started": "2024-12-08T12:44:01.097613Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'как это не так.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_tranlation(input: str) -> str:\n",
    "    return translate(\n",
    "        encoder=encoder,\n",
    "        decoder=decoder,\n",
    "        sentence=input,\n",
    "        en_word2int=EN_WORD2INT,\n",
    "        ru_int2word=RU_INT2WORD,\n",
    "        ru_word2int=RU_WORD2INT,\n",
    "        max_length=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T12:44:45.695828Z",
     "iopub.status.busy": "2024-12-08T12:44:45.694804Z",
     "iopub.status.idle": "2024-12-08T12:44:45.706825Z",
     "shell.execute_reply": "2024-12-08T12:44:45.706087Z",
     "shell.execute_reply.started": "2024-12-08T12:44:45.695792Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'давайте поговорим и не будем быть в бостоне.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    sentence=\"Let's try something.\",\n",
    "    en_word2int=EN_WORD2INT,\n",
    "    ru_int2word=RU_INT2WORD,\n",
    "    ru_word2int=RU_WORD2INT,\n",
    "    max_length=20\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5101699,
     "sourceId": 8539972,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
