{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1e5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "from datasets import load_dataset\n",
    "from qdrant_client import QdrantClient, models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a24410",
   "metadata": {},
   "source": [
    "## Building embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347efe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('If the crew behind \"Zombie Chronicles\" ever read this, here\\'s some advice '\n",
      " 'guys: <br /><br />1. In a \"Twist Ending\"-type movie, it\\'s not a good idea '\n",
      " 'to insert close-ups of EVERY DEATH IN THE MOVIE in the opening credits. That '\n",
      " \"tends to spoil the twists, y'know...? <br /><br />2. I know you produced \"\n",
      " 'this on a shoestring and - to be fair - you worked miracles with your budget '\n",
      " 'but please, hire people who can actually act. Or at least, walk, talk and '\n",
      " \"gesture at the same time. Joe Haggerty, I'm looking at you...<br /><br />3. \"\n",
      " \"If you're going to set a part of your movie in the past, only do this if you \"\n",
      " 'have the props and costumes of the time.<br /><br />4. Twist endings are '\n",
      " \"supposed to be a surprise. Sure, we don't want twists that make no sense, \"\n",
      " 'but signposting the \"reveal\" as soon as you introduce a character? That\\'s '\n",
      " 'not a great idea.<br /><br />Kudos to the guys for trying, but in all '\n",
      " \"honesty, I'd rather they hadn't...<br /><br />Only for zombie completists.\")\n"
     ]
    }
   ],
   "source": [
    "data = list(load_dataset(\"stanfordnlp/imdb\", split=\"train\")['text'])\n",
    "pprint(data[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f23e2479",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\n",
    "    \"paraphrase-MiniLM-L3-v2\",\n",
    "    model_kwargs={'dtype': 'float16'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518333a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"imdb_example_files\"):\n",
    "    embeddings = np.load(\"imdb_example_files/embeddings.npy\")\n",
    "else:\n",
    "    embeddings = embedding_model.encode(data, normalize_embeddings=True)\n",
    "    os.mkdir(\"imdb_example_files\")\n",
    "    np.save(\"imdb_example_files/embeddings\", embeddings)\n",
    "    with open(\"imdb_example_files/.gitignore\", \"w\") as f:\n",
    "        f.write(\"embeddings.npy\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d923a5f",
   "metadata": {},
   "source": [
    "## Vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5c43f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = QdrantClient(\":memory:\")\n",
    "embedding_size = embeddings.shape[1]\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"imdb\",\n",
    "    on_disk_payload=True,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=embedding_size,\n",
    "        distance=models.Distance.COSINE,\n",
    "        on_disk=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d4d3382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_179178/1207423332.py:9: UserWarning: Local mode is not recommended for collections with more than 20,000 points. Current collection contains 25000 points. Consider using Qdrant in Docker or Qdrant Cloud for better performance with large datasets.\n",
      "  client.upsert(collection_name=\"imdb\", points=points)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = [\n",
    "    models.PointStruct(\n",
    "        id=str(uuid.uuid4()),\n",
    "        vector=list(embeddings[i]),\n",
    "        payload={\"text\": data[i]}\n",
    "    )\n",
    "    for i in range(len(embeddings))\n",
    "]\n",
    "client.upsert(collection_name=\"imdb\", points=points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
