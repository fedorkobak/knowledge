{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text CNN\n",
    "\n",
    "Text CNN is a method for applying convolutional architecture to text tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from gensim import downloader\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections.abc import Collection\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "As an example, we'll use the `20newsgroups` dataset from `scikit-learn`. To minimize computing complexity only few categories will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"talk.politics.guns\", \"rec.motorcycles\"]\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are dealing with a set of text like shows at the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escape\n",
      "from Cheshire County jail last win-\n",
      "ter.  Santaw, 32 is scheduled to be\n",
      "sentenced next week.  The rape last\n",
      "fall came six months after Santaw\n",
      "was released from prision, where\n",
      "he spent 15 years for a rape he commit-\n",
      "ted when he was 16.  (AP)\n",
      "\n",
      "\n",
      " \n",
      "[end of article]\n",
      "\n",
      "Any reactions?  Did he do enough time?  What should his penalty\n",
      "be?  \n",
      "\n",
      "BTW, Walpole is a town in Massachusetts.  Of course, New\n",
      "hampshire is close by.\n",
      "J. Case Kim\n",
      "kim39@husc.harvard.edu\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test[\"data\"][80][500:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell implements a simple approach that will be used to transform the data into embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = downloader.load(\"word2vec-google-news-300\")\n",
    "\n",
    "def seq_to_emb(\n",
    "    sentences: Collection[str], \n",
    "    wv: KeyedVectors, \n",
    "    tokens_num: int, \n",
    "    pad_token: str = \"</s>\"\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Convert a set of sentences into embeddings. Each set of symbols separated by\n",
    "    a space will be recognized as a separate token.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentences: Collection[str]\n",
    "        A collection of sentences that require transformation into embeddings.\n",
    "    wv: KeyedVectors\n",
    "        This needs to be used to transform tokens into embeddings.\n",
    "    tokens_num: int\n",
    "        The number of tokens to take from each sample. Extra tokens will be \n",
    "        dropped, and if there are not enough tokens, padding will be added.\n",
    "    pad_token: str = \"</s.>\"\n",
    "        The token that will be used for padding if there are not enough tokens \n",
    "        in a sample.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out: np.ndarray\n",
    "        Of size (<samples> ,<embedding size>, <tokens_num>).\n",
    "    '''\n",
    "\n",
    "    rv = []\n",
    "    pad_vector = wv.get_vector(pad_token)\n",
    "\n",
    "    for sentence in sentences:\n",
    "\n",
    "        sentence_embeddings = []\n",
    "        got_emb = 0\n",
    "        for one_token in sentence.split():\n",
    "            if wv.has_index_for(one_token):\n",
    "                sentence_embeddings.append(wv.get_vector(one_token))\n",
    "                got_emb += 1\n",
    "                # Taking embedings only for some of the words\n",
    "                if got_emb >= tokens_num: break\n",
    "\n",
    "        sentence_embeddings = np.stack(sentence_embeddings, axis=1)\n",
    "        pad_array = np.tile(\n",
    "            pad_vector[:, None], \n",
    "            reps=(1, tokens_num - sentence_embeddings.shape[1])\n",
    "        )\n",
    "        sentence_embeddings = np.hstack([sentence_embeddings, pad_array])\n",
    "        rv.append(sentence_embeddings)\n",
    "\n",
    "    return np.stack(rv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sentence is transformed into a set of embeddings, with each token having its own embedding. **Note**: only the specified number of initial embeddings is taken.\n",
    "\n",
    "The following cell demonstrates building embeddings for a small subset of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 300, 20)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = seq_to_emb(\n",
    "    sentences=train[\"data\"][:10],\n",
    "    wv=wv,\n",
    "    tokens_num=20\n",
    ")\n",
    "ans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **result can be interpreted** as the first 20 tokens from the first 10 samples, each with 300 channels representing the meaning of each token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code transforms all the data using this tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_num = 100\n",
    "\n",
    "X_train = torch.tensor(seq_to_emb(\n",
    "    sentences=train[\"data\"],\n",
    "    wv=wv,\n",
    "    tokens_num=tokens_num\n",
    "))\n",
    "X_test = torch.tensor(seq_to_emb(\n",
    "    sentences=test[\"data\"],\n",
    "    wv=wv,\n",
    "    tokens_num=tokens_num\n",
    "))\n",
    "\n",
    "y_train = torch.tensor(train[\"target\"], dtype=torch.float)\n",
    "y_test = torch.tensor(test[\"target\"], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "TextCNN is designed to pass data through convolutional layers, where the kernel aggregates tokens in nearby positions. Then, an activation function should transform the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell shows how convolution can be applied to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1144, 10, 96])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution = nn.Conv1d(in_channels=300, out_channels=10, kernel_size=5)\n",
    "conv_transformed = convolution(X_train)\n",
    "conv_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the activation function, we'll use max pooling, which aggregates the maximum value from the output channels of the convolution, as shown in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1144, 10, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "pooling(conv_transformed).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These ideas are implemented in the complete network defined in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        kernel_sizes: list[int], \n",
    "        in_channels: int, \n",
    "        out_channels: int\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_transforms = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=ks\n",
    "                ),\n",
    "                nn.AdaptiveAvgPool1d(output_size=1),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "            for ks in kernel_sizes\n",
    "        ])\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=len(kernel_sizes)*out_channels,\n",
    "                out_features=1\n",
    "            ),\n",
    "            nn.Flatten(start_dim=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, X: torch.Tensor):\n",
    "        return self.head(torch.cat([ct(X) for ct in self.conv_transforms], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now really basic trainloop to fit such model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.86it/s]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "text_cnn = TextCNN([2,3], 300, 10)\n",
    "optimizer = torch.optim.Adam(text_cnn.parameters(), lr=1e-3)\n",
    "for i in tqdm(range(20)):\n",
    "    optimizer.zero_grad()\n",
    "    predict = text_cnn(X_train)\n",
    "    loss_value = nn.functional.binary_cross_entropy(\n",
    "        input=predict, target=y_train)\n",
    "    loss_value.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results analise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Following cell shows accuracy of the model on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy - 0.8635170459747314\n"
     ]
    }
   ],
   "source": [
    "text_cnn.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_pred = text_cnn(X_test)\n",
    "\n",
    "ans = (\n",
    "    (test_pred > 0.5).to(dtype=torch.float) == y_test\n",
    ").to(dtype=torch.float).mean()\n",
    "\n",
    "print(f\"accuracy - {ans}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least it seems to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual benchmark\n",
    "\n",
    "At the beginning, two categories were randomly chosen from the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec.motorcycles', 'talk.politics.guns']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"target_names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in the target, we used to train the model: 0 corresponds to `rec.motorcycles`, and 1 corresponds to `talk.politics.guns`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT has written some text on these topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motorcycle_safety_gear = \"\"\"\n",
    "When it comes to riding a motorcycle, safety should always be a top priority. \n",
    "While some riders may prefer the freedom of a light jacket or no gear at all, \n",
    "it's important to remember that protective equipment can save your life in the \n",
    "event of an accident. Full-face helmets, armored jackets, gloves, and boots are \n",
    "essential pieces of gear that should be worn on every ride. They not only protect \n",
    "you from injury but also increase your visibility to other road users. It's always \n",
    "better to be safe than sorry, especially when you're on the road with much larger \n",
    "vehicles.\n",
    "\"\"\"\n",
    "\n",
    "choosing_right_motorcycle = \"\"\"\n",
    "Choosing the right motorcycle can be a daunting task, especially for first-time \n",
    "riders. Factors like engine size, style, and comfort should be considered before \n",
    "making a decision. Cruiser motorcycles are popular for long-distance touring, \n",
    "while sportbikes offer agility and speed. For beginners, a smaller engine size \n",
    "is recommended to allow for more control and ease of learning. It's also important \n",
    "to test ride a few bikes to see which one feels most comfortable and fits your \n",
    "riding style.\n",
    "\"\"\"\n",
    "\n",
    "gun_control_debate = \"\"\"\n",
    "The debate around gun control has become increasingly polarized in recent years. \n",
    "Advocates for stricter laws argue that the rise in gun violence can be \n",
    "attributed to easy access to firearms, particularly assault weapons. They \n",
    "point to statistics showing higher gun-related deaths in countries with more \n",
    "relaxed gun laws. On the other hand, opponents of gun control emphasize the \n",
    "importance of the Second Amendment and the right of citizens to protect \n",
    "themselves. They argue that the solution lies not in restricting access to \n",
    "firearms, but in addressing underlying issues like mental health, crime rates, \n",
    "and personal responsibility. The challenge lies in finding common ground on \n",
    "this deeply contentious issue.\n",
    "\"\"\"\n",
    "\n",
    "self_defense_gun_ownership = \"\"\"\n",
    "In many parts of the country, people own guns primarily for self-defense. \n",
    "While some argue that carrying a firearm provides peace of mind and a sense \n",
    "of security, others worry about the risks associated with increased gun \n",
    "ownership. Statistics suggest that more guns in circulation can lead to more \n",
    "accidents and gun-related deaths, particularly in homes with children. However, \n",
    "gun rights advocates maintain that an armed citizenry is a deterrent against \n",
    "crime and tyranny, and that responsible ownership is key to mitigating risks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pass these texts through the model and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4796, 0.4586, 0.5786, 0.5647])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    motorcycle_safety_gear, \n",
    "    choosing_right_motorcycle,\n",
    "    gun_control_debate, \n",
    "    self_defense_gun_ownership, \n",
    "]\n",
    "\n",
    "inp = torch.tensor(seq_to_emb(texts, wv=wv, tokens_num=100))\n",
    "with torch.no_grad():\n",
    "    ans = text_cnn(inp)\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These texts were classified correctly by the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
