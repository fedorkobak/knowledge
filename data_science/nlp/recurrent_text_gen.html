
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Recurrent text gen &#8212; Knowledge base</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'data_science/nlp/recurrent_text_gen';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Recurrent translations" href="recurrent_translation.html" />
    <link rel="prev" title="Text CNN" href="text_cnn.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.jpg" class="logo__image only-light" alt="Knowledge base - Home"/>
    <img src="../../_static/logo.jpg" class="logo__image only-dark pst-js-only" alt="Knowledge base - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Knowlege
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Data science</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../gradient_descent.html">Gradient descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../decision_tree.html">Decision tree</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models_selection_methods/l2_regularisation.html">L2 (Ridge regularisation)</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../metrics.html">Metrics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../metrics/cross_entropy.html">Cross entropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metrics/confusion_matrix.html">Confusion matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metrics/pearson_correlation.html">Pearson correlation coefficient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metrics/CAP.html">CAP curve</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metrics/GINI.html">GINI coeficient</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metrics/jaccard_index.html">Jaccard index</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ranking_task.html">Ranking task</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../ranking_task/collaborative_filtering.html">Collaborative filtering</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../ranking_task/collaborative_filtering/prediction_functions.html">Prediction functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ranking_task/collaborative_filtering/self_made_mem_based.html">Selfmade memory based</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../ranking_task/task_generation.html">Task generation</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../ranking_task/metrics.html">Metrics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../ranking_task/metrics/precision_k.html">precision@k</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ranking_task/metrics/recall_k.html">recall@k</a></li>
<li class="toctree-l3"><a class="reference internal" href="../ranking_task/metrics/average_precision.html">AP@k (average precision)</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../nlp.html">NLP</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html">Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="tf_idf.html">TF-IDF</a></li>
<li class="toctree-l2"><a class="reference internal" href="text_cnn.html">Text CNN</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Recurrent text gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="recurrent_translation.html">Recurrent translations</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../recurrent_layer.html">Recurrent layer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Math</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../math/introduction.html">Intorduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../math/geometry.html">Geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../math/trigonometry.html">Trigonometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../math/union_probability.html">Union probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../math/conditional_probability.html">Сonditional probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../math/cent_limit_theorem.html">Central limit theorem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../math/maximum_likelihood.html">Maximum likelihood</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../math/latex.html">Latex</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../math/stat_testing.html">Statistical testing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../math/stat_testing/binomial_test.html">Binomial test</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Algorithms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../algorithms/complexity.html">Complexity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../algorithms/trees.html">Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../algorithms/dynamic_prog.html">Dynamic programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../algorithms/quick_sort.html">Quick sort</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../algorithms/specific_tasks.html">Specific tasks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../algorithms/specific_tasks/emergency_task.html">Emergency task</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../algorithms/specific_tasks/sinking_islands.html">Sinling islands</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Docker</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../docker/overview.html">Overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../docker/containers.html">Containers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../docker/containers/run.html">Run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../docker/containers/execute_in.html">Execute in</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../docker/containers/check_logs.html">Check logs</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../docker/images.html">Images</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../docker/images/build_image.html">Build image</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../docker/images/build_image/build_context.html">Build context</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../docker/images/build_image/ignore_files.html">Ignore files</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../docker/images/docker_file_directives.html">Dockerfile directives</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../docker/images/docker_file_directives/execute_with_run.html">Execute with start</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../docker/volumes.html">Volumes</a></li>

<li class="toctree-l1 has-children"><a class="reference internal" href="../../docker/networks.html">Networks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../docker/networks/default_networks.html">Default networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../docker/networks/container_communication.html">Containers communication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../docker/networks/local_network.html">Local network</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../docker/access.html">Acesss to containers</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../docker/compose.html">Compose</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../docker/compose/up_down.html">Up/down</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../docker/compose/service_configuration.html">Service configuration</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Git</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../git/overview.html">Overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../git/file_stages.html">File statuses</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../git/file_stages/commit.html">Commit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../git/file_stages/remove_from_staging.html">Remove from staging</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../git/diff.html">Difference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../git/checkout.html">Checkout</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../git/branches.html">Branches</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../git/branches/merge.html">Merge</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../git/branches/remote.html">Remotes</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../git/log.html">Log</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../git/previous_commit.html">Previous commit <code class="docutils literal notranslate"><span class="pre">~</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../git/ignore.html">How git ignore works</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../git/stash.html">Stash</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../git/configuration.html">Configuration</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../git/configuration/variables.html">Variables</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SQL</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../sql/intro.html">Intro</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../sql/select.html">Select</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../sql/select/join.html">JOIN</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../sql/select/join/join_types.html">Join types</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../sql/select/sorting.html">Sorting (ORDER BY)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sql/select/unique_values.html">Unique values (DISTINCT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sql/select/empty_values.html">Empty values</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../sql/select/aggregation_functions.html">Aggregation functions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../sql/select/aggregation_functions/collect_array.html">Collect array</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../sql/select/group_by.html">Group by</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../sql/select/group_by/conditions_on_aggregats.html">Conditions on aggregats (HAVING)</a></li>



</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../sql/select/window_functions.html">Window functions (OVER)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../sql/select/window_functions/functions.html">Functions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../sql/select/window_functions/functions/values_shifting_lag_lead.html">Values shifting (LAG/LEAD)</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../sql/select/expand_array.html">Expand array</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sql/select/conditional.html">Conditional (CASE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sql/select/records_range.html">Records range (OFFSET/LIMIT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sql/select/performance.html">Performance</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../sql/operating_tables.html">Operating tables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../sql/operating_tables/tables_properties.html">Tables properties</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../sql/datatypes.html">Data types</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../sql/datatypes/datetime.html">Date and time</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../sql/datatypes/datetime/date_components.html">Date components (DATE_PART)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../sql/datatypes/datetime/add_period.html">Add period</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../sql/datatypes/json.html">JSON</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../sql/load_modify.html">Load/Modify</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sql/versions_issues.html">Versions issues</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../sql/python_interaction.html">Python interaction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../sql/python_interaction/python_from_container.html">Python from container</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sql/python_interaction/python_on_host.html">Python on host</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sql/python_interaction/create_database.html">Create database</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Layout</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../layout/terminology.html">Terminology</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../layout/html.html">HTML</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../layout/html/other.html">Other</a></li>




<li class="toctree-l2"><a class="reference internal" href="../../layout/html/tables.html">Tables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../layout/html/lists.html">List tags</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../layout/html/svg.html">SVG</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../layout/css.html">CSS</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../layout/css/other.html">Other</a></li>







<li class="toctree-l2"><a class="reference internal" href="../../layout/css/style_application.html">Style application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../layout/css/margin.html">Margin (out space)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../layout/css/padding.html">Padding (in space)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../layout/css/overflow.html">Overflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../layout/css/elements_positions.html">Elements position (<code class="docutils literal notranslate"><span class="pre">display</span></code>)</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../layout/forms.html">Forms</a></li>


</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linux</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../linux/intro.html">Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linux/bash.html">Bash</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linux/manage_input_output.html">Manage input/output</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../linux/filesystem.html">Filesystem</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../linux/filesystem/files_directories.html">Files and directories</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linux/filesystem/archiving.html">Archiving</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../linux/variables.html">Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linux/system_information.html">System information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linux/backup.html">Backup</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../linux/network.html">Network</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../linux/network/curl.html">Curl</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linux/network/ssh.html">SSH</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linux/network/netcat_nc.html">Netcat (<code class="docutils literal notranslate"><span class="pre">nc</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linux/network/vpn.html">VPN</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../linux/users_groups.html">Users &amp; groups</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../linux/users_groups/users_manipulations.html">Users manipulations</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../linux/package_management.html">Package management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linux/path.html">Path</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linux/cron.html">Cron</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linux/gnupg.html">GnuPG</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../other/python_apache.html">Python with apache</a></li>







<li class="toctree-l1"><a class="reference internal" href="../../other/kubernetes.html">Kubernetes</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../other/redis.html">Redis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../other/redis/zset.html">Zset</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../other/nginx.html">Nginx</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../other/nginx/reverse_proxy.html">Reverse proxy</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../other/nginx/reverse_proxy/proxy_pass.html">Proxy pass</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../other/nginx/reverse_proxy/cache.html">Cache</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../other/nginx/variables.html">Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../other/nginx/server.html">Server</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../other/nginx/configuration.html">Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../other/nginx/logs.html">Logs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../other/nginx/connections_management.html">Connections management</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../other/gitlab.html">Gitlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../other/ansible.html">Ansible</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../other/java_script.html">Java script</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../other/go_templates.html">Go templates</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/fedorkobak/knowledge" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/data_science/nlp/recurrent_text_gen.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Recurrent text gen</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data">Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-form">Model form</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loss">Loss</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generation">Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training">Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-generation">Text generation</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="recurrent-text-gen">
<h1>Recurrent text gen<a class="headerlink" href="#recurrent-text-gen" title="Link to this heading">#</a></h1>
<p>This notebook considers building model that generate text using RNN architecture.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pprint</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">kagglehub</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">random</span><span class="w"> </span><span class="kn">import</span> <span class="n">sample</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tempfile</span><span class="w"> </span><span class="kn">import</span> <span class="n">TemporaryDirectory</span> 

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">huggingface_hub</span>
<span class="n">hf_api</span> <span class="o">=</span> <span class="n">huggingface_hub</span><span class="o">.</span><span class="n">HfApi</span><span class="p">()</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="n">files_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;recurrent_text_gen_files&quot;</span><span class="p">)</span>
<span class="n">files_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">path</span> <span class="o">=</span> <span class="n">kagglehub</span><span class="o">.</span><span class="n">dataset_download</span><span class="p">(</span><span class="s2">&quot;Cornell-University/arxiv/versions/205&quot;</span><span class="p">)</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">/</span><span class="s2">&quot;arxiv-metadata-oai-snapshot.json&quot;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/f.kobak@maxbit.local/Documents/knowledge/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre></div>
</div>
</div>
</div>
<section id="data">
<h2>Data<a class="headerlink" href="#data" title="Link to this heading">#</a></h2>
<p><em>arxiv</em> dataset will be used. As this notebook follows only educational puposes we’ll take relatevely small data subset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_path</span> <span class="o">=</span> <span class="n">files_path</span><span class="o">/</span><span class="s2">&quot;arxiv_small.json&quot;</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">data_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
    
    <span class="n">LINES</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">one_line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">())):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">LINES</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">one_line</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">writelines</span><span class="p">(</span><span class="n">LINES</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Data preparation can be divided into several stages:</p>
<ul class="simple">
<li><p>Adding BOS and EOS tokens to each text, marking the beginning and end of the text, respectively.</p></li>
<li><p>Splitting texts into tokens: each symbol will be treated as a separate token to reduce the total number of tokens.</p></li>
<li><p>Encoding tokens numerically. From this step, we can store the data as a <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>. However, PyTorch requires all rows in tensors to be the same size, so we’ll pad the data with indices corresponding to <code class="docutils literal notranslate"><span class="pre">EOS</span></code>.</p></li>
</ul>
<p>The following cell defines <code class="docutils literal notranslate"><span class="pre">BOS</span></code> (beggining of sentence) and <code class="docutils literal notranslate"><span class="pre">EOS</span></code> (end of sentence) tokens and adds them to each observation in the sample. As a result, we’ve got a <code class="docutils literal notranslate"><span class="pre">LINES</span></code> list that will be used as a data source throughout the notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BOS</span><span class="p">,</span> <span class="n">EOS</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="n">LINES</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">data</span>
    <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s2">&quot;title&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot; ; &quot;</span> <span class="o">+</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;abstract&quot;</span><span class="p">])[:</span><span class="mi">512</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">BOS</span> <span class="o">+</span> <span class="n">line</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">EOS</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">EOS</span><span class="p">)</span>
    <span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">LINES</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39; Calculation of prompt diphoton production cross sections at Tevatron and   LHC energies ;   A fully differential calculation in perturbative quantum chromodynamics is presented for the production of massive photon pairs at hadron colliders. All next-to-leading order perturbative contributions from quark-antiquark, gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as all-orders resummation of initial-state gluon radiation valid at next-to-next-to-leading logarithmic accuracy. The region o\n&#39;,
 &#39; Computing genus 2 Hilbert-Siegel modular forms over $\\Q(\\sqrt{5})$ via   the Jacquet-Langlands correspondence ;   In this paper we present an algorithm for computing Hecke eigensystems of Hilbert-Siegel cusp forms over real quadratic fields of narrow class number one. We give some illustrative examples using the quadratic field $\\Q(\\sqrt{5})$. In those examples, we identify Hilbert-Siegel eigenforms that are possible lifts from Hilbert eigenforms. \n&#39;,
 &#39; Molecular Synchronization Waves in Arrays of Allosterically Regulated   Enzymes ;   Spatiotemporal pattern formation in a product-activated enzymic reaction at high enzyme concentrations is investigated. Stochastic simulations show that catalytic turnover cycles of individual enzymes can become coherent and that complex wave patterns of molecular synchronization can develop. The analysis based on the mean-field approximation indicates that the observed patterns result from the presence of Hopf and wave bifu\n&#39;]
</pre></div>
</div>
</div>
</div>
<p>The following code finds all available letters in the dataset under consideration and saves them into the <code class="docutils literal notranslate"><span class="pre">TOKENS</span></code> list.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TOKENS</span> <span class="o">=</span> <span class="p">{</span><span class="n">one_char</span> <span class="k">for</span> <span class="n">one_line</span> <span class="ow">in</span> <span class="n">LINES</span> <span class="k">for</span> <span class="n">one_char</span> <span class="ow">in</span> <span class="n">one_line</span><span class="p">}</span>

<span class="n">TOKENS</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">TOKENS</span><span class="p">)</span>
<span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">TOKENS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;\n !&quot;#$%&amp;\&#39;()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\x7f\x80\x99â&#39;
</pre></div>
</div>
</div>
</div>
<p>The following cell defines the <code class="docutils literal notranslate"><span class="pre">TOKEN_TO_ID</span></code> dictionary that corresponds to the index of each token. And a <code class="docutils literal notranslate"><span class="pre">TO_TENSOR</span></code> function that can transform an array of texts into the <code class="docutils literal notranslate"><span class="pre">Torch.Tensor</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TOKEN_TO_ID</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">TOKENS</span><span class="p">)}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">to_tensor</span><span class="p">(</span>
    <span class="n">lines</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">pad</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">TOKEN_TO_ID</span><span class="p">[</span><span class="n">EOS</span><span class="p">],</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Turns a list of texts into a torch tensor. Each text in `lines` will form a </span>
<span class="sd">    row in the output tensor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lines: list[str]</span>
<span class="sd">        Array of the text that needed to be transformed into tensors.</span>
<span class="sd">    max_len: int | None = None</span>
<span class="sd">        Maximum length considered by the function. It defines the number of </span>
<span class="sd">        columns in the output. If not specified the length of the lonest</span>
<span class="sd">        element in `lines` will be used. Any text that is not long enough </span>
<span class="sd">        will be padded.</span>
<span class="sd">    pad: str</span>
<span class="sd">        Token that must be used to pad texts that does not have enough length.</span>
<span class="sd">    dtype: torch.dtype</span>
<span class="sd">        Type of data that&#39;ll be used in the output tensors</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    out: torch.Tensor</span>
<span class="sd">        `lines` that transformed into `torch.Tensor`.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">max_len</span> <span class="o">=</span> <span class="n">max_len</span> <span class="ow">or</span> <span class="nb">max</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span> <span class="n">lines</span><span class="p">))</span>
    <span class="n">lines_ix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">lines</span><span class="p">),</span> <span class="n">max_len</span><span class="p">],</span> <span class="n">pad</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lines</span><span class="p">)):</span>
        <span class="n">line_ix</span> <span class="o">=</span> <span class="p">[</span><span class="n">TOKEN_TO_ID</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span><span class="n">max_len</span><span class="p">]]</span>
        <span class="n">lines_ix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">line_ix</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">line_ix</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lines_ix</span>
</pre></div>
</div>
</div>
</div>
<p>So finally we have a procedure that allows to transform a list of texts into <code class="docutils literal notranslate"><span class="pre">torch.tensor</span></code>, the following cell shows how it can be used:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">to_tensor</span><span class="p">([</span><span class="s2">&quot; abc</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot; abacaba</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot; abc1234567890</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 1, 66, 67, 68,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
        [ 1, 66, 67, 66, 68, 66, 67, 66,  0,  0,  0,  0,  0,  0,  0],
        [ 1, 66, 67, 68, 18, 19, 20, 21, 22, 23, 24, 25, 26, 17,  0]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-form">
<h2>Model form<a class="headerlink" href="#model-form" title="Link to this heading">#</a></h2>
<p>In this section, we’ll consider a computational procedure that is realized in the model.</p>
<p>As an example, consider the inputs defined in the following cell:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inp</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">([</span><span class="s2">&quot;sentence 1 hi&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence 2 wow&quot;</span><span class="p">])</span>
<span class="n">emb_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
</div>
</div>
</div>
<p>First of all, for all tokens we will build embeddings of the dimension specified in <code class="docutils literal notranslate"><span class="pre">emb_size</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">TOKENS</span><span class="p">),</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="n">emb_size</span><span class="p">)</span>
<span class="n">embeded</span> <span class="o">=</span> <span class="n">emb</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="n">embeded</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([2, 14, 16])
</pre></div>
</div>
</div>
</div>
<p>In our case, for each text we get a matrix containing a 16-dimensional vector for each token in that text.</p>
<p>Then each sentence is transformed by RNN into a sequence of states with the chosen <code class="docutils literal notranslate"><span class="pre">hidden_state</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">emb_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">)</span>
<span class="n">states</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="n">embeded</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">states</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([2, 14, 10])
</pre></div>
</div>
</div>
</div>
<p>Finally, linear layer for each token “unzips” hidden states into vector where there is numer that corresponds to each token we work with.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">TOKENS</span><span class="p">))</span>
<span class="n">linear</span><span class="p">(</span><span class="n">states</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([2, 14, 100])
</pre></div>
</div>
</div>
</div>
<p>The entire complex of transformations is encapsulated in the class defined in the next cell:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">RNNLanguageModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    The model predicts the provability of the next token for each token in the </span>
<span class="sd">    array for tokens.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_tokens: int</span>
<span class="sd">        The number of unique tokens the model should work with.</span>
<span class="sd">    emb_size: int = 16</span>
<span class="sd">        Size of the encoding that each token is encoded as.</span>
<span class="sd">    hid_size: int = 256</span>
<span class="sd">        Dimensionality of the hidden state in the RNN layer.    </span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">n_tokens</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
        <span class="n">emb_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span> 
        <span class="n">hid_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="n">n_tokens</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="n">emb_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">emb_size</span><span class="p">,</span> <span class="n">hid_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">hid_size</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">n_tokens</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ix</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">rv</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">input_ix</span><span class="p">)</span>
        <span class="n">rv</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">rv</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">rv</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">rv</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">rv</span>
    
<span class="n">model</span> <span class="o">=</span> <span class="n">RNNLanguageModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">TOKENS</span><span class="p">))</span>
<span class="n">model</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([2, 14, 100])
</pre></div>
</div>
</div>
</div>
</section>
<section id="loss">
<h2>Loss<a class="headerlink" href="#loss" title="Link to this heading">#</a></h2>
<p>Loss, in my opinion, is a very tricky part of such models. Although it is just a modification of the really typical corssentropy, there are some problems with this model.</p>
<p>The loss formula is as follows:</p>
<div class="math notranslate nohighlight">
\[
L = - \cfrac{1}{N} \sum_{i=1}^N \ln p(x_t^{(i)} | x_{t-1}^{(i)}, \dots, x_1^{(i)})
\]</div>
<p>Next, let’s try to deconstruct its intuition and implementation peculiarities in torch.</p>
<p>We’ll pass a sequence of tokens to our network. To predict the <span class="math notranslate nohighlight">\(t\)</span>-th token, we need to pass all the previous <span class="math notranslate nohighlight">\(t-1\)</span> tokens. The result will be the probabilities for each token to be the <span class="math notranslate nohighlight">\(t\)</span>-th token.</p>
<p><span class="math notranslate nohighlight">\(p(x_t^{(i)} | x_{t-1}^{(i)}, \dots, x_1^{(i)})\)</span>: this represents the probability that the <span class="math notranslate nohighlight">\(t\)</span>-th token follows the previous <span class="math notranslate nohighlight">\(t-1\)</span> tokens, as predicted by the model. We want the probability of the true token to be as high as possible, so our goal can be achieved by minimizing <span class="math notranslate nohighlight">\(L\)</span>.</p>
<p>We’ll consider the procedure on the set of texts and model defined in the following cell.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inp</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">([</span><span class="s2">&quot;Some long input to the model&quot;</span><span class="p">,</span> <span class="s2">&quot;short&quot;</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RNNLanguageModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">TOKENS</span><span class="p">),</span> <span class="n">hid_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We should compare the outputs of the model for each token with the next token in the same sentnce. To achieve this:</p>
<ul class="simple">
<li><p>The last token of each input is skipped - we don’t have a target value for it anyway.</p></li>
<li><p>The first token of the output is skipped, we can’t predict it because there is no context for it.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rnn_input</span> <span class="o">=</span> <span class="n">inp</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">display</span><span class="p">(</span><span class="n">rnn_input</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">reference_answers</span> <span class="o">=</span> <span class="n">inp</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
<span class="n">display</span><span class="p">(</span><span class="n">reference_answers</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[52, 80, 78, 70,  1, 77, 80, 79, 72,  1, 74, 79, 81, 86, 85,  1, 85, 80,
          1, 85, 73, 70,  1, 78, 80, 69],
        [84, 73, 80, 83, 85,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0]])
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[80, 78, 70,  1, 77, 80, 79, 72,  1, 74, 79, 81, 86, 85,  1, 85, 80,  1,
         85, 73, 70,  1, 78, 80, 69, 70, 77],
        [73, 80, 83, 85,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
          0,  0,  0,  0,  0,  0,  0,  0,  0]])
</pre></div>
</div>
</div>
</div>
<p>As a result, the input and output sequences are shifted so that each token in the input corresponds to the next token in the output.</p>
<p>The softmax function is applied to the results of the model to give them probability properties that are important for cross-entropy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">rnn_input</span><span class="p">)</span>
<span class="n">probas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">real_probas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">probas</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">reference_answers</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">real_probas</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.0106, 0.0087, 0.0081, 0.0082, 0.0207, 0.0070, 0.0022, 0.0062, 0.0087,
         0.0085, 0.0043, 0.0246, 0.0097, 0.0057, 0.0090, 0.0044, 0.0040, 0.0054,
         0.0044, 0.0096, 0.0078, 0.0084, 0.0069, 0.0037, 0.0071, 0.0099, 0.0110],
        [0.0086, 0.0086, 0.0046, 0.0053, 0.0120, 0.0074, 0.0073, 0.0073, 0.0073,
         0.0073, 0.0073, 0.0073, 0.0073, 0.0073, 0.0073, 0.0073, 0.0073, 0.0073,
         0.0073, 0.0073, 0.0073, 0.0073, 0.0073, 0.0073, 0.0073, 0.0073, 0.0073]],
       grad_fn=&lt;SqueezeBackward1&gt;)
</pre></div>
</div>
</div>
</div>
<p>There is another problem - paddings. They are only used to make the recurrent layers work properly on the data samples, but the model shouldn’t care about the correctness of the predictions for them. To avoid this, we’ll build a pass that marks tokens that really match some inputs as <code class="docutils literal notranslate"><span class="pre">true</span></code>, but marks padded tokens as <code class="docutils literal notranslate"><span class="pre">false</span></code>. The following cell shows code that achieves such a goal:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eos_ix</span> <span class="o">=</span> <span class="n">TOKEN_TO_ID</span><span class="p">[</span><span class="n">EOS</span><span class="p">]</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">inp</span> <span class="o">==</span> <span class="n">eos_ix</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">pad</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="n">value</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">mask</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True],
        [ True,  True,  True,  True,  True,  True, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False]])
</pre></div>
</div>
</div>
</div>
<p>It searches for the first occurrence of the <code class="docutils literal notranslate"><span class="pre">EOS</span></code> token, all subsequent tokens are padded.</p>
<p>Finally, a truly typical cross-entropy formula that uses a mask to make the padded components zero in the sum.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">real_probas</span><span class="p">)</span> <span class="o">*</span> <span class="n">mask</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span> <span class="o">/</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(78.6129, grad_fn=&lt;DivBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>The following code defines everything we’ve thought of so far as convenient, out-of-the-box functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compute_mask</span><span class="p">(</span>
    <span class="n">input_ix</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
    <span class="n">eos_ix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">TOKEN_TO_ID</span><span class="p">[</span><span class="n">EOS</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Compute a boolean mask that identifies real tokens as true and padded tokens</span>
<span class="sd">    as false. Works under the assumption that all tokens following the EOS token</span>
<span class="sd">    are padding.</span>

<span class="sd">    Paramters</span>
<span class="sd">    ---------</span>
<span class="sd">    input_ix: torch.Tensor</span>
<span class="sd">        Tensor of encoded tokens.</span>
<span class="sd">    eos_ix: int</span>
<span class="sd">        Index of the EOF token.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    out: torch.Tensor</span>
<span class="sd">        Mask.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">input_ix</span> <span class="o">==</span> <span class="n">eos_ix</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">pad</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="n">value</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_loss</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">RNNLanguageModel</span><span class="p">,</span> 
    <span class="n">input_ix</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> 
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Computes the cross-entropy loss of the given model in the given tensor of </span>
<span class="sd">    encoded tokens.</span>

<span class="sd">    Parametrs</span>
<span class="sd">    ---------</span>
<span class="sd">    model: RNNLanguageModel</span>
<span class="sd">        Model that requires loss.</span>
<span class="sd">    input_ix: list[str]</span>
<span class="sd">        Set of data that is used to compute loss.</span>
<span class="sd">    device: torch.device = torch.device(&quot;cpu&quot;)</span>
<span class="sd">        Device that is used by model.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    out: torch.Tensor</span>
<span class="sd">        0 dimensional tensor representing the loss value.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">input_ix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">input_ix</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">input_ix</span> <span class="o">=</span> <span class="n">input_ix</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ix</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">reference_answers</span> <span class="o">=</span> <span class="n">input_ix</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="n">rv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">rv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">rv</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">reference_answers</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">rv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">rv</span><span class="p">)</span>

    <span class="n">rv</span> <span class="o">=</span> <span class="n">rv</span> <span class="o">*</span> <span class="n">compute_mask</span><span class="p">(</span><span class="n">input_ix</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">rv</span><span class="p">)</span> <span class="o">/</span> <span class="n">input_ix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Tools from the previous cell may be lost to the calculation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compute_loss</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">input_ix</span><span class="o">=</span><span class="n">inp</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(78.6129, grad_fn=&lt;DivBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="generation">
<h2>Generation<a class="headerlink" href="#generation" title="Link to this heading">#</a></h2>
<p>Our model, as it stands, predicts a vector representing the probabilities of the next token. However, to generate text, we need to predict a sequence of tokens. The idea is straightforward: predict the next token based on the tokens previously predicted by the model itself, invoking the model as many times as needed for our purposes.</p>
<p>Each time we obtain a vector <span class="math notranslate nohighlight">\(\left(p_1, p_2, \dots, p_n\right)\)</span>, there are various strategies for selecting the most appropriate token based on this vector. A detailed overview of these strategies warrants a separate page. Here, we implement the most popular one: random selection with temperature. High temperature smooths differences between all <span class="math notranslate nohighlight">\(p_i\)</span>, thereby increasing the probability of selecting tokens with lower probabilities. It makes model more creating but can reduce quality.</p>
<hr class="docutils" />
<p>The following cell defines <code class="docutils literal notranslate"><span class="pre">generate</span></code> function that realises generation for the given model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">RNNLanguageModel</span><span class="p">,</span>
    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">BOS</span><span class="p">,</span>
    <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span>
    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Function generates text using given model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model: RNNLanguageModel</span>
<span class="sd">        Model that have to be used for predictions.</span>
<span class="sd">    prefix: str = BOS</span>
<span class="sd">        Line from which we&#39;ll generate outcomes.</span>
<span class="sd">    max_len: int = 100</span>
<span class="sd">        Maximum length of the generated result.</span>
<span class="sd">    device:</span>
<span class="sd">        Device that is used by model.</span>
<span class="sd">    temperature: float = 1.</span>
<span class="sd">        Temperature of the model. If 0 is selected, the deterministic approach </span>
<span class="sd">        is used - only the token with the higher predicted probability is </span>
<span class="sd">        selected.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    out: str</span>
<span class="sd">        Predicted text.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">):</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">to_tensor</span><span class="p">([</span><span class="n">prefix</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">temperature</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">next_token</span> <span class="o">=</span> <span class="n">TOKENS</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">)]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">probs</span> <span class="o">=</span> <span class="n">probs</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">temperature</span><span class="p">)</span>
                <span class="n">probs</span> <span class="o">/=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
                <span class="n">next_token</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">TOKENS</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">probs</span><span class="p">)</span>

            <span class="n">prefix</span> <span class="o">+=</span> <span class="n">next_token</span>
            <span class="k">if</span> <span class="n">next_token</span> <span class="o">==</span> <span class="n">EOS</span><span class="p">:</span>
                <span class="k">break</span>
    
    <span class="k">return</span> <span class="n">prefix</span>
</pre></div>
</div>
</div>
</div>
<p>Here is an example how this function can be used.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">generate</span><span class="p">(</span><span class="n">RNNLanguageModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">TOKENS</span><span class="p">)),</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;test line&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;test lineYKEtd&lt;wV\x7f E14,H\x80#g\x80Q=,;G\n&#39;
</pre></div>
</div>
</div>
</div>
</section>
<section id="training">
<h2>Training<a class="headerlink" href="#training" title="Link to this heading">#</a></h2>
<p>Training loop really typical, except for <code class="docutils literal notranslate"><span class="pre">nn.utils.clip_grad_norm_</span></code> - this is needed due to peculiarities of recurrent layers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">clip_norm</span> <span class="o">=</span> <span class="mf">1e5</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

<span class="n">train_history</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">examples</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">trange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_history</span><span class="p">),</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="n">LINES</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">loss_i</span> <span class="o">=</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss_i</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip_norm</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">train_history</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss_i</span><span class="p">)))</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">examples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">generate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>


<span class="k">with</span> <span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdir</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">Path</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">)</span><span class="o">/</span><span class="s2">&quot;rec_text_gen.pth&quot;</span><span class="p">)</span>
    <span class="n">hf_api</span><span class="o">.</span><span class="n">upload_folder</span><span class="p">(</span>
        <span class="n">repo_id</span><span class="o">=</span><span class="s2">&quot;fedorkobak/knowledge&quot;</span><span class="p">,</span>
        <span class="n">folder_path</span><span class="o">=</span><span class="n">tmpdir</span>
    <span class="p">)</span>

<span class="p">(</span><span class="n">files_path</span><span class="o">/</span><span class="s2">&quot;examples.json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">write_text</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">examples</span><span class="p">))</span>
<span class="p">(</span><span class="n">files_path</span><span class="o">/</span><span class="s2">&quot;train_history.json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">write_text</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">train_history</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Here is a plot of the train curve.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_history</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">((</span><span class="n">files_path</span><span class="o">/</span><span class="s2">&quot;train_history.json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read_text</span><span class="p">())</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">*</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">train_history</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Train curve&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/0f9baaab7bb415128119edb8b8c4e21f57c910618bd3ee9ddb99b246ea7559dd.png" src="../../_images/0f9baaab7bb415128119edb8b8c4e21f57c910618bd3ee9ddb99b246ea7559dd.png" />
</div>
</div>
<p>Here you can see how the model gradually improves during the fitting process.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">examples</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">((</span><span class="n">files_path</span><span class="o">/</span><span class="s2">&quot;examples.json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read_text</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
 W3i0 probuin the. it frov of Boted Modiiticale as of meland incourbattoriinax ,ffensior, in the meun
================================================================================
 String inemped of the from dSepine of the anfinoments of a bathen 2mN$}$. A mended toprkied The\rage
================================================================================
 Fabraic 1ME$r&#39;{\M}^{02}4,,$.]W ;   Tups ;   We low curburabures structure constroator mu

================================================================================
 Oxhered by the didronamination viable coonduptious for zis over (T).5 cluss and nenalated propotions
================================================================================
 Stractly the spin and Highstly or-the exploiting the remequation as  of generalized by multi-phase l
================================================================================
 Leall EOffodiate and Wave and on surface of the vanism problems collisions. In inequality: In tunste
</pre></div>
</div>
</div>
</div>
</section>
<section id="text-generation">
<h2>Text generation<a class="headerlink" href="#text-generation" title="Link to this heading">#</a></h2>
<p>The following cell represents how created model can be loaded.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">file_path</span> <span class="o">=</span> <span class="n">huggingface_hub</span><span class="o">.</span><span class="n">hf_hub_download</span><span class="p">(</span>
    <span class="n">repo_id</span><span class="o">=</span><span class="s2">&quot;fedorkobak/knowledge&quot;</span><span class="p">,</span> 
    <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;rec_text_gen.pth&quot;</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RNNLanguageModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">TOKENS</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>And cell where you can try generations of the model</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ans</span> <span class="o">=</span> <span class="n">generate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;Some input&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">ans</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&#39;Some input and cross conditions ;   The shear spectrostars. A solution &#39;
 &#39;theory consented it is a fundamental geometries with the challenges a &#39;
 &#39;Competing spin system of the felliable are abservation, which set of average &#39;
 &#39;group processes and an equivalent intemator Thic are theory propagiant &#39;
 &#39;characterize the finite the fraction for the numerical spin end Yirmovenco &#39;
 &#39;images of the incompanied to method various of semayn state. Completing &#39;
 &#39;fraument, of the thin problem to determine nots on corpling of the space: &#39;)
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./data_science/nlp"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="text_cnn.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Text CNN</p>
      </div>
    </a>
    <a class="right-next"
       href="recurrent_translation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Recurrent translations</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data">Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-form">Model form</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loss">Loss</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generation">Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training">Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-generation">Text generation</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Fedor Kobak
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>