{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent layer\n",
    "\n",
    "This page explains the concept of a recurrent layer.\n",
    "\n",
    "The key idea is to create a mechanism where each input affects the processing and outcome of subsequent inputs.\n",
    "\n",
    "![](recurent_layer_files/recurent_schema.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An RNN is essentially a single layer. At each step, it uses $h_{t-1}$, a special state vector from the previous step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strictly speaking, the deduction is as follows:  \n",
    "\n",
    "$$h_t = f(x_t W^T_1 + b_1 + h_{t-1} W^T_2 + b_2)$$  \n",
    "\n",
    "Where:  \n",
    "- $x_t$: input at the $t$-th step.  \n",
    "- $h_t$: vector that describes hidden state at the $t$-th step.  \n",
    "- $W_1$: weights associated with the input.  \n",
    "- $W_2$: weights associated with the state.  \n",
    "- $b_1$: bias associated with the input.  \n",
    "- $b_2$: bias associated with the state.  \n",
    "- $f$: activation function, typically a hyperbolic tangent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realization on python\n",
    "\n",
    "In this section, we will step by step implement the computations performed by a recurrent layer and compare them with `torch.nn.RNN` as the reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines the parameters of the recurrent procedure that we will use as an example.\n",
    "\n",
    "We have:  \n",
    "\n",
    "- A sequence of 15 elements: $\\left\\{ x_1, x_2, \\dots, x_{15} \\right\\}$.  \n",
    "- Each element is a vector of 5 elements: $x_t \\in \\mathbb{R}^5$.  \n",
    "- We are working with a sample containing 15 sequences.  \n",
    "- The state vector is a 3-element vector: $h_t \\in \\mathbb{R}^3$.  \n",
    "- The activation function $f(x)$ is the hyperbolic tangent.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "samples_size = 10\n",
    "element_size = 5\n",
    "sequence_size = 15\n",
    "state_size = 3\n",
    "activation = torch.nn.Tanh()\n",
    "\n",
    "input_data = torch.rand(samples_size, sequence_size, element_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For given inputs:\n",
    "\n",
    "- Input weights $W_1$ should be a $3 \\times 5$ matrix.  \n",
    "- Input bias $b_1$ should be a vector with $3$ elements.  \n",
    "- State weights $W_2$ should be a $3 \\times 3$ matrix.  \n",
    "- State bias $b_2$ should be a vector with $3$ elements.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_1 = torch.rand(state_size, element_size)\n",
    "b_1 = torch.rand(state_size)\n",
    "W_2 = torch.rand(state_size, state_size)\n",
    "b_2 = torch.rand(state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realisation of $x_1 W^T_1 + b_1 + h_{0} W^T_2 + b_2$ will take form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1063, 2.5003, 2.6427],\n",
       "        [3.3605, 2.6550, 2.9545],\n",
       "        [3.1519, 2.5479, 2.1526],\n",
       "        [2.9270, 2.3460, 2.6681],\n",
       "        [3.4005, 2.7839, 2.4954],\n",
       "        [3.5589, 2.9070, 2.9149],\n",
       "        [3.3401, 2.7549, 2.4623],\n",
       "        [3.0115, 2.4006, 2.3053],\n",
       "        [3.2647, 2.6268, 2.4131],\n",
       "        [2.8917, 2.3394, 2.4433]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.zeros(samples_size, state_size)\n",
    "(input_data[:, 0, :] @ W_1.T) + b_1 + (state @ W_2.T) + b_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the full recurrent procedure for all 15 elements of the sequence is provided in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [state]\n",
    "\n",
    "for i in range(input_data.shape[1]):\n",
    "    res = activation( \n",
    "        (input_data[:, i, :] @ W_1.T) + b_1\n",
    "        + (states[-1] @ W_2.T) + b_2\n",
    "    )\n",
    "    states.append(res)\n",
    "\n",
    "my_ans = (\n",
    "    torch.stack(states[1:]).permute((1, 0, 2)), \n",
    "    states[-1][None, ...]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will do the same using the ready-made `torch.nn.RNN` class. Before computing, we need to set the weights of the instance to match those used in the custom procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.RNN(element_size, state_size, batch_first=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Copying the parameters that were used earlier:\n",
    "    rnn.weight_ih_l0.copy_(W_1)\n",
    "    rnn.bias_ih_l0.copy_(b_1)\n",
    "    rnn.weight_hh_l0.copy_(W_2)\n",
    "    rnn.bias_hh_l0.copy_(b_2)\n",
    "\n",
    "    torch_ans = rnn(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell verifies that both outputs are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(torch_ans[0], my_ans[0])\n",
    "torch.testing.assert_close(torch_ans[1], my_ans[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
