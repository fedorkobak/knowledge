{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18428b2c-1235-48c9-8f91-450e5e7c3144",
   "metadata": {},
   "source": [
    "# Transformers\n",
    "\n",
    "`transformers` is a library in python that allows you to use pre-trained machine learning models that belong to the transformers architecture. So in the following example, the pre-trained Bert model has been loaded and deiaplayed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8803b34-a5cb-4182-ae2e-d114f5d7d971",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4d2120f-e773-4bc3-8cee-7042c2a83187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87a2ef8-5703-4895-8a22-2254789de471",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n",
    "To use the model correctly, you may need a tokiniser - a program that trains text to tokens. Trainformers also have special tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70504625-388f-47ac-ad23-6a8491350c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a49544-7d5d-4119-acc3-9cd470a048fe",
   "metadata": {},
   "source": [
    "So here is example how \"Hello!\" phrase can be tokinized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d99edc-79fb-4dd3-acb9-f603a0be0ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 8667,  106,  102]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus(\n",
    "    'Hello!', \n",
    "    add_special_tokens=True, \n",
    "    return_token_type_ids=False, \n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7af3ce-1efe-42ae-ba21-65a667a1a315",
   "metadata": {},
   "source": [
    "## Model usage\n",
    "\n",
    "Here we combine the downloaded tokiniser and model and use it to run some phrase through the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddee02cb-473e-492e-b598-b18d0558e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "    'Hello!', \n",
    "    add_special_tokens=True, \n",
    "    return_token_type_ids=False, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "res = model(**encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672437e2-4086-408e-bf7d-90183171d72d",
   "metadata": {},
   "source": [
    "We've got back an instance of a specific class that implements the result of the BERT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01a0bc82-a2cc-4758-a334-bd21925945e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a60659-1265-474e-91f8-b6b7d98e0611",
   "metadata": {},
   "source": [
    "It contains two objects:\n",
    "\n",
    "- `last_hidden_state` - state of last hidden layer;\n",
    "- `pooler_output` - output of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6834cba7-c8be-406c-8ebf-f135d6e2b5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Last hidden state:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6283,  0.2166,  0.5605,  ...,  0.0136,  0.6158, -0.1712],\n",
      "         [ 0.6108, -0.2253,  0.9263,  ..., -0.3028,  0.4500, -0.0714],\n",
      "         [ 0.8040,  0.1809,  0.7076,  ..., -0.0685,  0.4837, -0.0774],\n",
      "         [ 1.3290,  0.2360,  0.4567,  ...,  0.1509,  0.9621, -0.4841]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br><b>Pooler output:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7105,  0.4876,  0.9999, -0.9947,  0.9599,  0.9521,  0.9767, -0.9946,\n",
      "         -0.9815, -0.6238,  0.9776,  0.9984, -0.9989, -0.9998,  0.8559, -0.9755,\n",
      "          0.9895, -0.5281, -1.0000, -0.7414, -0.7056, -0.9999,  0.2901,  0.9786,\n",
      "          0.9729,  0.0734,  0.9828,  1.0000,  0.8981, -0.1109,  0.2780, -0.9920,\n",
      "          0.8693, -0.9985,  0.1461,  0.2067,  0.8092, -0.2430,  0.8580, -0.9585,\n",
      "         -0.8130, -0.6138,  0.7961, -0.5727,  0.9737,  0.2362, -0.1194, -0.0789,\n",
      "          0.0031,  0.9997, -0.9519,  0.9899, -0.9962,  0.9931,  0.9950,  0.5050,\n",
      "          0.9952,  0.1090, -0.9994,  0.3416,  0.9792,  0.2506,  0.8923, -0.2238,\n",
      "          0.3518, -0.5293, -0.9570,  0.1357, -0.3313,  0.1627, -0.0078,  0.3608,\n",
      "          0.9833, -0.9160,  0.0196, -0.9141,  0.2075, -0.9999,  0.9449,  1.0000,\n",
      "          0.7796, -0.9997,  0.9935, -0.2309, -0.7830,  0.8880, -0.9994, -0.9994,\n",
      "          0.0160, -0.6875,  0.9554, -0.9846,  0.7813, -0.9322,  1.0000, -0.9511,\n",
      "         -0.1583,  0.3866,  0.9699, -0.8283, -0.7689,  0.9346,  0.9994, -0.9965,\n",
      "          0.9992,  0.8548, -0.9459, -0.9451,  0.8292,  0.0406,  0.9891, -0.9857,\n",
      "         -0.9555,  0.0784,  0.9803, -0.9302,  0.9901,  0.8020, -0.2408,  1.0000,\n",
      "         -0.2367,  0.9689,  0.9982,  0.8761, -0.8891, -0.2167, -0.7227,  0.9385,\n",
      "         -0.7771, -0.5691,  0.8276, -0.9881, -0.9987,  0.9994, -0.2452,  1.0000,\n",
      "         -0.9992,  0.9935, -0.9999, -0.8808, -0.7632, -0.1224, -0.9886,  0.0386,\n",
      "          0.9893,  0.0950, -0.9691, -0.8293,  0.7363, -0.9115,  0.4936,  0.6483,\n",
      "         -0.9581,  0.9715,  0.9982,  0.9653,  0.9890,  0.1850, -0.9722,  0.8544,\n",
      "          0.9774, -0.9995,  0.8701, -0.9960,  0.9993,  0.9746,  0.8500, -0.9971,\n",
      "          0.9999, -0.8101,  0.0206,  0.0232,  0.0982, -0.9993,  0.4584,  0.4759,\n",
      "          0.8759,  0.9993, -0.9945,  0.9995,  0.8257, -0.0958,  0.8097,  0.9992,\n",
      "         -0.9966, -0.9701, -0.9847,  0.2290,  0.8039,  0.8126,  0.4859,  0.9628,\n",
      "          0.9992,  0.7803, -0.9974, -0.3289,  0.9692, -0.1398,  1.0000, -0.4062,\n",
      "         -0.9998, -0.7585,  0.9499,  0.9883, -0.2351,  0.9828, -0.7602, -0.1856,\n",
      "          0.9882, -0.9727,  0.9989,  0.4863,  0.9102,  0.8847,  0.9915, -0.9258,\n",
      "         -0.0788,  0.1543, -0.7543,  0.9999, -0.9996, -0.2332,  0.5874, -0.9942,\n",
      "         -0.9979,  0.9794, -0.0194, -0.8693, -0.2168,  0.7979,  0.2004,  0.9521,\n",
      "          0.9900, -0.6276, -0.7824, -0.9998, -0.9979, -0.8998, -0.9672,  0.0430,\n",
      "          0.6920, -0.3973, -0.9400, -0.9990,  0.9653,  0.4508, -0.8941,  0.1173,\n",
      "         -0.7708, -0.9993,  0.6723, -0.9301, -0.9982,  0.9996, -0.7676,  0.9977,\n",
      "          0.9586, -0.9940,  0.8469, -0.9993, -0.1126, -0.9871,  0.6339,  0.6951,\n",
      "         -0.6402, -0.0494,  0.9932, -0.9665, -0.8052,  0.8924, -0.9999,  0.9337,\n",
      "         -0.2121,  0.9991,  0.8133,  0.2323,  0.9850,  0.9504, -0.9842, -0.9998,\n",
      "          0.9709,  0.8598, -0.9926, -0.1464,  0.9999, -0.9989, -0.8643, -0.9607,\n",
      "         -0.9940, -0.9996,  0.2709, -0.8859,  0.2709,  0.9882,  0.6940,  0.1279,\n",
      "          0.9929,  0.9910,  0.2286, -0.3951,  0.1043, -0.9768, -0.9314,  0.9270,\n",
      "          0.1190, -1.0000,  0.9999, -0.9937,  0.9782,  0.9644, -0.9963,  0.8284,\n",
      "          0.1232, -0.9757,  0.0153,  0.9999,  0.9855, -0.1870,  0.2675,  0.9221,\n",
      "         -0.3209,  0.6954, -0.8953, -0.7505,  0.2031, -0.9330,  0.9959,  0.7163,\n",
      "         -0.9901,  0.9979,  0.0020,  0.8427, -0.8604,  0.9138,  0.9909, -0.1418,\n",
      "         -0.6551,  0.0506, -0.1576, -0.9825,  0.2171, -0.9974, -0.5776,  0.9791,\n",
      "          0.9842, -0.9881,  0.9842, -0.0714,  0.9470, -0.9988,  1.0000, -0.9961,\n",
      "          0.0919,  0.8178, -0.8827, -0.6587,  0.9920,  0.9926,  0.9770, -0.9782,\n",
      "         -0.8553,  0.8854,  0.9670, -0.9807, -0.0805, -0.9996, -0.8613,  0.9954,\n",
      "          0.9971,  0.0548, -0.1328, -0.9985,  0.9674, -0.8499, -0.9574, -0.0873,\n",
      "         -0.8494,  0.8687,  0.9986, -0.7471,  0.7234,  0.1623, -0.9843,  0.9408,\n",
      "          0.9139,  0.9998, -0.9575,  0.6504,  0.9878, -0.2068, -0.8754,  0.6124,\n",
      "          0.9995, -0.9634, -0.2490, -0.9995, -0.0428, -0.6623, -0.3127, -0.6662,\n",
      "          0.0496, -0.8922,  0.9753,  0.0668,  0.8677, -0.4532,  0.9877, -0.1256,\n",
      "         -0.0084, -0.3633, -0.4310,  0.5263,  0.2795,  0.9855, -0.9623,  0.9997,\n",
      "         -0.2454, -1.0000, -0.9985, -0.8149, -0.9996,  0.8664, -0.9936,  0.9833,\n",
      "          0.9645, -0.9990, -0.9995, -0.9971, -0.9827,  0.8944,  0.7312, -0.0281,\n",
      "          0.3282, -0.0801, -0.0505, -0.5034,  0.0436, -0.9379, -0.6098, -0.9991,\n",
      "          0.9075, -1.0000, -0.8943,  0.9983, -0.9974, -0.9702, -0.9073, -0.5143,\n",
      "         -0.8728,  0.5948,  0.9871, -0.4346, -0.8071, -0.9995,  0.9870, -0.8455,\n",
      "          0.0911, -0.9254, -0.9747,  0.9997,  0.8546, -0.1713, -0.0070, -0.9989,\n",
      "          0.9919, -0.9512, -0.9604, -0.9775,  0.2517, -0.9669, -0.9998,  0.0274,\n",
      "          0.9981,  0.9918,  0.9872,  0.3586, -0.4554, -0.9641,  0.1662, -0.9999,\n",
      "          0.8734,  0.9199, -0.9861, -0.7962,  0.9937,  0.9731, -0.9745, -0.9908,\n",
      "          0.9605,  0.3886,  0.9752, -0.6621, -0.5456,  0.3875,  0.0179, -0.9900,\n",
      "         -0.9324,  0.9966, -0.9996,  0.9857,  0.9975,  0.9992, -0.2936,  0.1672,\n",
      "         -0.9914, -0.9807, -0.5163,  0.3407, -0.9999,  0.9999, -1.0000,  0.4725,\n",
      "         -0.8529,  0.9192,  0.9880, -0.4080, -0.9999, -0.9998,  0.3443,  0.1171,\n",
      "          0.9887,  0.4144,  0.1948, -0.6747, -0.3843,  0.9973, -0.8765, -0.8126,\n",
      "         -0.9988,  0.9997,  0.4865, -0.9982,  0.9962, -0.9995,  0.8606,  0.9813,\n",
      "          0.8977,  0.9750, -0.9995,  1.0000, -0.9998,  0.9968, -1.0000, -0.9994,\n",
      "          0.9998, -0.9914, -0.8091, -0.9997, -0.9992,  0.7226,  0.1572, -0.5659,\n",
      "          0.9883, -0.9998, -0.9987, -0.4541, -0.9309, -0.8762,  0.9972, -0.8189,\n",
      "          0.9894, -0.0908,  0.9623,  0.3485,  0.9983,  0.9907, -0.7728, -0.8770,\n",
      "         -0.9934,  0.9906, -0.6931,  0.4029,  0.9709, -0.0175, -0.8430,  0.3529,\n",
      "         -0.9967,  0.5958,  0.1322,  0.9368,  0.9241,  0.8697, -0.1084, -0.5757,\n",
      "         -0.3093, -0.9923,  0.5895, -0.9995,  0.9794, -0.9611,  0.0368, -0.4532,\n",
      "          0.2907, -0.9616,  0.9996,  0.9988, -0.9890,  0.0842,  0.9875, -0.8991,\n",
      "          0.9725, -0.9923,  0.0591,  0.9806, -0.7373,  0.9830, -0.0013,  0.0637,\n",
      "          0.9887, -0.9946, -0.9119, -0.6857,  0.3650,  0.0621, -0.9661,  0.0115,\n",
      "          0.9902, -0.4771, -0.9997,  0.9412, -0.9993, -0.1202,  0.9763, -0.0377,\n",
      "          0.9999, -0.8283,  0.1905,  0.1534, -0.9998, -0.9995,  0.0540, -0.1655,\n",
      "         -0.9095,  0.9996, -0.3539,  0.8774, -0.9999,  0.3085,  0.9981,  0.2593,\n",
      "          0.8318, -0.9150, -0.9679, -0.9740, -0.7623,  0.0018,  0.8898, -0.9830,\n",
      "         -0.6928, -0.9300,  1.0000, -0.9982, -0.9065, -0.9884,  0.7844,  0.9037,\n",
      "          0.4408,  0.1464, -0.9218,  0.9302, -0.9442,  0.9973, -0.9939, -0.9963,\n",
      "          0.9998,  0.5109, -0.9965,  0.2434, -0.4521,  0.3922,  0.1305,  0.8537,\n",
      "         -0.8603, -0.2880, -0.9964,  0.8409, -0.9161, -0.9866, -0.6739, -0.3227,\n",
      "         -0.9776,  0.9935,  0.9731,  0.9999, -0.9998,  0.9386, -0.0222,  0.9991,\n",
      "          0.0548, -0.7093,  0.9169,  0.9997, -0.7628,  0.8665, -0.1445,  0.0659,\n",
      "          0.4782, -0.4443,  0.9984, -0.9318,  0.0735, -0.9737, -0.9999,  0.9999,\n",
      "         -0.0253,  0.9916,  0.3062,  0.8545, -0.9106,  0.9857, -0.9849, -0.9302,\n",
      "         -1.0000,  0.1720, -0.9895, -0.9877, -0.1270,  0.9847, -0.9996, -0.9917,\n",
      "         -0.4165, -1.0000,  0.9550, -0.9948, -0.8871, -0.9896,  0.9988, -0.2867,\n",
      "         -0.8413,  0.9756, -0.9648,  0.9592,  0.9145, -0.4687,  0.2182,  0.1638,\n",
      "         -0.8462, -0.9960, -0.9356, -0.9699,  0.9437, -0.9875, -0.8543,  0.9966,\n",
      "          0.9835, -0.9992, -0.9944,  0.9973,  0.2491,  0.9927, -0.5164, -0.9998,\n",
      "         -0.9999,  0.0790,  0.2047,  0.9947, -0.3889,  0.9576,  0.8522, -0.5662,\n",
      "          0.6047, -0.8014, -0.2958, -0.6084, -0.2891,  1.0000, -0.9179,  0.9894]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "display(HTML(\"<b>Last hidden state:</b>\"))\n",
    "print(res.last_hidden_state)\n",
    "display(HTML(\"<br><b>Pooler output:</b>\"))\n",
    "print(res.pooler_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2900567e-a5b2-4308-ba24-43ffd86b3efe",
   "metadata": {},
   "source": [
    "## Apply to dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5409df0-1bd0-4602-98c5-a58ecb323dcd",
   "metadata": {},
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04e69782-b305-4cdd-ad20-fed805522d92",
   "metadata": {},
   "source": [
    "def tokenization(example):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        example['text'], \n",
    "        add_special_tokens=True, \n",
    "        return_token_type_ids=False, \n",
    "        truncation=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
