{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6e78e44c-98cc-4059-8ae6-72fb058cabf4",
      "metadata": {
        "id": "6e78e44c-98cc-4059-8ae6-72fb058cabf4"
      },
      "source": [
        "# Managing network\n",
        "\n",
        "Is a class that allows you to define complex neural networks in Torch. Simply use this class as a descendant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7cb58b03-6c03-4bf4-bed2-be16d2fc2287",
      "metadata": {
        "id": "7cb58b03-6c03-4bf4-bed2-be16d2fc2287"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b89b3b93",
      "metadata": {
        "id": "b89b3b93"
      },
      "source": [
        "## Sequential\n",
        "\n",
        "You can use `torch.nn.Sequential` to combine multiple network layers into a sequential chain. Find out more in the [specific page](managing_network/sequential.ipynb).\n",
        "\n",
        "---\n",
        "\n",
        "The following cell demonstrates a basic example where a linear transformation is applied to the input, followed by a ReLU activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "329df276",
      "metadata": {
        "id": "329df276",
        "outputId": "c1e0ae45-77df-49ac-f646-a9416d80458a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.8781],\n",
              "        [0.4362, 0.0000, 0.7350],\n",
              "        [0.0000, 0.0000, 1.1225]], grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "size = 3\n",
        "\n",
        "sequential = torch.nn.Sequential(\n",
        "    torch.nn.Linear(size, size, bias=False),\n",
        "    torch.nn.ReLU()\n",
        ")\n",
        "\n",
        "X = torch.randn([3, 3])\n",
        "sequential(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87b5b73f",
      "metadata": {
        "id": "87b5b73f"
      },
      "source": [
        "## Separate class\n",
        "\n",
        "You can define a neural network as a separate class, which allows you to add custom logic for initialization or network-specific procedures. To create a network class, follow these rules:\n",
        "\n",
        "- **Inherit from `torch.nn.Module`:** This establishes your class as a PyTorch module, providing access to its functionality.\n",
        "- **Call `super().__init__()` in the constructor:** This initializes the base `nn.Module` class, ensuring proper setup.\n",
        "- **Define a `forward` method:** This method implements the computational procedure of your network. It defines how input data flows through your layers to produce output."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b28f6b2",
      "metadata": {
        "id": "2b28f6b2"
      },
      "source": [
        "---\n",
        "\n",
        "The following cell defines a set of Linear layers whose size is determined during class creation. The forward method standardizes the data before applying the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61dc0fcf",
      "metadata": {
        "id": "61dc0fcf"
      },
      "outputs": [],
      "source": [
        "class ExampleNetwork(torch.nn.Module):\n",
        "    def __init__(self, layers_number: int, neurons: int):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.network = torch.nn.Sequential(*[\n",
        "            torch.nn.Linear(neurons, neurons)\n",
        "            for i in range(layers_number)\n",
        "        ])\n",
        "\n",
        "    def forward(self, X: torch.Tensor):\n",
        "        X = (X - X.mean(axis=0, keepdim=True))/X.std(axis=0, keepdim=True)\n",
        "        return self.network(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c6f24bf",
      "metadata": {
        "id": "0c6f24bf"
      },
      "source": [
        "Let's check if the network we've defined works as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e32c819",
      "metadata": {
        "id": "3e32c819",
        "outputId": "4dc56fd0-1e08-481c-f0b3-22fc8b6842fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.2482,  0.0882,  0.4507],\n",
              "        [-0.2465,  0.0897,  0.4466],\n",
              "        [-0.2531,  0.0827,  0.4587],\n",
              "        [-0.2463,  0.0899,  0.4459],\n",
              "        [-0.2461,  0.0892,  0.4429]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ExampleNetwork(layers_number=10, neurons=3)(X = torch.randn([5, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66b0f9df-64a9-4613-98da-670e17eb8244",
      "metadata": {
        "id": "66b0f9df-64a9-4613-98da-670e17eb8244"
      },
      "source": [
        "## Parameters\n",
        "\n",
        "To be able to optimize network properly you need tools that allows to access paraterers and manage them. As this section we consider typical methods that help to manage model parameters in torch."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28f17636",
      "metadata": {
        "id": "28f17636"
      },
      "source": [
        "### Access parameters\n",
        "\n",
        "To access model parameters, use the `torch.nn.Module.parameters` method. This method returns a generator that iterates over the parameters of all layers in the network.\n",
        "\n",
        "Check the official [documentation on the `parameters` method](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2d7afce-4e96-4d41-b8c6-f5e7a328741d",
      "metadata": {
        "id": "e2d7afce-4e96-4d41-b8c6-f5e7a328741d"
      },
      "source": [
        "---\n",
        "\n",
        "In the following cell we have an empty `nn.Module` - so when we try to unpack it generator to list we have just an empty list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad8022cb-2f1d-4a23-a29d-540946fa9cc7",
      "metadata": {
        "id": "ad8022cb-2f1d-4a23-a29d-540946fa9cc7",
        "outputId": "49a1dd18-f2fc-4e5d-92d2-ac4aa772d31f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class EmptyNetwork(nn.Module):\n",
        "    pass\n",
        "empty_network = EmptyNetwork()\n",
        "[i for i in empty_network.parameters()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f585fdc-cd8f-41f6-8075-57899c5a6d49",
      "metadata": {
        "id": "1f585fdc-cd8f-41f6-8075-57899c5a6d49"
      },
      "source": [
        "This cell implements such a descendant of the `nn.Module`, taking some parameters from its files. To be more specific, there are two fully connected layers defined here. So we end up with four tensors, two matrices for fully connected layers and their biases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bad4179-1ca1-4e10-a24a-3510f80c57f2",
      "metadata": {
        "id": "0bad4179-1ca1-4e10-a24a-3510f80c57f2",
        "outputId": "0f7c1db9-ea9c-4c06-920f-ba818fb005cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.4889, -0.2448, -0.1750],\n",
            "        [ 0.0770, -0.0333,  0.2421],\n",
            "        [-0.0755, -0.2302, -0.4851]])\n",
            "tensor([ 0.1668, -0.5771,  0.4508])\n",
            "tensor([[ 0.1828, -0.3526, -0.3598,  0.4468, -0.2286],\n",
            "        [-0.0492,  0.3426,  0.2613,  0.2133, -0.2792],\n",
            "        [-0.2052,  0.2514,  0.0616,  0.4382, -0.2944],\n",
            "        [-0.2796, -0.0471, -0.4185,  0.4359,  0.2697],\n",
            "        [ 0.3577,  0.4372, -0.0179,  0.1575,  0.2003]])\n",
            "tensor([-0.4275,  0.0130,  0.4131, -0.2934,  0.3826])\n"
          ]
        }
      ],
      "source": [
        "class ParametersNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.foo = nn.Linear(3, 3)\n",
        "        self.bar = nn.Linear(5, 5)\n",
        "\n",
        "network = ParametersNetwork()\n",
        "for i in network.parameters():\n",
        "    print(i.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "319f1b6e",
      "metadata": {
        "id": "319f1b6e"
      },
      "source": [
        "### Requires grad\n",
        "\n",
        "You can manipulate the set of parameters that will compute gradients in a neural network. You can do this directly by accessing the parameters and setting their `requires_grad` attribute to `False`. However, there is a `requires_grad_()` method that allows you to set the gradient property for all weights of an `nn.Module`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a97e0d1e",
      "metadata": {
        "id": "a97e0d1e"
      },
      "source": [
        "---\n",
        "\n",
        "The following cell defines a network and prints the `requires_grad` attribute of its weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8725953",
      "metadata": {
        "id": "b8725953",
        "outputId": "9920f9aa-8932-4590-fc21-69e4ab18a99c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.weight True\n",
            "0.bias True\n",
            "2.weight True\n",
            "2.bias True\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(10)\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=10, out_features=10),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=10, out_features=1),\n",
        ")\n",
        "\n",
        "for name, parameters in model.named_parameters():\n",
        "    print(name, parameters.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ebb55d2",
      "metadata": {
        "id": "5ebb55d2"
      },
      "source": [
        "By default, all parameters require gradients. The following cell applies `requires_grad_(False)` to the entire network and then sets `requires_grad(True)` for just one of the layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35a8fb67",
      "metadata": {
        "id": "35a8fb67",
        "outputId": "6013b113-3ae4-4186-842d-bccdbc38aa30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.weight False\n",
            "0.bias False\n",
            "2.weight True\n",
            "2.bias True\n"
          ]
        }
      ],
      "source": [
        "model.requires_grad_(False)\n",
        "model[2].requires_grad_(True)\n",
        "\n",
        "for name, parameters in model.named_parameters():\n",
        "    print(name, parameters.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0718f659",
      "metadata": {
        "id": "0718f659"
      },
      "source": [
        "As a result, only the corresponding parameters will require gradients. During the optimization process, only those parameters that require gradients will be updated."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fe2df83",
      "metadata": {
        "id": "4fe2df83"
      },
      "source": [
        "## Copying model\n",
        "\n",
        "There are many cases where you will need to make a copy of a torch model. However, there are some issues associated with this. This section discusses those issues."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5df780be",
      "metadata": {
        "id": "5df780be"
      },
      "source": [
        "---\n",
        "\n",
        "An obvious example is that copying through the `=` operator merely assigns a new name to the same object. The following cell creates a simple `torch.nn.Module` and displays its parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "12a0c5ba",
      "metadata": {
        "id": "12a0c5ba",
        "outputId": "45620598-0b73-4432-db97-af46f1daa1e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.3469,  0.2282, -0.4584],\n",
              "        [ 0.3923, -0.0788, -0.3660],\n",
              "        [ 0.3362, -0.4471, -0.4651]], requires_grad=True)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = torch.nn.Linear(in_features=3, out_features=3, bias=False)\n",
        "next(iter(model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a17c01b9",
      "metadata": {
        "id": "a17c01b9"
      },
      "source": [
        "Now, suppose, you've made a copy of the model using the `=` operator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5983884d",
      "metadata": {
        "id": "5983884d"
      },
      "outputs": [],
      "source": [
        "copy_model = model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d0df74b",
      "metadata": {
        "id": "3d0df74b"
      },
      "source": [
        "Now, imagine the original object was edited in some way—the following cell assigns a matrix of ones to the parameters we saw before. The key point is that the parameters of the \"copy\" were also edited."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0d878478",
      "metadata": {
        "id": "0d878478",
        "outputId": "e624c3cc-3099-4c44-aa46-df636e46467d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]], requires_grad=True)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(model.parameters())).data = torch.ones(3, 3)\n",
        "next(iter(copy_model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b941ee33",
      "metadata": {
        "id": "b941ee33"
      },
      "source": [
        "### Deep copy\n",
        "\n",
        "One option is to use the \"classical\" Python `copy.deepcopy`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdbfb0ed",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "The following cell demonstrates that a copy made through `deepcopy` preserves all the properties of the original model at the moment of creation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b4ed1e73",
      "metadata": {
        "id": "b4ed1e73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0346, -0.4097,  0.0998],\n",
              "        [ 0.2439,  0.1766, -0.2577],\n",
              "        [-0.0638, -0.3555,  0.1458]], requires_grad=True)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = torch.nn.Linear(in_features=3, out_features=3, bias=False)\n",
        "models_copy = deepcopy(model)\n",
        "next(iter(model.parameters())).data = torch.ones(3, 3)\n",
        "next(iter(models_copy.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4e1d808",
      "metadata": {},
      "source": [
        "**Note:** `deepcopy` will replicate the model on the device the original model is on. The following cell attempts to `deepcopy` a model on the GPU, and the copied model will also be on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "YG9p7ZSC4ElH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "YG9p7ZSC4ElH",
        "outputId": "94ef7ff4-a786-417b-bef4-edf43d10cd9c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = torch.nn.Linear(\n",
        "    in_features=3, \n",
        "    out_features=10, \n",
        "    bias=False\n",
        ").to(\n",
        "    device=torch.device(\"cuda\")\n",
        ")\n",
        "model_copy = deepcopy(model)\n",
        "next(iter(model_copy.parameters())).device.type"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p8QfZUXO4qL0",
      "metadata": {
        "id": "p8QfZUXO4qL0"
      },
      "source": [
        "### State dict\n",
        "\n",
        "Another option is to recreate model and pass to `load_state_dict` of the recreated model, `state_dict` of the original model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edef193e",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "In the following cell, this trick is demonstrated — `copy_model` still retains the parameters of the copied model as they were at the moment of copying."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "7d50a633",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.2850, -0.3748,  0.5246],\n",
              "        [ 0.0166, -0.5607, -0.5215],\n",
              "        [ 0.4310, -0.5429, -0.2672]], requires_grad=True)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = torch.nn.Linear(\n",
        "    in_features=3,\n",
        "    out_features=3,\n",
        "    bias=False\n",
        ")\n",
        "\n",
        "copy_model = torch.nn.Linear(\n",
        "    in_features=3,\n",
        "    out_features=3,\n",
        "    bias=False\n",
        ")\n",
        "copy_model.load_state_dict(model.state_dict())\n",
        "next(iter(model.parameters())).data = torch.zeros(3, 3)\n",
        "next(iter(copy_model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42add6b8",
      "metadata": {},
      "source": [
        "And there aren’t any issues with GPUs. The copied model will retain the device it had during creation — meaning the state dict will be loaded to the `cpu`, which is the preferable option in most cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "plyMto1s4vly",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "plyMto1s4vly",
        "outputId": "b7fc8520-d405-4082-a81f-fa626c336378"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = torch.nn.Linear(\n",
        "    in_features=3,\n",
        "    out_features=10,\n",
        "    bias=False\n",
        ").to(device=torch.device(\"cuda\"))\n",
        "\n",
        "copy_model = torch.nn.Linear(\n",
        "    in_features=3,\n",
        "    out_features=10,\n",
        "    bias=False\n",
        ")\n",
        "copy_model.load_state_dict(state_dict=model.state_dict())\n",
        "next(iter(copy_model.parameters())).device.type"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
