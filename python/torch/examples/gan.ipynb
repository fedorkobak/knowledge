{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gan\n",
    "\n",
    "This notebook covers the process of building a Generative Adversarial Network (GAN) and it's application to the `MNIST` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(\"using device\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As example `MNIST` dataset will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST(\n",
    "    Path(\"mnist_files\"),\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=T.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator's feature map\n",
    "ngf = 64\n",
    "# Input channels\n",
    "nc = 1\n",
    "# Size of the vector from which generator will create a picture\n",
    "nz = 100\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # (nz) x 1 x 1\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=nz, \n",
    "                out_channels=ngf * 2, \n",
    "                kernel_size=7,\n",
    "                stride=1, \n",
    "                padding=0, \n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # (ngf*2) x 7 x 7\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # (ngf) x 14 x 14\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh(),\n",
    "            # (nc) x 28 x 28\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Discriminator's feature map\n",
    "ndf = 64\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # (nc) x 28 x 28\n",
    "            nn.Conv2d(\n",
    "                in_channels=nc, \n",
    "                out_channels=ndf, \n",
    "                kernel_size=4, \n",
    "                stride=2, \n",
    "                padding=1, \n",
    "                bias=False\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "\n",
    "            # (ndf) x 14 x 14\n",
    "            nn.Conv2d(\n",
    "                in_channels=ndf, \n",
    "                out_channels=ndf * 2, \n",
    "                kernel_size=4, \n",
    "                stride=2, \n",
    "                padding=1, \n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "\n",
    "            # (ndf*2) x 7 x 7\n",
    "            nn.Conv2d(\n",
    "                in_channels=ndf * 2, \n",
    "                out_channels=1, \n",
    "                kernel_size=7, \n",
    "                stride=1, \n",
    "                padding=0, \n",
    "                bias=False\n",
    "            ),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "netG = Generator().to(DEVICE)\n",
    "netG = netG.apply(weights_init)\n",
    "\n",
    "netD = Discriminator().to(DEVICE)\n",
    "netD = netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "lr = 0.001\n",
    "beta1 = 0.5\n",
    "\n",
    "# We'll draw images from the same input to compare results.\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=DEVICE)\n",
    "\n",
    "# Labels for real and fake images\n",
    "real_label, fake_label = 1., 0.\n",
    "\n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "num_epochs = 10\n",
    "dataloader = DataLoader(train_dataset)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        real_batch = data[0].to(DEVICE)\n",
    "        batch_size = real_batch.size(0)\n",
    "        \n",
    "\n",
    "        # Maximazing over discriminator log(D(x)) + log(1 - D(G(z)))\n",
    "        # Step on the real image\n",
    "        netD.zero_grad()\n",
    "        label = torch.full((batch_size,), real_label, dtype=torch.float, device=DEVICE)\n",
    "        output = netD(real_batch).view(-1)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # Step on the fake image\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=DEVICE)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Maximizing for generator log(D(G(z)))\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        output = netD(fake).view(-1)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(\n",
    "                \"[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f\"\n",
    "                % (\n",
    "                    epoch,\n",
    "                    num_epochs,\n",
    "                    i,\n",
    "                    len(dataloader),\n",
    "                    errD.item(),\n",
    "                    errG.item(),\n",
    "                    D_x,\n",
    "                    D_G_z1,\n",
    "                    D_G_z2,\n",
    "                )\n",
    "            )\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        if (iters % 500 == 0) or (\n",
    "            (epoch == num_epochs - 1) and (i == len(dataloader) - 1)\n",
    "        ):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noize = torch.randn(batch_size, nz, 1, 1, device=DEVICE)\n",
    "plt.imshow(netG(noize).squeeze().detach().numpy())\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
