{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "686c74bd-4d60-42b5-9f00-006801892d41",
   "metadata": {},
   "source": [
    "# Differentiation\n",
    "\n",
    "Torch has tools that allow you to calculate derivatives. This page created for this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6adde5-b680-4ff4-b42a-d2ce2a5f0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f9ea1-7d1d-4d0a-89c3-f5650c4aceab",
   "metadata": {},
   "source": [
    "## Basic\n",
    "\n",
    "To compute derivative in torch you need to create `torch.tensor` with the property `requires_grad = True` so that torch will look for the gradient of any function this tensor is involved in.\n",
    "\n",
    "Then we need to define a function that depends on the tensor under consideration. And call the `backward` method from it - it will compute partial derivatives for each tensor on which it depends.\n",
    "\n",
    "After previous step you will have derivative values in `grad` field of tensor under consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485da64a-0281-44fc-a380-44e8ae900c05",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "Let's say we have function:\n",
    "\n",
    "$$y(\\omega)=\\sum_i^n 3\\omega_i.$$\n",
    "\n",
    "And we need to find the derivative of the function on the variables $\\omega_i, i\\in\\overline{1,n}$. Let's do it by hand at first:\n",
    "\n",
    "$$\\frac{dy}{d \\omega_i} = \\sum_j^n\\frac{d3\\omega_j}{d \\omega_i} = \\sum_j^n3\\frac{d\\omega_j}{d \\omega_i}.$$\n",
    "\n",
    "And that's considering the fact that:\n",
    "\n",
    "$$\\frac{d \\omega_i}{d \\omega_j} = \\begin{cases} 0 , i\\neq j; \\\\ 1 , i=j.\\end{cases}$$\n",
    "\n",
    "We got:\n",
    "\n",
    "$$\\frac{dy}{d \\omega_i} = 3.$$\n",
    "\n",
    "The implementation of this example in Torch is listed in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "626d8d98-838f-467f-aa29-94188c61fea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 3., 3., 3.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "w = torch.rand(n, requires_grad = True)\n",
    "y = torch.sum(w*3)\n",
    "y.backward()\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612d82c1-d2e5-4c4d-af4e-37e18d41ea38",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "Now we have a slightly more complicated function:\n",
    "\n",
    "$$y(\\omega, \\gamma)=\\sum_i^n \\omega_i \\gamma_i.$$\n",
    "\n",
    "So derivatives by $\\omega_i$ and $\\gamma_i, i \\in \\overline{1,n}$ accordingly:\n",
    "\n",
    "$$\\frac{dy}{d \\omega_i} = \\sum_j^n\\frac{d\\omega_j\\gamma_j}{d \\omega_i} = \\sum_j^n\\gamma_j\\frac{d\\omega_j}{d \\omega_i}=\\gamma_i;$$\n",
    "$$\\frac{dy}{d \\gamma_i} = \\sum_j^n\\frac{d\\omega_j\\gamma_j}{d \\gamma_i} = \\sum_j^n\\omega_j\\frac{d\\gamma_j}{d \\gamma_i}=\\omega_i.$$\n",
    "\n",
    "And the implementation in the Torch for this case will look like the following cell. The main purpose of this example is to show that if the derivative contains a variable, its value is substituted into the expression. So in the example:\n",
    "\n",
    "- $\\omega=(1,2,3,4)$ - so derivatives of the $\\gamma_i$ take these values;\n",
    "- likewise $\\gamma=(5,6,7,8)$ - derivatvies of the $\\omega_i$ take these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5e36335-e2b3-48ff-8fc6-891bcd6ba0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omega gradient value\n",
      "tensor([5., 6., 7., 8.])\n",
      "gamma gradient value\n",
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor([1, 2, 3, 4], dtype = torch.float, requires_grad = True)\n",
    "g = torch.tensor([5, 6, 7, 8], dtype = torch.float, requires_grad = True)\n",
    "\n",
    "y = torch.matmul(w, g)\n",
    "y.backward()\n",
    "print(\"omega gradient value\")\n",
    "print(w.grad)\n",
    "print(\"gamma gradient value\")\n",
    "print(g.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
