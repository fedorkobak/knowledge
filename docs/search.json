[
  {
    "objectID": "layout/css.html",
    "href": "layout/css.html",
    "title": "CSS",
    "section": "",
    "text": "Few details about building css styles.\nfrom IPython.display import HTML"
  },
  {
    "objectID": "layout/css.html#integrated",
    "href": "layout/css.html#integrated",
    "title": "CSS",
    "section": "Integrated",
    "text": "Integrated\nBy using style attribute inside definition of element:\n\n%%HTML\n&lt;p style=\"color:red\"&gt;Red paragraph&lt;/p&gt;\n\nRed paragraph"
  },
  {
    "objectID": "layout/css.html#insideoutsize",
    "href": "layout/css.html#insideoutsize",
    "title": "CSS",
    "section": "Inside/Outsize",
    "text": "Inside/Outsize\n\nInside\nYou can use &lt;style&gt; tag inside &lt;head&gt; of html page. More details in html-&gt;style_tag. And basic example displayed here.\n\n\nOutsize\nWith &lt;link rel=\"stylesheet\"&gt; tag for giving reference for special css file. Here you can check an example of using &lt;link rel=\"stylesheet\"&gt; tag."
  },
  {
    "objectID": "layout/css.html#basic-selectors",
    "href": "layout/css.html#basic-selectors",
    "title": "CSS",
    "section": "Basic selectors",
    "text": "Basic selectors\nYou can apply some style:\n\nto all definitions of specific tag;\nto elements with specific class .class_name;\nto element with specific id #id_name;\nto each element of the page with universal selector *.\n\nSo the basic css syntax looks like:\n    * {property_1:value_1, property_1:value_1, ...}\n    &lt;tag name 1&gt; {property_1_1:value_1_1, property_1_2:value_1_2, ...}\n    &lt;tag name 2&gt; {property_2_1:value_2_1, property_2_2:value_2_2, ...}\n    ...\n    &lt;tag name n&gt; {property_n_1:value_n_1, property_n_2:value_n_2, ...}\n    .&lt;class name 1&gt; {property_n+1_1:value_n+1_1, property_n+1_2:value_n+1_2, ...}\n    .&lt;class name 2&gt; {property_n+2_1:value_n+2_1, property_n+2_2:value_n+2_2, ...}\n    ...\n    .&lt;class name k&gt; {property_n+k_1:value_n+k_1, property_n+k_2:value_n+k_2, ...}\n    #&lt;id name 1&gt; property_n+k+1_1:value_n+k+1_1, property_n+k+1_2:value_n+k+1_2, ...}\n    #&lt;id name 2&gt; property_n+k+2_1:value_n+k+2_1, property_n+k+2_2:value_n+k+2_2, ...}\n    ...\n    #&lt;id name m&gt; property_n+k+m_1:value_n+k+m_1, property_n+k+m_2:value_n+k+m_2, ...}\nIn the following example, I use all of these options. See the results here.\n\ndisplay(HTML('''&lt;hr&gt;'''))\nwith open(\"css_files/selectors.html\") as file:\n    print(file.read())\ndisplay(HTML('''&lt;hr&gt;'''))\n\n\n\n\n&lt;head&gt;\n&lt;style&gt;\n  * {background-color: purple;}\n  h1 {background-color: red;}\n  #spec_id {background-color: green;} \n  .spec_class {background-color: yellow;}\n&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n\n&lt;p&gt;not header at all&lt;/p&gt;\n&lt;h1&gt;just header&lt;/h1&gt;\n&lt;h1 class=\"spec_class\"&gt;header with class&lt;/h1&gt;\n&lt;h1  id=\"spec_id\" class=\"spec_class\"&gt;header with id&lt;/h1&gt;\n&lt;h1  id=\"spec_id\" class=\"spec_class\" style=\"background-color: blue;\"&gt;header with style&lt;/h1&gt;\n\n&lt;/body&gt;\n\n\n\n\n\nNote the last example shows that properties mentioned for tag are less important than properties mentioned for class. Id properties are more important than class properties. And properties mentioned in the style attribute have the higher priority."
  },
  {
    "objectID": "layout/css.html#combination-selectors",
    "href": "layout/css.html#combination-selectors",
    "title": "CSS",
    "section": "Combination selectors",
    "text": "Combination selectors\nYou can define selector relatevety other selector.\n\nDescendant selector A B\nIf you are using the following syntax.\nA B : {property_1:value_1, property_1:value_1, ...}\nWhere A and B are some other selectors. You will apply properties to items belonging to selector B, but only to A’s descendant at the same time.\nFor example I setted blue font and red background for each elemnt with class my_class. But by using div .my_class {...} slector I set a different background color for each .my_class instance inside div.\n\ndisplay(HTML('''&lt;hr&gt;'''))\nwith open(\"css_files/descendant_selector.html\") as file:\n    print(file.read())\ndisplay(HTML('''&lt;hr&gt;'''))\n\n\n\n\n&lt;header&gt;&lt;style&gt;\n    .my_class {\n        background: red;\n        color: blue\n    }\n    div .my_class {\n        background: green\n    }\n&lt;/style&gt;&lt;/header&gt;\n&lt;p class=\"my_class\"&gt;Just paragraph&lt;/p&gt;\n&lt;div&gt;\n    &lt;p class=\"my_class\"&gt;Paragraph in div&lt;/p&gt;\n    &lt;table&gt;\n        &lt;tr&gt;\n            &lt;td&gt;&lt;text class=\"my_class\"&gt;my_class&lt;/text&gt;&lt;/td&gt;\n            &lt;td&gt;&lt;text&gt;some other cell&lt;/text&gt;&lt;/text&gt;&lt;/td&gt;&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;\n            &lt;td&gt;&lt;text&gt;some other cell&lt;/text&gt;&lt;/td&gt;\n            &lt;td&gt;&lt;text class=\"my_class\"&gt;my_class&lt;/text&gt;&lt;/td&gt;\n        &lt;/tr&gt;\n    &lt;/table&gt;\n&lt;/div&gt;\n&lt;p class=\"my_class\"&gt;Just paragraph&lt;/p&gt;\n\n\n\n\n\nSee the result here.\n\n\nDaughter selector A &gt; B\nIf you are using the following syntax:\nA B : {property_1:value_1, property_1:value_1, ...}\nWhere A and B are some other selectors. You will apply properties to items belonging to selector B, but only to A’s daughter element at the same timу (an element B is a child of element A if element B is a direct descendant of element A, i.e. there are no other levels of inheritance between them).\nSo in the following example I define red background for colour for each p tag. But by using the syntax .some_class &gt; p {background: yellow} I set yellow back ground to each daughter of .some_class instances.\nThe main feature of the example is that I have used pargraphs:\n\nOnly paragraph - obvious red colour;\nDaughter paragraph of &lt;div class=\"some_class\"&gt; - obvious yellow color;\nDescendant of &lt;div class=\"some_class\"&gt; but not daughter - red color.\n\nSee the result here.\n\ndisplay(HTML('''&lt;hr&gt;'''))\nwith open(\"css_files/daughter_selector.html\") as file:\n    print(file.rea())\ndisplay(HTML('''&lt;hr&gt;'''))\n\n\n\n\n&lt;header&gt;\n    &lt;style&gt;\n        .some_class {\n            background: red\n        }\n        .some_class &gt; p {\n            background: yellow\n        }\n    &lt;/style&gt;\n&lt;/header&gt;\n\n&lt;p&gt;some random paragraph&lt;/p&gt;\n&lt;div class=\"some_class\"&gt;\n    &lt;p&gt;Test paragraph daughter of some_class&lt;/p&gt;\n    &lt;div&gt;\n        &lt;p&gt;Test paragraph descendant but not daughter of some_class&lt;/p&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n\n\n\n\n\n\nNext element selector A+B\nIf you are using the following syntax:\nA+B : {property_1:value_1, property_1:value_1, ...}\nWhere A and B are some other selectors. Will apply properties to all elements belonging to the B selector, but only next to elements belonging to A within a parent.\nSo in following example I using syntax p+p {background:purple}. As a result every paragraph after another paragraph will have a purple background:\n\nFirst paragraph - obviously nothing before that =&gt; no colour;\nSecond paragraph - next to the first paragraph =&gt; purple colour;\nThird paragraph - next to the second paragraph =&gt; purple colour;\nForth paragraph - the first inside this div =&gt; no colour;\nFifth paragraph - next to the forth in the same div =&gt; purple color;\nSixth paragraph - next to div, not paragraph =&gt; no color.\n\nSee results here.\n\ndisplay(HTML('''&lt;hr&gt;'''))\nwith open(\"css_files/next_element_selector.html\") as file:\n    print(file.read())\ndisplay(HTML('''&lt;hr&gt;'''))\n\n\n\n\n&lt;head&gt;\n    &lt;style&gt;\n        p~p {background:purple}\n    &lt;/style&gt;\n&lt;/head&gt;\n\n&lt;p&gt;First paragraph&lt;/p&gt;\n&lt;p&gt;Second paragraph&lt;/p&gt;\n&lt;p&gt;Third paragraph&lt;/p&gt;\n\n&lt;div&gt;\n    &lt;p&gt;Fourth paragraph (in div)&lt;/p&gt;\n    &lt;p&gt;Fifth paragraph (in div)&lt;/p&gt;\n&lt;/div&gt;\n\n&lt;p&gt;Sixth paragraph&lt;/p&gt;\n\n\n\n\n\n\n\nAfter element selector A~B\nIf you are using the following syntax:\nA~B : {property_1:value_1, property_1:value_1, ...}\nWhere A and B are some other selectors. Will apply properties to all elements belonging to the B selector, but only after elements belonging to A within a parent.\nIn following exmaple I use syntax #my_id~p {background: yellow}. So every paragraph after an element with id=my_id with same parent should have yellow background. See result here.\nA detailed breakdown of the result:\n\nFirst paragraph - obviously nothing before that =&gt; no colour;\nSecond paragraph - have only first paragraph before wich don’t have any id =&gt; no colour;\nThird paragraph - have second paragraph before, which have an id=my_id =&gt; yellow colour;\nForth paragraph - first paragraph in the div =&gt; no colour;\nFifth paragraph - have second paragraph before, which have an id=my_id =&gt; yellow colour.\n\n\ndisplay(HTML('''&lt;hr&gt;'''))\nwith open(\"css_files/after_element_selector.html\") as file:\n    print(file.read())\ndisplay(HTML('''&lt;hr&gt;'''))\n\n\n\n\n&lt;head&gt;\n    &lt;style&gt;\n        #my_id~p {background: yellow}\n    &lt;/style&gt;\n&lt;/head&gt;\n\n&lt;p&gt;First paragraph&lt;/p&gt;\n&lt;p id=\"my_id\"&gt;Second paragraph with id&lt;/p&gt;\n&lt;p&gt;Third paragraph&lt;/p&gt;\n&lt;div&gt;\n    &lt;p&gt;Fourth paragraph&lt;/p&gt;\n&lt;/div&gt;\n&lt;p&gt;Fiftht paragraph&lt;/p&gt;\n\n\n\n\n\nNote аlways prioritise the style that is listed later. In following example I have two divs:\n\nFirst div:\n\nFirst paragraph make second paragraph to have yellow background;\nThird paragraph make fourth, fifth, sixth to have purple colour;\nSixth paragraph doesn’t return yellow colour;\n\nSecond div:\n\nFist paragraph make all paragraphs after to have a purple color;\nThird paragraph doesn’t make the folowing paragraphs yellow.\n\n\nSee result here.\nLooks like that style for id_two was defined later so this style is preferable than style defined for id_one.\n\ndisplay(HTML('''&lt;hr&gt;'''))\nwith open(\"css_files/after_element_selector_hierarchy.html\") as file:\n    print(file.read())\ndisplay(HTML('''&lt;hr&gt;'''))\n\n\n\n\n&lt;head&gt;\n    &lt;style&gt;\n        #id_one~p {background: yellow}\n        #id_two~p {background: purple}\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;h1&gt;div1&lt;/h1&gt;\n&lt;div&gt;\n    &lt;p id=\"id_one\"&gt;first paragraph div1&lt;/p&gt;\n    &lt;p&gt;second paragraph div1&lt;/p&gt;\n    &lt;p id=\"id_two\"&gt;third paragraph div1&lt;/p&gt;\n    &lt;p&gt;forth paragraph div1&lt;/p&gt;\n    &lt;p&gt;fifth paragraph div1&lt;/p&gt;\n    &lt;p id=\"id_one\"&gt;sixth paragraph div1&lt;/p&gt;\n    &lt;p id=\"id_one\"&gt;seventh paragraph div1&lt;/p&gt;\n&lt;/div&gt;\n\n&lt;h1&gt;div2&lt;/h1&gt;\n&lt;div&gt;\n    &lt;p id=\"id_two\"&gt;first paragraph div2&lt;/p&gt;\n    &lt;p&gt;second paragraph div2&lt;/p&gt;\n    &lt;p id=\"id_one\"&gt;third paragraph div2&lt;/p&gt;\n    &lt;p&gt;forth paragraph div2&lt;/p&gt;\n    &lt;p&gt;fifth paragraph div2&lt;/p&gt;\n&lt;/div&gt;"
  },
  {
    "objectID": "layout/css.html#properties",
    "href": "layout/css.html#properties",
    "title": "CSS",
    "section": "Properties",
    "text": "Properties\n\ncolor - text color\n\n\n%%HTML\n&lt;text style=\"color:aqua\"&gt;aqua&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:black\"&gt;black&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:blue\"&gt;blue&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:fuchsia\"&gt;fuchsia&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:gray\"&gt;gray&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:green\"&gt;green&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:lime\"&gt;lime&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:maroon\"&gt;maroon&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:navy\"&gt;navy&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:olive\"&gt;olive&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:purple\"&gt;purple&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:red\"&gt;red&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:silver\"&gt;silver&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:teal\"&gt;teal&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:white\"&gt;white&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"color:yellow\"&gt;yellow&lt;/text&gt;&lt;br&gt;\n\naqua\nblack\nblue\nfuchsia\ngray\ngreen\nlime\nmaroon\nnavy\nolive\npurple\nred\nsilver\nteal\nwhite\nyellow\n\n\n\n\nbackground - background color \nNote background-color make the same.\n\n\n%%HTML\n&lt;text style=\"background:aqua\"&gt;aqua&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:black\"&gt;black&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:blue\"&gt;blue&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:fuchsia\"&gt;fuchsia&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:gray\"&gt;gray&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:green\"&gt;green&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:lime\"&gt;lime&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:maroon\"&gt;maroon&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:navy\"&gt;navy&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:olive\"&gt;olive&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:purple\"&gt;purple&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:red\"&gt;red&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:silver\"&gt;silver&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:teal\"&gt;teal&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:white\"&gt;white&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background:yellow\"&gt;yellow&lt;/text&gt;&lt;br&gt;\n\naqua\nblack\nblue\nfuchsia\ngray\ngreen\nlime\nmaroon\nnavy\nolive\npurple\nred\nsilver\nteal\nwhite\nyellow"
  },
  {
    "objectID": "layout/css.html#ways-of-determining",
    "href": "layout/css.html#ways-of-determining",
    "title": "CSS",
    "section": "Ways of determining",
    "text": "Ways of determining\n\nColor name\n\n%%HTML\n&lt;text style=\"color:red\"&gt;red text&lt;/text&gt;\n\nred text\n\n\n\n\nRGB\nUse the following syntax rgb(R, G, B). \\[R,G,B \\in (0,1,2,...,255)\\]\n\n%%HTML\n&lt;text style=\"background-color:rgb(60, 179, 113);\"&gt;rgb(60, 179, 113)&lt;/text&gt;\n\nrgb(60, 179, 113)\n\n\n\n\nRGBA\nUse the following syntax rgba(R, G, B, A). \\[R,G,B \\in (0,1,2,...,255);\\] \\[A \\in [0,1].\\]\n\n\n%%HTML\n&lt;text style=\"background-color:rgba(60, 179, 113, 0.0);\"&gt;rgba(60, 179, 113, 0.0)&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background-color:rgba(60, 179, 113, 0.1);\"&gt;rgba(60, 179, 113, 0.1)&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background-color:rgba(60, 179, 113, 0.2);\"&gt;rgba(60, 179, 113, 0.2)&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background-color:rgba(60, 179, 113, 0.3);\"&gt;rgba(60, 179, 113, 0.3)&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background-color:rgba(60, 179, 113, 0.4);\"&gt;rgba(60, 179, 113, 0.4)&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background-color:rgba(60, 179, 113, 0.5);\"&gt;rgba(60, 179, 113, 0.5)&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background-color:rgba(60, 179, 113, 0.6);\"&gt;rgba(60, 179, 113, 0.6)&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background-color:rgba(60, 179, 113, 0.7);\"&gt;rgba(60, 179, 113, 0.7)&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background-color:rgba(60, 179, 113, 0.8);\"&gt;rgba(60, 179, 113, 0.8)&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background-color:rgba(60, 179, 113, 0.9);\"&gt;rgba(60, 179, 113, 0.9)&lt;/text&gt;&lt;br&gt;\n&lt;text style=\"background-color:rgba(60, 179, 113, 1.0);\"&gt;rgba(60, 179, 113, 1.0)&lt;/text&gt;&lt;br&gt;\n\nrgba(60, 179, 113, 0.0)\nrgba(60, 179, 113, 0.1)\nrgba(60, 179, 113, 0.2)\nrgba(60, 179, 113, 0.3)\nrgba(60, 179, 113, 0.4)\nrgba(60, 179, 113, 0.5)\nrgba(60, 179, 113, 0.6)\nrgba(60, 179, 113, 0.7)\nrgba(60, 179, 113, 0.8)\nrgba(60, 179, 113, 0.9)\nrgba(60, 179, 113, 1.0)\n\n\n\n\nHEX\nUse the following syntax #rrggbb.\n\n%%HTML\n&lt;text style=\"background-color:#afc445;\"&gt;#afc445&lt;/text&gt;\n\n#afc445\n\n\n\n\nHSL\nHue Saturation Lightness.\nUse the following syntax HSL(H,S,L).\nWhere: \\[H \\in [0,360);\\] \\[S, L \\in [0,100].\\]\n\n%%HTML\n&lt;text style=\"background-color:HSL(150, 60%, 50%);\"&gt;HSL(150, 60%, 50%)&lt;/text&gt;\n\nHSL(150, 60%, 50%)\n\n\n\n\nHSLA\nHue Saturation Lightness Alpha.\nUse the following syntax HSL(H,S,L).\nWhere: \\[H \\in [0,360);\\] \\[S, L \\in [0,100];\\] \\[A \\in [0,1].\\]\n\n%%HTML\n&lt;text style=\"background-color:HSL(150, 60%, 50%, 0.3);\"&gt;HSL(150, 60%, 50%, 0.3)&lt;/text&gt;\n\nHSL(150, 60%, 50%, 0.3)"
  },
  {
    "objectID": "layout/css.html#background-color",
    "href": "layout/css.html#background-color",
    "title": "CSS",
    "section": "background-color",
    "text": "background-color\nThis is the property when you can use any color as page background. I have describet it here."
  },
  {
    "objectID": "layout/css.html#background-image",
    "href": "layout/css.html#background-image",
    "title": "CSS",
    "section": "background-image",
    "text": "background-image\nProvide way to fullfill any html element with picture. Use the following syntax:\nbackground-image: url(&lt;path to image&gt;)\nNote: Whether it’s a link or an image on a computer, you have to wrap it in url() in any case.\nAs an example look the following code:\n\ndisplay(HTML(\n    '''\n    &lt;hr&gt;&lt;text style=\\\"font-size:16px\\\"&gt;HTML&lt;/text&gt;\n    '''\n))\nwith open(\"css_files/background_image.html\") as file:\n    print(file.read())\ndisplay(HTML('''&lt;hr&gt;'''))\n\n\n    HTML\n    \n\n\n&lt;div style=\"background-image: url('fractal_css.gif')\"&gt;\n&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;\n&lt;/div&gt;\n\n&lt;div style=\"background-image: url('https://content.codecademy.com/courses/web-101/web101-image_brownbear.jpg')\"&gt;\n&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;\n&lt;/div&gt;\n\n\n\n\n\nYou can check the result here."
  },
  {
    "objectID": "layout/css.html#background-repeat",
    "href": "layout/css.html#background-repeat",
    "title": "CSS",
    "section": "background-repeat",
    "text": "background-repeat\nDescribes the way in which the image represented by the background-image will fill the area (repeat).\nCan take values:\n\nno-repeat - without repeats;\nrepeat - the image repeats horizontally and vertically;\nrepeat-x - the image repeats only horizontally;\nrepeat-y - the image repeats only vertically;\nspace - an integer number of repeats will be used, but if it’s not possible to fullfill area with an integer number of images then spaces will be added;\nround - the whole area must be filled with an integer number of images, the size of the image will be adjusted.\n\nIn the following example, I try all the diggerent options. You can see the result here.\n\ntypes = [\n    \"no-repeat\", \n    \"repate\", \n    \"repeat-x\", \n    \"repeat-y\", \n    \"space\", \n    \"round\"\n]\n\npattern_line = '''\n&lt;h2&gt;{type}&lt;/h2&gt;\n&lt;div style=\"background-image: url('mkpic.webp'); background-repeat: {type};\"&gt;\n    &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;\n&lt;/div&gt;\n'''\nhtml_res = \"\"\n\nfor type in types:\n    html_res += pattern_line.format(type = type)\n\n\n\nwith open(\"css_files/background-repeate.html\", \"w\") as file:\n    file.write(html_res)\n    \ndisplay(HTML('''&lt;hr&gt;'''))\nprint(html_res)\ndisplay(HTML('''&lt;hr&gt;'''))\n\n\n\n\n\n&lt;h2&gt;no-repeat&lt;/h2&gt;\n&lt;div style=\"background-image: url('mkpic.webp'); background-repeat: no-repeat;\"&gt;\n    &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;\n&lt;/div&gt;\n\n&lt;h2&gt;repate&lt;/h2&gt;\n&lt;div style=\"background-image: url('mkpic.webp'); background-repeat: repate;\"&gt;\n    &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;\n&lt;/div&gt;\n\n&lt;h2&gt;repeat-x&lt;/h2&gt;\n&lt;div style=\"background-image: url('mkpic.webp'); background-repeat: repeat-x;\"&gt;\n    &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;\n&lt;/div&gt;\n\n&lt;h2&gt;repeat-y&lt;/h2&gt;\n&lt;div style=\"background-image: url('mkpic.webp'); background-repeat: repeat-y;\"&gt;\n    &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;\n&lt;/div&gt;\n\n&lt;h2&gt;space&lt;/h2&gt;\n&lt;div style=\"background-image: url('mkpic.webp'); background-repeat: space;\"&gt;\n    &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;\n&lt;/div&gt;\n\n&lt;h2&gt;round&lt;/h2&gt;\n&lt;div style=\"background-image: url('mkpic.webp'); background-repeat: round;\"&gt;\n    &lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;\n&lt;/div&gt;"
  },
  {
    "objectID": "layout/css.html#basic",
    "href": "layout/css.html#basic",
    "title": "CSS",
    "section": "Basic",
    "text": "Basic\nAllows you to set borders for the hmlt element. Use the following syntax:\nstyle=\"border: &lt;width&gt; &lt;style&gt; &lt;color&gt;\"\nOr separetely:\nborder-width: &lt;width&gt;;\nborder-style: &lt;style&gt;;\nborder-color: &lt;color&gt;;\n\n\n%%HTML\n&lt;p style=\"border:red solid 5px\"&gt;red solid 5px&lt;/text&gt;&lt;br&gt;\n&lt;p style=\"border:red solid 10px\"&gt;red solid 10px&lt;/text&gt;&lt;br&gt;\n&lt;p style=\"border:red dotted 5px\"&gt;red dotted 5px&lt;/text&gt;&lt;br&gt;\n&lt;p style=\"border:red dotted 10px\"&gt;red dotted 10px&lt;/text&gt;&lt;br&gt;\n&lt;p style=\"border:yellow solid 5px\"&gt;yellow solid 5px&lt;/text&gt;&lt;br&gt;\n&lt;p style=\"border:yellow solid 10px\"&gt;yellow solid 10px&lt;/text&gt;&lt;br&gt;\n&lt;p style=\"border:yellow dotted 5px\"&gt;yellow dotted 5px&lt;/text&gt;&lt;br&gt;\n&lt;p style=\"border:yellow dotted 10px\"&gt;yellow dotted 10px&lt;/text&gt;&lt;br&gt;\n&lt;p style=\"border:green solid 5px\"&gt;green solid 5px&lt;/text&gt;&lt;br&gt;\n&lt;p style=\"border:green solid 10px\"&gt;green solid 10px&lt;/text&gt;&lt;br&gt;\n&lt;p style=\"border:green dotted 5px\"&gt;green dotted 5px&lt;/text&gt;&lt;br&gt;\n&lt;p style=\"border:green dotted 10px\"&gt;green dotted 10px&lt;/text&gt;&lt;br&gt;\n\nred solid 5px\nred solid 10px\nred dotted 5px\nred dotted 10px\nyellow solid 5px\nyellow solid 10px\nyellow dotted 5px\nyellow dotted 10px\ngreen solid 5px\ngreen solid 10px\ngreen dotted 5px\ngreen dotted 10px\n\n\nBy using syntax border:... you can use any sequence of properties - browser should recogise them.\n\n%%HTML\n&lt;p style=\"border:red 3px solid\"&gt;red 3px solid&lt;/p&gt;\n&lt;p style=\"border:3px solid red\"&gt;3px solid red&lt;/p&gt;\n\nred 3px solid\n3px solid red"
  },
  {
    "objectID": "layout/css.html#styles",
    "href": "layout/css.html#styles",
    "title": "CSS",
    "section": "Styles",
    "text": "Styles\nIn following example I mentioned all possible border styles:\n\n\n%%HTML\n&lt;p style=\"border-style:solid\"&gt;solid&lt;/p&gt;\n&lt;p style=\"border-style:dotted\"&gt;dotted&lt;/p&gt;\n&lt;p style=\"border-style:dashed\"&gt;dashed&lt;/p&gt;\n&lt;p style=\"border-style:double\"&gt;double&lt;/p&gt;\n&lt;p style=\"border-style:groove\"&gt;groove&lt;/p&gt;\n&lt;p style=\"border-style:ridge\"&gt;ridge&lt;/p&gt;\n&lt;p style=\"border-style:outset\"&gt;outset&lt;/p&gt;\n&lt;p style=\"border-style:inset\"&gt;inset&lt;/p&gt;\n\nsolid\ndotted\ndashed\ndouble\ngroove\nridge\noutset\ninset"
  },
  {
    "objectID": "layout/css.html#width",
    "href": "layout/css.html#width",
    "title": "CSS",
    "section": "Width",
    "text": "Width\nYou can set border widht: - In some measures: px, pt, cm, em etc.; - Using keywords: thin, medium, thick.\n\n\n%%HTML\n&lt;p style=\"border-width: top_bottom left_right;\"&gt;fsdf&lt;/p&gt;\n\nfsdf\n\n\n\n%%HTML\n&lt;p style=\"border:3px solid\"&gt;3px solid&lt;/p&gt;\n&lt;p style=\"border:3pt solid\"&gt;3pt solid&lt;/p&gt;\n&lt;p style=\"border:3cm solid\"&gt;3cm solid&lt;/p&gt;\n&lt;p style=\"border:3em solid\"&gt;3em solid&lt;/p&gt;\n&lt;p style=\"border:thin solid\"&gt;thin solid&lt;/p&gt;\n&lt;p style=\"border:medium solid\"&gt;medium solid&lt;/p&gt;\n&lt;p style=\"border:thick solid\"&gt;thick solid&lt;/p&gt;\n\n3px solid\n3pt solid\n3cm solid\n3em solid\nthin solid\nmedium solid\nthick solid"
  },
  {
    "objectID": "layout/css.html#different-borders",
    "href": "layout/css.html#different-borders",
    "title": "CSS",
    "section": "Different borders",
    "text": "Different borders\n\nSyntax 1\nYou can specify different settings for different borders using syntax:\n\nborder-&lt;width/color/style&gt;: &lt;top and bottom&gt; &lt;left and right&gt;;\nborder-&lt;width/color/style&gt;: &lt;top&gt; &lt;left and right&gt; &lt;bottom&gt;;\nborder-&lt;width/color/style&gt;: &lt;top&gt; &lt;right&gt; &lt;bottom&gt; &lt;left&gt;.\n\nYou can check it by following example:\n\n\n%%HTML\n&lt;p style=\"border-width:3px ; border-style:solid ; border-color:red \"&gt;widthes:3px |colors:red |styles:solid &lt;/p&gt;\n&lt;p style=\"border-width:3px 9px ; border-style:solid dotted ; border-color:red yellow \"&gt;widthes:3px 9px |colors:red yellow |styles:solid dotted &lt;/p&gt;\n&lt;p style=\"border-width:3px 9px 15px ; border-style:solid dotted dashed ; border-color:red yellow green \"&gt;widthes:3px 9px 15px |colors:red yellow green |styles:solid dotted dashed &lt;/p&gt;\n&lt;p style=\"border-width:3px 9px 15px 21px ; border-style:solid dotted dashed double ; border-color:red yellow green purple \"&gt;widthes:3px 9px 15px 21px |colors:red yellow green purple |styles:solid dotted dashed double &lt;/p&gt;\n\nwidthes:3px |colors:red |styles:solid \nwidthes:3px 9px |colors:red yellow |styles:solid dotted \nwidthes:3px 9px 15px |colors:red yellow green |styles:solid dotted dashed \nwidthes:3px 9px 15px 21px |colors:red yellow green purple |styles:solid dotted dashed double \n\n\n\n\nSyntax 2\nYou can specify different settings for different borders using syntax border-&lt;\"\"/top/bottom/left/right&gt;-&lt;\"\"/color/style/width&gt;.\n\n%%HTML\n&lt;p style=\"border-top-style:dotted\"&gt;border-top-style:dotted&lt;/p&gt;\n&lt;p style=\"border-bottom:dashed 10px blue\"&gt;border-bottom:dashed 10px blue&lt;/p&gt;\n\nborder-top-style:dotted\nborder-bottom:dashed 10px blue"
  },
  {
    "objectID": "layout/css.html#corner-rounding",
    "href": "layout/css.html#corner-rounding",
    "title": "CSS",
    "section": "Corner rounding",
    "text": "Corner rounding\nYou can set borders rounding by using the following syntax:\n\nborder-&lt;top/bottom&gt;-&lt;left/right&gt;-radius: &lt;value&gt;;\nborder-radius: &lt;all egtes value&gt;;\nborder-radius: &lt;top-left and bottom-right&gt; &lt;bottom-left and top-right&gt;;\nborder-radius: &lt;top-left&gt; &lt;bottom-left and top-right&gt; &lt;bottom-right&gt;;\nborder-radius: &lt;top-left&gt; &lt;top-right&gt; &lt;bottom-right&gt; &lt;bottom-left&gt;;\n\nYou can check all these options in the following example:\n\n%%HTML\n&lt;p style=\"border-top-left-radius:10px; border: solid\"&gt;border-top-left-radius:10px&lt;/p&gt;\n&lt;p style=\"border-radius: 10px; border: solid\"&gt;border-radius: 10px&lt;/p&gt;\n&lt;p style=\"border-radius: 10px 30px; border: solid\"&gt;border-radius: 10px 30px&lt;/p&gt;\n&lt;p style=\"border-radius: 10px 0px 20px; border: solid\"&gt;border-radius: 10px 0px 20px&lt;/p&gt;\n&lt;p style=\"border-radius: 10px 0px 20px 30px; border: solid\"&gt;border-radius: 10px 0px 20px 30px&lt;/p&gt;\n\nborder-top-left-radius:10px\nborder-radius: 10px\nborder-radius: 10px 30px\nborder-radius: 10px 0px 20px\nborder-radius: 10px 0px 20px 30px"
  },
  {
    "objectID": "layout/css.html#basic-1",
    "href": "layout/css.html#basic-1",
    "title": "CSS",
    "section": "Basic",
    "text": "Basic\nBy using this property you can set distance from outside elemnts. Use following syntax:\n\nmargin-&lt;top/left/right/bottom&gt;: &lt;value&gt;;\nmargin: &lt;value for all sides&gt;;\nmargin: &lt;top and bottom&gt; &lt;left and right&gt;;\nmargin: &lt;top&gt; &lt;left and right&gt; &lt;bottom&gt;;\nmargin: &lt;top&gt; &lt;right&gt; &lt;bottom&gt; &lt;left&gt;.\n\n\n%%HTML\n&lt;div style=\"border:solid green\"&gt;\n    &lt;div style=\"border:solid 10px; margin-top: 10px\"&gt;Upper element&lt;/div&gt;\n    &lt;div style=\"border:solid 10px; margin: 50px 0px 100px 50px\"&gt;Middle element&lt;/div&gt;\n    &lt;div style=\"border:solid 10px\"&gt;Lower element&lt;/div&gt;\n&lt;/div&gt;\n\n\n    Upper element\n    Middle element\n    Lower element"
  },
  {
    "objectID": "layout/css.html#available-values",
    "href": "layout/css.html#available-values",
    "title": "CSS",
    "section": "Available values",
    "text": "Available values\nValue can be setted as:\n\npx, cm, pt etc.\ninherit - use option like parent;\nauto.\n\n\nInherit\n\n%%HTML\n&lt;div style=\"border:solid green\"&gt;\n    &lt;div style=\"border:solid 10px red; margin: 0px 30px 100px 50px\"&gt;\n        &lt;div style=\"border:solid 10px; margin: inherit\"&gt;margin: inherit&lt;/div&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n\n    \n        margin: inherit\n    \n\n\n\n\n\nAuto\nWith this option, the element will take up all available vertical space and be centred horizontally.\n\n%%HTML\n&lt;div style=\"border:solid green\"&gt;\n    &lt;div style=\"border:solid 10px red; margin: auto;width: 500px; height: 200px\"&gt;\n        border:solid 10px red; margin: auto;width: 500px; height: 200px\n    &lt;/div&gt;\n&lt;/div&gt;\n\n\n    \n        border:solid 10px red; margin: auto;width: 500px; height: 200px\n    \n\n\n\n\n%%HTML\n&lt;div style=\"border:solid green\"&gt;\n    &lt;div&gt;Some other div&lt;/div&gt;\n    &lt;div style=\"border:solid 10px red; margin: auto;width: 500px; height: 200px\"&gt;\n        border:solid 10px red; margin: auto;width: 500px; height: 200px\n    &lt;/div&gt;\n&lt;/div&gt;\n\n\n    Some other div\n    \n        border:solid 10px red; margin: auto;width: 500px; height: 200px"
  },
  {
    "objectID": "layout/css.html#slamming-the-indentation",
    "href": "layout/css.html#slamming-the-indentation",
    "title": "CSS",
    "section": "Slamming the indentation",
    "text": "Slamming the indentation\nIf you are unig two elememtns close and:\n\nTop element has bottom margin;\nBottom element has top margin;\n\nThe browser interprets this as an offset equal to the maximum of the original. In the following example, you can compare two blocks with two 200px margins and two blocks with only one 400px margin.\n\n%%HTML\n&lt;div style=\"border:solid green\"&gt;\n    &lt;div style=\"margin-bottom: 200px;border:solid red\"&gt;Top div&lt;/div&gt;\n    &lt;div style=\"margin-top: 200px; border:solid red\"&gt; Bottom div&lt;/div&gt;\n&lt;/div&gt;\n&lt;div style=\"border:solid green\"&gt;\n    &lt;div style=\"margin-bottom: 400px;border:solid red\"&gt;Top div&lt;/div&gt;\n    &lt;div style=\"border:solid red\"&gt; Bottom div&lt;/div&gt;\n&lt;/div&gt;\n\n\n    Top div\n     Bottom div\n\n\n    Top div\n     Bottom div"
  },
  {
    "objectID": "layout/css.html#width-1",
    "href": "layout/css.html#width-1",
    "title": "CSS",
    "section": "width",
    "text": "width\nNot to be confused with the width attribute\nYou can set width using:\n\npx, cm, em;\npercentage relative to parent size;\ninherit - using same values as parent;\nauto.\n\n\n%%HTML\n&lt;strong&gt;No width option&lt;/strong&gt;\n&lt;p&gt;\nLorem ipsum dolor sit amet, consectetur adipiscing elit. \nEtiam semper diam at erat pulvinar, at pulvinar felis blandit. \nVestibulum volutpat tellus diam, consequat gravida libero rhoncus ut.\nMaecenas imperdiet felis nisi, fringilla luctus felis hendrerit\nsit amet. Pellentesque interdum, nisl nec interdum maximus, augue\ndiam porttitor lorem, et sollicitudin felis neque sit amet erat.\n&lt;/p&gt;\n\n&lt;strong&gt;Width 200px&lt;/strong&gt;\n&lt;p style=\"width:200px\"&gt;\nLorem ipsum dolor sit amet, consectetur adipiscing elit. \nEtiam semper diam at erat pulvinar, at pulvinar felis blandit. \nVestibulum volutpat tellus diam, consequat gravida libero rhoncus ut.\nMaecenas imperdiet felis nisi, fringilla luctus felis hendrerit\nsit amet. Pellentesque interdum, nisl nec interdum maximus, augue\ndiam porttitor lorem, et sollicitudin felis neque sit amet erat.\n&lt;/p&gt;\n\n&lt;strong&gt;Width 50%&lt;/strong&gt;\n&lt;p style=\"width:50%\"&gt;\nLorem ipsum dolor sit amet, consectetur adipiscing elit. \nEtiam semper diam at erat pulvinar, at pulvinar felis blandit. \nVestibulum volutpat tellus diam, consequat gravida libero rhoncus ut.\nMaecenas imperdiet felis nisi, fringilla luctus felis hendrerit\nsit amet. Pellentesque interdum, nisl nec interdum maximus, augue\ndiam porttitor lorem, et sollicitudin felis neque sit amet erat.\n&lt;/p&gt;\n\nNo width option\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. \nEtiam semper diam at erat pulvinar, at pulvinar felis blandit. \nVestibulum volutpat tellus diam, consequat gravida libero rhoncus ut.\nMaecenas imperdiet felis nisi, fringilla luctus felis hendrerit\nsit amet. Pellentesque interdum, nisl nec interdum maximus, augue\ndiam porttitor lorem, et sollicitudin felis neque sit amet erat.\n\n\nWidth 200px\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. \nEtiam semper diam at erat pulvinar, at pulvinar felis blandit. \nVestibulum volutpat tellus diam, consequat gravida libero rhoncus ut.\nMaecenas imperdiet felis nisi, fringilla luctus felis hendrerit\nsit amet. Pellentesque interdum, nisl nec interdum maximus, augue\ndiam porttitor lorem, et sollicitudin felis neque sit amet erat.\n\n\nWidth 50%\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. \nEtiam semper diam at erat pulvinar, at pulvinar felis blandit. \nVestibulum volutpat tellus diam, consequat gravida libero rhoncus ut.\nMaecenas imperdiet felis nisi, fringilla luctus felis hendrerit\nsit amet. Pellentesque interdum, nisl nec interdum maximus, augue\ndiam porttitor lorem, et sollicitudin felis neque sit amet erat."
  },
  {
    "objectID": "layout/css.html#max-width",
    "href": "layout/css.html#max-width",
    "title": "CSS",
    "section": "max-width",
    "text": "max-width\nThe width of the element cannot be exceeded. In the following example, I have created some paris of parent/child divs, each child has max-width:200px property, but the parent is gradually expanding. The feature here is that the child width follows the parent width only before 200px.\n\n\n%%HTML\n&lt;div style=\"width:170px;border:solid green\"&gt;\n    &lt;div style=\"max-width:200px; border:solid red\"&gt; parent width 170&lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div style=\"width:180px;border:solid green\"&gt;\n    &lt;div style=\"max-width:200px; border:solid red\"&gt; parent width 180&lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div style=\"width:190px;border:solid green\"&gt;\n    &lt;div style=\"max-width:200px; border:solid red\"&gt; parent width 190&lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div style=\"width:200px;border:solid green\"&gt;\n    &lt;div style=\"max-width:200px; border:solid red\"&gt; parent width 200&lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div style=\"width:210px;border:solid green\"&gt;\n    &lt;div style=\"max-width:200px; border:solid red\"&gt; parent width 210&lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div style=\"width:220px;border:solid green\"&gt;\n    &lt;div style=\"max-width:200px; border:solid red\"&gt; parent width 220&lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div style=\"width:230px;border:solid green\"&gt;\n    &lt;div style=\"max-width:200px; border:solid red\"&gt; parent width 230&lt;/div&gt;\n&lt;/div&gt;\n\n\n     parent width 170\n\n\n\n     parent width 180\n\n\n\n     parent width 190\n\n\n\n     parent width 200\n\n\n\n     parent width 210\n\n\n\n     parent width 220\n\n\n\n     parent width 230"
  },
  {
    "objectID": "layout/css.html#min-width",
    "href": "layout/css.html#min-width",
    "title": "CSS",
    "section": "min-width",
    "text": "min-width\nAn item cannot take a value shorter than this length. In the following example, I have created some paris of parent/child divs, each child has min-width:200px property, but the parent is gradually expanding. The feature here is that the child width follows the parent width only after 200px.\n\n\n%%HTML\n&lt;div style=\"width:170px;border:solid green\"&gt;\n    &lt;div style=\"min-width:200px; border:solid red\"&gt; parent width 170&lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div style=\"width:180px;border:solid green\"&gt;\n    &lt;div style=\"min-width:200px; border:solid red\"&gt; parent width 180&lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div style=\"width:190px;border:solid green\"&gt;\n    &lt;div style=\"min-width:200px; border:solid red\"&gt; parent width 190&lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div style=\"width:200px;border:solid green\"&gt;\n    &lt;div style=\"min-width:200px; border:solid red\"&gt; parent width 200&lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div style=\"width:210px;border:solid green\"&gt;\n    &lt;div style=\"min-width:200px; border:solid red\"&gt; parent width 210&lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div style=\"width:220px;border:solid green\"&gt;\n    &lt;div style=\"min-width:200px; border:solid red\"&gt; parent width 220&lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div style=\"width:230px;border:solid green\"&gt;\n    &lt;div style=\"min-width:200px; border:solid red\"&gt; parent width 230&lt;/div&gt;\n&lt;/div&gt;\n\n\n     parent width 170\n\n\n\n     parent width 180\n\n\n\n     parent width 190\n\n\n\n     parent width 200\n\n\n\n     parent width 210\n\n\n\n     parent width 220\n\n\n\n     parent width 230"
  },
  {
    "objectID": "layout/css.html#font-size---font-size",
    "href": "layout/css.html#font-size---font-size",
    "title": "CSS",
    "section": "font-size - font size",
    "text": "font-size - font size\nmeasures\n\n%%HTML\n&lt;p style=\"font-size:20px\"&gt;20px font size&lt;/p&gt;\n&lt;p style=\"font-size:10px\"&gt;10px font size&lt;/p&gt;\n&lt;p style=\"font-size:100%\"&gt;100% font size&lt;/p&gt;\n&lt;p style=\"font-size:120%\"&gt;120% font size&lt;/p&gt;\n\n20px font size\n10px font size\n100% font size\n120% font size"
  },
  {
    "objectID": "layout/css.html#font-weight---boldthin-text",
    "href": "layout/css.html#font-weight---boldthin-text",
    "title": "CSS",
    "section": "font-weight - bold/thin text",
    "text": "font-weight - bold/thin text\nShapes the weight (saturation) of the font.\n\nnormal - Sets normal font saturation (default value).\nbold - Sets the font to bold.\nbolder Increases font saturation by one level relative to the parent element.\nlighter - Decreases the boldness of the font by one level relative to the parent element.\nSetting values between 100 and 900: These values define the specific font style, where 400 is equal to normal bold and 700 is equal to bold. Some browsers may not support all values in this range.\n\n\n\n%%HTML\n&lt;text style=\"font-weight:normal\"&gt;normal&lt;/text&gt;\n&lt;text style=\"font-weight:bold\"&gt;bold&lt;/text&gt;\n&lt;text style=\"font-weight:bolder\"&gt;bolder&lt;/text&gt;\n&lt;text style=\"font-weight:lighter\"&gt;lighter&lt;/text&gt;\n&lt;text style=\"font-weight:200\"&gt;200&lt;/text&gt;\n&lt;text style=\"font-weight:250\"&gt;250&lt;/text&gt;\n&lt;text style=\"font-weight:300\"&gt;300&lt;/text&gt;\n&lt;text style=\"font-weight:350\"&gt;350&lt;/text&gt;\n&lt;text style=\"font-weight:400\"&gt;400&lt;/text&gt;\n&lt;text style=\"font-weight:450\"&gt;450&lt;/text&gt;\n&lt;text style=\"font-weight:500\"&gt;500&lt;/text&gt;\n&lt;text style=\"font-weight:550\"&gt;550&lt;/text&gt;\n&lt;text style=\"font-weight:600\"&gt;600&lt;/text&gt;\n&lt;text style=\"font-weight:650\"&gt;650&lt;/text&gt;\n&lt;text style=\"font-weight:700\"&gt;700&lt;/text&gt;\n&lt;text style=\"font-weight:750\"&gt;750&lt;/text&gt;\n&lt;text style=\"font-weight:800\"&gt;800&lt;/text&gt;\n\nnormal\nbold\nbolder\nlighter\n200\n250\n300\n350\n400\n450\n500\n550\n600\n650\n700\n750\n800"
  },
  {
    "objectID": "layout/css.html#text-align---position-of-the-text",
    "href": "layout/css.html#text-align---position-of-the-text",
    "title": "CSS",
    "section": "text-align - position of the text",
    "text": "text-align - position of the text\n\n%%HTML\n&lt;p style=\"text-align:center\"&gt;Centered text&lt;/p&gt;\n&lt;p style=\"text-align:right\"&gt;Rigth side text&lt;/p&gt;\n&lt;p style=\"text-align:left\"&gt;Left side text&lt;/p&gt;\n\nCentered text\nRigth side text\nLeft side text"
  },
  {
    "objectID": "layout/css.html#float---float-position",
    "href": "layout/css.html#float---float-position",
    "title": "CSS",
    "section": "float - float position",
    "text": "float - float position\nThe float CSS property places an element on the left or right side of its container, allowing text and inline elements to wrap around it."
  },
  {
    "objectID": "layout/css.html#overflow---behaviour-in-limited-space",
    "href": "layout/css.html#overflow---behaviour-in-limited-space",
    "title": "CSS",
    "section": "overflow - behaviour in limited space",
    "text": "overflow - behaviour in limited space\nThe property describes how element will look like in case if has not enought space to display it’s contents.\nYou can find out more in mdn web docs.\n\nBasic example\nIn the following example displayed all options:\n\n\n%%HTML\n&lt;details&gt;\n    &lt;summary&gt;scroll&lt;/summary&gt;\n    &lt;div style='height:3cm;overflow:scroll;width:5cm;border:solid;font-size:20px'&gt;Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.&lt;/div&gt;\n&lt;/details&gt;\n\n&lt;details&gt;\n    &lt;summary&gt;hidden&lt;/summary&gt;\n    &lt;div style='height:3cm;overflow:hidden;width:5cm;border:solid;font-size:20px'&gt;Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.&lt;/div&gt;\n&lt;/details&gt;\n\n&lt;details&gt;\n    &lt;summary&gt;visible&lt;/summary&gt;\n    &lt;div style='height:3cm;overflow:visible;width:5cm;border:solid;font-size:20px'&gt;Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.&lt;/div&gt;\n&lt;/details&gt;\n\n&lt;details&gt;\n    &lt;summary&gt;auto&lt;/summary&gt;\n    &lt;div style='height:3cm;overflow:auto;width:5cm;border:solid;font-size:20px'&gt;Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.&lt;/div&gt;\n&lt;/details&gt;\n\n&lt;details&gt;\n    &lt;summary&gt;clip&lt;/summary&gt;\n    &lt;div style='height:3cm;overflow:clip;width:5cm;border:solid;font-size:20px'&gt;Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.&lt;/div&gt;\n&lt;/details&gt;\n\n\n    scroll\n    Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.\n\n\n\n    hidden\n    Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.\n\n\n\n    visible\n    Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.\n\n\n\n    auto\n    Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.\n\n\n\n    clip\n    Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.\n\n\n\n\n\nclip vs hidden\n\nhidden does not show any content that lies outside the element;\nclip does not show any content that lies ouside the elemnt + extra space described by overflow-clip-margin property.\n\nSo in the following example, I have created two divs, the first with overflow: hidden, the second with overflow: clip, and both have overflow-clip-margin: 1cm. As a result, only the content of the second div leaves the box for 1 cm.\n\nfrom IPython.display import HTML\n\ncontents = \"Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.\"\ndiv_styles = \"border:solid;width:5cm;height:3cm;overflow-clip-margin: 1cm;\"\n\nhtml_line = f\"\"\"\n&lt;div style=\"display:flex;height:5cm\"&gt;\n    &lt;div style=\\\"{div_styles}overflow: hidden\\\"&gt;{contents}&lt;/div&gt;\n    &lt;div style=\\\"{div_styles}overflow: clip\\\"&gt;{contents}&lt;/div&gt;\n&lt;/div&gt;\"\"\"\n\ndisplay(HTML(\"&lt;hr&gt;\"))\nprint(html_line)\ndisplay(HTML(\"&lt;hr&gt;\"))\n\n\nHTML(html_line)\n\n\n\n\n\n&lt;div style=\"display:flex;height:5cm\"&gt;\n    &lt;div style=\"border:solid;width:5cm;height:3cm;overflow-clip-margin: 1cm;overflow: hidden\"&gt;Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.&lt;/div&gt;\n    &lt;div style=\"border:solid;width:5cm;height:3cm;overflow-clip-margin: 1cm;overflow: clip\"&gt;Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.&lt;/div&gt;\n&lt;/div&gt;\n\n\n\n\n\n\n\n    Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.\n    Michaelmas term lately over, and the Lord Chancellor sitting in Lincoln's Inn Hall. Implacable November weather. As much mud in the streets as if the waters had but newly retired from the face of the earth.\n\n\n\n\n\nscroll vs auto\nIf you are using the scroll option, this means that scrollbars will always be displayed, but if you are using auto, it will only add scrollbars when needed.\nThe following example shows the difference. Note Some browsers display the scroll bar only when scrolling, but in the box less that uses the scroll option, letters are displayed in one line because the browser reserved space for scroll bars that will appear when you suppouse to start scrolling.\n\ncontents = \"\"\nfor i in range(65, 90): contents += chr(i) + \" \"\ndiv_styles = \"border:solid;width:5cm;height:5cm;overflow-clip-margin: 1cm;\"\n\n# you must set height for outer div\n# because if it's too small you\n# won't see difference between\n# options of overflow-clip-margin\n# property\nhtml_line = f\"\"\"\n&lt;div style=\"display:flex;height:5cm;width:10cm\"&gt;\n    &lt;div style=\\\"{div_styles}overflow: scroll\\\"&gt;{contents}&lt;/div&gt;\n    &lt;div style=\\\"{div_styles}overflow: auto\\\"&gt;{contents}&lt;/div&gt;\n&lt;/div&gt;\n\"\"\"\ndisplay(HTML(\"&lt;hr&gt;\"))\nprint(html_line)\ndisplay(HTML(\"&lt;hr&gt;\"))\n\n\nHTML(html_line)\n\n\n\n\n\n&lt;div style=\"display:flex;height:5cm;width:10cm\"&gt;\n    &lt;div style=\"border:solid;width:5cm;height:5cm;overflow-clip-margin: 1cm;overflow: scroll\"&gt;A B C D E F G H I J K L M N O P Q R S T U V W X Y &lt;/div&gt;\n    &lt;div style=\"border:solid;width:5cm;height:5cm;overflow-clip-margin: 1cm;overflow: auto\"&gt;A B C D E F G H I J K L M N O P Q R S T U V W X Y &lt;/div&gt;\n&lt;/div&gt;\n\n\n\n\n\n\n\n\n    A B C D E F G H I J K L M N O P Q R S T U V W X Y \n    A B C D E F G H I J K L M N O P Q R S T U V W X Y"
  },
  {
    "objectID": "layout/forms.html",
    "href": "layout/forms.html",
    "title": "Forms",
    "section": "",
    "text": "Forms allow the user to interact with the html page. There are a few special html tags to work with forms, these are covered on this page."
  },
  {
    "objectID": "layout/forms.html#type-atribute",
    "href": "layout/forms.html#type-atribute",
    "title": "Forms",
    "section": "type atribute",
    "text": "type atribute\nDescribe a purpose of the input. Can take the following values:\n\ntext;\npassword;\nemail;\ntel;\nnumber;\nrange;\nsubmit.\n\nThe values are discussed in more detail in other sub-sections."
  },
  {
    "objectID": "layout/forms.html#typetext",
    "href": "layout/forms.html#typetext",
    "title": "Forms",
    "section": "type=\"text\"",
    "text": "type=\"text\"\nJust basic input."
  },
  {
    "objectID": "layout/forms.html#typepassword",
    "href": "layout/forms.html#typepassword",
    "title": "Forms",
    "section": "type=\"password\"",
    "text": "type=\"password\"\nUsed to enter passwords. Symbols change to dots as you type.\n\n%%HTML\n&lt;input type=\"password\"&gt;"
  },
  {
    "objectID": "layout/forms.html#typeemail",
    "href": "layout/forms.html#typeemail",
    "title": "Forms",
    "section": "type=\"email\"",
    "text": "type=\"email\"\nUsed to enter an email address. The value is validated to ensure it is a real email address when sumbit button will be pressed.\n\n%%HTML\n&lt;form&gt;\n    &lt;input type=\"email\"&gt;\n    &lt;input type=\"submit\"&gt;\n&lt;/form&gt;\n\n\n    \n    \n\n\n\n\ntype=\"tel\"\nUsed to enter an phone numter. The value is validated ito ensure that it is a telephone number that satisfies the given pattern atribute. The following example dispays using of &lt;input type=\"tel\"&gt;. You can check the result here.\n\ndisplay(HTML(\"&lt;hr&gt;\"))\nwith open(\"forms_files/input_type_tel.html\") as file:\n    print(file.read())\ndisplay(HTML(\"&lt;hr&gt;\"))\n\n\n\n\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;body&gt;\n\n&lt;h2&gt;Input for phone&lt;/h2&gt;\n\n&lt;form&gt;\n    &lt;label for=\"phone\"&gt;Phone number:&lt;/label&gt;&lt;br&gt;\n    &lt;input type=\"tel\" id=\"phone\" \n           pattern=\"[0-9]{3}-[0-9]{2}-[0-9]{3}\"&gt;&lt;br&gt;&lt;br&gt;\n           \n    &lt;small&gt;Fomat: 123-45-678&lt;/small&gt;\n    &lt;br&gt;&lt;br&gt;\n    &lt;input type=\"submit\"&gt;\n&lt;/form&gt;\n\n&lt;/body&gt;\n&lt;/html&gt;"
  },
  {
    "objectID": "layout/forms.html#typenumber",
    "href": "layout/forms.html#typenumber",
    "title": "Forms",
    "section": "type=\"number\"",
    "text": "type=\"number\"\nUsed to enter the number.\nAttributes:\n\nmin minimum value;\nmax maximum value.\n\nIn the following example you can play such an element.\n\n%%HTML\n&lt;form&gt;\n    &lt;input type=\"number\" min=3 max=10&gt;\n&lt;/form&gt;"
  },
  {
    "objectID": "layout/forms.html#typerange",
    "href": "layout/forms.html#typerange",
    "title": "Forms",
    "section": "type=\"range\"",
    "text": "type=\"range\"\nCreates a slider.\nAttributes:\n\nmin - describe a minimal value;\nmax - describe a maximum value;\nstep - describe a step of the slider.\n\n\n%%HTML\n    &lt;label for=\"range1\"&gt;Range1&lt;/label&gt;&lt;input id=\"range1\" type=\"range\" min=0 max=100 step=0.5&gt;&lt;br&gt;\n    &lt;label for=\"range2\"&gt;Range2&lt;/label&gt;&lt;input id=\"range2\" type=\"range\" min=0 max=5 step = 2&gt;\n\n    Range1\n    Range2"
  },
  {
    "objectID": "layout/html.html",
    "href": "layout/html.html",
    "title": "HTML",
    "section": "",
    "text": "from IPython.display import HTML"
  },
  {
    "objectID": "layout/html.html#id---object-identificator",
    "href": "layout/html.html#id---object-identificator",
    "title": "HTML",
    "section": "id - object identificator",
    "text": "id - object identificator"
  },
  {
    "objectID": "layout/html.html#style-set-a-style-of-element",
    "href": "layout/html.html#style-set-a-style-of-element",
    "title": "HTML",
    "section": "style set a style of element",
    "text": "style set a style of element\nAllows to use integrated CSS for html elements.\n&lt;property1 name&gt;:&lt;setted value&gt;;&lt;property2 name&gt;:&lt;setted value&gt;;...;&lt;propertyn name&gt;:&lt;setted value&gt;\n\n%%HTML\n&lt;p style=\"color:blue\"&gt;Blue text color&lt;/p&gt;\n&lt;p style=\"background:red\"&gt;Red background color&lt;/p&gt;\n&lt;p style=\"background:red;color:blue\"&gt;Red background color&lt;/p&gt;\n\nBlue text color\nRed background color\nRed background color"
  },
  {
    "objectID": "layout/html.html#title---hint-text",
    "href": "layout/html.html#title---hint-text",
    "title": "HTML",
    "section": "title - hint text",
    "text": "title - hint text\nIf you hold the mouse for some time on the element created by the tag with the title attribute - close to the mouse, a small hint appears. So try it wit text which is the result for the next cell.\n\n%%HTML\n&lt;p title=\"hello im title\"&gt;text with title&lt;/p&gt;\n\ntext with title"
  },
  {
    "objectID": "layout/html.html#p---paragraph",
    "href": "layout/html.html#p---paragraph",
    "title": "HTML",
    "section": "<p> - paragraph",
    "text": "&lt;p&gt; - paragraph\nCreates a new paragraph.\n\n%%HTML\n&lt;p&gt;Paragraph 1&lt;/p&gt;&lt;p&gt;Paragraph 2&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;Paragraph n&lt;/p&gt;\n\nParagraph 1Paragraph 2...Paragraph n"
  },
  {
    "objectID": "layout/html.html#hr---thematic-break",
    "href": "layout/html.html#hr---thematic-break",
    "title": "HTML",
    "section": "<hr> - thematic break",
    "text": "&lt;hr&gt; - thematic break\nIt will be displayed as horizontal line by page width.\n\n%%HTML\nText with sence 1\n&lt;hr&gt;\nText with sence 2\n\nText with sence 1\n\nText with sence 2"
  },
  {
    "objectID": "layout/html.html#span",
    "href": "layout/html.html#span",
    "title": "HTML",
    "section": "<span>",
    "text": "&lt;span&gt;\nThis tag exists to assign different styles to the text, without getting any unintended changes set by the style.\nIn following example i use style with &lt;div&gt; tag and &lt;span&gt; tag:\n\n&lt;div&gt; tag sets the text in a separate paragraph;\n&lt;span&gt; tag just apply font style to text.\n\n\n%%HTML\n&lt;span style=\"color:red\"&gt;Text&lt;/span&gt; surrounded by snap.\n&lt;div style=\"color:red\"&gt;Text&lt;/div&gt; surrounded by div.    \n\nText surrounded by snap.\nText surrounded by div."
  },
  {
    "objectID": "layout/html.html#pre---preformatted-text",
    "href": "layout/html.html#pre---preformatted-text",
    "title": "HTML",
    "section": "<pre> - preformatted text",
    "text": "&lt;pre&gt; - preformatted text\nThe &lt;pre&gt; tag in HTML is used to define preformatted text, which preserves both spaces and line breaks. It is commonly used to display code snippets or other types of text that require a fixed-width font and exact formatting.\nSo in the following example, аor the first two stanzas I do not use the &lt;pre&gt; tag for the remaining ones I use:\n\n%%HTML\nIn the realm of dreams we wander,\nWhere reality is torn asunder.\nWhispers of love and tales untold,\nA symphony of emotions, bold.\n\nStars dance upon a velvet sky,\nAs moonbeams paint a lullaby.\nNature's canvas, a masterpiece,\nWhere hearts find solace and peace.\n&lt;pre&gt;\n\nThrough winding paths we tread,\nSeeking answers that lie ahead.\nLife's tapestry, a vibrant hue,\nEach moment, a story to pursue.\n\nSo let us cherish this fleeting rhyme,\nEmbrace the beauty in every chime.\nFor in these words, a glimpse we find,\nOf the magic that dwells in mankind.\n&lt;/pre&gt;\n\nIn the realm of dreams we wander,\nWhere reality is torn asunder.\nWhispers of love and tales untold,\nA symphony of emotions, bold.\n\nStars dance upon a velvet sky,\nAs moonbeams paint a lullaby.\nNature's canvas, a masterpiece,\nWhere hearts find solace and peace.\nThrough winding paths we tread,\nSeeking answers that lie ahead.\nLife's tapestry, a vibrant hue,\nEach moment, a story to pursue.\n\nSo let us cherish this fleeting rhyme,\nEmbrace the beauty in every chime.\nFor in these words, a glimpse we find,\nOf the magic that dwells in mankind."
  },
  {
    "objectID": "layout/html.html#i---italic",
    "href": "layout/html.html#i---italic",
    "title": "HTML",
    "section": "<i> - italic",
    "text": "&lt;i&gt; - italic\n\n%%HTML\n&lt;i&gt;Some emphasized text&lt;/i&gt;\n\nSome emphasized text"
  },
  {
    "objectID": "layout/html.html#em---important-italic",
    "href": "layout/html.html#em---important-italic",
    "title": "HTML",
    "section": "<em> - important italic",
    "text": "&lt;em&gt; - important italic\nIt looks just like bold but It has special importance for search engines.\n\n%%HTML\n&lt;em&gt;Some emphasized text&lt;/em&gt;'\n\nSome emphasized text'"
  },
  {
    "objectID": "layout/html.html#dfn---tag-for-definitions",
    "href": "layout/html.html#dfn---tag-for-definitions",
    "title": "HTML",
    "section": "<dfn> - tag for definitions",
    "text": "&lt;dfn&gt; - tag for definitions\nIf you want to define smt. you should use this tag. By default it is displayed in italics.\n\n%%HTML\n&lt;dfn&gt;Definition&lt;/dfn&gt;\n\nDefinition"
  },
  {
    "objectID": "layout/html.html#b---bold",
    "href": "layout/html.html#b---bold",
    "title": "HTML",
    "section": "<b> - bold",
    "text": "&lt;b&gt; - bold\n\n%%HTML\n&lt;b&gt;Some emphasized text&lt;/b&gt;\n\nSome emphasized text"
  },
  {
    "objectID": "layout/html.html#strong---inportant-bold",
    "href": "layout/html.html#strong---inportant-bold",
    "title": "HTML",
    "section": "<strong> - inportant bold",
    "text": "&lt;strong&gt; - inportant bold\nIt looks just like bold but It has special importance for search engines.\n\n%%HTML\n&lt;strong&gt;Some emphasized text&lt;/strong&gt;\n\nSome emphasized text"
  },
  {
    "objectID": "layout/html.html#small---smaller-text",
    "href": "layout/html.html#small---smaller-text",
    "title": "HTML",
    "section": "<small> - smaller text",
    "text": "&lt;small&gt; - smaller text\nText surrounded by this tag will be one size smaller than the parent font.\n\n%%HTML\n&lt;p&gt;Parent font1 &lt;small&gt;small font&lt;/small&gt; parent font2&lt;/p&gt;\n\nParent font1 small font parent font2"
  },
  {
    "objectID": "layout/html.html#del---deleted-info",
    "href": "layout/html.html#del---deleted-info",
    "title": "HTML",
    "section": "<del> - deleted info",
    "text": "&lt;del&gt; - deleted info\nThis tag is used to mark outdated information that should be deleted from the document. This will look like crossed out text.\n\n%%HTML\n&lt;del&gt; outdated information&lt;/del&gt;\n\n outdated information"
  },
  {
    "objectID": "layout/html.html#u---underlined-text",
    "href": "layout/html.html#u---underlined-text",
    "title": "HTML",
    "section": "<u> - underlined text",
    "text": "&lt;u&gt; - underlined text\nText which just will be showen as underlined.\n\n%%HTML\n&lt;u&gt;Just underlined text&lt;/u&gt;\n\nJust underlined text"
  },
  {
    "objectID": "layout/html.html#ins---inserted-info",
    "href": "layout/html.html#ins---inserted-info",
    "title": "HTML",
    "section": "<ins> - inserted info",
    "text": "&lt;ins&gt; - inserted info\nThis tag usually surrounds text that was inserted later in the page. It looks like underlined text.\n\n%%HTML\n&lt;ins&gt; new information&lt;/ins&gt;\n\n new information"
  },
  {
    "objectID": "layout/html.html#q---quote",
    "href": "layout/html.html#q---quote",
    "title": "HTML",
    "section": "<q> - quote",
    "text": "&lt;q&gt; - quote\nYou should surround quotes with this tag. Browsers usually display them surrounded by \".\n\n%%HTML\n&lt;q&gt;Fedor Kobak truly ingenious&lt;/q&gt;\n\nFedor Kobak truly ingenious"
  },
  {
    "objectID": "layout/html.html#blockquote---multiline-quote",
    "href": "layout/html.html#blockquote---multiline-quote",
    "title": "HTML",
    "section": "<blockquote> - multiline quote",
    "text": "&lt;blockquote&gt; - multiline quote\nYou should surround long quotations with this tag.\n\n%%HTML\n&lt;blockquote&gt;\nPeople think focus means saying yes to the thing you've got to focus on.&lt;br&gt; It means saying no to the hundred other good ideas that there are. You have to pick carefully.\n&lt;/blockquote&gt;\n\n\nPeople think focus means saying yes to the thing you've got to focus on. It means saying no to the hundred other good ideas that there are. You have to pick carefully."
  },
  {
    "objectID": "layout/html.html#ulli---unordered-list",
    "href": "layout/html.html#ulli---unordered-list",
    "title": "HTML",
    "section": "<ul>,<li> - unordered list",
    "text": "&lt;ul&gt;,&lt;li&gt; - unordered list\nTags: - &lt;ul&gt; describes an unordered list; - &lt;li&gt; describes a item of list.\n\n%%HTML\n&lt;ul&gt;\n    &lt;li&gt;item 1&lt;/li&gt;\n    &lt;li&gt;item 2&lt;/li&gt;\n    &lt;li&gt;...&lt;/li&gt;\n    &lt;li&gt;item n&lt;/li&gt;\n&lt;/ul&gt;\n\n\n    item 1\n    item 2\n    ...\n    item n\n\n\n\nMarkers can be setted as style=\"list-style-type:&lt;marker type&gt;\". There are following markers available:\n\ndisc;\nsquare;\ncircle.\n\n\n%%HTML\n&lt;text&gt;Marker type for whole list:\n&lt;ul style=\"list-style-type:square\"&gt;\n    &lt;li&gt;item 1&lt;/li&gt;\n    &lt;li&gt;item 2&lt;/li&gt;\n    &lt;li&gt;...&lt;/li&gt;\n    &lt;li&gt;item n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;text&gt;Different marker type for each point:&lt;/text&gt;\n&lt;ul&gt;\n    &lt;li style=\"list-style-type:disc\"&gt;disc&lt;/li&gt;\n    &lt;li style=\"list-style-type:square\"&gt;square&lt;/li&gt;\n    &lt;li style=\"list-style-type:circle\"&gt;circle&lt;/li&gt;\n&lt;/ul&gt;\n\nMarker type for whole list:\n\n    item 1\n    item 2\n    ...\n    item n\n\nDifferent marker type for each point:\n\n    disc\n    square\n    circle"
  },
  {
    "objectID": "layout/html.html#olli---ordered-list",
    "href": "layout/html.html#olli---ordered-list",
    "title": "HTML",
    "section": "<ol>,<li> - ordered list",
    "text": "&lt;ol&gt;,&lt;li&gt; - ordered list\n\n&lt;ol&gt; describes an ordered list;\n&lt;li&gt; describes a item of list.\n\n\n%%HTML\n&lt;ol&gt;\n    &lt;li&gt;item 1&lt;/li&gt;\n    &lt;li&gt;item 2&lt;/li&gt;\n    &lt;li&gt;...&lt;/li&gt;\n    &lt;li&gt;item n&lt;/li&gt;\n&lt;/ol&gt;\n\n\n    item 1\n    item 2\n    ...\n    item n\n\n\n\n\ntype - attribute\nNumeration type: - “1” - arabian numeration; - “A” - Latin caps; - “a” - lowercase Latin letters; - “I” - uppercase Roman numerals; - “i” - lowercase Roman numerals.\nFor some reasons these features can’t be displayed in jupyter, so the following cell generates this file where you can check the result of using these features.\n\nvariants = [\"1\", \"A\", \"a\", \"I\", \"i\"]\nformat_str = '''\n    &lt;ol type=\\\"{}\\\"&gt;\n        &lt;li&gt;item 1&lt;/li&gt;\n        &lt;li&gt;item 2&lt;/li&gt;\n        &lt;li&gt;...&lt;/li&gt;\n        &lt;li&gt;item n&lt;/li&gt;\n    &lt;/ol&gt;\n'''\n\nhtml_line = \"\"\nfor var in variants:\n    html_line += format_str.format(var)\n\nwith open(\"html_files/ordered_lists_types.html\", \"w\") as file:\n    file.write(html_line)\n\n\n\nreversed\nDisplay the list in reverse order\n\n%%HTML\n&lt;ol reversed&gt;\n    &lt;li&gt;item 1&lt;/li&gt;\n    &lt;li&gt;item 2&lt;/li&gt;\n    &lt;li&gt;...&lt;/li&gt;\n    &lt;li&gt;item n&lt;/li&gt;\n&lt;/ol&gt;\n\n\n    item 1\n    item 2\n    ...\n    item n\n\n\n\n\n\nstart - first number\nYou can select the number to use as the first value.\n\n%%HTML\n&lt;ol start = 5&gt;\n    &lt;li&gt;item 1&lt;/li&gt;\n    &lt;li&gt;item 2&lt;/li&gt;\n    &lt;li&gt;...&lt;/li&gt;\n    &lt;li&gt;item n&lt;/li&gt;\n&lt;/ol&gt;\n\n\n    item 1\n    item 2\n    ...\n    item n\n\n\n\n\n\nNegative elements\nI wonder how the list will behave if I start counting from 2 but there are more than two items. As it turns out the list goes beyond natural numbers.\n\n%%HTML\n&lt;ol start = 1 reversed&gt;\n    &lt;li&gt;item 1&lt;/li&gt;\n    &lt;li&gt;item 2&lt;/li&gt;\n    &lt;li&gt;item 3&lt;/li&gt;\n    &lt;li&gt;item 4&lt;/li&gt;\n&lt;/ol&gt;\n\n\n    item 1\n    item 2\n    item 3\n    item 4"
  },
  {
    "objectID": "layout/html.html#dt-dd-dl---definitions-list",
    "href": "layout/html.html#dt-dd-dl---definitions-list",
    "title": "HTML",
    "section": "<dt>, <dd>, <dl> - definitions list",
    "text": "&lt;dt&gt;, &lt;dd&gt;, &lt;dl&gt; - definitions list\n\n&lt;dl&gt; (definitions list) sets a definitions list;\n&lt;dt&gt; (definitions term) sets a new term;\n&lt;dd&gt; (definitions descriptions) describe the term.\n\n\n%%HTML\n&lt;dl&gt;\n    &lt;dt&gt;Term1&lt;/dt&gt;\n    &lt;dd&gt;Definition 1&lt;/dd&gt;\n    &lt;dt&gt;Term2&lt;/dt&gt;\n    &lt;dd&gt;Definition 2&lt;/dd&gt;\n    &lt;dt&gt;...&lt;/dt&gt;\n    &lt;dd&gt;...&lt;/dd&gt;\n    &lt;dt&gt;Term n&lt;/dt&gt;\n    &lt;dd&gt;Definition n&lt;/dd&gt;\n&lt;/dl&gt;\n\n\n    Term1\n    Definition 1\n    Term2\n    Definition 2\n    ...\n    ...\n    Term n\n    Definition n"
  },
  {
    "objectID": "layout/html.html#table-tr-td---basic",
    "href": "layout/html.html#table-tr-td---basic",
    "title": "HTML",
    "section": "<table>, <tr>, <td> - basic",
    "text": "&lt;table&gt;, &lt;tr&gt;, &lt;td&gt; - basic\n\n&lt;table&gt; - tag defines new table;\n&lt;tr&gt; - (table row) define the new row for the table;\n&lt;td&gt; - (table data) define the new cell.\n\n\n%%HTML\n&lt;table&gt;\n    &lt;tr&gt;\n        &lt;td&gt;row1 cell1&lt;/td&gt;\n        &lt;td&gt;row1 cell2&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n        &lt;td&gt;row2 cell1&lt;/td&gt;\n        &lt;td&gt;row2 cell2&lt;/td&gt;\n    &lt;/tr&gt;\n&lt;/table&gt;\n\n\n\n\nrow1 cell1\nrow1 cell2\n\n\nrow2 cell1\nrow2 cell2"
  },
  {
    "objectID": "layout/html.html#th---table-header",
    "href": "layout/html.html#th---table-header",
    "title": "HTML",
    "section": "<th> - table header",
    "text": "&lt;th&gt; - table header\nInstead of using &lt;td&gt; tag you can use &lt;th&gt; which will be interpreted as the table header, and printed as bold text.\n\n%%HTML\n&lt;table&gt;\n    &lt;tr&gt;\n        &lt;td&gt;row1 cell1&lt;/td&gt;\n        &lt;td&gt;row1 cell2&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n        &lt;th&gt;row2 cell1&lt;/th&gt;\n        &lt;th&gt;row2 cell2&lt;/th&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n        &lt;td&gt;row2 cell1&lt;/td&gt;\n        &lt;td&gt;row2 cell2&lt;/td&gt;\n    &lt;/tr&gt;\n&lt;/table&gt;\n\n\n\n\nrow1 cell1\nrow1 cell2\n\n\nrow2 cell1\nrow2 cell2\n\n\nrow2 cell1\nrow2 cell2"
  },
  {
    "objectID": "layout/html.html#caption",
    "href": "layout/html.html#caption",
    "title": "HTML",
    "section": "<caption>",
    "text": "&lt;caption&gt;\nTag &lt;caption&gt; inside &lt;table&gt; will allow to show a captions of the tables. Interesting that you can put it anywhere - it prints at the top of the page anyway.\n\n%%HTML\n&lt;table&gt;\n    &lt;tr&gt;\n        &lt;td&gt;row1 cell1&lt;/td&gt;\n        &lt;td&gt;row1 cell2&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n        &lt;td&gt;row2 cell1&lt;/td&gt;\n        &lt;td&gt;row2 cell2&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;caption&gt; Test caption&lt;/caption&gt;\n    &lt;tr&gt;\n        &lt;td&gt;row2 cell1&lt;/td&gt;\n        &lt;td&gt;row2 cell2&lt;/td&gt;\n    &lt;/tr&gt;\n&lt;/table&gt;\n\n\n\n    \n        row1 cell1\n        row1 cell2\n    \n    \n        row2 cell1\n        row2 cell2\n    \n     Test caption\n    \n        row2 cell1\n        row2 cell2"
  },
  {
    "objectID": "layout/html.html#img-add-image-to-html",
    "href": "layout/html.html#img-add-image-to-html",
    "title": "HTML",
    "section": "<img> add image to html",
    "text": "&lt;img&gt; add image to html\n\nsrc - set picture\nYou can add url of the image or filepath on computer. In this argument you can use:\n\nurl;\nfilename on computer;\nbase64 - use the following syntax data:image/&lt;img type&gt;;base64;&lt;base64 code&gt;:\n\nget base64 from bash: base64 &lt;filename&gt;;\nget base64 from python: import base64; base64.b64encode(&lt;binary picture data&gt;).\n\n\n\n%%HTML\n&lt;img src=\"https://content.codecademy.com/courses/web-101/web101-image_brownbear.jpg\"/&gt;\n&lt;img src=\"html_files/display_picture.jpg\"&gt;\n&lt;img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAwAAAAMCAYAAABWdVznAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA\nSklEQVQokc2QSQ4AIAgDW+L/v1wvmhDFhXiRG800kKEEITHmF3IGxsxmJHHhjwKfLF0VIpXLdwiY\nFPuPYKm9dCp1GABKD3clOS0V5DQSGUBEBc8AAAAASUVORK5CYII=\" width=200 height=200&gt;\n\n\n\n\n\n\n\n\nalt - text hint\nDescribes the text that will be used if the picture cannot be uploaded. There no option to show how it works in jupyter notebook, but the html page with the following code:\n\n%%bash\ncat html_files/img_alt_ex.html\n\n&lt;img src=\"unreal image\" alt=\"description of some image\"/&gt;\n\n\nYou can check here."
  },
  {
    "objectID": "layout/html.html#video---insert-video",
    "href": "layout/html.html#video---insert-video",
    "title": "HTML",
    "section": "<video> - insert video",
    "text": "&lt;video&gt; - insert video\n\ncontrols handle video\nAttributes allow you to set controls for handling the video playback process. In the following example I have inserted the first video with the control attribute and the second without.\n\n%%HTML\n&lt;video src=\"html_files/some_video.webm\" widht=200 height=200 controls&gt;\n&lt;/video&gt;\n&lt;video src=\"html_files/some_video.webm\" widht=200 height=200&gt;\n&lt;/video&gt;"
  },
  {
    "objectID": "layout/html.html#div---division",
    "href": "layout/html.html#div---division",
    "title": "HTML",
    "section": "<div> - division",
    "text": "&lt;div&gt; - division\nHelps to group html elements."
  },
  {
    "objectID": "layout/html.html#sec-style_tag",
    "href": "layout/html.html#sec-style_tag",
    "title": "HTML",
    "section": "<style> - style for element group",
    "text": "&lt;style&gt; - style for element group\nBy useing this tag inside &lt;head&gt; tag you can set some css properties.\nIn the following example I set styles for all &lt;p&gt; and &lt;img&gt; tags in html page. You can check the results here. I can’t show in Jupyter notebook because the results are applied to the whole notebook.\n\nwith open(\"html_files/style_tag.html\") as file:\n    print(file.read())\n\n&lt;head&gt;\n    &lt;style&gt;\n        p {text-align:center; color: red}\n        img {border: 5px solid blue}\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;p&gt; Test paragraph1&lt;/p&gt;\n    &lt;p&gt; Test paragraph2&lt;/p&gt;\n    &lt;img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAwAAAAMCAYAAABWdVznAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAA\nSklEQVQokc2QSQ4AIAgDW+L/v1wvmhDFhXiRG800kKEEITHmF3IGxsxmJHHhjwKfLF0VIpXLdwiY\nFPuPYKm9dCp1GABKD3clOS0V5DQSGUBEBc8AAAAASUVORK5CYII=\"&gt;\n&lt;/body&gt;"
  },
  {
    "objectID": "layout/html.html#link",
    "href": "layout/html.html#link",
    "title": "HTML",
    "section": "<link>",
    "text": "&lt;link&gt;\nUsed inside the &lt;head&gt; tag to load an external resource.\n\nhref - url\n\n\nrel - relationship\nDefine the relationship between html document and external resource.\n\nstylesheet - used for loading css file\nHere you can describe file that should be used as style table. In the following example I show html file and associated css file.\n\ndisplay(HTML(\n    '''\n    &lt;hr&gt;&lt;text style=\\\"font-size:16px\\\"&gt;HTML&lt;/text&gt;\n    '''\n))\n\nwith open(\"html_files/css_example.html\") as file:\n    print(file.read())\n\ndisplay(HTML(\n    '''\n    &lt;hr&gt;&lt;text style=\\\"font-size:16px\\\"&gt;CSS&lt;/text&gt;\n    '''\n))\n\nwith open(\"html_files/css_example.css\") as file:\n    print(file.read())\n\n\n    HTML\n    \n\n\n&lt;head&gt;\n    &lt;link href=\"css_example.css\" rel=\"stylesheet\"&gt;&lt;/link&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;p&gt;Paragraph 1&lt;/p&gt;\n    &lt;p&gt;Paragraph 2&lt;/p&gt;\n&lt;/body&gt;\np {\n  background-color: powderblue;\n  color: red\n}\n\n\n\n    CSS\n    \n\n\nYou can find the results here."
  },
  {
    "objectID": "layout/html.html#a---link",
    "href": "layout/html.html#a---link",
    "title": "HTML",
    "section": "<a> - link",
    "text": "&lt;a&gt; - link\n\nhref - url\nurl to which reference is made.\n\n\ntarget - widow\nDefine how exactly html page should be opened:\n\n_self - use the same tab where the link was displayed;\n_blank - use new tab;\n_parent- ???;\n_top - ???.\n\nYou can try different options here.\n\n\ndownload\nTells the browser that the document must be downloaded and not opened in the browser. So in the following example, I have created a link that allows you to download the page from the previous example.\n\n%%HTML\n&lt;a href=\"html_files/a_target.html\" download&gt;Download a_target.html&lt;/a&gt;\n\nDownload a_target.html"
  },
  {
    "objectID": "layout/html.html#details---hiden-info",
    "href": "layout/html.html#details---hiden-info",
    "title": "HTML",
    "section": "<details> - hiden info",
    "text": "&lt;details&gt; - hiden info\n\nBasics\nYou can describe some information that is hidden by default, but appears when you press the “arrow” button.\n\n%%HTML\n&lt;details&gt;\nSome hidden information.\n&lt;/details&gt;\n\n\nSome hidden information.\n\n\n\nBy using &lt;summary&gt; tag you can add extra information.\n\n%%HTML\n&lt;details&gt;\n    &lt;summary&gt;Details title&lt;button&gt;Test button&lt;/button&gt;&lt;/summary&gt;\n    Some hidden information\n&lt;/details&gt;\n\n\n    Details titleTest button\n    Some hidden information\n\n\n\n\n\nOverlapping\nBy default, expanded &lt;details&gt; will move the following content. So the following example shows how expanded details moves div.\n\n\n%%HTML\n&lt;details&gt;\n    line 0 &lt;br&gt;line 1 &lt;br&gt;line 2 &lt;br&gt;line 3 &lt;br&gt;line 4 &lt;br&gt;line 5 &lt;br&gt;line 6 &lt;br&gt;line 7 &lt;br&gt;line 8 &lt;br&gt;line 9 &lt;br&gt;\n&lt;/details&gt;\n&lt;details&gt;\n    line 0 &lt;br&gt;line 1 &lt;br&gt;line 2 &lt;br&gt;line 3 &lt;br&gt;line 4 &lt;br&gt;line 5 &lt;br&gt;line 6 &lt;br&gt;line 7 &lt;br&gt;line 8 &lt;br&gt;line 9 &lt;br&gt;\n&lt;/details&gt;\n&lt;div&gt;\n    Some other content\n&lt;/div&gt;\n\n\n    line 0 line 1 line 2 line 3 line 4 line 5 line 6 line 7 line 8 line 9 \n\n\n    line 0 line 1 line 2 line 3 line 4 line 5 line 6 line 7 line 8 line 9 \n\n\n    Some other content"
  },
  {
    "objectID": "layout/sources.html",
    "href": "layout/sources.html",
    "title": "Sources",
    "section": "",
    "text": "Stepic html css course (rus);\nMDN Documenting web technologies, including CSS, HTML, and JavaScript;\n\nCSS float property."
  },
  {
    "objectID": "postgres/conditions_on_agregats.html",
    "href": "postgres/conditions_on_agregats.html",
    "title": "Conditions on agregats",
    "section": "",
    "text": "In the next cell, I create everything I need for the examples in this page.\n%%bash\ndocker run --rm -d\\\n    -e POSTGRES_PASSWORD=postgres \\\n    --name cond_on_agregats_example \\\n    postgres:15.4 &&gt; /dev/null\nsleep 5\ndocker exec -i cond_on_agregats_example psql -U postgres -d postgres\n\nCREATE TABLE aggregation_table(\n    col1 TEXT,\n    col2 INT\n);\nINSERT INTO aggregation_table(col1, col2) VALUES\n('A', 5),\n('A', 1),\n('B', 2),\n('B', 1),\n('C', 3),\n('C', 4);\n\nCREATE TABLE\nINSERT 0 6\nNote don’t forget to stop the container when you finish playing with examples.\n!docker stop cond_on_agregats_example &&gt; /dev/null\nLet’s begin with the view of the example table.\n%%bash \ndocker exec -i cond_on_agregats_example psql -U postgres -d postgres\n\nSELECT * FROM aggregation_table;\n\n col1 | col2 \n------+------\n A    |    5\n A    |    1\n B    |    2\n B    |    1\n C    |    3\n C    |    4\n(6 rows)\nNow a problem: I need to aggregate SUM(col2) by the values of col1 and I only get the results where the sums are greater than 5. So I need to set a condition on a result of the aggregation."
  },
  {
    "objectID": "postgres/conditions_on_agregats.html#wont-work",
    "href": "postgres/conditions_on_agregats.html#wont-work",
    "title": "Conditions on agregats",
    "section": "Won’t work",
    "text": "Won’t work\nThe first thing that comes to mind is to use the arger functions inside the WHERE block. This will cause an error because the WHERE block in sql is executed before all aggregations.\n\n%%bash \ndocker exec -i cond_on_agregats_example psql -U postgres -d postgres\n\nSELECT col1, SUM(col2)\nFROM aggregation_table WHERE SUM(col2) &gt; 5\nGROUP BY col1;\n\nERROR:  aggregate functions are not allowed in WHERE\nLINE 2: FROM aggregation_table WHERE SUM(col2) &gt; 5\n                                     ^"
  },
  {
    "objectID": "postgres/conditions_on_agregats.html#subquery",
    "href": "postgres/conditions_on_agregats.html#subquery",
    "title": "Conditions on agregats",
    "section": "Subquery",
    "text": "Subquery\nA possible but not optimal solution is to use aggregation in the subquery and then describe the condition on the aggregation in the external query.\nIn the following example, I just solve the problem mentioned at the beginning of the page using this path.\n\n%%bash \ndocker exec -i cond_on_agregats_example psql -U postgres -d postgres\n\nSELECT * FROM (\n    SELECT col1, SUM(col2)\n    FROM aggregation_table\n    GROUP BY col1\n) AS tab1\nWHERE sum &gt; 5;\n\n col1 | sum \n------+-----\n C    |   7\n A    |   6\n(2 rows)"
  },
  {
    "objectID": "postgres/conditions_on_agregats.html#having",
    "href": "postgres/conditions_on_agregats.html#having",
    "title": "Conditions on agregats",
    "section": "HAVING",
    "text": "HAVING\nThere’s a special keyword for describing these cases: HAVING, which is the same as WHERE, but for aggregates. It’s the optimal way to solve such a task.\nYou have to use HAVING after GROUP BY satement.\nIn the following example, I just solve the problem mentioned at the beginning of the page using this path.\n\n%%bash \ndocker exec -i cond_on_agregats_example psql -U postgres -d postgres\n\nSELECT col1, SUM(col2)\nFROM aggregation_table\nGROUP BY col1\nHAVING SUM(col2) &gt; 5;\n\n col1 | sum \n------+-----\n C    |   7\n A    |   6\n(2 rows)\n\n\n\nNote You can also use conditions on aggregates not mentioned in the SELECT statement. So in the next cell I got sums of col2 by col1, but only for cases where the average of col2 by col1 is greater than 3.\n\n%%bash \ndocker exec -i cond_on_agregats_example psql -U postgres -d postgres\n\nSELECT col1, SUM(col2)\nFROM aggregation_table\nGROUP BY col1\nHAVING AVG(col2) &gt; 3;\n\n col1 | sum \n------+-----\n C    |   7\n(1 row)\n\n\n\nNote You can use aggregation variables in conditions. So in the following example I got sums of col2 only for certain values of col1.\n\n%%bash \ndocker exec -i cond_on_agregats_example psql -U postgres -d postgres\n\nSELECT col1, SUM(col2)\nFROM aggregation_table\nGROUP BY col1\nHAVING col1 IN ('A', 'B');\n\n col1 | sum \n------+-----\n B    |   3\n A    |   6\n(2 rows)"
  },
  {
    "objectID": "postgres/join.html",
    "href": "postgres/join.html",
    "title": "JOIN",
    "section": "",
    "text": "Join is a keyword that allows you to combine information from different tables. It’s really important, but sometimes it’s hard to understand, so this whole page is about features and usecases of joins in Postgres SQL.\nIn the following cell, I’m creating a database that will be used for all the examples on this page.\n%%bash\ndocker run -d --rm\\\n    --name join_example\\\n    -e POSTGRES_PASSWORD=postgres\\\n    postgres:15.4 &&gt; /dev/null\nsleep 5\ndocker exec -i join_example psql -U postgres -d postgres\n\nCREATE TABLE central_table (\n    id INT NOT NULL,\n    someinfo1_id INT NOT NULL,\n    someinfo2_id INT NOT NULL\n);\nINSERT INTO central_table (id, someinfo1_id, someinfo2_id) VALUES\n(1, 1, 1),\n(2, 2, 2),\n(3, 2, 1);\n\nCREATE TABLE some_info1 (\n    id INT NOT NULL,\n    some_info TEXT\n);\nINSERT INTO some_info1 (id, some_info) VALUES\n(1, 'some_info1.1'),\n(2, 'some_info1.2'),\n(3, 'some_info1.3');\n\nCREATE TABLE some_info2 (\n    id INT NOT NULL,\n    some_info TEXT\n);\nINSERT INTO some_info2 (id, some_info) VALUES\n(1, 'some_info2.1'),\n(2, 'some_info2.2'),\n(3, 'some_info2.3');\n\nCREATE TABLE\nINSERT 0 3\nCREATE TABLE\nINSERT 0 3\nCREATE TABLE\nINSERT 0 3\nIn basic case examples I’ll use tables central_table, some_info1, some_info2. So in the next cell I just show their content.\n%%bash\ndocker exec -i join_example psql -U postgres -d postgres\n\nSELECT * FROM central_table;\nSELECT * FROM some_info1;\nSELECT * FROM some_info2;\n\n id | someinfo1_id | someinfo2_id \n----+--------------+--------------\n  1 |            1 |            1\n  2 |            2 |            2\n  3 |            2 |            1\n(3 rows)\n\n id |  some_info   \n----+--------------\n  1 | some_info1.1\n  2 | some_info1.2\n  3 | some_info1.3\n(3 rows)\n\n id |  some_info   \n----+--------------\n  1 | some_info2.1\n  2 | some_info2.2\n  3 | some_info2.3\n(3 rows)\nNote Remember to close the container when you have finished playing with the examples.\n!docker stop join_example\n\njoin_example"
  },
  {
    "objectID": "postgres/join.html#short-names",
    "href": "postgres/join.html#short-names",
    "title": "JOIN",
    "section": "Short names",
    "text": "Short names\nYou can use short names for the tables involved in the join to make it easier to write code. Just give the new name of the table separated by a space from the original name of the table.\nIn the next cell I set the sent name for the table central_table and the si1 name for the table some_info1 and use it everywhere to refer to the tables used in the join.\n\n%%bash\ndocker exec -i join_example psql -U postgres -d postgres\n\nSELECT sent.id, si1.some_info FROM \n    central_table sent\n    JOIN\n    some_info1 si1\n    ON sent.someinfo1_id=si1.id\n;\n\n id |  some_info   \n----+--------------\n  1 | some_info1.1\n  2 | some_info1.2\n  3 | some_info1.2\n(3 rows)"
  },
  {
    "objectID": "postgres/join.html#more-tables",
    "href": "postgres/join.html#more-tables",
    "title": "JOIN",
    "section": "More tables",
    "text": "More tables\nYou can use more than two tables in a join. Just use multiple JOIN ... ON ... blocks to select more information.\nSo in the following example, I simply combine all the sample database information into one query!\n\n%%bash\ndocker exec -i join_example psql -U postgres -d postgres\n\nSELECT sent.id, si1.some_info, si2.some_info FROM \n    central_table sent\n    JOIN\n    some_info1 si1\n    ON sent.someinfo1_id=si1.id\n    JOIN\n    some_info2 si2\n    ON sent.someinfo2_id=si2.id\n;\n\n id |  some_info   |  some_info   \n----+--------------+--------------\n  1 | some_info1.1 | some_info2.1\n  3 | some_info1.2 | some_info2.1\n  2 | some_info1.2 | some_info2.2\n(3 rows)"
  },
  {
    "objectID": "postgres/join.html#duplication",
    "href": "postgres/join.html#duplication",
    "title": "JOIN",
    "section": "Duplication",
    "text": "Duplication\nIf in joined table will be duplicates in join key, you will find that some tables of original table have been duplicated.\nIn the example for this page, central_table.someinfo1_id takes the value 2 twice. So if you join it to some_info, the record of some_info that has id=2 will be duplicated, just like in the following cell.\n\n%%bash\ndocker exec -i join_example psql -U postgres -d postgres\n\nSELECT * \nFROM some_info1\nFULL OUTER JOIN central_table ON some_info1.id=central_table.someinfo1_id;\n\n id |  some_info   | id | someinfo1_id | someinfo2_id \n----+--------------+----+--------------+--------------\n  1 | some_info1.1 |  1 |            1 |            1\n  2 | some_info1.2 |  2 |            2 |            2\n  2 | some_info1.2 |  3 |            2 |            1\n  3 | some_info1.3 |    |              |             \n(4 rows)"
  },
  {
    "objectID": "postgres/join.html#join-types",
    "href": "postgres/join.html#join-types",
    "title": "JOIN",
    "section": "Join types",
    "text": "Join types\nThis diagram describes the different types of joins available in SQL."
  },
  {
    "objectID": "postgres/load_tables.html",
    "href": "postgres/load_tables.html",
    "title": "Load tables",
    "section": "",
    "text": "This page is about how to read information in postgres database.\n\nCSV\nIn this section I will show you how to load information from a csv file. Main source of information was this page.\nLong story short:\n\nCreate table;\nRead “*.csv” file using COPY sql command.\n\nThe following example just does all of that stuff.\n\n%%bash\n# creating a container and comming to psql command line\ndocker run -d --rm\\\n    --name csv_loading_postgres\\\n    -e POSTGRES_PASSWORD=docker_app\\\n    -v ./load_tables/CSV/iris_csv.csv:/iris_csv.csv\\\n    postgres:15.4 &&gt; /dev/null\nsleep 5\ndocker exec -i csv_loading_postgres psql -U postgres -d postgres\n\n-- creating table\nCREATE TABLE main_table(\n    sepallength REAL,\n    sepalwidth REAL,\n    petallength REAL,\n    petalwidth REAL,\n    class VARCHAR(20)\n);\n-- loading csv table to created table\nCOPY main_table(sepallength, sepalwidth, petallength, petalwidth,class)\nFROM '/iris_csv.csv'\nDELIMITER ','\nCSV HEADER;\n\n-- showing results\nSELECT * FROM main_table LIMIT 10;\n\nCREATE TABLE\nCOPY 150\n sepallength | sepalwidth | petallength | petalwidth |    class    \n-------------+------------+-------------+------------+-------------\n         5.1 |        3.5 |         1.4 |        0.2 | Iris-setosa\n         4.9 |          3 |         1.4 |        0.2 | Iris-setosa\n         4.7 |        3.2 |         1.3 |        0.2 | Iris-setosa\n         4.6 |        3.1 |         1.5 |        0.2 | Iris-setosa\n           5 |        3.6 |         1.4 |        0.2 | Iris-setosa\n         5.4 |        3.9 |         1.7 |        0.4 | Iris-setosa\n         4.6 |        3.4 |         1.4 |        0.3 | Iris-setosa\n           5 |        3.4 |         1.5 |        0.2 | Iris-setosa\n         4.4 |        2.9 |         1.4 |        0.2 | Iris-setosa\n         4.9 |        3.1 |         1.5 |        0.1 | Iris-setosa\n(10 rows)\n\n\n\n\n!docker stop csv_loading_postgres &&gt; /dev/null"
  },
  {
    "objectID": "postgres/DISTINCT_unique.html",
    "href": "postgres/DISTINCT_unique.html",
    "title": "DISTINCT unique",
    "section": "",
    "text": "Using the syntax SELECT DISTINCT ... you can get unique values in any column.\nIn the next cell, I create everything I need for the examples in this page.\n%%bash\ndocker run --rm -d\\\n    -e POSTGRES_PASSWORD=postgres \\\n    --name sql_DISTINCT_examples \\\n    postgres:15.4 &&gt; /dev/null\nsleep 5\ndocker exec -i sql_DISTINCT_examples psql -U postgres -d postgres\n\n\\set QUIET on\nCREATE TABLE non_unique_values(\n    col1 TEXT,\n    col2 TEXT\n);\nINSERT INTO non_unique_values(col1, col2) VALUES\n('A', 'X'),\n('A', 'Y'),\n('A', 'X'),\n('B', 'X'),\n('C', 'Y'),\n('C', 'Y');\nThe next cell shows the table I will use for examples in this section.\n%%bash\ndocker exec -i sql_DISTINCT_examples psql -U postgres -d postgres\n\nSELECT * FROM non_unique_values;\n\n col1 | col2 \n------+------\n A    | X\n A    | Y\n A    | X\n B    | X\n C    | Y\n C    | Y\n(6 rows)\nNote don’t forget to stop the container when you finish playing with examples.\n!docker stop sql_DISTINCT_examples &&gt; /dev/null"
  },
  {
    "objectID": "postgres/DISTINCT_unique.html#specific-column",
    "href": "postgres/DISTINCT_unique.html#specific-column",
    "title": "DISTINCT unique",
    "section": "Specific column",
    "text": "Specific column\nIf you use only one column as the result of a SELECT, the unique values of that column will be retrieved.\n\n%%bash\ndocker exec -i sql_DISTINCT_examples psql -U postgres -d postgres\n\nSELECT DISTINCT col1 FROM non_unique_values;\n\n col1 \n------\n B\n C\n A\n(3 rows)"
  },
  {
    "objectID": "postgres/DISTINCT_unique.html#columns-combination",
    "href": "postgres/DISTINCT_unique.html#columns-combination",
    "title": "DISTINCT unique",
    "section": "Columns combination",
    "text": "Columns combination\nIf you use multiple columns as the result of a SELECT, you will get every possible combination of values in the columns once.\n\n%%bash\ndocker exec -i sql_DISTINCT_examples psql -U postgres -d postgres\n\nSELECT DISTINCT col1, col2 FROM non_unique_values;\n\n col1 | col2 \n------+------\n B    | X\n A    | Y\n A    | X\n C    | Y\n(4 rows)"
  },
  {
    "objectID": "postgres/order_by.html",
    "href": "postgres/order_by.html",
    "title": "ORDER BY",
    "section": "",
    "text": "This is key word that allow you to sort the results of the SELECT.\nIn the next cell, I create everything I need for the examples in this page.\n%%bash\n# creating a container and comming to psql command line\ndocker run -d --rm\\\n    --name order_by_examples\\\n    -e POSTGRES_PASSWORD=docker_app\\\n    -v ./load_tables/CSV/iris_csv.csv:/iris_csv.csv\\\n    postgres:15.4 &&gt; /dev/null\nsleep 5\ndocker exec -i order_by_examples psql -U postgres -d postgres\n\nCREATE TABLE table_for_ordering(\n    int_value INT,\n    text_value TEXT\n);\nINSERT INTO table_for_ordering(int_value, text_value) VALUES\n(4, 'ab'),\n(1, 'bw'),\n(1, 'bc'),\n(3, 'ba'),\n(5, 'cg'),\n(2, 'cd'),\n(7, 'ba');\n\nCREATE TABLE\nINSERT 0 7\nHere is the table used for the examples. As you can see, I’ve put some variables in there and not sorted them all in any systematic way.\n%%bash\ndocker exec -i order_by_examples psql -U postgres -d postgres\nSELECT * FROM table_for_ordering;\n\n int_value | text_value \n-----------+------------\n         4 | ab\n         1 | bw\n         1 | bc\n         3 | ba\n         5 | cg\n         2 | cd\n(6 rows)\nNote don’t forget to stop the container when you finish playing with examples.\n!docker stop order_by_examples &&gt; /dev/null"
  },
  {
    "objectID": "postgres/order_by.html#numeric-variable",
    "href": "postgres/order_by.html#numeric-variable",
    "title": "ORDER BY",
    "section": "Numeric variable",
    "text": "Numeric variable\nVery simple - just sort records in ascending order for the selected variable.\n\n%%bash\ndocker exec -i order_by_examples psql -U postgres -d postgres\n\nSELECT * FROM table_for_ordering ORDER BY int_value;\n\n int_value | text_value \n-----------+------------\n         1 | bw\n         1 | bc\n         2 | cd\n         3 | ba\n         4 | ab\n         5 | cg\n(6 rows)"
  },
  {
    "objectID": "postgres/order_by.html#text-varible",
    "href": "postgres/order_by.html#text-varible",
    "title": "ORDER BY",
    "section": "Text varible",
    "text": "Text varible\nIt seems that sorting by text variables is done in the usual order according to the encoding table, аnd if the first i characters are the same, the decision will be made based on the i+1th character. The following example confirms it.\n\n%%bash\ndocker exec -i order_by_examples psql -U postgres -d postgres\n\nSELECT * FROM table_for_ordering ORDER BY text_value;\n\n int_value | text_value \n-----------+------------\n         4 | ab\n         3 | ba\n         1 | bc\n         1 | bw\n         2 | cd\n         5 | cg\n(6 rows)"
  },
  {
    "objectID": "postgres/order_by.html#descending",
    "href": "postgres/order_by.html#descending",
    "title": "ORDER BY",
    "section": "Descending",
    "text": "Descending\nDy default ORDER BY sort values in ascending order, but by using key word DESC after column name in ORDER BY block you can make posgres use descending order.\nSo in following example I apply this option for int_value.\n\n%%bash\ndocker exec -i order_by_examples psql -U postgres -d postgres\n\nSELECT * FROM table_for_ordering ORDER BY int_value DESC;\n\n int_value | text_value \n-----------+------------\n         7 | ba\n         5 | cg\n         4 | ab\n         3 | ba\n         2 | cd\n         1 | bc\n         1 | bw\n(7 rows)"
  },
  {
    "objectID": "postgres/order_by.html#order-by-several",
    "href": "postgres/order_by.html#order-by-several",
    "title": "ORDER BY",
    "section": "Order by several",
    "text": "Order by several\nYou can use multiple columns in the ORDER BY block. In this case the records will be sorted by the ith column, but if there are some options caused by equal values in the ith column, the i+1th column will be used to determine the final order.\nSo in the following example:\n\nThe first query uses int_value, text_value in ORDER BY;\n\nIt has int_value = 1 twice, but the final order is determined by 'bc'&lt;'dw' in text_value;\n\nSecond query uses text_value, int_value DESC in ORDER BY.\n\nIt has text_value = 'ba' twice, but I also mentioned sorting by int_value in descending order, so 7 | ba is preferable to 3 | ba.\n\n\n\n%%bash\ndocker exec -i order_by_examples psql -U postgres -d postgres\n\nSELECT * FROM table_for_ordering ORDER BY int_value, text_value;\nSELECT * FROM table_for_ordering ORDER BY text_value, int_value DESC;\n\n int_value | text_value \n-----------+------------\n         1 | bc\n         1 | bw\n         2 | cd\n         3 | ba\n         4 | ab\n         5 | cg\n         7 | ba\n(7 rows)\n\n int_value | text_value \n-----------+------------\n         4 | ab\n         7 | ba\n         3 | ba\n         1 | bc\n         1 | bw\n         2 | cd\n         5 | cg\n(7 rows)"
  },
  {
    "objectID": "postgres/NULL_conditions.html",
    "href": "postgres/NULL_conditions.html",
    "title": "NULL conditions",
    "section": "",
    "text": "It’s a really common task to find records with empty values, or vice versa, to find records where all the information is available.\nIn the next cell, I create everything I need for the examples in this page.\n%%bash\ndocker run --rm -d\\\n    -e POSTGRES_PASSWORD=postgres \\\n    --name null_conditions_example \\\n    postgres:15.4 &&gt; /dev/null\nsleep 5\ndocker exec -i null_conditions_example psql -U postgres -d postgres\n\nCREATE TABLE table_with_nulls(\n    col1 TEXT,\n    col2 INT\n);\nINSERT INTO table_with_nulls(col1, col2) VALUES\n('A', NULL),\n('A', 1),\n('A', 2),\n(NULL, 1),\n('C', 3),\n(NULL, 4);\n\nCREATE TABLE\nINSERT 0 6\nIn the next cell, I’ll show the table I’m going to use as an example.\nNote psql show NULL values just as empty places.\n%%bash\ndocker exec -i null_conditions_example psql -U postgres -d postgres\nSELECT col1, col2 FROM table_with_nulls;\n\n col1 | col2 \n------+------\n A    |     \n A    |    1\n A    |    2\n      |    1\n C    |    3\n      |    4\n(6 rows)\nNote don’t forget to stop the container when you finish playing with examples.\n!docker stop null_conditions_example &&gt; /dev/null"
  },
  {
    "objectID": "postgres/NULL_conditions.html#is-null",
    "href": "postgres/NULL_conditions.html#is-null",
    "title": "NULL conditions",
    "section": "IS NULL",
    "text": "IS NULL\nBy using &lt;column name&gt; IS NULL in the WHERE block, you can select records with empty values in a particular column.\nIn the following example I SELECT only values with NULL values in col1.\n\n%%bash\ndocker exec -i null_conditions_example psql -U postgres -d postgres\nSELECT col1, col2 \nFROM table_with_nulls\nWHERE col1 IS NULL;\n\n col1 | col2 \n------+------\n      |    1\n      |    4\n(2 rows)"
  },
  {
    "objectID": "postgres/NULL_conditions.html#is-not-null",
    "href": "postgres/NULL_conditions.html#is-not-null",
    "title": "NULL conditions",
    "section": "IS NOT NULL",
    "text": "IS NOT NULL\nBy using &lt;column name&gt; IS NOT NULL in the WHERE block, you can select records with filled values in a particular column.\nIn the following example I SELECT only values that hase something in col1.\n\n%%bash\ndocker exec -i null_conditions_example psql -U postgres -d postgres\nSELECT col1, col2\nFROM table_with_nulls\nWHERE col1 IS NOT NULL;\n\n col1 | col2 \n------+------\n A    |     \n A    |    1\n A    |    2\n C    |    3\n(4 rows)"
  },
  {
    "objectID": "postgres/python_interaction.html",
    "href": "postgres/python_interaction.html",
    "title": "Python interaction",
    "section": "",
    "text": "In this page I will show you how to deploy and interact with a Postgres database in a Docker container.\nNote psycopg2 is a central library for organising Python&lt;-&gt;Postgres interaction, developers distribute it uncompiled for optimisation purposes, but if you just want to install and use it pip3 install psycopg2-binary."
  },
  {
    "objectID": "postgres/python_interaction.html#python-image",
    "href": "postgres/python_interaction.html#python-image",
    "title": "Python interaction",
    "section": "Python image",
    "text": "Python image\nYou need to create a Python image.\n\n%%bash\ndocker build -t pg_example_python python_interaction/python_container &&gt; /dev/null"
  },
  {
    "objectID": "postgres/python_interaction.html#start-containers",
    "href": "postgres/python_interaction.html#start-containers",
    "title": "Python interaction",
    "section": "Start containers",
    "text": "Start containers\nYou should share the same net between containers, in the following example which is completed by test_project_net.\n\n%%bash\n# network\ndocker network create test_project_net &&gt; /dev/null\n# postgres\ndocker run --rm -d\\\n    --name pg_example_posgres_cont\\\n    -e POSTGRES_USER=docker_app\\\n    -e POSTGRES_PASSWORD=docker_app\\\n    -e POSTGRES_DB=docker_app_db\\\n    --net=test_project_net\\\n    -v ./python_interaction/create_table.sql:/docker-entrypoint-initdb.d/create_table.sql\\\n    postgres:15.4 &&gt; /dev/null\n# python\ndocker run --rm -itd\\\n    --name pg_example_python_cont\\\n    --net=test_project_net\\\n    pg_example_python &&gt; /dev/null"
  },
  {
    "objectID": "postgres/python_interaction.html#executing-python",
    "href": "postgres/python_interaction.html#executing-python",
    "title": "Python interaction",
    "section": "Executing python",
    "text": "Executing python\nIn the next cell, we run the Python script in the Python container. The script simply adds some random values to the main_table from the ohter container. The message “Adding records is done!” indicates that the Python program was executed normally.\n\n%%bash\ndocker exec pg_example_python_cont bash -c \"python3 script.py\"\n\nAdding records is done!"
  },
  {
    "objectID": "postgres/python_interaction.html#check-the-table",
    "href": "postgres/python_interaction.html#check-the-table",
    "title": "Python interaction",
    "section": "Check the table",
    "text": "Check the table\nSo now, to make sure we have done everything right, let us select values from the created table.\n\n%%bash\ndocker exec pg_example_posgres_cont bash -c \\\n\"psql -U docker_app -d docker_app_db -c \\\"SELECT * FROM main_table;\\\"\"\n\n id |         text         \n----+----------------------\n 0  | sroybaubnkkggzuegofw\n 1  | afwgyapddpvuukdpkxxc\n 2  | lfxohpbhhsdcxfiiqyfp\n 3  | lfqwakbcgxefmnwsnixu\n 4  | glmxqjoovbyvwwphfcgd\n 5  | cagjujihvyntzykigrar\n 6  | tagrodfgevcqzeoyrdyt\n 7  | ngjgbkkppcvcbspypvsv\n 8  | vtyxgkaouosrkszkfwtr\n 9  | lwcxnrsrvazombgaqwuo\n 10 | dgxyzzjyuhwsotxabdbo\n 11 | ahdmlqgmauydtcxmrsrp\n 12 | oedpcbffjnblbizucezc\n 13 | ijoxobrthmytpirqijbu\n 14 | ipunrnsjrrohcwuukzsy\n 15 | eprawbrdpvhrmwhwhnrk\n 16 | yhlcgjwtuoqcpcbkaify\n 17 | eityjwmjonpfvvqarrcq\n 18 | rablibcsibalhbkqoynd\n 19 | xbnimzepzzbvjqwygiam\n(20 rows)"
  },
  {
    "objectID": "postgres/python_interaction.html#stop-containers",
    "href": "postgres/python_interaction.html#stop-containers",
    "title": "Python interaction",
    "section": "Stop containers",
    "text": "Stop containers\n\n%%bash\ndocker stop pg_example_posgres_cont pg_example_python_cont &&gt; /dev/null\ndocker network rm test_project_net &&gt; /dev/null"
  },
  {
    "objectID": "postgres/python_interaction.html#clear-python-image",
    "href": "postgres/python_interaction.html#clear-python-image",
    "title": "Python interaction",
    "section": "Clear python image",
    "text": "Clear python image\nTo avoid creating a lot of rubbish in docker images, you should delete the container created for this example.\n\n%%bash\ndocker rmi pg_example_python &&gt; /dev/null"
  },
  {
    "objectID": "postgres/python_interaction.html#database-container",
    "href": "postgres/python_interaction.html#database-container",
    "title": "Python interaction",
    "section": "Database container",
    "text": "Database container\nJust postgres container with sql script to create base table.\nNote you need to specify the port to be referred to later in the Python program.\n\n%%bash\ndocker run --rm -d\\\n    --name pg_example_posgres_cont\\\n    -e POSTGRES_USER=docker_app\\\n    -e POSTGRES_PASSWORD=docker_app\\\n    -e POSTGRES_DB=docker_app_db\\\n    -p 5431:5432\\\n    -v ./python_interaction/create_table.sql:/docker-entrypoint-initdb.d/create_table.sql\\\n    postgres:15.4 &&gt; /dev/null"
  },
  {
    "objectID": "postgres/python_interaction.html#python-program",
    "href": "postgres/python_interaction.html#python-program",
    "title": "Python interaction",
    "section": "Python program",
    "text": "Python program\nI’m just going to connect to the database from this notebook.\n\nEstablish conneciton\nIn the psycopg2.connect function, mention port used in postgres container creation and localhost argument for host parameter.\n\nimport psycopg2\n\nconn = psycopg2.connect(\n    port = \"5431\", # same as when creating a postgres container\n    dbname = \"docker_app_db\",\n    user = \"docker_app\",\n    password = \"docker_app\",\n    host= \"localhost\"\n)"
  },
  {
    "objectID": "postgres/python_interaction.html#insert-information",
    "href": "postgres/python_interaction.html#insert-information",
    "title": "Python interaction",
    "section": "Insert information",
    "text": "Insert information\nTo understand that everything works insert a few lines into database.\n\nimport random\nimport string\n\ncur = conn.cursor()\nfor i in range(20):\n    text = ''.join(random.choices(string.ascii_lowercase, k=20))\n    query = f\"INSERT INTO main_table (id, text) VALUES ('{i}', '{text}');\"\n    cur.execute(query)\ncur.close()"
  },
  {
    "objectID": "postgres/python_interaction.html#check-the-result",
    "href": "postgres/python_interaction.html#check-the-result",
    "title": "Python interaction",
    "section": "Check the result",
    "text": "Check the result\nQuery from python.\n\ncur = conn.cursor()\ncur.execute(\"SELECT * FROM main_table;\")\nfor i in cur:\n    print(i)\ncur.close()\n\n('0', 'hsehwcmxpbtamszipfnk')\n('1', 'kaqlzwklriihtmaomshb')\n('2', 'bxjyghghcopkezizliug')\n('3', 'pbdbazfbvurlfalgqjam')\n('4', 'aezqsciszlpamzxleorr')\n('5', 'lhtazvbdgpogvaveoirj')\n('6', 'msgmudlhwvrwhaovjusu')\n('7', 'dhjbmxfyfiwkldfkxbrb')\n('8', 'ciofcgizmcrhtldxplzo')\n('9', 'yimdyxfxuuchsfaxvhxo')\n('10', 'zmsukkgbbuzedxdyxlwr')\n('11', 'yaxbxgbijxsanoynpfaf')\n('12', 'ktglycpkszgbwoeibzxp')\n('13', 'sydethofplcyxcxwhiju')\n('14', 'iauhvlagywalaovfbaee')\n('15', 'rovfndivwpvulwbipubi')\n('16', 'euxrvimdiqzziaskeqbg')\n('17', 'zwldwelpwphmjptdzkdi')\n('18', 'oiywhhbnhhrktvnqdxrj')\n('19', 'jnzemljvxcjielikmqce')\n\n\nQuery from container.\nNote Before quering from the container, you need to commit the changes from the connection.\n\nconn.commit()\n%%bash\ndocker exec pg_example_posgres_cont \\\n    psql --username docker_app --dbname docker_app_db -c 'SELECT * FROM main_table;'\n\n id |         text         \n----+----------------------\n 0  | hsehwcmxpbtamszipfnk\n 1  | kaqlzwklriihtmaomshb\n 2  | bxjyghghcopkezizliug\n 3  | pbdbazfbvurlfalgqjam\n 4  | aezqsciszlpamzxleorr\n 5  | lhtazvbdgpogvaveoirj\n 6  | msgmudlhwvrwhaovjusu\n 7  | dhjbmxfyfiwkldfkxbrb\n 8  | ciofcgizmcrhtldxplzo\n 9  | yimdyxfxuuchsfaxvhxo\n 10 | zmsukkgbbuzedxdyxlwr\n 11 | yaxbxgbijxsanoynpfaf\n 12 | ktglycpkszgbwoeibzxp\n 13 | sydethofplcyxcxwhiju\n 14 | iauhvlagywalaovfbaee\n 15 | rovfndivwpvulwbipubi\n 16 | euxrvimdiqzziaskeqbg\n 17 | zwldwelpwphmjptdzkdi\n 18 | oiywhhbnhhrktvnqdxrj\n 19 | jnzemljvxcjielikmqce\n(20 rows)\n\n\n\nClose connection.\n\nconn.close()"
  },
  {
    "objectID": "postgres/python_interaction.html#stop-container",
    "href": "postgres/python_interaction.html#stop-container",
    "title": "Python interaction",
    "section": "Stop container",
    "text": "Stop container\n\n%%bash\ndocker stop pg_example_posgres_cont\n\npg_example_posgres_cont"
  },
  {
    "objectID": "postgres/build_container.html",
    "href": "postgres/build_container.html",
    "title": "Build container",
    "section": "",
    "text": "The postgres section of this site will be inextricably linked to docker, so it is extremely important to dive into the intricacies of running docker containers with postgres.\nThe greatest amount of information for this page is taken from official postgres dockerhub page.\n\nInitialisation scripts\nIf you need to organise the initialisation at container startup, you can mount a folder containing *.sql and *.sh initialisation scripts on /docker-entrypoint-initdb.d. This will execute the files in /docker-entrypoint-initdb.d.\nSo in the following example, I start the docker container with the folder mounted as /docker-entrypoint-initdb.d. This folder only contains a create_table.sql which creates an empty main_table. Then I check the existence of the table that should be created by create_table.sql.\n\n%%bash\ndocker run --rm -d\\\n    -v ./build_container/initialisation_scripts:/docker-entrypoint-initdb.d\\\n    -e POSTGRES_PASSWORD=docker_app \\\n    --name init_scripts_example \\\n    postgres:15.4 &&gt; /dev/null\n\nsleep 5\necho \"=====CHECK TABLE=====\"\ndocker exec init_scripts_example bash -c \"psql -U postgres -d postgres -c \\\"\\dt\\\"\"\n\ndocker stop  init_scripts_example &&gt; /dev/null\n\n=====CHECK TABLE=====\n           List of relations\n Schema |    Name    | Type  |  Owner   \n--------+------------+-------+----------\n public | main_table | table | postgres\n(1 row)"
  },
  {
    "objectID": "postgres/special_cases.html",
    "href": "postgres/special_cases.html",
    "title": "Special cases",
    "section": "",
    "text": "In this section, I’ll describe some common tasks associated with posgres and their solutions.\nThe following cell creates all needed for examples in this page.\n%%bash\ndocker run --rm -d\\\n    -e POSTGRES_PASSWORD=postgres \\\n    --name special_cases \\\n    postgres:15.4 &&gt; /dev/null\nsleep 5\ndocker exec -i special_cases psql -U postgres -d postgres\n\nCREATE TABLE simple_table(\n    id TEXT NOT NULL,\n    text TEXT NOT NULL\n);\nINSERT INTO simple_table (id, text) VALUES\n(0, 'Text1'),\n(1, 'tExT2'),\n(3, 'TEXT3');\n\nCREATE TABLE\nINSERT 0 3\nThe table to be used for the experiments.\n%%bash \ndocker exec -i special_cases psql -U postgres -d postgres\n\nSELECT * FROM simple_table;\n\n id | text  \n----+-------\n 0  | Text1\n 1  | tExT2\n 3  | TEXT3\n(3 rows)\nStop container! After playing with examples, you should turn it off with the following command.\n!docker stop special_cases &&gt; /dev/null"
  },
  {
    "objectID": "postgres/special_cases.html#columns-names",
    "href": "postgres/special_cases.html#columns-names",
    "title": "Special cases",
    "section": "Columns names",
    "text": "Columns names\nTo get names of all columns you should use SELECT column_name FROM information_schema.columns WHERE table_name=. Just like in following example:\n\n%%bash \ndocker exec -i special_cases psql -U postgres -d postgres\n\nSELECT column_name\nFROM information_schema.columns\nWHERE table_name = 'simple_table';\n\n column_name \n-------------\n id\n text\n(2 rows)"
  },
  {
    "objectID": "postgres/special_cases.html#count-raws",
    "href": "postgres/special_cases.html#count-raws",
    "title": "Special cases",
    "section": "Count raws",
    "text": "Count raws\nTo get counts of observations in table you can use command: SELECT COUNT(*) FROM &lt;table_name&gt;.\n\n%%bash \ndocker exec -i special_cases psql -U postgres -d postgres\n\nSELECT COUNT(*) FROM simple_table\n\n count \n-------\n     3\n(1 row)"
  },
  {
    "objectID": "postgres/special_cases.html#list-tables",
    "href": "postgres/special_cases.html#list-tables",
    "title": "Special cases",
    "section": "List tables",
    "text": "List tables\nIt’s a common task to list all available tables for the current database. So in this section I want to mention some options.\n\n\\dt\nVery simple method, but it doesn’t always work.\n\n%%bash \ndocker exec -i special_cases psql -U postgres -d postgres\n\\dt;\n\n            List of relations\n Schema |     Name     | Type  |  Owner   \n--------+--------------+-------+----------\n public | simple_table | table | postgres\n(1 row)\n\n\n\n\n\npg_catalog.pg_tables table\nThis is a service table that contains the tables available for this base.\nIn the following example, I have simply selected everything from it. By default it contains some service tables.\n\n%%bash \ndocker exec -i special_cases psql -U postgres -d postgres\nSELECT * FROM pg_catalog.pg_tables;\n\n     schemaname     |        tablename         | tableowner | tablespace | hasindexes | hasrules | hastriggers | rowsecurity \n--------------------+--------------------------+------------+------------+------------+----------+-------------+-------------\n public             | simple_table             | postgres   |            | f          | f        | f           | f\n pg_catalog         | pg_statistic             | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_type                  | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_foreign_table         | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_authid                | postgres   | pg_global  | t          | f        | f           | f\n pg_catalog         | pg_statistic_ext_data    | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_user_mapping          | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_subscription          | postgres   | pg_global  | t          | f        | f           | f\n pg_catalog         | pg_attribute             | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_proc                  | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_class                 | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_attrdef               | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_constraint            | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_inherits              | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_index                 | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_operator              | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_opfamily              | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_opclass               | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_am                    | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_amop                  | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_amproc                | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_language              | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_largeobject_metadata  | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_aggregate             | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_statistic_ext         | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_rewrite               | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_trigger               | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_event_trigger         | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_description           | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_cast                  | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_enum                  | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_namespace             | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_conversion            | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_depend                | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_database              | postgres   | pg_global  | t          | f        | f           | f\n pg_catalog         | pg_db_role_setting       | postgres   | pg_global  | t          | f        | f           | f\n pg_catalog         | pg_tablespace            | postgres   | pg_global  | t          | f        | f           | f\n pg_catalog         | pg_auth_members          | postgres   | pg_global  | t          | f        | f           | f\n pg_catalog         | pg_shdepend              | postgres   | pg_global  | t          | f        | f           | f\n pg_catalog         | pg_shdescription         | postgres   | pg_global  | t          | f        | f           | f\n pg_catalog         | pg_ts_config             | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_ts_config_map         | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_ts_dict               | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_ts_parser             | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_ts_template           | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_extension             | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_foreign_data_wrapper  | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_foreign_server        | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_policy                | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_replication_origin    | postgres   | pg_global  | t          | f        | f           | f\n pg_catalog         | pg_default_acl           | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_init_privs            | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_seclabel              | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_shseclabel            | postgres   | pg_global  | t          | f        | f           | f\n pg_catalog         | pg_collation             | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_parameter_acl         | postgres   | pg_global  | t          | f        | f           | f\n pg_catalog         | pg_partitioned_table     | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_range                 | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_transform             | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_sequence              | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_publication           | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_publication_namespace | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_publication_rel       | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_subscription_rel      | postgres   |            | t          | f        | f           | f\n pg_catalog         | pg_largeobject           | postgres   |            | t          | f        | f           | f\n information_schema | sql_features             | postgres   |            | f          | f        | f           | f\n information_schema | sql_implementation_info  | postgres   |            | f          | f        | f           | f\n information_schema | sql_parts                | postgres   |            | f          | f        | f           | f\n information_schema | sql_sizing               | postgres   |            | f          | f        | f           | f\n(69 rows)\n\n\n\nBut we can impose restrictions, for example, on the schemaname column and get only those tables we are interested in.\n\n%%bash \ndocker exec -i special_cases psql -U postgres -d postgres\nSELECT * FROM pg_catalog.pg_tables WHERE schemaname='public';\n\n schemaname |  tablename   | tableowner | tablespace | hasindexes | hasrules | hastriggers | rowsecurity \n------------+--------------+------------+------------+------------+----------+-------------+-------------\n public     | simple_table | postgres   |            | f          | f        | f           | f\n(1 row)"
  },
  {
    "objectID": "jupyter/nbconvert/example_notebook.html",
    "href": "jupyter/nbconvert/example_notebook.html",
    "title": "Latex",
    "section": "",
    "text": "Notebook - пример для того чтобы разобраться в особенностсях рабты с nbcnovert\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\n\\[f(x) = x_2+3x+22\\]\n\nMatplotlib график\n\nans = plt.plot([1,2,3], [3,4,5])\n\n\n\n\n\n\nПросто картинка\n\n\n\npandas таблица\n\npd.DataFrame(\n    np.random.rand(20, 30)\n)\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n\n\n0\n0.663143\n0.021464\n0.858000\n0.766506\n0.985039\n0.346647\n0.364177\n0.912234\n0.037032\n0.272790\n...\n0.327494\n0.880709\n0.041401\n0.369179\n0.451213\n0.611814\n0.560559\n0.523025\n0.205788\n0.422654\n\n\n1\n0.827827\n0.649757\n0.215769\n0.179621\n0.570741\n0.088579\n0.845170\n0.596793\n0.161002\n0.002342\n...\n0.034259\n0.278648\n0.882712\n0.355811\n0.766390\n0.151718\n0.863036\n0.730791\n0.114088\n0.379146\n\n\n2\n0.865272\n0.487274\n0.399290\n0.380105\n0.088102\n0.054062\n0.795389\n0.883104\n0.364047\n0.394248\n...\n0.415779\n0.853940\n0.773343\n0.865510\n0.672601\n0.770037\n0.088337\n0.236902\n0.437594\n0.369074\n\n\n3\n0.009670\n0.119128\n0.477052\n0.103209\n0.975513\n0.152730\n0.106975\n0.577861\n0.976428\n0.734008\n...\n0.431997\n0.990676\n0.972629\n0.698313\n0.197316\n0.172827\n0.365104\n0.543878\n0.373947\n0.177256\n\n\n4\n0.209034\n0.328370\n0.747825\n0.912026\n0.684328\n0.730339\n0.222565\n0.723777\n0.249022\n0.515858\n...\n0.344164\n0.825411\n0.107212\n0.722163\n0.064626\n0.557274\n0.979061\n0.617117\n0.129202\n0.828734\n\n\n5\n0.748535\n0.438338\n0.321346\n0.048413\n0.564367\n0.938365\n0.504495\n0.701783\n0.817506\n0.966032\n...\n0.833825\n0.877737\n0.827943\n0.433181\n0.188727\n0.847585\n0.873378\n0.414874\n0.385979\n0.283664\n\n\n6\n0.169217\n0.189379\n0.279181\n0.105524\n0.321006\n0.469294\n0.298573\n0.752147\n0.512748\n0.326833\n...\n0.978364\n0.807084\n0.742420\n0.718420\n0.715044\n0.568432\n0.673553\n0.608451\n0.242622\n0.858917\n\n\n7\n0.318894\n0.703588\n0.918537\n0.798998\n0.097702\n0.837357\n0.734335\n0.260800\n0.746494\n0.996407\n...\n0.895983\n0.674704\n0.269369\n0.561942\n0.527911\n0.219911\n0.668875\n0.098179\n0.040179\n0.268487\n\n\n8\n0.538815\n0.789962\n0.170698\n0.653034\n0.209657\n0.784521\n0.721873\n0.653080\n0.735756\n0.870527\n...\n0.816603\n0.700780\n0.589116\n0.054555\n0.269549\n0.292141\n0.051452\n0.064437\n0.029045\n0.033099\n\n\n9\n0.825010\n0.985221\n0.892499\n0.012812\n0.073686\n0.189973\n0.263994\n0.868104\n0.625486\n0.905932\n...\n0.810490\n0.282077\n0.346684\n0.959549\n0.245090\n0.283466\n0.027302\n0.097790\n0.422846\n0.071181\n\n\n10\n0.071752\n0.566090\n0.576133\n0.042006\n0.724374\n0.617664\n0.646433\n0.685819\n0.075983\n0.945756\n...\n0.379925\n0.579344\n0.854027\n0.674528\n0.111671\n0.101454\n0.556477\n0.319533\n0.891699\n0.777899\n\n\n11\n0.321099\n0.606897\n0.152936\n0.282932\n0.240571\n0.523979\n0.499664\n0.103284\n0.252159\n0.749216\n...\n0.756029\n0.388600\n0.771017\n0.406881\n0.670963\n0.328559\n0.055640\n0.058266\n0.255477\n0.231221\n\n\n12\n0.069434\n0.471599\n0.879479\n0.150907\n0.259604\n0.121494\n0.283101\n0.632702\n0.969049\n0.416081\n...\n0.228064\n0.802990\n0.601474\n0.595615\n0.171583\n0.885227\n0.570803\n0.629680\n0.481346\n0.823556\n\n\n13\n0.008207\n0.210180\n0.048300\n0.360097\n0.540163\n0.947513\n0.017571\n0.152821\n0.986996\n0.352458\n...\n0.460305\n0.102086\n0.617660\n0.219018\n0.832248\n0.308261\n0.002964\n0.548857\n0.822519\n0.257786\n\n\n14\n0.564729\n0.040055\n0.281084\n0.704265\n0.293981\n0.351052\n0.014585\n0.487037\n0.433179\n0.850257\n...\n0.708030\n0.932107\n0.591465\n0.046695\n0.475054\n0.762240\n0.329465\n0.752053\n0.205726\n0.453508\n\n\n15\n0.916010\n0.569487\n0.000574\n0.240208\n0.380580\n0.704447\n0.128708\n0.905343\n0.504579\n0.139354\n...\n0.489544\n0.711177\n0.540197\n0.433703\n0.889278\n0.716258\n0.368589\n0.243502\n0.430579\n0.207018\n\n\n16\n0.555162\n0.159681\n0.611847\n0.286136\n0.345460\n0.190651\n0.211620\n0.289052\n0.445264\n0.415703\n...\n0.782363\n0.835031\n0.996787\n0.903400\n0.236019\n0.176010\n0.306686\n0.103315\n0.948140\n0.046661\n\n\n17\n0.867713\n0.831490\n0.288641\n0.728252\n0.620024\n0.315909\n0.273223\n0.423136\n0.236910\n0.257647\n...\n0.016341\n0.977661\n0.601080\n0.977532\n0.088836\n0.754579\n0.807837\n0.050929\n0.439012\n0.721582\n\n\n18\n0.333013\n0.409006\n0.669115\n0.700568\n0.903307\n0.822934\n0.635862\n0.613437\n0.187538\n0.050552\n...\n0.724519\n0.016494\n0.550508\n0.223219\n0.444358\n0.734620\n0.902881\n0.728414\n0.595171\n0.161489\n\n\n19\n0.614472\n0.792331\n0.300568\n0.345817\n0.407511\n0.816590\n0.950677\n0.037251\n0.316392\n0.058362\n...\n0.296249\n0.254440\n0.963934\n0.222605\n0.509345\n0.495333\n0.685706\n0.500341\n0.956666\n0.333952\n\n\n\n\n20 rows × 30 columns\n\n\n\n\n\nТэги\nВ следующих ячейках записано какой тэг для каждой применен.\nТэг remove_cell для markdown ячейки.\n\nprint(\"remove_input\")\n\nremove_input\n\n\n\nprint(\"remove_output\")\n\nremove_output"
  },
  {
    "objectID": "jupyter/nbconvert/nbconvert_examples.html",
    "href": "jupyter/nbconvert/nbconvert_examples.html",
    "title": "Источники",
    "section": "",
    "text": "Как пользоваться nbconvert\nnbconvernt моежт быть использован как утилита командной строки или же python библиотека. Тут я буду рассматривать nbconvert как python библиотеку.\nimport io\n\nimport nbformat\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom traitlets.config import Config\n\nfrom nbconvert import HTMLExporter,\\\n                        RSTExporter"
  },
  {
    "objectID": "jupyter/nbconvert/nbconvert_examples.html#htmlexporter",
    "href": "jupyter/nbconvert/nbconvert_examples.html#htmlexporter",
    "title": "Источники",
    "section": "HTMLExporter",
    "text": "HTMLExporter\nПозволяет экспортировать файл в html.\n\nhtml_exporter = HTMLExporter(template_name='classic')\n(body, resources) = html_exporter.from_notebook_node(notebook)\n\nИ так возвращаяется два объекта\n\nbody\nПервый это тело html файла, его можно сразу сохранить и получается вполне себе html.\n\nfile = open(\"basic_html_exporter.html\", \"w+\")\nfile.write(body)\nfile.close()\n\nНо при спользовании такого подхода есть проблема - картинки, формируемые как часть markdown разметки не будут встроены в .html, а будут лишь ссылками на файлы.\n\n\nresources\nСписок ресурсов используемых для формирования jupyter.\n\nresources\n\nResourcesDict(None,\n              {'metadata': ResourcesDict(None, {'name': 'Notebook'}),\n               'output_extension': '.html',\n               'deprecated': &lt;function nbconvert.exporters.templateexporter.deprecated(msg)&gt;,\n               'theme': 'light',\n               'include_css': &lt;function nbconvert.exporters.html.HTMLExporter._init_resources.&lt;locals&gt;.resources_include_css(name)&gt;,\n               'include_lab_theme': &lt;function nbconvert.exporters.html.HTMLExporter._init_resources.&lt;locals&gt;.resources_include_lab_theme(name)&gt;,\n               'include_js': &lt;function nbconvert.exporters.html.HTMLExporter._init_resources.&lt;locals&gt;.resources_include_js(name)&gt;,\n               'include_url': &lt;function nbconvert.exporters.html.HTMLExporter._init_resources.&lt;locals&gt;.resources_include_url(name)&gt;,\n               'require_js_url': 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js',\n               'mathjax_url': 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe',\n               'jquery_url': 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js',\n               'jupyter_widgets_base_url': 'https://unpkg.com/',\n               'widget_renderer_url': '',\n               'html_manager_semver_range': '*',\n               'inlining': {'css': ['pre { line-height: 125%; }\\ntd.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\\nspan.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\\ntd.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\\nspan.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\\n.highlight .hll { background-color: #ffffcc }\\n.highlight { background: #f8f8f8; }\\n.highlight .c { color: #3D7B7B; font-style: italic } /* Comment */\\n.highlight .err { border: 1px solid #FF0000 } /* Error */\\n.highlight .k { color: #008000; font-weight: bold } /* Keyword */\\n.highlight .o { color: #666666 } /* Operator */\\n.highlight .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\\n.highlight .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\\n.highlight .cp { color: #9C6500 } /* Comment.Preproc */\\n.highlight .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\\n.highlight .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\\n.highlight .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\\n.highlight .gd { color: #A00000 } /* Generic.Deleted */\\n.highlight .ge { font-style: italic } /* Generic.Emph */\\n.highlight .gr { color: #E40000 } /* Generic.Error */\\n.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */\\n.highlight .gi { color: #008400 } /* Generic.Inserted */\\n.highlight .go { color: #717171 } /* Generic.Output */\\n.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\\n.highlight .gs { font-weight: bold } /* Generic.Strong */\\n.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\\n.highlight .gt { color: #0044DD } /* Generic.Traceback */\\n.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\\n.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\\n.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\\n.highlight .kp { color: #008000 } /* Keyword.Pseudo */\\n.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\\n.highlight .kt { color: #B00040 } /* Keyword.Type */\\n.highlight .m { color: #666666 } /* Literal.Number */\\n.highlight .s { color: #BA2121 } /* Literal.String */\\n.highlight .na { color: #687822 } /* Name.Attribute */\\n.highlight .nb { color: #008000 } /* Name.Builtin */\\n.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */\\n.highlight .no { color: #880000 } /* Name.Constant */\\n.highlight .nd { color: #AA22FF } /* Name.Decorator */\\n.highlight .ni { color: #717171; font-weight: bold } /* Name.Entity */\\n.highlight .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\\n.highlight .nf { color: #0000FF } /* Name.Function */\\n.highlight .nl { color: #767600 } /* Name.Label */\\n.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\\n.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */\\n.highlight .nv { color: #19177C } /* Name.Variable */\\n.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\\n.highlight .w { color: #bbbbbb } /* Text.Whitespace */\\n.highlight .mb { color: #666666 } /* Literal.Number.Bin */\\n.highlight .mf { color: #666666 } /* Literal.Number.Float */\\n.highlight .mh { color: #666666 } /* Literal.Number.Hex */\\n.highlight .mi { color: #666666 } /* Literal.Number.Integer */\\n.highlight .mo { color: #666666 } /* Literal.Number.Oct */\\n.highlight .sa { color: #BA2121 } /* Literal.String.Affix */\\n.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */\\n.highlight .sc { color: #BA2121 } /* Literal.String.Char */\\n.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */\\n.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\\n.highlight .s2 { color: #BA2121 } /* Literal.String.Double */\\n.highlight .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\\n.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */\\n.highlight .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\\n.highlight .sx { color: #008000 } /* Literal.String.Other */\\n.highlight .sr { color: #A45A77 } /* Literal.String.Regex */\\n.highlight .s1 { color: #BA2121 } /* Literal.String.Single */\\n.highlight .ss { color: #19177C } /* Literal.String.Symbol */\\n.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */\\n.highlight .fm { color: #0000FF } /* Name.Function.Magic */\\n.highlight .vc { color: #19177C } /* Name.Variable.Class */\\n.highlight .vg { color: #19177C } /* Name.Variable.Global */\\n.highlight .vi { color: #19177C } /* Name.Variable.Instance */\\n.highlight .vm { color: #19177C } /* Name.Variable.Magic */\\n.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */']},\n               'raw_mimetypes': ['text/html', ''],\n               'global_content_filter': {'include_code': True,\n                'include_markdown': True,\n                'include_raw': True,\n                'include_unknown': True,\n                'include_input': True,\n                'include_output': True,\n                'include_output_stdin': False,\n                'include_input_prompt': True,\n                'include_output_prompt': True,\n                'no_prompt': False}})"
  },
  {
    "objectID": "jupyter/nbconvert/nbconvert_examples.html#rstexporter",
    "href": "jupyter/nbconvert/nbconvert_examples.html#rstexporter",
    "title": "Источники",
    "section": "RSTExporter",
    "text": "RSTExporter\nПозволяет диаграммы на графике экспортировать не в .html файл а в ресурсы.\nСпособ использования ничем не отличатеся от рассмотренного выше HTMLExporter.\n\nrst_exporter = RSTExporter()\n(body, resources) = rst_exporter.from_notebook_node(notebook)\n\nНо полученный body содержит только текст.\n\nfile = open(\"rst_exporter.html\", \"w+\")\nfile.write(body)\nfile.close()\n\nНекоторые дополнительные элементы сохранены в resources. Так, например, картинки-результаты выполнения ячеек будут лежать resources[\"outputs\"]. Далее пример их извлечения:\n\noutputs = resources[\"outputs\"]\noutputs_len = len(outputs)\n\nplt.figure(figsize = [5,20])\nfor i, pic_name in enumerate(outputs.keys()):\n    plt.subplot(outputs_len, 1, i+1)\n    plt.xticks([]); plt.yticks([])\n    plt.imshow(\n        plt.imread(\n            io.BytesIO(outputs[pic_name]), format='jpeg'\n        )\n    )\n\n\n\n\nГде были сохранены стили, и почему слетают способы формирования ячеек не понятно."
  },
  {
    "objectID": "jupyter/voila_vs_nbconvert_saving_html/contains_html.html",
    "href": "jupyter/voila_vs_nbconvert_saving_html/contains_html.html",
    "title": "NBconvert",
    "section": "",
    "text": "В этом простом notebook содражться несколько latex выражений. Я намереваю сравнить два случая: - Конвернация в html используя nbconvert; - И используя voila с последующим сохраненнием в html.\nЦель - выяснить, как отличаются части html документов, полученных при использовании каждого из подходов, ответсвенные за latex.\n\\[x_2+3=3232\\]\nА это latex внутри markdown с использованием всего одного знака $ для выделения \\(\\sqrt{x_2}\\).\nКак результат в не слишком продвинух html движках (например базовый viewer jupyter lab) результат получается не очень.\n$$x_2+3=3232$$\nНу а html разметка для той ячейки где сидит latex, выглядит так.\n&lt;div class=\"jp-Cell jp-MarkdownCell jp-Notebook-cell\"&gt;\n&lt;div class=\"jp-Cell-inputWrapper\"&gt;\n&lt;div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"&gt;\n&lt;/div&gt;\n&lt;div class=\"jp-InputArea jp-Cell-inputArea\"&gt;&lt;div class=\"jp-InputPrompt jp-InputArea-prompt\"&gt;\n&lt;/div&gt;&lt;div class=\"jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput \" data-mime-type=\"text/markdown\"&gt;\n$$x_2+3=3232$$\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n\nСохранение страницы из voila\nНа любом из известных графических движков выглядит нормально… Соответсвующий html для ячейки.\n&lt;div class=\"jp-Cell jp-MarkdownCell jp-Notebook-cell\"&gt;\n&lt;div class=\"jp-Cell-inputWrapper\"&gt;\n&lt;div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"&gt;\n&lt;/div&gt;\n&lt;div class=\"jp-InputArea jp-Cell-inputArea\"&gt;&lt;div class=\"jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput \" data-mime-type=\"text/markdown\"&gt;\n&lt;span class=\"MathJax_Preview\" style=\"color: inherit;\"&gt;&lt;/span&gt;&lt;span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"&gt;&lt;span id=\"MathJax-Element-1-Frame\" class=\"mjx-chtml MathJax_CHTML\" tabindex=\"0\" style=\"font-size: 116%; text-align: center; position: relative;\" data-mathml=\"&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;3232&lt;/mn&gt;&lt;/math&gt;\" role=\"presentation\"&gt;&lt;span id=\"MJXc-Node-1\" class=\"mjx-math\" aria-hidden=\"true\"&gt;&lt;span id=\"MJXc-Node-2\" class=\"mjx-mrow\"&gt;&lt;span id=\"MJXc-Node-3\" class=\"mjx-msubsup\"&gt;&lt;span class=\"mjx-base\"&gt;&lt;span id=\"MJXc-Node-4\" class=\"mjx-mi\"&gt;&lt;span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.249em; padding-bottom: 0.311em;\"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"&gt;&lt;span id=\"MJXc-Node-5\" class=\"mjx-mn\" style=\"\"&gt;&lt;span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.373em; padding-bottom: 0.373em;\"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span id=\"MJXc-Node-6\" class=\"mjx-mo MJXc-space2\"&gt;&lt;span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.311em; padding-bottom: 0.434em;\"&gt;+&lt;/span&gt;&lt;/span&gt;&lt;span id=\"MJXc-Node-7\" class=\"mjx-mn MJXc-space2\"&gt;&lt;span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.373em; padding-bottom: 0.373em;\"&gt;3&lt;/span&gt;&lt;/span&gt;&lt;span id=\"MJXc-Node-8\" class=\"mjx-mo MJXc-space3\"&gt;&lt;span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.065em; padding-bottom: 0.311em;\"&gt;=&lt;/span&gt;&lt;/span&gt;&lt;span id=\"MJXc-Node-9\" class=\"mjx-mn MJXc-space3\"&gt;&lt;span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.373em; padding-bottom: 0.373em;\"&gt;3232&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"&gt;&lt;math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;3232&lt;/mn&gt;&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;script type=\"math/tex; mode=display\" id=\"MathJax-Element-1\"&gt;x_2+3=3232&lt;/script&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\nПонятное дело html полученный из voila выглядит значительно солиднее."
  },
  {
    "objectID": "python/plotly/hovers.html",
    "href": "python/plotly/hovers.html",
    "title": "Hovers",
    "section": "",
    "text": "Some items when you hover your mouse over them show a hint. To control the properties of this tooltip, plotly offers a number of properties that usually start with hover.\nPlotly user guide to work with it."
  },
  {
    "objectID": "python/plotly/hovers.html#basic",
    "href": "python/plotly/hovers.html#basic",
    "title": "Hovers",
    "section": "Basic",
    "text": "Basic\nSo in the following example there is a scatter with blue dots that have hovertemplate specified and a scatter with red dots that don’t have hovertemplate specified.\n\nimport numpy as np\nimport plotly.graph_objects as go\n\nsample_size = 100\n\nfig = go.Figure()\nfig.add_trace(\n    go.Scatter(\n        x = np.random.rand(sample_size),\n        y = np.random.rand(sample_size),\n        mode = \"markers\",\n        hovertemplate = \"x=%{x}&lt;br&gt;y=%{y}\",\n        name = \"I have hovertemplate\",\n        marker_size = 10\n    )\n)\nfig.add_trace(\n    go.Scatter(\n        x = np.random.rand(sample_size),\n        y = np.random.rand(sample_size),\n        mode = \"markers\",\n        marker={\"color\" : \"red\"},\n        name = \"No hovertemplate\",\n        marker_size = 10\n    )\n)\n\nfig.update_layout(height = 700)"
  },
  {
    "objectID": "python/plotly/hovers.html#variable",
    "href": "python/plotly/hovers.html#variable",
    "title": "Hovers",
    "section": "%{variable}",
    "text": "%{variable}\nYou can display different parameters of elements on the plots, just using syntax {%variable}. And you can add some formatting, see here and here for dates.\n\nimport numpy as np\nimport plotly.graph_objects as go\nfrom IPython.display import HTML\n\nsample_size = 100\n\nlanguages = [\"R\", \"Python\", \"Java Script\", \"Matlab\"]\nusers = [2, 5, 3, 2.5]\ntext = [\"textA\", \"TextB\", \"TextC\", \"TextD\"]\n\nfig = go.Figure()\nfig.add_trace(\n    go.Pie(\n        name = \"\",\n        values = users,\n        labels = languages,\n        text = text,\n        hovertemplate = \"%{label}: &lt;br&gt;Popularity: %{percent} &lt;br&gt;%{text}&lt;extra&gt;&lt;/extra&gt;\"\n    )\n)\nfig.show()\n\n\nfig = go.Figure()\nfig.add_trace(\n    go.Bar(\n        x = languages,\n        y = users,\n        text = text,\n        hovertemplate = \"%{x} has %{y} users &lt;extra&gt;&lt;/extra&gt;\"\n    )\n)\nfig.show()"
  },
  {
    "objectID": "python/plotly/hovers.html#extra",
    "href": "python/plotly/hovers.html#extra",
    "title": "Hovers",
    "section": "<extra>",
    "text": "&lt;extra&gt;\nAn additional block is added to the tooltip - by default, it is a semi-prominent part to the left of the main tooltip. Its content is resolved by the &lt;extra&gt; tag in hovertemplate. To get rid of it, the &lt;extra&gt; tag should be left empty.\nSo in the following example, I build the scatter with different cases with &lt;extra&gt;:\n\nsample_size = 50\n\nplot_params = [\n    dict(name = \"No hovertemplate\"),\n    dict(\n        hovertemplate = \"%{x} - %{y}\",\n        name = \"No extra\",\n    ),\n    dict(\n        hovertemplate = \"%{x} - %{y}&lt;extra&gt;&lt;/extra&gt;\",\n        name = \"Empty extra\",\n    ),\n    dict(\n        hovertemplate = \"%{x} - %{y}&lt;extra&gt;random hovertext %{hovertext}&lt;/extra&gt;\",\n        name = \"Content in extra\",\n        hovertext = [\n            \"\".join(\n                np.random.choice([i for i in \"abdcefghijkilm\"], 10)\n            )\n            for i in range(sample_size)\n        ]\n    )\n]\n\nfig = go.Figure()\nfor pp in plot_params:\n    fig.add_trace(\n        go.Scatter(\n            x = np.random.rand(sample_size),\n            y = np.random.rand(sample_size),\n            mode = \"markers\",\n            marker_size = 10,\n            **pp\n        )\n    )\n\nfig.update_layout(height = 700)\n\nfig.show()"
  },
  {
    "objectID": "python/sklearn/pipeline.html",
    "href": "python/sklearn/pipeline.html",
    "title": "Pipeline",
    "section": "",
    "text": "The sklearn.pipeline.Pipeline is a tool that allows you to create objects that contain all the necessary stages of model fitting. In other words, you can create your own estimator as a combination of different objects that perform data processing or model fitting.\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import KFold, cross_validate\nfrom sklearn.metrics import mean_squared_error"
  },
  {
    "objectID": "python/sklearn/pipeline.html#demonstration-of-benefits",
    "href": "python/sklearn/pipeline.html#demonstration-of-benefits",
    "title": "Pipeline",
    "section": "Demonstration of benefits",
    "text": "Demonstration of benefits\nImagine that you need to create a model building pipeline that includes data standardisation and then model fitting. In this section I want to show the difference in code length and convenience of coding all by yourself and using the sklean.pipeline.Pipeline class.\n\nData generation\nIn the following cell I just generate a random regression task for use in the example.\n\nsample_size = 1000\nfeatures_count = 20\nnp.random.seed(50)\n\nX = []\n\nfor i in range(features_count):\n\n    mean = np.random.uniform(0,100)\n    std = np.abs(np.random.normal(0, 50))\n    \n    X.append(np.random.normal(mean, std, [sample_size, 1]))\n\nX = np.concatenate(X,axis=1)\ntheoretical_coefs = np.random.normal(0, 20, [features_count, 1])\ny = np.dot(X, theoretical_coefs) + np.random.normal(0, 500, sample_size)\n\n\n\nSelf coding\nSo here is code that does:\n\n10-fold split cross-validation for the named pipeline;\nDisplay cross-validation results;\nFit model to full data sample;\nCompute the mean prediction over the entire data sample.\n\nYou need to create a cycle that fits StandardScaler for current split and fit model to standardised data. After the cycle at the step of fitting the model to the whole data, you need to describe the whole pipeline again!\n\nmy_split = KFold(n_splits = 10)\ntrain_errors = []\ntest_errors = []\n\n\nfor train_ind, test_ind in my_split.split(X):\n    \n    this_scaler = StandardScaler().fit(X[train_ind, :])\n    \n    train_X = this_scaler.transform(X[train_ind, :])\n    train_y = y[train_ind]\n    \n    test_X = this_scaler.transform(X[test_ind,:])\n    test_y = y[test_ind]\n\n    model = LinearRegression().fit(train_X, train_y)\n    train_errors.append(mean_squared_error(train_y, model.predict(train_X)))\n    test_errors.append(mean_squared_error(test_y, model.predict(test_X)))\n\nprint(\"Train error:\", np.mean(np.array(train_errors)))\nprint(\"Test error:\", np.mean(np.array(test_errors)))\n\nstandart_X = StandardScaler().fit_transform(X)\nfinal_model = LinearRegression().fit(standart_X, y)\nprint(\"Mean predict\", np.mean(final_model.predict(standart_X)))\n\nTrain error: 3.5097084970944476e-22\nTest error: 3.4625913023012295e-22\nMean predict 19010.954067406543\n\n\n\n\nUsing sklearn.pipeline\nIn the following cell, I perform exactly the same calculations using only sklearn.pipeline.Pipeline.\nYou just need to define a my_pipline object where I describe the steps of the pipeline in the format [(&lt;name of step 1&gt;,&lt;object performing step 1&gt;), (&lt;name of step 2&gt;,&lt;object performing step 2&gt;), ...] and then just use it as a normal estimator - it will perform all the steps automatically.\nSo in the following cell it used in combination with cross_validate function to perform cross-validation, and after that just called fit(...).predict(...) to run the entire sample through the pipeline.\nThe results are exactly the same.\nLess code! Easier to manage!\n\nmy_split = KFold(n_splits = 10)\n\nmy_pipe = Pipeline([\n    (\"test_scaler\", StandardScaler()),\n    (\"my_model\", LinearRegression())\n])\n\ncv_results = cross_validate(\n    estimator = my_pipe,\n    X = X, y = y,\n    scoring=\"neg_mean_squared_error\",\n    cv = my_split,\n    return_train_score=True\n)\n\nprint(\"Train error:\", np.mean(cv_results[\"train_score\"]))\nprint(\"Test error:\", np.mean(cv_results[\"test_score\"]))\nprint(\"Mean predict\", np.mean(my_pipe.fit(X,y).predict(X)))\n\nTrain error: -3.5097084970944476e-22\nTest error: -3.4625913023012295e-22\nMean predict 19010.954067406543"
  },
  {
    "objectID": "python/basics/operators.html",
    "href": "python/basics/operators.html",
    "title": "Operators",
    "section": "",
    "text": "On this page I’ll describe some details about operators in Python."
  },
  {
    "objectID": "python/basics/operators.html#list",
    "href": "python/basics/operators.html#list",
    "title": "Operators",
    "section": "list",
    "text": "list\n\ntest_list = [1,2,3,4,5] \nprint(5 in test_list)\nprint(6 in test_list)\n\nTrue\nFalse"
  },
  {
    "objectID": "python/basics/operators.html#tuple",
    "href": "python/basics/operators.html#tuple",
    "title": "Operators",
    "section": "tuple",
    "text": "tuple\n\ntest_tuple = (1,2,3,4,5)\nprint(5 in test_tuple)\nprint(6 in test_tuple)\n\nTrue\nFalse"
  },
  {
    "objectID": "python/basics/operators.html#str",
    "href": "python/basics/operators.html#str",
    "title": "Operators",
    "section": "str",
    "text": "str\n\ntest_str = \"this is the test str contains subline to check it\"\n\nprint(\"subline\" in test_str)\nprint(\"subliner\" in test_str)\n\nTrue\nFalse"
  },
  {
    "objectID": "python/basics/operators.html#dict",
    "href": "python/basics/operators.html#dict",
    "title": "Operators",
    "section": "dict",
    "text": "dict\nChecks if the element on the left side of in is in the keys (not values) of the dictionary on the right side of in.\n\ntest_dict = {\"a\":1, \"b\":2}\nprint(\"a\" in test_dict)\nprint(1 in test_dict)\n\nTrue\nFalse"
  },
  {
    "objectID": "python/basics/operators.html#easy-examples",
    "href": "python/basics/operators.html#easy-examples",
    "title": "Operators",
    "section": "Easy examples",
    "text": "Easy examples\nNow some simple examples that demonstrate how to use the proposed table in practice.\n\nOperator sequence\nThe following example show that ** will be executed before * anyway. Calculation always follows the way \\(4^2=16 \\rightarrow 16*2 = 32\\) and never \\(2*4=8 \\rightarrow 8^2=64\\).\n\nprint(2*4**2)\nprint(4**2*2)\n\n32\n\n\n\n\nAssociativity\nAs mentioned for the operators / and *, they are executed from left to right. So the following example will use logic \\(3/3=1 \\rightarrow 1*2=2\\), not \\(3*2=6 \\rightarrow 3/6=0.5\\).\n\n3/3*2\n\n2.0\n\n\nOne more example shows how associativity rool changes the result with exactly same operands.\n\nIn first case it uses logic \\(3/3=1 \\rightarrow [1/3]=1\\);\nIn second case it uses logic \\([3/3]=0 \\rightarrow 0/3=0\\).\n\n\nprint(3/3%3)\nprint(3%3/3)\n\n1.0\n0.0"
  },
  {
    "objectID": "python/basics/operators.html#nested-loops",
    "href": "python/basics/operators.html#nested-loops",
    "title": "Operators",
    "section": "Nested loops",
    "text": "Nested loops\nWhat will happens if you put cycle incide two cycles? Will it leave both cycles or just the internal one?\nIt will leave only intertal loop.\nSo in the following example we will use the break operator inside the internal cycle only if we loop to a variable of the internal cycle that is equal to or greater than 2. As a result, we go through all the operations provided by the outer loop, but each interation of the internal loop is ended when the loop variable enriches 2.\n\nfor i in range(4):\n    print(\"external loop\", i)\n    for j in range(4):\n        if j &gt;= 2:\n            break\n        print(\"    internal loop\", j)\n\nexternal loop 0\n    internal loop 0\n    internal loop 1\nexternal loop 1\n    internal loop 0\n    internal loop 1\nexternal loop 2\n    internal loop 0\n    internal loop 1\nexternal loop 3\n    internal loop 0\n    internal loop 1\n\n\nSolution the best solution for today is to organise a flag that will cause a break operator in the external cycle.\nSo in the following example I have added a flag that gets a True value before exiting the internal loop, and if after exiting the internal loop flag==True it will cause exiting the external cycle as well.\nNo better solution has been found to date.\n\nfor i in range(4):\n    print(\"external loop\", i)\n    for j in range(4):\n        if j &gt;= 2:\n            flag = True\n            break\n        print(\"    internal loop\", j)\n\n    if flag: break\n\nexternal loop 0\n    internal loop 0\n    internal loop 1"
  },
  {
    "objectID": "python/basics/operators.html#negative-index",
    "href": "python/basics/operators.html#negative-index",
    "title": "Operators",
    "section": "Negative index",
    "text": "Negative index\nIn Python, all indices have an alternate index which is negative. Suppose we have a list of n elements, so elements will have indexes from 0 to n-1 and from -n to -1.\nThe following table puts positive and negative indexing in python into a visual correlation.\n\n\n\n\nPositive indexing\n\n\n0\n\n\n1\n\n\n…\n\n\nn-1\n\n\n\n\nNegative indexing\n\n\n-n\n\n\n-n+1\n\n\n…\n\n\n-1\n\n\n\n\nIt can be very useful to access items from the end of the collection. So in the last example, I easily accessed the penultimate item in the list.\n\nlist(range(50))[-2]\n\n48"
  },
  {
    "objectID": "python/basics/numpy/functions.html",
    "href": "python/basics/numpy/functions.html",
    "title": "fromfunciton",
    "section": "",
    "text": "Тут я собираю сведения о функция numpy которымы должен пользоваться или постоянно забываю как\n\nimport numpy as np\n\nПозволяет создать numpy.array используя правило задаваемое через функцию.\n\nnp.fromfunction(lambda i, j: i*3 + j, (4,4))\n\narray([[ 0.,  1.,  2.,  3.],\n       [ 3.,  4.,  5.,  6.],\n       [ 6.,  7.,  8.,  9.],\n       [ 9., 10., 11., 12.]])\n\n\n\nnumpy всегда оперирует массивами\nСледует помнить, что numpy всегда оперирует массивами. Рассмотрим пример кода из следующей ячейки. Тут предполагается возвращать для четной суммы индексов строковое значение “четная” а для не четной суммы индексов “нечетная”.\n\nnp.fromfunction(\n    lambda i,j:\"Четая\" if i&gt;j else \"Не четная\",\n    (4,4)\n)\n\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n\n\nДля того, чтобы разобраться почему так происходит, выведем параметы, которые приходят в функцию-правило переданную fromfunction.\n\ndef test_func(i,j):\n    print(i)\n    print(j)\n    return 0\n\nnp.fromfunction(test_func, (4,4))\n\n[[0. 0. 0. 0.]\n [1. 1. 1. 1.]\n [2. 2. 2. 2.]\n [3. 3. 3. 3.]]\n[[0. 1. 2. 3.]\n [0. 1. 2. 3.]\n [0. 1. 2. 3.]\n [0. 1. 2. 3.]]\n\n\n0\n\n\nИтак, приходят матрицы с индексами по строчкам для аргумента i и по столбцам для аргумента j.\n\nnp.fromfunction(\n    lambda i,j: np.where((i+j)%2==0, \"четная\", \"нечетная\"),\n    (4,4)\n)\n\narray([['четная', 'нечетная', 'четная', 'нечетная'],\n       ['нечетная', 'четная', 'нечетная', 'четная'],\n       ['четная', 'нечетная', 'четная', 'нечетная'],\n       ['нечетная', 'четная', 'нечетная', 'четная']], dtype='&lt;U8')"
  },
  {
    "objectID": "python/basics/numpy/set_printoptions.html",
    "href": "python/basics/numpy/set_printoptions.html",
    "title": "Источники информации",
    "section": "",
    "text": "В numpy, как оказалось можно настроить вывод инофрмации на в консоль, делается это с помощью функции set_printoptions, которой и посвящена эта книжка, далее я постепенно разбираю аргументы функции, распространенные и интерестные случаи из моей практики связанные с этой функцией.\n\nimport numpy as np\n\nnp.random.seed(1)\n# эксперементальный набор данных, который будет исопльзоваться для описания большинства примеров\narr = np.random.uniform(-10, 10, 20)\n\n\nhttps://numpy.org/doc/stable/reference/generated/numpy.set_printoptions.html. \n\n\nДалее разоран каждый аргумент:\n\nprecision;\nthreshold;\nedgeitems;\nlinewidth;\nsuppress;\nnanstr;\ninfstr;\nsing;\nformatter;\nfloatmode;\nlegacy.\n\n\n\nprecision\nПозволяет настроить сколько знаков после запятой numpy будет отображать. По умолчанию 8.\n\nprint(\"precision = 3\")\nnp.set_printoptions(\n    precision = 3\n)\nprint(arr)\nprint(\"precision = 5\")\nnp.set_printoptions(\n    precision = 5\n)\nprint(arr)\n\nprecision = 3\n[-1.66   4.406 -9.998 -3.953 -7.065 -8.153 -6.275 -3.089 -2.065  0.776\n -1.616  3.704 -5.911  7.562 -9.452  3.409 -1.654  1.174 -7.192 -6.038]\nprecision = 5\n[-1.65956  4.40649 -9.99771 -3.95335 -7.06488 -8.15323 -6.2748  -3.08879\n -2.06465  0.77633 -1.61611  3.70439 -5.91096  7.56235 -9.45225  3.40935\n -1.6539   1.1738  -7.19226 -6.03797]\n\n\n\n\nthreshold\nПозволяет настроить насколько большие массивы будут выводиться без “сокращения”. (По умолчанию 1000)\n\nprint(\"threshold = 20; приведёт к полному отображению массива\")\nnp.set_printoptions(threshold = 20)\nprint(arr)\nprint(\"threshold = 19; приведёт к сокращенному отображению массива\")\nnp.set_printoptions(threshold = 19)\nprint(arr)\n\nthreshold = 20; приведёт к полному отображению массива\n[-1.65956  4.40649 -9.99771 -3.95335 -7.06488 -8.15323 -6.2748  -3.08879\n -2.06465  0.77633 -1.61611  3.70439 -5.91096  7.56235 -9.45225  3.40935\n -1.6539   1.1738  -7.19226 -6.03797]\nthreshold = 19; приведёт к сокращенному отображению массива\n[-1.65956  4.40649 -9.99771 ...  1.1738  -7.19226 -6.03797]\n\n\n\n\nedgeitems\nУкажет сколько в сокращенном отображении массива должно элементов отображаться с каждой стороны. По умолчанию 3.\n\nnp.set_printoptions(\n    edgeitems=3,\n    threshold=0 #для того, \n    # чтобы заставить любой массив\n    # отображаться в сокращенной форме\n)\nprint(\"edgeitems=3\")\nprint(arr)\nnp.set_printoptions(\n    edgeitems=5\n)\nprint(\"edgeitems=5\")\nprint(arr)\n\nedgeitems=3\n[-1.65956  4.40649 -9.99771 ...  1.1738  -7.19226 -6.03797]\nedgeitems=5\n[-1.65956  4.40649 -9.99771 -3.95335 -7.06488 ...  3.40935 -1.6539\n  1.1738  -7.19226 -6.03797]\n\n\n\n\nlinewidth\nСколько символов будет отображено в каждой строке, по умолчанию используется 75. [ и \\n тоже учитываются. Потому всегда получается на 3 символа из массива меньше. Похоже результат приблизительный, потому как указанное linewidth может быть не кратно числу символов матрицы. Более того, строки бывают разные - минусы, и значение аргумента precision будут влиять на длинну строк.\nВот пару примеров\nlinewidth = 40\n\nnp.set_printoptions(\n    linewidth = 40,\n    threshold=1000 # для того, чтобы вне зависимости\n    # от предыдущих дейсвий отображался полный массив\n)\nprint(arr)\n\nprint(\"Число символов по строкам (\\\\n был удален)\")\nmatr_strs = str(arr).split(\"\\n\")\n[len(s) for s in matr_strs]\n\n[-1.65956  4.40649 -9.99771 -3.95335\n -7.06488 -8.15323 -6.2748  -3.08879\n -2.06465  0.77633 -1.61611  3.70439\n -5.91096  7.56235 -9.45225  3.40935\n -1.6539   1.1738  -7.19226 -6.03797]\nЧисло символов по строкам (\\n был удален)\n\n\n[36, 36, 36, 36, 37]\n\n\nlinewidth = 20\n\nnp.set_printoptions(\n    linewidth = 20,\n    threshold=1000 # для того, чтобы вне зависимости\n    # от предыдущих дейсвий отображался полный массив\n)\nprint(arr)\n\nprint(\"Число символов по строкам (\\\\n был удален)\")\nmatr_strs = str(arr).split(\"\\n\")\n[len(s) for s in matr_strs]\n\n[-1.65956  4.40649\n -9.99771 -3.95335\n -7.06488 -8.15323\n -6.2748  -3.08879\n -2.06465  0.77633\n -1.61611  3.70439\n -5.91096  7.56235\n -9.45225  3.40935\n -1.6539   1.1738\n -7.19226 -6.03797]\nЧисло символов по строкам (\\n был удален)\n\n\n[18, 18, 18, 18, 18, 18, 18, 18, 17, 19]\n\n\n\n\nsuppress\nОпределяет, будет ли использована экспоненциальная форма записи числа. В случае True числа всегда будут печататьсяв привычном формате, будучи сокращенными в соответствии со значением аргумента precision. В случае False, если в массиве находится число менее 0.0001 или отношение максимального и модуля минимального элемента массива составляет более 1000, весь массив будет напечатан в экспоненциальной форме. По умолчанию всегда False.\n\nОдно маленькое число (&lt;0.0001)\n\nunavailible_number = np.array([0.000099])\navailible_number = np.array([0.0001])\n\nnp.set_printoptions(\n    suppress = True,\n    linewidth = 20, # это для того, чтобы числа\n    # помещались в вывод\n    precision = 8 # это чтобы числа, которые я указал\n    # не округлились автоматически\n)\n\nprint(\"=================suppress = True================\")\nprint(\"availible number\", availible_number)\nprint(\"unavailible number\", unavailible_number, end = \"\\n\\n\\n\")\n\nnp.set_printoptions(suppress = False)\n\nprint(\"=================suppress = False================\")\nprint(\"availible number\", availible_number)\nprint(\"unavailible number\", unavailible_number)\n\n=================suppress = True================\navailible number [0.0001]\nunavailible number [0.000099]\n\n\n=================suppress = False================\navailible number [0.0001]\nunavailible number [9.9e-05]\n\n\n\n\nОтношение максимального числа к минимальному составляет более 1000\n\navailible_arr = np.array([1.0, 1000])\nunavailible_arr = np.array([1.0, 1001])\n\nnp.set_printoptions(\n    suppress = True,\n    linewidth = 20, # это для того, чтобы числа\n    # помещались в вывод\n    precision = 8 # это чтобы числа, которые я указал\n    # не округлились автоматически\n)\n\nprint(\"=================suppress = True==================\")\nprint(\"unavailible arr\", unavailible_arr)\nprint(\"availible arr\", availible_arr, end=\"\\n\\n\\n\")\n\nnp.set_printoptions(suppress = False)\nprint(\"=================suppress = False==================\")\nprint(\"unavailible arr\", unavailible_arr)\nprint(\"availible arr\", availible_arr, end=\"\\n\\n\\n\")\n\n=================suppress = True==================\nunavailible arr [   1. 1001.]\navailible arr [   1. 1000.]\n\n\n=================suppress = False==================\nunavailible arr [1.000e+00\n 1.001e+03]\navailible arr [   1. 1000.]\n\n\n\n\n\n\nЗаметим, что это работет только для массивов типа float\n\nnp.set_printoptions(suppress = False)\n\nprint(\"int не меняются\")\nints_arr = np.array([1, 1001])\nprint(ints_arr, end = \"\\n\\n\\n\")\n\nfloats_arr = np.array([1.0, 1001])\nprint(\"float меняется\")\nprint(floats_arr)\n\nint не меняются\n[   1 1001]\n\n\nfloat меняется\n[1.000e+00\n 1.001e+03]\n\n\n\n\n\nnanstr\nПозволяет настроить как будет отображен np.NaN в коммандном окне. По умолчанию 'nan'.\n\nnp.set_printoptions(nanstr = \"Нет данных\")\n\nnan_arr = np.fromfunction(\n    lambda i, j: np.where(\n        (i+j)%2, 0, np.NaN\n    ),\n    (4,4)\n)\n\nnan_arr\n\narray([[Нет данных,\n                0.,\n        Нет данных,\n                0.],\n       [        0.,\n        Нет данных,\n                0.,\n        Нет данных],\n       [Нет данных,\n                0.,\n        Нет данных,\n                0.],\n       [        0.,\n        Нет данных,\n                0.,\n        Нет данных]])\n\n\n\n\ninfstr\nПозволяет настроить как будет отображент np.inf в коммандном окне. По умолчанию 'inf'\n\nnp.set_printoptions(infstr = \"Бесконечность\")\n\nnan_arr = np.fromfunction(\n    lambda i, j: np.where(\n        (i+j)%2, -np.inf, np.inf\n    ),\n    (4,4)\n)\n\nnan_arr\n\narray([[ Бесконечность,\n        -Бесконечность,\n         Бесконечность,\n        -Бесконечность],\n       [-Бесконечность,\n         Бесконечность,\n        -Бесконечность,\n         Бесконечность],\n       [ Бесконечность,\n        -Бесконечность,\n         Бесконечность,\n        -Бесконечность],\n       [-Бесконечность,\n         Бесконечность,\n        -Бесконечность,\n         Бесконечность]])\n\n\n\n\nsign\nПозволяет определить как будет при выводе записан символ + для положительных дробных чисел, может принимать значения:\n\n'-' будет обозначать, что знак + следует просто опускать;\n'+' будет обозначать, что знак + будет явно записан;\n' ' будет обозначать, что знак на месте каждого знака + будет помещен ' ' (пробел).\n\nПо умолчанию используется значение '-'.\n\nnp.set_printoptions(\n    sign = '-',\n    linewidth = 10\n)\nprint(np.array([1.0]))\n\nnp.set_printoptions(sign = '+')\nprint(np.array([1.0]))\n\nnp.set_printoptions(sign = ' ')\nprint(np.array([1.0]))\n\n[1.]\n[+1.]\n[ 1.]\n\n\n\nЗамети, что это работает только для типа данных float\n\nnp.set_printoptions(sign = ' ')\nnp.array([1])\n\narray([1])\n\n\n\n\nЭто не работает когда numpy подгоняет под отображение матрицей\nВ следующем примере, по идее, не отрицательные числа должны не иметь пробелов вместо минуса, но для того, чтобы матрица была “ровная”, подставляется побел.\n\nnp.set_printoptions(\n    sign = '-',\n    linewidth = 40\n)\narr\n\narray([-1.65955991,  4.40648987,\n       -9.9977125 , -3.95334855,\n       -7.06488218, -8.1532281 ,\n       -6.27479577, -3.08878546,\n       -2.06465052,  0.77633468,\n       -1.61610971,  3.70439001,\n       -5.91095501,  7.56234873,\n       -9.45224814,  3.4093502 ,\n       -1.65390395,  1.17379657,\n       -7.19226123, -6.03797022])\n\n\n\n\n\nformatter\nПозволяет для каждого типа определить функцию как элементы этого массива будут преобразованы в функции. Функция ожидает словарь, в котором для каждого типа массива numpy может быть указан способ превращения в строку. Более подробно о всех типах можно уздать из оффициальной документации. Мы же рассмотрим только случаи показавшиеся мне интерестными:\n\nБазовый случай рассмотрим с использованием типа данных bool\n\nbool_exprimental = np.array([True, False])\ndef bool_formatter(val):\n    return \"Истинна\" if val else \"Ложь\"\n\nnp.set_printoptions(\n    formatter={'bool':bool_formatter}\n)\nprint(\"bool dtype\")\nprint(bool_exprimental)\n\nprint(\"int dtype\")\nprint(arr)\n\nbool dtype\n[Истинна Ложь]\nint dtype\n[-1.65955991  4.40648987 -9.9977125\n -3.95334855 -7.06488218 -8.1532281\n -6.27479577 -3.08878546 -2.06465052\n  0.77633468 -1.61610971  3.70439001\n -5.91095501  7.56234873 -9.45224814\n  3.4093502  -1.65390395  1.17379657\n -7.19226123 -6.03797022]\n\n\nИспользование пустого словаря переданного formatter приведёт к отмене всех установлленых функций форматирования.\n\nnp.set_printoptions(formatter={})\nprint(bool_exprimental)\n\n[ True False]\n\n\n\n\nКлюч all позволит применить этот форматер ко всем типам данных\nВ следующем примере для ключа all применяется функция которая для чисел типа numpy.float64 вернет Дробное а для любого другого числа Что-то ещё.\n\nnp.set_printoptions(\n    formatter = {\n        'all' : lambda val: \n        \"Дробное\" if type(val) == np.float64 else \"Что-то ещё\"\n    }\n)\n\nprint(\"float64 примет вид\")\nprint(arr)\nprint(\"int64 примет вид\")\nprint(np.array([0, 1, 2, 3]))\n\nfloat64 примет вид\n[Дробное Дробное Дробное Дробное\n Дробное Дробное Дробное Дробное\n Дробное Дробное Дробное Дробное\n Дробное Дробное Дробное Дробное\n Дробное Дробное Дробное Дробное]\nint64 примет вид\n[Что-то ещё Что-то ещё Что-то ещё\n Что-то ещё]\n\n\nИнтерестно, какой из ключей будет приоритетнее all или для некоторого конкретного типа.\n\nnp.set_printoptions(\n    formatter = {\n        'bool' : lambda x: \"ключ для bool\",\n        'all' : lambda x: \"ключ для all\"\n    }\n)\n\nbool_array = np.random.choice([True, False], 20)\nbool_array\n\narray([ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool])\n\n\nПохоже, ключ определнного типа имеет приоритет.\n\n\n\nfloatmode\nПозволяет уточникть повередение преобразования дробных чисел в случае, если precision имеет спорное знечение. Вообще все сводится к двум случаям: - Число не может быть однозначно определено используя столько знаков; - Для однозначного определения числа слишком много знаков.\nВ следующем массиве при precision = 3 представлены оба случая.\n\nnp.set_printoptions(precision = 3)\n\ntest_arr = np.array(\n    [0.4839, 0.7]\n)\n\nДалее рассмотрим значения, которые может принимать floatmode.\n\nfixed\nОзначат безприкословное исполнение числа символов указанное, в precision. То есть неоднозначно определяемые числа будут округлены а числа с излишним количесвом знаков для однозначного определния будут дополнены 0.\n\nnp.set_printoptions(\n    floatmode = 'fixed',\n    precision = 3\n)\n\ntest_arr\n\narray([0.484, 0.700])\n\n\n\n\nunique\nОзанчает, что будет использовано ровно столько знаков, сколько требуется для однозначного определения числа. По сути, это эквивалентно полному игнорированию аргумента precision.\n\nnp.set_printoptions(\n    floatmode = 'unique'\n)\n\ntest_arr\n\narray([0.4839, 0.7   ])\n\n\n\n\nmaxprec\nИспользуется не более чем precision цифр. То есть, несмотря на неоднозначно определяемые числа используется не более precision знаков, а для числа, содеражащего менее precision цифр не происходит автодополнения нулями.\n\nnp.set_printoptions(floatmode = \"maxprec\")\ntest_arr\n\narray([0.484, 0.7  ])\n\n\n\n\nmaxprec_equal\nБудет обозначать что используется всегда не более precision знаков. Но, в случае, если ни для однозначного определния любого из чисел требуется меньше знаков чем precision то будет использовано ровно столько занков сколько требуется. При этом все числа имеют одинаковое число выводимых знаков, т.е. вслучае если число (\\(a\\)) однозначно определяется меньшим числом знаков нежели число определившие число знаков, то число \\(a\\) при выводе будет дополнено нулями.\n\nnp.set_printoptions(floatmode = \"maxprec_equal\")\nprint('требуется 4 занка для определения первого числа')\nprint(test_arr)\nprint('требуется 2 знака для определения первого числа')\nprint(np.array([0.55, 0.5]))\n\nтребуется 4 занка для определения первого числа\n[0.484 0.700]\nтребуется 2 знака для определения первого числа\n[0.55 0.50]\n\n\n\n\n\nlegacy\nИспользуется для ограницазции поддержки старого когда. Может быть использован для возврата к версиям:\n\n1.13;\n1.21;\nFalse - гворит о том, что не надо использовать legacy.\n\n\n1.13\nИз документации удалось выяснить только что предыдущие версии отличаются заменой знака на пропуск для полижительного числа. В документации упоминаются и прочие особенности отображения для нульмерных массивов, которые до сих поа для меня остаются загадкой.\n\ntest_arr = np.array([1.123456789])\n\nnp.set_printoptions(legacy = False)\nprint(test_arr)\n\nnp.set_printoptions(legacy = '1.13')\nprint(test_arr)\n\n[1.123]\n[ 1.123]\n\n\n\n\n1.21\nУтвержается об сособенностях в отображении для сложных структурных типов. Но пока о об таких типах мне тоже не известно, потому, пока просто будем иметь эту возможность ввиду.\n\ntest_arr = np.array(\n    [('Rex', 9, 81.0), ('Fido', 3, 27.0)],\n    dtype=[('name', 'U10'), ('age', 'i4'), ('weight', 'f4')]\n)\n\nnp.set_printoptions(legacy = False)\nprint(test_arr)\n\nnp.set_printoptions(legacy = '1.21')\nprint(test_arr)\n\n[('Rex', 9, 81.) ('Fido', 3, 27.)]\n[('Rex', 9, 81.) ('Fido', 3, 27.)]"
  },
  {
    "objectID": "python/basics/basic_datatypes/set.html",
    "href": "python/basics/basic_datatypes/set.html",
    "title": "set",
    "section": "",
    "text": "Array of unique values. You can create it by using {&lt;element1&gt;, &lt;element2&gt;, ..., &lt;elementn&gt;} or tuple function.\nIn the following example, I show that it can contain only unique elements. Although element 2 is specified twice, it appears only once as a result.\n{1,2,3,4,2}\n\n{1, 2, 3, 4}"
  },
  {
    "objectID": "python/basics/basic_datatypes/set.html#empty-set",
    "href": "python/basics/basic_datatypes/set.html#empty-set",
    "title": "set",
    "section": "Empty set",
    "text": "Empty set\nTo create an empty set you should:\n\nUse the set function without arguments;\nDo not use empty curly brackets, it will create empty dict not set;\nDo not use curly curly brackets with a comma (lite it works for tuple), it will cause an error.\n\nThe following cell shows that curly brackets alone create a tuple but not a set. And the set() expression will in turn create an instance of set.\n\nprint(type({}))\nprint(type(set()))\n\n&lt;class 'dict'&gt;\n&lt;class 'set'&gt;\n\n\nThe following cell shows that using braces with a comma is an error.\n\n{,}\n\nSyntaxError: invalid syntax (3645013520.py, line 1)\n\n\nInterestingly, applying the print function to an empty set results in set() output.\n\nprint(set())\n\nset()"
  },
  {
    "objectID": "python/basics/basic_datatypes/set.html#no-order",
    "href": "python/basics/basic_datatypes/set.html#no-order",
    "title": "set",
    "section": "No order",
    "text": "No order\nOne of the main features of the set datatype is that it doesn’t have any order. This has important implications:\n\nYou can’t apply indexing syntax (the [] operator) to sets;\nThere are no functions associated with indexing (e.g. pop in the list datatype)."
  },
  {
    "objectID": "python/basics/basic_datatypes/set.html#only-immutable",
    "href": "python/basics/basic_datatypes/set.html#only-immutable",
    "title": "set",
    "section": "Only immutable",
    "text": "Only immutable\nIn sets, you can only use immutable datatypes. The following cells show that if you add a mutable type to a tuple (e.g. list), you will get an error.\n\n{1,\"1\", 9.4, (1,3,4)}\n\n{(1, 3, 4), 1, '1', 9.4}\n\n\n\n{1,\"1\", 9.4, (1,3,4), [3,4,5]}\n\nTypeError: unhashable type: 'list'"
  },
  {
    "objectID": "python/basics/basic_datatypes/set.html#add-new-value",
    "href": "python/basics/basic_datatypes/set.html#add-new-value",
    "title": "set",
    "section": "add new value",
    "text": "add new value\n\ntest_set = {1,2,3}\nprint(\"initital set\", test_set)\ntest_set.add(\"s\")\nprint(\"result set\", test_set)\n\ninitital set {1, 2, 3}\nresult set {1, 2, 3, 's'}\n\n\nNote that adding an element that already exists in the set won’t cause an error, it will simply be ignored.\n\ntest_set = {1,2,3,4}\nprint(\"initial set\", test_set)\ntest_set.add(3)\nprint(\"restult set\", test_set)\n\ninitial set {1, 2, 3, 4}\nrestult set {1, 2, 3, 4}"
  },
  {
    "objectID": "python/basics/basic_datatypes/set.html#remove-delete-by-value",
    "href": "python/basics/basic_datatypes/set.html#remove-delete-by-value",
    "title": "set",
    "section": "remove delete by value",
    "text": "remove delete by value\nYou can delete element by value.\n\ntest_set = {1,2,3,4,5}\nprint(\"initial list\", test_set)\ntest_set.remove(4)\nprint(\"resutl list\", test_set)\n\ninitial list {1, 2, 3, 4, 5}\nresutl list {1, 2, 3, 5}\n\n\nNote that if there’s no removing value in the source list, you’ll have an error.\n\ntest_set = {5,3,4,1}\ntest_set.remove(6)\n\nKeyError: 6"
  },
  {
    "objectID": "python/basics/basic_datatypes/set.html#intercection",
    "href": "python/basics/basic_datatypes/set.html#intercection",
    "title": "set",
    "section": "intercection",
    "text": "intercection\nThis method allows you to get a set that contains only common elements for argument sets.\n\ntest_set1 = {1,2,3}\ntest_set2 = {2,3,4}\ntest_set1.intersection(test_set2)\n\n{2, 3}"
  },
  {
    "objectID": "python/basics/basic_datatypes/set.html#union",
    "href": "python/basics/basic_datatypes/set.html#union",
    "title": "set",
    "section": "union",
    "text": "union\nThis method allows you to get a set that contains all elements from both argument sets.\n\ntest_set1 = {1,2,3}\ntest_set2 = {2,3,4}\ntest_set1.union(test_set2)\n\n{1, 2, 3, 4}"
  },
  {
    "objectID": "python/basics/basic_datatypes/set.html#symmetric_difference",
    "href": "python/basics/basic_datatypes/set.html#symmetric_difference",
    "title": "set",
    "section": "symmetric_difference",
    "text": "symmetric_difference\nThis method allows you to get a set that contains elements that are present in only one of the argument sets, but not in both.\n\ntest_set1 = {1,2,3}\ntest_set2 = {2,3,4}\ntest_set1.symmetric_difference(test_set2)\n\n{1, 4}"
  },
  {
    "objectID": "python/basics/basic_datatypes/set.html#sets-difference-a-b",
    "href": "python/basics/basic_datatypes/set.html#sets-difference-a-b",
    "title": "set",
    "section": "Sets difference A-B",
    "text": "Sets difference A-B\nIn case you subtract set A from set B you get a set of elements from the set not contained in set B.\n\ntest_set1 = {1,2,3}\ntest_set2 = {2,3,4}\ntest_set1 - test_set2\n\n{1}"
  },
  {
    "objectID": "python/basics/basic_datatypes/dict.html",
    "href": "python/basics/basic_datatypes/dict.html",
    "title": "dict",
    "section": "",
    "text": "Allow to build arrays that has key&lt;-&gt;value relationship."
  },
  {
    "objectID": "python/basics/basic_datatypes/dict.html#get-extract-element",
    "href": "python/basics/basic_datatypes/dict.html#get-extract-element",
    "title": "dict",
    "section": "get extract element",
    "text": "get extract element\nBy using this function you can get value by key from the dict.\n\nPurpose\nIt may not be clear why this is necessary, as there is a [] operator which allows you to perform exactly the same actions. The difference from the [] operator is that it doesn’t cause an error if there is no specified key in the dictionary.\nSo the following cells show that the [] operator caused an error when you tried to load a non-existent key, but in the identical example the get method just returned None.\n\ntest_dict = {\"a\":1, \"b\":2}\nprint(test_dict[\"c\"])\n\nKeyError: 'c'\n\n\n\ntest_dict = {\"a\":1, \"b\":2}\nprint(test_dict.get(\"c\"))\n\nNone\n\n\n\n\ndefault argument\nAllows to set value to be returned If there is no item with the requested key.\n\ntest_dict = {\"a\":1, \"b\":2}\nprint(test_dict.get(\"c\", \"default value\"))\n\ndefault value"
  },
  {
    "objectID": "python/basics/basic_datatypes/dict.html#delete-specific-item",
    "href": "python/basics/basic_datatypes/dict.html#delete-specific-item",
    "title": "dict",
    "section": "Delete specific item",
    "text": "Delete specific item\n\ndel operator\nYou can simply apply the del operator to the specific element. As in the following example:\n\ntest_dict = {\"a\":1, \"b\":2}\ndel test_dict[\"a\"]\nprint(test_dict)\n\n{'b': 2}\n\n\nNote If there is no item in the dict that you want to delete in this way, you will get the error. The next cell shows exactly this case:\n\ntest_dict = {\"a\":1, \"b\":2}\ndel test_dict[\"c\"]\nprint(test_dict)\n\nKeyError: 'c'\n\n\n\n\npop method\nIt will remove element by key passed as an argument to this method and return value as a result of the function. The following example shows how it works:\n\nIn the first print we show the result of the pop method;\nIn the second part, we’ll show that the dictionary no longer has an element with the key “a”.\n\n\ntest_dict = {\"a\":1, \"b\":2}\nprint(test_dict.pop(\"a\"))\nprint(test_dict)\n\n1\n{'b': 2}\n\n\nNote this method will still cause an error if you apply it to a key that doesn’t exist in the dictionary.\n\ntest_dict = {\"a\":1, \"b\":2}\ntest_dict.pop(\"C\")\n\nKeyError: 'C'"
  },
  {
    "objectID": "python/basics/basic_datatypes/dict.html#clear-delete-all",
    "href": "python/basics/basic_datatypes/dict.html#clear-delete-all",
    "title": "dict",
    "section": "clear delete all",
    "text": "clear delete all\nThis method allows you to delete all the values written in the dictionary. The following example shows what it can look like.\n\ntest_dict = {\"a\":1, \"b\":2}\ntest_dict.clear()\nprint(test_dict)\n\n{}"
  },
  {
    "objectID": "python/basics/basic_datatypes/dict.html#in-operator",
    "href": "python/basics/basic_datatypes/dict.html#in-operator",
    "title": "dict",
    "section": "in operator",
    "text": "in operator\nChecks if the element on the left side of in is in the keys (not values) of the dictionary on the right side of in.\n\ntest_dict = {\"a\":1, \"b\":2}\nprint(\"a\" in test_dict)\nprint(1 in test_dict)\n\nTrue\nFalse"
  },
  {
    "objectID": "python/basics/basic_datatypes/dict.html#key-of-max",
    "href": "python/basics/basic_datatypes/dict.html#key-of-max",
    "title": "dict",
    "section": "Key of max",
    "text": "Key of max\nIt was a common task for me to find a key of dict that matches the max/min value of the dictionary. The most elegant solution I found is to use dict as an argument for the max/min basic Python function, but as key argument use the dict.get method.\nThe logic is as follows - the function will iterate over the dictionary keys, and use only the results of execution of the function passed as an argument to the key parameter for comparison. Since we pass to the get function the corresponding value to the key, the comparison will be performed on the values of the dictionary.\nSo in the following example, I apply this solution to the randomly generated dictionary:\n\nfrom random import randint\nfrom IPython.display import HTML\n\nexample_dict = {\n    chr(iscii_code): randint(0,10)\n    for iscii_code in range(ord(\"a\"), ord(\"g\"))\n}\ndisplay(HTML(\"&lt;b style=\\\"font-size:120%\\\"&gt;=====Input dict=====&lt;/b&gt;\"))\ndisplay(example_dict)\ndisplay(HTML(\"&lt;b style=\\\"font-size:120%\\\"&gt;=====Result=====&lt;/b&gt;\"))\ndisplay(HTML(max(example_dict, key=example_dict.get)))\n\n=====Input dict=====\n\n\n{'a': 3, 'b': 8, 'c': 6, 'd': 9, 'e': 6, 'f': 3}\n\n\n=====Result=====\n\n\nd"
  },
  {
    "objectID": "python/basics/basic_datatypes/str.html",
    "href": "python/basics/basic_datatypes/str.html",
    "title": "str",
    "section": "",
    "text": "This data type describes the variables in which you want to store the text information."
  },
  {
    "objectID": "python/basics/basic_datatypes/str.html#istitle---is-first-capital",
    "href": "python/basics/basic_datatypes/str.html#istitle---is-first-capital",
    "title": "str",
    "section": "istitle - is first capital",
    "text": "istitle - is first capital\nLets you check if all words in the calling string are capitalised.\nThe following example shows how it works for\n\nLower case only;\nOne capitalised word;\nLine with several capitalised words;\nLine with several words but only the first one is capitalised.\n\n\ntest_lines =[\n    \"test line\",\n    \"Test\",\n    \"Test Line\",\n    \"Test line\"\n]\n\nfor test_line in test_lines:\n    print(f\"\\\"{test_line}\\\".istitle() -&gt; {test_line.istitle()}\")\n\n\"test line\".istitle() -&gt; False\n\"Test\".istitle() -&gt; True\n\"Test Line\".istitle() -&gt; True\n\"Test line\".istitle() -&gt; False"
  },
  {
    "objectID": "python/basics/basic_datatypes/frozenset.html",
    "href": "python/basics/basic_datatypes/frozenset.html",
    "title": "frozenset",
    "section": "",
    "text": "set in Python is a mutable data type, so you cannot use it in many cases (e.g. as a key for dict or as an element of another set). To fix this, Python provides a special data type frozenset which is like set but immutable.\nSo in the following example I try to use frozenset and set as elements of another set:\n\nWith frozenset all is well;\nRegular set causes an error.\n\n\nregular_set = {1,3}\nfrozen_set = frozenset([1,2,3,4])\n\nprint(\"Using a frozenset:\", {1,2,3, frozen_set})\nprint(\"Using a regular set:\", {1, 2, 3, regular_set, 1})\n\nUsing a frozenset: {1, 2, 3, frozenset({1, 2, 3, 4})}\n\n\nTypeError: unhashable type: 'set'"
  },
  {
    "objectID": "python/basics/basic_datatypes/tuple.html",
    "href": "python/basics/basic_datatypes/tuple.html",
    "title": "tuple",
    "section": "",
    "text": "Is an array that can’t be changed at runtime."
  },
  {
    "objectID": "python/basics/basic_datatypes/tuple.html#one-element-tuple",
    "href": "python/basics/basic_datatypes/tuple.html#one-element-tuple",
    "title": "tuple",
    "section": "One element tuple",
    "text": "One element tuple\nTo create one element tuple you have to use the syntax (&lt;element&gt;,) not (&lt;element&gt;). By default, parentheses are not used to create a tuple, but to prioritise executions in the expression, so you have to use at least one comma inside the parentheses to tell the interpreter that it is the tuple.\n\nprint(\"Just a variable\", (4))\nprint(\"One element tuple\", (5,))\n\nJust a variable 4\nOne element tuple (5,)"
  },
  {
    "objectID": "python/basics/basic_datatypes/list.html",
    "href": "python/basics/basic_datatypes/list.html",
    "title": "list",
    "section": "",
    "text": "Is an array that you can change at runtime."
  },
  {
    "objectID": "python/basics/basic_datatypes/list.html#pop---delete-by-index",
    "href": "python/basics/basic_datatypes/list.html#pop---delete-by-index",
    "title": "list",
    "section": "pop - delete by index",
    "text": "pop - delete by index\nYou can delete element by index and get it back.\n\ntest_list = [3,4,5,2]\nprint(\"Poped element\", test_list.pop(2))\nprint(\"Result list\", test_list)\n\nPoped element 5\nResult list [3, 4, 2]\n\n\nBy default it deltes the first element.\n\ntest_list = [5,6,4,3]\nprint(\"Poped elemnt\", test_list.pop())\nprint(\"Result list\", test_list)\n\nPoped elemnt 3\nResult list [5, 6, 4]"
  },
  {
    "objectID": "python/basics/basic_datatypes/list.html#remove---delete-by-value",
    "href": "python/basics/basic_datatypes/list.html#remove---delete-by-value",
    "title": "list",
    "section": "remove - delete by value",
    "text": "remove - delete by value\nYou can delete element by value.\n\ntest_list = [4,5,4,5]\nprint(\"initial list\", test_list)\ntest_list.remove(4)\nprint(\"resutl list\", test_list)\n\ninitial list [4, 5, 4, 5]\nresutl list [5, 4, 5]\n\n\nNote that if there’s no removing value in the source list, you’ll have an error.\n\ntest_list = [5,3,4,1]\ntest_list.remove(6)\n\nValueError: list.remove(x): x not in list"
  },
  {
    "objectID": "python/basics/basic_datatypes/list.html#index---index-of-value",
    "href": "python/basics/basic_datatypes/list.html#index---index-of-value",
    "title": "list",
    "section": "index - index of value",
    "text": "index - index of value\nUsing this method you can get the index by which you can get the first occurrence of this element in the list.\nIn the following example I ask .index(3) and got 2 as a result because the first occurrence of number 3 in the 2 index.\nNote any other entry of the element will be ignored, just like the second 3 value with 4 index in the example.\n\ntest_list = [1,2,3,4,3,5]\ntest_list.index(3)\n\n2"
  },
  {
    "objectID": "python/basics/basic_datatypes/list.html#appned-vs",
    "href": "python/basics/basic_datatypes/list.html#appned-vs",
    "title": "list",
    "section": "appned vs +",
    "text": "appned vs +\nThere are two common ways to extend a Python list: by using the append method and the + operator. There is a significant difference: + creates a new list and copies operands to it, but append changes the initial list.\nThe following example:\n\nPrints “Initial list: ”;\nPrints id of list modified with + operator - it has different id with initial list;\nPrints the id of the list modified with the append method - it has the same id as the initial list.\n\n\ninternal_list = [1,2,3,4,5]\nprint(\"Initial list:\", id(internal_list))\nprint(\"Plus list:\", id(internal_list + [3]))\ninternal_list.append(3)\nprint(\"Append list:\", id(internal_list))\n\nInitial list: 139771686692224\nPlus list: 139771686592256\nAppend list: 139771686692224"
  },
  {
    "objectID": "python/basics/basic_datatypes/list.html#drop-duplicates",
    "href": "python/basics/basic_datatypes/list.html#drop-duplicates",
    "title": "list",
    "section": "drop duplicates",
    "text": "drop duplicates\n\nlist(set(&lt;input&gt;))\nThe easiest way is to convert the input list to set and then back to list. set can’t have duplicates, so they’re dropped.\nNote this option does not save the original order of the items in the list, because the `set’ data type ignores the order of the items.\nThe following example allows you to obtain unique values, but despite the fact that the elements in the original list are not in ascending order, they are in the result of the transformation.\n\ntest_list = [1,4,4,2,2,3,3]\nlist(set(test_list))\n\n[1, 2, 3, 4]\n\n\n\n\nSaving the order\nIt is possible to loop through the elements of the transformed list and check if the result of the item method for the selected element corresponds to the iteration number:\n\nIf the iteration number and the result of the item method match, it means that this is the first occurrence of this element and it should be included in the result;\nOtherwise, it means that this item has already been included in the result earlier and it should not be added to the result.\n\nThe following cell shows a possible implementation of the described algorithm. As a result, 4 appears immediately after 1, as in the original list.\n\ntest_list = [1,4,4,2,2,3,3]\n[val for i, val in enumerate(test_list) if test_list.index(val) == i]\n\n[1, 4, 2, 3]"
  },
  {
    "objectID": "python/basics/packages.html",
    "href": "python/basics/packages.html",
    "title": "Packages",
    "section": "",
    "text": "This page describes features related to packages in Python.\n\nVersion\nTo get the version of a package imported into the environment just from python program, you can call the __version__ attribute.\nIn the following cell I just do it to pandas installed in the operating system.\n\nimport pandas\npandas.__version__\n\n'2.0.1'"
  },
  {
    "objectID": "python/basics/functions.html",
    "href": "python/basics/functions.html",
    "title": "Functions",
    "section": "",
    "text": "Arguments vs parameters\nParameters - local variables to which values are assigned at the moment of its call.\nArguments are information passed to the function. They are real values corresponding to the parameters that were specified when the function was declared.\nSo in following example: - val is a parameter of some_function; - \"test\" is an argument passed to some_function.\n\ndef some_function(val):\n    print(\"I got\", val)\n\nsome_function(\"test\")\n\nI got test"
  },
  {
    "objectID": "python/basics/collections.html",
    "href": "python/basics/collections.html",
    "title": "collections library",
    "section": "",
    "text": "Allows date types that enhance standard Python collections."
  },
  {
    "objectID": "python/basics/collections.html#basics",
    "href": "python/basics/collections.html#basics",
    "title": "collections library",
    "section": "Basics",
    "text": "Basics\nYou need to pass a function that will return the items that will be used as default values.\nIn the following example, I have created a dictionary where when I try to access an unknown key in the dictionary, an int is created, one more than the last time.\n\nfrom collections import defaultdict\n\ncounter = 0\n\ndef dict_filler():\n    global counter\n    counter += 1\n    return counter\n\nmy_defaultdict = defaultdict(dict_filler)\n\nprint(\"before cycle \", dict(my_defaultdict))\n\nfor i in range(5):\n    print(f\"my_defaultdict[\\\"element{i}\\\"] == \", my_defaultdict[f\"element{i}\"])\n\nprint(\"after cycle \", dict(my_defaultdict))\n\nbefore cycle  {}\nmy_defaultdict[\"element0\"] ==  1\nmy_defaultdict[\"element1\"] ==  2\nmy_defaultdict[\"element2\"] ==  3\nmy_defaultdict[\"element3\"] ==  4\nmy_defaultdict[\"element4\"] ==  5\nafter cycle  {'element0': 1, 'element1': 2, 'element2': 3, 'element3': 4, 'element4': 5}\n\n\nA more applied example is calculating the frequencies of random integers. It is enough to create a defaultdict which by default uses 0 as a value for an unknown key. Without any initialisation, you can just use the += operator for the dictionary, where each key corresponds to the number of times a given number is used.\n\nimport random\nfrom collections import defaultdict\nmy_defaultdict = defaultdict(int)\n\nfor i in range(500):\n    my_defaultdict[random.randint(1, 10)] += 1\n\nsorted_dict = dict(sorted(my_defaultdict.items(), key=lambda x: x[0]))\nprint(sorted_dict)\n\n{1: 47, 2: 54, 3: 43, 4: 52, 5: 46, 6: 57, 7: 47, 8: 57, 9: 52, 10: 45}"
  },
  {
    "objectID": "python/basics/collections.html#tofrom-dict",
    "href": "python/basics/collections.html#tofrom-dict",
    "title": "collections library",
    "section": "To/from dict",
    "text": "To/from dict"
  },
  {
    "objectID": "python/basics/collections.html#from",
    "href": "python/basics/collections.html#from",
    "title": "collections library",
    "section": "From",
    "text": "From\nYou can convert a regular dict to the defaultdict simply by passing it as the second argument to the defalutdict function.\nSo in the following example I will convert initial_dict to default_dict and then show that it has got properties of defaultdcit.\n\nfrom collections import defaultdict\ninitial_dict = {\"key1\": 1, \"key2\":3}\ndefault_dict = defaultdict(int, initial_dict)\nmy_defalut_value = default_dict[\"key3\"]\nprint(default_dict)\n\ndefaultdict(&lt;class 'int'&gt;, {'key1': 1, 'key2': 3, 'key3': 0})"
  },
  {
    "objectID": "python/basics/collections.html#to",
    "href": "python/basics/collections.html#to",
    "title": "collections library",
    "section": "To",
    "text": "To\nJust pass defaultdict to the dict function to get it as a regular Python dict.\n\nfrom collections import defaultdict\ndefault_dict = defaultdict(int)\n# create dict using defaultdict mechanisms\nfor i in range(10): default_dict[i]\n# but for clearer printing, let's convert it \n# into a regular dictionary\ndict(default_dict)\n\n{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}"
  },
  {
    "objectID": "python/basics/collections.html#basic",
    "href": "python/basics/collections.html#basic",
    "title": "collections library",
    "section": "Basic",
    "text": "Basic\nYou will have the result just as dictionary with items &lt;value in input collection&gt; : &lt;number of occurrences of an element in the collection&gt;.\nThe following example shows how Counter is applied to a list of frequently recurring items.\n\nfrom random import randint\nfrom collections import Counter\n\ninput_lst = [randint(1,4) for i in range(10)]\nprint(\"Initial list:\", input_lst)\nCounter(input_lst)\n\nInitial list: [2, 2, 4, 1, 1, 2, 4, 2, 2, 2]\n\n\nCounter({2: 6, 4: 2, 1: 2})"
  },
  {
    "objectID": "python/basics/collections.html#dict-properties",
    "href": "python/basics/collections.html#dict-properties",
    "title": "collections library",
    "section": "dict properties",
    "text": "dict properties\nCounter objects have all the properties of a normal dictionary.\nSo in the following example I show that Counter can be easily accessed by inedex.\n\nfrom random import randint\nfrom collections import Counter\n\ninput_lst = [randint(1,4) for i in range(10)]\nprint(\"Initial list:\", input_lst)\nmy_counter = Counter(input_lst)\nprint(f\"You can find '{2}' element {my_counter[2]} times in the input array\")\n\nInitial list: [2, 2, 2, 1, 3, 4, 4, 4, 2, 4]\nYou can find '2' element 4 times in the input array"
  },
  {
    "objectID": "python/basics/collections.html#unhashable-types",
    "href": "python/basics/collections.html#unhashable-types",
    "title": "collections library",
    "section": "Unhashable types",
    "text": "Unhashable types\nAs we know, unhashable types cannot be used as keys in a dictionary. Counter is just a modified dictionary, so you may get trouble trying to apply the Counter to the collection with unhashable items in it:\n\nCounter([[1,2,3], \"test\"])\n\nTypeError: unhashable type: 'list'"
  },
  {
    "objectID": "python/basics/class_spesials/python_class_specials.html",
    "href": "python/basics/class_spesials/python_class_specials.html",
    "title": "Источники информации",
    "section": "",
    "text": "Разбор спецальных меодов/полей в языке программирования python3"
  },
  {
    "objectID": "python/basics/class_spesials/python_class_specials.html#методы-метаклассов",
    "href": "python/basics/class_spesials/python_class_specials.html#методы-метаклассов",
    "title": "Источники информации",
    "section": "Методы метаклассов",
    "text": "Методы метаклассов\n\n__instancecheck__\nДоступен пример использования https://github.com/Dranikf/knowledge_bank/blob/main/python_class_interface/python_class_interface.ipynb (см. раздел “Использование метаклассов”)\nБудет вызван для класса при использовании встроенной функции isinstace(instance, class) - функции которая (при __instancecheck__ оставленного по умолчанию) вернет True если первый аргумент экземпляр класса указанного вторым.\n\nisinstance(Auto(\"Gelentvagen\"), TechThing)\n\n__isinstacecheck__ called\nGelentvagen удачно был удален\n\n\nTrue\n\n\nПритом, ход приведенный в следующей ячейке, не сработает.\n\nisinstance(Auto(\"Toyota\"), Auto)\n\nToyota удачно был удален\n\n\nTrue\n\n\nВидимо потому, что в класс Auto не указан метакласс Thing как это сделано для класса TechThing. Весьма обывательское объяснение, но возможно в будующем я буду знать об этой концепции больше.\n\n\n__subclasscheck__\nДоступен пример использования https://github.com/Dranikf/knowledge_bank/blob/main/python_class_interface/python_class_interface.ipynb (см. раздел “Использование метаклассов”)\nБудет вызван для класса при использовании встроенной функции issubclass(class1, class2) которая (при __subclasscheck__ оставленной по умолчанию), вернет True если class1 наследник class2.\n\nissubclass(Auto, TechThing)\n\n__issubclasscheck__ called\n\n\nTrue\n\n\nПритом, ход приведенный в следующей ячейке, сработает, в отличии от аналогичной ситуации для другого специального метода метаклассов __instancecheck__.\n\nissubclass(Auto, Machine)\n\n__issubclasscheck__ called\n\n\nTrue\n\n\nПочему так, на данном этапе погружения в pyhton, остается загадкой."
  },
  {
    "objectID": "python/basics/class_spesials/python_class_specials.html#методы-приведения-к-типу",
    "href": "python/basics/class_spesials/python_class_specials.html#методы-приведения-к-типу",
    "title": "Источники информации",
    "section": "Методы приведения к типу",
    "text": "Методы приведения к типу\n\n__bool__\nЭтот метод будет вызван для любого экземпляра переданного в базовую функцию bool\n\nprint(\"Gili result\", bool(Auto(\"Gili\")))\nprint(\"None result\", bool(Auto(None)))\n\nGili удачно был удален\nGili result True\nNone удачно был удален\nNone result False\n\n\n\n\n__complex__\nЭтот метод будет вызваться при передече экземпляра класса в функцию complex. complex производит преведение переданного объекта к типу complex. В данном случае я в преобразование заложил чтобы действительная и мнимая части числа были равны числу букв в марке автомобиля.\n\ncomplex(Auto(\"Lexus\"))\n\nLexus удачно был удален\n\n\n(5+5j)\n\n\n\n\n__float__\nЭтот метод будет вызваться при предаче экземпляра класса в функцию float. float произодит приведение переданного объекта к типу float. В данном случае я в преобразование заложил, чтобы возвращалось число символов в поле marka преобарзованное к типу float\n\nfloat(Auto(\"Hyundai\"))\n\nHyundai удачно был удален\n\n\n7.0\n\n\n\n\n__int__\nЭтот метод будет вызываться при передаче экземпляра класса в функцию int. int производит приведенение переданного объекта к типу int. В данном случае я в преобразование заложил, чтобы приведение означало подсчет числа символов в марке автомобиля.\n\nint(Auto(\"Mitsubishi\"))\n\nMitsubishi удачно был удален\n\n\n10\n\n\n\n\n__str__\nЭтот метод будет вызываться при передаче экземпляра класса в функцию str. str производит приведение переданного объекта к строковому типу. В данном случае я в преобразование заложил, чтобы приведение просто возвращало марку автомобиля.\n\nstr(Auto(\"Honda\"))\n\nHonda удачно был удален\n\n\n'Honda'"
  },
  {
    "objectID": "python/basics/class_spesials/python_class_specials.html#методы-для-работы-с-индексами",
    "href": "python/basics/class_spesials/python_class_specials.html#методы-для-работы-с-индексами",
    "title": "Источники информации",
    "section": "Методы для работы с индексами",
    "text": "Методы для работы с индексами\n\n__setitem__\nМетод, который будет вызваться при использовании оператора [] с присвоением. В метод __setitem__ должен содерать два аргумента: 1. индекс - объект указонный в скобках; 2. значение - присваимое заначение (после оператора =).\nБыл заложен смысл извлечения замены символа в марке автомобиля.\n\nmaz_car = Auto(\"Maserati\")\nmaz_car[3] = \"t\"\nprint(maz_car)\n\nMastrati удачно был удален\nMastrati\n\n\n\n\n__getitem__\nМетод, который будет вызваться при использовании оператора [], для извелечения значения. В данном случае, индекс используется как индекс марки автомобиля.\n\nbug_car = Auto(\"Bugatti\")\nbug_car[:3]\n\n'Bug'\n\n\n\n\n__delitem__\nМетод, который будет вызываться при использовании оператора [] вместе с оператором del. В данном случае, из марки автомобиля\n\nbmw_car = Auto(\"BMW\")\ndel bmw_car[1]\nbmw_car.marka\n\nBW удачно был удален\n\n\n'BW'\n\n\n\n\nМножественный индекс\nПри передаче множественного индекса, функции __setitem__, __getitem__ и __delitem__ в аргуметы соответвующие индексу получают картеж.\n\nind_exmpl = indexer_example()\n\nind_exmpl[3,4,5,\"str index\"]\n\nпришёл инедкс (3, 4, 5, 'str index')\n\n\n\n\nОпретор : внутри индекса\nПри использовании : внутри индекса в методы отвечающие за управление поведением класса придет slice\n\nind_exmpl = indexer_example()\n\nind_exmpl[:3]\n\nпришёл инедкс slice(None, 3, None)"
  },
  {
    "objectID": "python/basics/class_spesials/python_class_specials.html#протокол-итерации",
    "href": "python/basics/class_spesials/python_class_specials.html#протокол-итерации",
    "title": "Источники информации",
    "section": "Протокол итерации",
    "text": "Протокол итерации\nИли методы которые делают экземпляры класса iterable.\n\n__iter__\nВызывается для того, что-бы “предупредить” объект, что по нему будут итерироваться - можно провести некоторый процессинг, который будет готовить этот класс к итерированию по нему. Будет вызван при: - Передаче экземпляра в функцию iter(); - При использовании после оператора in в цикле for.\nОжидается возврат любого объекта у которого переопределен метод __next__. Чаще всего возврящают self но не всегда.\n\n\n__next__\nОпределяет что класс будет возвращать при каждой следующей итерации по нему. Будет вызван при: - Передаче экземпляра в фнукцию next(); - При каждой идерации цикла for по объекту.\nВозвращать следует, то что должно попасть в теририрующую переменную на этой итерации. В момент, когда требуется прeкратить процесс итерирования следует использовать raise StopIteration.\n\n\nБазовый пример\nЭти операторы лучше рассматривать в комбинации, потому общий пример для них:\n\nclass ar_progression_shower:\n    '''\n        Класс имплементирует расчет элементов\n        арифметической прогрессии до определенного\n        наблюдения в прогрессии\n    '''\n    def __init__(self, a0 = 0, n = 5, d = 3):\n        self.n = n\n        self.a0 = a0\n        self.d = d\n        \n    def __iter__(self):\n        print(\"был вызван __iter__\")\n        self.i = 0\n        self.curr_a = self.a0\n        return self\n    \n    def __next__(self):\n        print(\"был вызван __next__\")\n        if self.i &lt; self.n:\n            self.curr_a = self.a0 + self.d*self.i\n            self.i += 1\n            return \"{} : {}\".format(self.i-1, self.curr_a)\n        else:\n            print(\"вызван StopIteration\")\n            raise StopIteration\n        \n        \n        \nexample_iter = ar_progression_shower()\n\nМожно использовать методы iter() и next().\n\niter(example_iter)\n\nprint(next(example_iter))\nprint(next(example_iter))\nprint(next(example_iter))\nprint(next(example_iter))\nprint(next(example_iter))\n\nбыл вызван __iter__\nбыл вызван __next__\n0 : 0\nбыл вызван __next__\n1 : 3\nбыл вызван __next__\n2 : 6\nбыл вызван __next__\n3 : 9\nбыл вызван __next__\n4 : 12\n\n\nНо в случае, если вывалиться за допустииое число итераций. Вывод будет следующий.\n\niter(example_iter)\n\nprint(next(example_iter))\nprint(next(example_iter))\nprint(next(example_iter))\nprint(next(example_iter))\nprint(next(example_iter))\nprint(next(example_iter))\n\nбыл вызван __iter__\nбыл вызван __next__\n0 : 0\nбыл вызван __next__\n1 : 3\nбыл вызван __next__\n2 : 6\nбыл вызван __next__\n3 : 9\nбыл вызван __next__\n4 : 12\nбыл вызван __next__\nвызван StopIteration\n\n\nStopIteration: \n\n\nВсе те-же самые результаты при использовании цикла.\n\nfor val in example_iter:\n    print(val)\n\nбыл вызван __iter__\nбыл вызван __next__\n0 : 0\nбыл вызван __next__\n1 : 3\nбыл вызван __next__\n2 : 6\nбыл вызван __next__\n3 : 9\nбыл вызван __next__\n4 : 12\nбыл вызван __next__\nвызван StopIteration\n\n\n\ntype(iter(example_iter))\n\nбыл вызван __iter__\n\n\n__main__.ar_progression_shower\n\n\n\n\nФишки\n\nБез __next__\n\nclass test:\n    def __iter__(self):\n        return self\n    \niter(test())\n\nTypeError: iter() returned non-iterator of type 'test'\n\n\n\nclass test:\n    def __next__(self):\n        return 0\n    def __iter__(self):\n        return self\n    \niter(test())\n\n&lt;__main__.test at 0x7f081022c220&gt;\n\n\n\n\nlist/tuple/dict как результат __iter__\nСами по себе эти пипы не переопределяют __next__, как следвие, вернуть их как из __iter__ не получится.\n\nclass test():\n    def __iter__(self):\n        return [10, 20, 30, 40]\n    \niter(test())\n\nTypeError: iter() returned non-iterator of type 'list'\n\n\n\nclass test():\n    def __iter__(self):\n        return (10, 20, 30, 40)\n    \niter(test())\n\nTypeError: iter() returned non-iterator of type 'tuple'\n\n\n\nclass test():\n    def __iter__(self):\n        return {\"a\":10, \"b\":20, \"c\":30, \"d\":40}\n    \niter(test())\n\nTypeError: iter() returned non-iterator of type 'dict'\n\n\nНо можно вернуть результат передачи их функции iter(). Обращею отдельное внимание на типы данных результатов.\n\nclass test():\n    def __iter__(self):\n        return iter([10, 20, 30, 40])\n    \ntype(iter(test()))\n\nlist_iterator\n\n\n\nclass test():\n    def __iter__(self):\n        return iter((10, 20, 30, 40))\n    \ntype(iter(test()))\n\ntuple_iterator\n\n\n\nclass test():\n    def __iter__(self):\n        return iter({\"a\":10, \"b\":20, \"c\":30, \"d\":40})\n    \ntype(iter(test()))\n\ndict_keyiterator"
  },
  {
    "objectID": "python/basics/class_spesials/python_class_specials.html#другие-методы",
    "href": "python/basics/class_spesials/python_class_specials.html#другие-методы",
    "title": "Источники информации",
    "section": "Другие методы",
    "text": "Другие методы\n\n__init__\nБудет вызван при создании экземпляра класса\n\nAuto(\"mersedes\").marka\n\nmersedes удачно был удален\n\n\n'mersedes'\n\n\n\n\n__del__\nБудет вызван при удалении экземпляра класса\n\na = Auto(\"москвич\")\ndel a\n\nмосквич удачно был удален\n\n\n\n\n__call__\nВызывается при попытке “вызвать” экземпляр класса, то есть ипользование оператора () для экземплара класса.\n\nAuto(\"tesla\")()\n\ntesla удачно был удален\n\n\n'вы вызвали tesla'\n\n\n\n\n__len__\nВызывается при передаче экземпляра в функцию базовую функцию len. В данном случае я заложил возврат числа символов в марке.\n\nlen(Auto(\"Mazda\"))\n\nMazda удачно был удален\n\n\n5\n\n\n\n\n__index__\nВызывается при передаче экземпляра в одну из базовых функций bin, oct и hex. Вернуть из __index__ следует число, которое в зависимости от вызванной функции будет преобразовано соответсвенно к соответсвующей системе исчисления. В данном случае __index__ всегда возвращает число 17.\n\nmy_auto = Auto(\"Lambargini\")\n\nprint(\"Приведение к бинарному виду \", bin(my_auto))\nprint(\"Приведение к восьмеричному виду \", oct(my_auto))\nprint(\"Приведение к шестнадцатиричному виду \", hex(my_auto))\n\nLambargini удачно был удален\nПриведение к бинарному виду  0b10001\nПриведение к восьмеричному виду  0o21\nПриведение к шестнадцатиричному виду  0x11\n\n\n\n\n__round__\nВызвается при передаче экземпляра базовой функции round.\n\njeep_auto = Auto(\"Jeep\")\nround(jeep_auto).marka\n\nJeep rounded удачно был удален\n\n\n'Jeep rounded'"
  },
  {
    "objectID": "python/basics/exceptions.html",
    "href": "python/basics/exceptions.html",
    "title": "Exceptions",
    "section": "",
    "text": "If you want to handle multiple exceptions for a block, you can use one of the following options:\n\n\nTo use the same code to handle different types of exceptions, you can simply mention them as tuples in the condition for the except block.\nIn the following example, I have called a random exception type, but only three of four possible error types are mentioned in the except block. So I will only get a message from the except block until I get the unmentioned error type.\nI would like to emphasise once again that this is not done to handle all error types, there is a special design for this which is described here.\n\ntest_lst = [1,2]\ntry_functions = {\n    \"ZeroDivisionError\": lambda: 8/0, # \n    \"IndexError\" : lambda: test_lst[5],\n    \"TypeError\" : lambda: \"hello\" + 4,\n    \"NameError\" : lambda: unknown_name\n}\nerror_types = list(try_functions.keys())\n\nfor i in range(10):\n    try:\n        this_type = np.random.choice(error_types)\n        print(f\"====I got a type {this_type}====\")\n        try_functions[this_type]()\n    except (ZeroDivisionError, IndexError, TypeError):\n        print(\"I handle all mentioned exceptions\")\n\n====I got a type IndexError====\nI handle all mentioned exceptions\n====I got a type TypeError====\nI handle all mentioned exceptions\n====I got a type ZeroDivisionError====\nI handle all mentioned exceptions\n====I got a type TypeError====\nI handle all mentioned exceptions\n====I got a type NameError====\n\n\nNameError: name 'unknown_name' is not defined\n\n\n\n\n\nYou can set code to handle a particular type of error, and do it several times for a try block. All you have to do is mention several except blocks one after the other.\nSo in the following example, I call random error in a loop, and different errors have different handlers. You can see that there is a specific message for each iteration.\n\nimport numpy as np\n\ntest_lst = [1,2]\ntry_functions = {\n    \"ZeroDivisionError\": lambda: 8/0, # \n    \"IndexError\" : lambda: test_lst[5],\n    \"TypeError\" : lambda: \"hello\" + 4,\n}\nerror_types = list(try_functions.keys())\n\nfor i in range(10):\n    try:\n        this_type = np.random.choice(error_types)\n        print(f\"====I got a type {this_type}====\")\n        try_functions[this_type]()\n    except ZeroDivisionError:\n        print(\"This is divison by zero (first option)\")\n    except IndexError:\n        print(\"This is wrong index (second option)\")\n    except TypeError:\n        print(\"This is wrong operations with types (third option)\")\n\n====I got a type TypeError====\nThis is wrong operations with types (third option)\n====I got a type ZeroDivisionError====\nThis is divison by zero (first option)\n====I got a type TypeError====\nThis is wrong operations with types (third option)\n====I got a type IndexError====\nThis is wrong index (second option)\n====I got a type TypeError====\nThis is wrong operations with types (third option)\n====I got a type TypeError====\nThis is wrong operations with types (third option)\n====I got a type ZeroDivisionError====\nThis is divison by zero (first option)\n====I got a type TypeError====\nThis is wrong operations with types (third option)\n====I got a type ZeroDivisionError====\nThis is divison by zero (first option)\n====I got a type TypeError====\nThis is wrong operations with types (third option)\n\n\n\n\n\nYou can define any number of `except’ blocks for the same exception type, but only the first one will be called.\nIn the following example, even though I declared two codes for the ZeroDivisionError type exception, only the first one was executed.\n\ntry:\n    1/0\nexcept ZeroDivisionError:\n    print(\"First code to handle exception\")\nexcept ZeroDivisionError:\n    print(\"Second code to handle exception\")\n\nFirst code to handle exception"
  },
  {
    "objectID": "python/basics/exceptions.html#same-except-block",
    "href": "python/basics/exceptions.html#same-except-block",
    "title": "Exceptions",
    "section": "",
    "text": "To use the same code to handle different types of exceptions, you can simply mention them as tuples in the condition for the except block.\nIn the following example, I have called a random exception type, but only three of four possible error types are mentioned in the except block. So I will only get a message from the except block until I get the unmentioned error type.\nI would like to emphasise once again that this is not done to handle all error types, there is a special design for this which is described here.\n\ntest_lst = [1,2]\ntry_functions = {\n    \"ZeroDivisionError\": lambda: 8/0, # \n    \"IndexError\" : lambda: test_lst[5],\n    \"TypeError\" : lambda: \"hello\" + 4,\n    \"NameError\" : lambda: unknown_name\n}\nerror_types = list(try_functions.keys())\n\nfor i in range(10):\n    try:\n        this_type = np.random.choice(error_types)\n        print(f\"====I got a type {this_type}====\")\n        try_functions[this_type]()\n    except (ZeroDivisionError, IndexError, TypeError):\n        print(\"I handle all mentioned exceptions\")\n\n====I got a type IndexError====\nI handle all mentioned exceptions\n====I got a type TypeError====\nI handle all mentioned exceptions\n====I got a type ZeroDivisionError====\nI handle all mentioned exceptions\n====I got a type TypeError====\nI handle all mentioned exceptions\n====I got a type NameError====\n\n\nNameError: name 'unknown_name' is not defined"
  },
  {
    "objectID": "python/basics/exceptions.html#different-except-blocks",
    "href": "python/basics/exceptions.html#different-except-blocks",
    "title": "Exceptions",
    "section": "",
    "text": "You can set code to handle a particular type of error, and do it several times for a try block. All you have to do is mention several except blocks one after the other.\nSo in the following example, I call random error in a loop, and different errors have different handlers. You can see that there is a specific message for each iteration.\n\nimport numpy as np\n\ntest_lst = [1,2]\ntry_functions = {\n    \"ZeroDivisionError\": lambda: 8/0, # \n    \"IndexError\" : lambda: test_lst[5],\n    \"TypeError\" : lambda: \"hello\" + 4,\n}\nerror_types = list(try_functions.keys())\n\nfor i in range(10):\n    try:\n        this_type = np.random.choice(error_types)\n        print(f\"====I got a type {this_type}====\")\n        try_functions[this_type]()\n    except ZeroDivisionError:\n        print(\"This is divison by zero (first option)\")\n    except IndexError:\n        print(\"This is wrong index (second option)\")\n    except TypeError:\n        print(\"This is wrong operations with types (third option)\")\n\n====I got a type TypeError====\nThis is wrong operations with types (third option)\n====I got a type ZeroDivisionError====\nThis is divison by zero (first option)\n====I got a type TypeError====\nThis is wrong operations with types (third option)\n====I got a type IndexError====\nThis is wrong index (second option)\n====I got a type TypeError====\nThis is wrong operations with types (third option)\n====I got a type TypeError====\nThis is wrong operations with types (third option)\n====I got a type ZeroDivisionError====\nThis is divison by zero (first option)\n====I got a type TypeError====\nThis is wrong operations with types (third option)\n====I got a type ZeroDivisionError====\nThis is divison by zero (first option)\n====I got a type TypeError====\nThis is wrong operations with types (third option)"
  },
  {
    "objectID": "python/basics/exceptions.html#ony-one-exception-per-type",
    "href": "python/basics/exceptions.html#ony-one-exception-per-type",
    "title": "Exceptions",
    "section": "",
    "text": "You can define any number of `except’ blocks for the same exception type, but only the first one will be called.\nIn the following example, even though I declared two codes for the ZeroDivisionError type exception, only the first one was executed.\n\ntry:\n    1/0\nexcept ZeroDivisionError:\n    print(\"First code to handle exception\")\nexcept ZeroDivisionError:\n    print(\"Second code to handle exception\")\n\nFirst code to handle exception"
  },
  {
    "objectID": "python/basics/paths_settings/pathlib.html",
    "href": "python/basics/paths_settings/pathlib.html",
    "title": "Pathlib",
    "section": "",
    "text": "Pathlib is a special library built into Python that makes it easier to work with paths in Python. This page is focused on usage of this library."
  },
  {
    "objectID": "python/basics/paths_settings/pathlib.html#path-class",
    "href": "python/basics/paths_settings/pathlib.html#path-class",
    "title": "Pathlib",
    "section": "Path class",
    "text": "Path class\nYou should pass your folder path to the constructor, and you’ll get an instance that encapsulates the path behaviour.\nYou can:\n\nGet the path to the parent folder using the parent field;\nGet path to child folder with syntax &lt;pathlib.Path instance&gt; / &lt;name of child folder&gt; (just use division operator).\n\nAll these features are shown below:\n\nfrom pathlib import Path\nmy_path = Path(os.getcwd())\n\nprint(\"Original path: \", my_path)\nprint(\"Parent path: \", my_path.parent)\nprint(\"Using '/' operator: \", my_path/\"folder\"/\"file\")\n\nOriginal path:  /home/fedor/Documents/knowledge/python/basics/paths_settings\nParent path:  /home/fedor/Documents/knowledge/python/basics\nUsing '/' operator:  /home/fedor/Documents/knowledge/python/basics/paths_settings/folder/file"
  },
  {
    "objectID": "python/basics/paths_settings/pythonpath.html",
    "href": "python/basics/paths_settings/pythonpath.html",
    "title": "Python path",
    "section": "",
    "text": "Sometimes it’s hard to export Python files from other Python files or Jupyter notebooks. Usually problem related to list of folders where Python interpreter tends to search for names."
  },
  {
    "objectID": "python/basics/paths_settings/pythonpath.html#sys.path",
    "href": "python/basics/paths_settings/pythonpath.html#sys.path",
    "title": "Python path",
    "section": "sys.path",
    "text": "sys.path\nIs a list that contains all folders where interpreter will find names you try to export.\n\nThis jupyter\nIn the following example I have listed mine. The first is the folder where this notebook was started.\n\nimport sys\nsys.path\n\n['/home/fedor/Documents/knowledge/python/basics/paths_settings',\n '/usr/lib/python310.zip',\n '/usr/lib/python3.10',\n '/usr/lib/python3.10/lib-dynload',\n '',\n '/home/fedor/.local/lib/python3.10/site-packages',\n '/usr/local/lib/python3.10/dist-packages',\n '/usr/lib/python3/dist-packages']\n\n\n\n\nCLI\nBut let’s try the same trick with a Python file run from the CLI.\nThe following cell shows the code of the file I’m going to run.\n\n%%writefile python_path_files/python_path_files.py\nimport sys\nfor p in sys.path:\n    print(p)\n\nOverwriting print_sys_folder/print_sys_folder.py\n\n\nRun the code from bash - as a result, the first item of the lsit contains the same folder as file in.\n\n!python3 python_path_files/python_path_files.py\n\n/home/fedor/Documents/knowledge/python/basics/paths_settings/print_sys_folder\n/usr/lib/python310.zip\n/usr/lib/python3.10\n/usr/lib/python3.10/lib-dynload\n/home/fedor/.local/lib/python3.10/site-packages\n/usr/local/lib/python3.10/dist-packages\n/usr/lib/python3/dist-packages\n\n\n\n\nAdd item\nThe simplest way to solve file access problems is to add the appropriate directory to the os.path list.\nIn the following cell I just create a python file that cantain only one print - printing the message marks that the module has been successfully loaded. It is created in the folder python_path_files/some_hidden_module so that files from python_path_files cannot see it.\n\n%%writefile python_path_files/some_hidden_module/test_module.py\nprint(\"Test module successfully loaded!\")\n\nOverwriting python_path_files/some_hidden_module/test_module.py\n\n\nNext cell defines file in python_path_files. It will try to import file from previous cell before and after some_hiddem_module added to sys.path, in fail case it will print a corresponding message.\n\n%%writefile python_path_files/append_to_path.py\nimport os\nimport sys\n\n\ndef try_import_module():\n    try:\n        import test_module\n    except ModuleNotFoundError:\n        print(\"Module import went wrong!\")\n\ntry_import_module()\nsys.path.append(\"some_hidden_module\")\ntry_import_module()\n\nOverwriting python_path_files/append_to_path.py\n\n\nThe run of the file show:\n\nIn the first case I got an error message;\nBut after appending some_hidden_module to sys.path everything works fine.\n\n\n%%bash\ncd python_path_files\npython3 append_to_path.py\n\nModule import went wrong!\nTest module successfully loaded!"
  },
  {
    "objectID": "python/basics/paths_settings/pythonpath.html#environment-variable",
    "href": "python/basics/paths_settings/pythonpath.html#environment-variable",
    "title": "Python path",
    "section": "Environment variable",
    "text": "Environment variable\nYou can define the environment variable PYTHONPATH and list the paths with “:” - they will automatically appear in the sys.path of python running in that environment.\nSo in the following cell we have run some code that defines PYTHONPATH as two paths separated by “:”, then run a script that prints out sys.path. As a result you can see that the mentioned paths have been added to the sys.path list.\n\n%%bash\nexport PYTHONPATH=\"example/path1:example/path2\"\necho $PYTHONPATH\n\necho\necho \"=====python output=====\"\npython3 python_path_files/print_sys_folder.py\n\nexample/path1:example/path2\n\n=====python output=====\n/home/fedor/Documents/knowledge/python/basics/paths_settings/python_path_files\n/home/fedor/Documents/knowledge/python/basics/paths_settings/example/path1\n/home/fedor/Documents/knowledge/python/basics/paths_settings/example/path2\n/usr/lib/python310.zip\n/usr/lib/python3.10\n/usr/lib/python3.10/lib-dynload\n/home/fedor/.local/lib/python3.10/site-packages\n/usr/local/lib/python3.10/dist-packages\n/usr/lib/python3/dist-packages"
  },
  {
    "objectID": "python/basics/ipython_magics.html",
    "href": "python/basics/ipython_magics.html",
    "title": "IPython magics",
    "section": "",
    "text": "A special expression in IPython that allows you to use some of the special features provided by IPython. There are two types of magics:"
  },
  {
    "objectID": "python/basics/ipython_magics.html#lsmagic",
    "href": "python/basics/ipython_magics.html#lsmagic",
    "title": "IPython magics",
    "section": "%lsmagic",
    "text": "%lsmagic\nThis command allows you to list available IPython magics\n\n%lsmagic\n\nAvailable line magics:\n%alias  %alias_magic  %autoawait  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %colors  %conda  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n\nAvailable cell magics:\n%%!  %%HTML  %%SVG  %%bash  %%capture  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n\nAutomagic is ON, % prefix IS NOT needed for line magics."
  },
  {
    "objectID": "python/basics/ipython_magics.html#time",
    "href": "python/basics/ipython_magics.html#time",
    "title": "IPython magics",
    "section": "%time",
    "text": "%time\nMeasures the time of execution of some expression.\n\nBasic example\nHere I just have a function that runs a cycle with a given number of iterations, and show results for 10 and 500 iterations.\n\ndef some_computing(i_count):\n    for i in range(i_count): 5+5\n\nprint(\"=====10 iterations=====\")\n%time some_computing(10)\nprint(\"=====500 iterations=====\")\n%time some_computing(500)\n\n=====10 iterations=====\nCPU times: user 2 µs, sys: 0 ns, total: 2 µs\nWall time: 3.58 µs\n=====500 iterations=====\nCPU times: user 14 µs, sys: 2 µs, total: 16 µs\nWall time: 16.7 µs\n\n\n\n\nMetrics meaning\n\nCPU times gives description of the duration by stage of execution:\n\nuser user-side duration;\nsys system-side duration;\ntotal total duration of the calculation.\n\nWall time duration of the calculation with overhead resources (whatever they may be).\n\nNote Nowadays, I don’t know exactly what the difference is between the user side and the system side - but you should learn Linux to find out."
  },
  {
    "objectID": "python/basics/ipython_magics.html#timeit",
    "href": "python/basics/ipython_magics.html#timeit",
    "title": "IPython magics",
    "section": "%timeit",
    "text": "%timeit\nEstimates the execution time of a certain command over a series of runs.\nIn the following example I have a function that runs a cycle with a given number of iterations, and show results for 10 and 500 iterations.\n\ndef some_computing(i_count):\n    for i in range(i_count): 5+5\n\nprint(\"=====10 iterations=====\")\n%timeit some_computing(10)\nprint(\"=====500 iterations=====\")\n%timeit some_computing(500)\n\n=====10 iterations=====\n203 ns ± 6.87 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n=====500 iterations=====\n5.88 µs ± 115 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)"
  },
  {
    "objectID": "python/basics/ipython_magics.html#system-command",
    "href": "python/basics/ipython_magics.html#system-command",
    "title": "IPython magics",
    "section": "! - system command",
    "text": "! - system command\nYou can access the environment you ran IPython from by simply adding ! before the line. For linux/macOS this is usually terminal line for windows it is usually powerShall.\nIn the following example, I ran the Linux ls command from Jupyter Cell.\n\n!ls -l\n\ntotal 196\n-rwxrwxr-x 1 fedor fedor 34744 жні 26 20:36 basic_datatypes.ipynb\ndrwxrwxr-x 2 fedor fedor  4096 жні 26 20:39 class_interface\ndrwxrwxr-x 2 fedor fedor  4096 жні 26 20:39 class_spesials\n-rw-rw-r-- 1 fedor fedor 11496 жні 26 20:36 collections.ipynb\ndrwxrwxr-x 2 fedor fedor  4096 жні 26 20:39 excel_export_files\n-rwxrwxr-x 1 fedor fedor  2109 жні 26 20:36 excel_export.ipynb\n-rwxrwxr-x 1 fedor fedor 14411 жні 26 20:36 exceptions.ipynb\n-rw-rw-r-- 1 fedor fedor  1696 жні 26 20:36 functions.ipynb\ndrwxrwxr-x 4 fedor fedor  4096 жні 26 20:39 ipython_magics_files\n-rw-rw-r-- 1 fedor fedor 18796 жні 27 12:34 ipython_magics.ipynb\ndrwxrwxr-x 2 fedor fedor  4096 жні 26 20:39 logging_files\n-rwxrwxr-x 1 fedor fedor 17750 жні 26 20:36 logging.ipynb\n-rwxrwxr-x 1 fedor fedor  5037 жні 26 20:36 multi_threads.ipynb\ndrwxrwxr-x 2 fedor fedor  4096 жні 26 20:39 numpy\ndrwxrwxr-x 2 fedor fedor  4096 жні 26 20:39 operators_files\n-rwxrwxr-x 1 fedor fedor 14722 жні 26 20:36 operators.ipynb\n-rwxrwxr-x 1 fedor fedor     0 жні 26 20:36 output.xlsx\n-rw-rw-r-- 1 fedor fedor  1448 жні 26 20:36 packages.ipynb\ndrwxrwxr-x 2 fedor fedor  4096 жні 26 20:39 regex\ndrwxrwxr-x 2 fedor fedor  4096 жні 26 20:39 tkinter\ndrwxrwxr-x 2 fedor fedor  4096 жні 26 20:36 venv_files\n-rwxrwxr-x 1 fedor fedor 13168 жні 26 20:36 virtual_environment.ipynb"
  },
  {
    "objectID": "python/basics/ipython_magics.html#specific-code",
    "href": "python/basics/ipython_magics.html#specific-code",
    "title": "IPython magics",
    "section": "Specific code",
    "text": "Specific code\nYou can use some other codes in IPython just specifying them with magic &lt;code type&gt;. Next, I list some of the options available.\nNote looks like this magic is only available in whole cell mode.\n\nbash\n\n%%bash\nls -l\n\ntotal 16\n-rw-rw-r-- 1 fedor fedor 4127 жні 26 18:40 magic_commands.ipynb\ndrwxrwxr-x 3 fedor fedor 4096 жні 25 15:10 nbconvert\ndrwxrwxr-x 4 fedor fedor 4096 жні 25 15:10 voila_vs_nbconvert_saving_html\n\n\n\n\nHTML\n\n%%HTML\n&lt;button&gt;Button as HTML element&lt;/button&gt;\n\nButton as HTML element"
  },
  {
    "objectID": "python/basics/ipython_magics.html#load_ext",
    "href": "python/basics/ipython_magics.html#load_ext",
    "title": "IPython magics",
    "section": "%load_ext",
    "text": "%load_ext\nAllows you to load extentions of IPython.  Learn more. Looks like that’s a topic for another page, but for now I’ll just mention a few extensions that I use.\n\nautoreload\nBy default, IPython will only read imported modules when their import is mentioned for the first time. But this option allows you to set some specific rules for importing modules. Official documentation.\nIn essence this extension doles out two magic %autoreload and %aimport:\n\n%autoreload - specifies the import mode;\n%aimport - sets exceptions for %autoreload if they are provided by the current mode.\n\nNote look like you should use the full path to the files if you want to mention them for %aimport.\n\n%autoreload 1/explicit\nBefore executing a cell, only modules mentioned with %aimport will be reloaded.\nIn the following example I:\n\nCreate two files fun&lt;i&gt; \\(i \\in {1,2}\\), each containing only one function that returns a line like \"Original line from fun&lt;i&gt;.py\";\nImport them using the %autoreload explicit magic and mentioning fun1 in %aimport.\nCall them, and got obvious result - Original line from fun&lt;i&gt;.py;\nThen change both functions to return New line from fun&lt;i&gt;.py;\nCall the functions again:\n\nFunction from fun1 has changed the line;\nFunction from fun2 still has the word Original at the beginning (because it was mentioned in %aimport as module to me reloaded).\n\n\n\n%%bash\ncat &gt; ipython_magics_files/fun1.py &lt;&lt; EOF\ndef return_line():\n    return \"Original line from fun1.py\"\nEOF\ncat &gt; ipython_magics_files/fun2.py &lt;&lt; EOF\ndef return_line():\n    return \"Original line from fun2.py\"\nEOF\n\n\n%load_ext autoreload\n%autoreload explicit\nfrom ipython_magics_files import fun1, fun2\n%aimport ipython_magics_files.fun1\n\nprint(fun1.return_line())\nprint(fun2.return_line())\n\nOriginal line from fun1.py\nOriginal line from fun2.py\n\n\n\n%%bash\ncat &gt; ipython_magics_files/fun1.py &lt;&lt; EOF\ndef return_line():\n    return \"New line from fun1.py\"\nEOF\ncat &gt; ipython_magics_files/fun2.py &lt;&lt; EOF\ndef return_line():\n    return \"New line from fun2.py\"\nEOF\n\n\nprint(fun1.return_line())\nprint(fun2.return_line())\n\nNew line from fun1.py\nOriginal line from fun2.py\n\n\n\n\n%autoreload 2/all\nIt’s the most common mode for me - reload all modules before running any cell except those mentioned in %aimport.\nIf you want to exclude some modules from reimport, you should use %aimport -&lt;module name&gt; (the “-” symbol is crucial here).\nIn the following example I:\n\nCreate two files fun&lt;i&gt; \\(i \\in {1,2}\\), each containing only one function that returns a line like \"Original line from fun&lt;i&gt;.py\";\nImport them using the %autoreload all magic and mentioning fun2 in %aimport.\nCall them, and got obvious result - Original line from fun&lt;i&gt;.py;\nThen change both functions to return New line from fun&lt;i&gt;.py;\nCall the functions again:\n\nFunction from fun1 has changed the line;\nFunction from fun2 still has the word Original at the beginning (because it was mentioned in %aimport as an exclusion).\n\n\n\n%%bash\ncat &gt; ipython_magics_files/fun1.py &lt;&lt; EOF\ndef return_line():\n    return \"Original line from fun1.py\"\nEOF\ncat &gt; ipython_magics_files/fun2.py &lt;&lt; EOF\ndef return_line():\n    return \"Original line from fun2.py\"\nEOF\n\n\n%load_ext autoreload\n%autoreload all\n\nfrom ipython_magics_files import fun1, fun2\n%aimport -ipython_magics_files.fun2\nprint(fun1.return_line())\nprint(fun2.return_line())\n\nOriginal line from fun1.py\nOriginal line from fun2.py\n\n\n\n%%bash\ncat &gt; ipython_magics_files/fun1.py &lt;&lt; EOF\ndef return_line():\n    return \"New line from fun1.py\"\nEOF\ncat &gt; ipython_magics_files/fun2.py &lt;&lt; EOF\ndef return_line():\n    return \"New line from fun2.py\"\nEOF\n\n\nprint(fun1.return_line())\nprint(fun2.return_line())\n\nNew line from fun1.py\nOriginal line from fun2.py"
  },
  {
    "objectID": "python/basics/ipython_magics.html#writefile",
    "href": "python/basics/ipython_magics.html#writefile",
    "title": "IPython magics",
    "section": "%%writefile",
    "text": "%%writefile\nThis is the magic that allows you to save the contents of the cell to a file. You need to use the syntax %%writefile &lt;directory&gt; in the first line of the cell to save it in the &lt;directory&gt;.\nAll code cells in this section are the same example and should be run one by one.\nA new folder has been created here. The ls command confirms that it’s empty.\n\n%%bash\nmkdir ipython_magics_files/writefile_files\nls ipython_magics_files/writefile_files\n\nUsing %%writefile to a non-existent file.\n\n%%writefile ipython_magics_files/writefile_files/writefile\nthis is the file from the cell\n\nWriting ipython_magics_files/writefile_files/writefile\n\n\nVerify that the file has been created and contains the content specified in the previous cell.\n\n%%bash \necho \"=====files=====\"\nls ipython_magics_files/writefile_files\necho \"=====content=====\"\ncat ipython_magics_files/writefile_files/writefile\n\n=====files=====\nwritefile\n=====content=====\nthis is the file from the cell\n\n\nNow let’s try using the same file, but for a different cell. The message Overwriting ... indicates that the content will be completely replaced.\n\n%%writefile ipython_magics_files/writefile_files/writefile\nsome other message for another cell\n\nOverwriting ipython_magics_files/writefile_files/writefile\n\n\nMake sure that the contents of the file are from the last cell.\n\n%%bash\ncat ipython_magics_files/writefile_files/writefile\n\nsome other message for another cell\n\n\nFinally delete the folder so that the content remains fully playable.\n\n%%bash\nrm -r ipython_magics_files/writefile_files/"
  },
  {
    "objectID": "python/basics/tkinter/basics.html",
    "href": "python/basics/tkinter/basics.html",
    "title": "Источники",
    "section": "",
    "text": "Отсновы библиотеки tkinter\n\nфайл предоставленный на курсах от belhard по программированию на python (см. в тойже папке, в которой лежит этот .ipynb);"
  },
  {
    "objectID": "python/basics/tkinter/list_box.html",
    "href": "python/basics/tkinter/list_box.html",
    "title": "Источники",
    "section": "",
    "text": "Виджет Listbox из библиотеки tkinter\n\nфайл предоставленный на курсах от belhard по программированию на python (см. в тойже папке, в которой лежит этот .ipynb);\n\n\nСодержание\n\nМетоды;\n\ninsert вставка элементов в Listbox;\nget получение элементов из Listbox;\ndelete удаление элементо из Listbox;\ncurselection\n\nПоля.\n\n\n\nПодготовка\n\nfrom tkinter import *\n\ndef get_l_box():\n    '''\n        Для того, чтобы кратко создавать окно с `Listbox` внутри сделал функию.\n    '''\n    root = Tk()\n\n    lst_box = Listbox()\n    lst_box.pack()\n\n    return root, lst_box\n\ndef insert_123(lst_box):\n    '''\n        Для быстрой вставки\n        one\n        two \n        three\n        в переданный listbox\n    '''\n    for i in (\"one\", \"two\", \"three\"):\n        lst_box.insert(0, i)\n\n\n\nМетоды\n\ninsert\nПроизводит вставку элементов в Listbox\nАгрументы:\n\nИдекс вставки;\n\n\nroot, lst_box = get_l_box()\n\nfor i in (\"one\", \"two\", \"three\"):\n    lst_box.insert(0, i)\n    \nroot.mainloop()\n\n\n\n\nget\nПроизводит извлечение элементов из Listbox\nАргументы для извлечения одного элемента:\n\nиндекс или срез извлекаемых элементов;\n\n\nroot, lst_box = get_l_box()\ninsert_123(lst_box)\n    \nprint(\"Извлечение из индекса '1'\", lst_box.get(1))\n\nroot.mainloop()\n\nИзвлечение из индекса '1' two\n\n\nАргументы для извлечения слеза:\n\nпервый индекс среза;\nпоследний индекс среза.\n\n\nroot, lst_box = get_l_box()\ninsert_123(lst_box)\n    \nprint(\"Извлечение среза с от 0 до 1\", lst_box.get(0,1))\n\nroot.mainloop()\n\nИзвлечение среза с от 0 до 1 ('three', 'two')\n\n\n\n\ndelete\nПроизводит удаление по индексу или срезу.\nАргументы для удаления по индексу:\n\nИндекс удаляемого элемента.\n\n\nroot, lst_box = get_l_box()\ninsert_123(lst_box)\n    \nlst_box.delete(2)\n\nroot.mainloop()\n\n\nАргументы для удаления среза:\n\nпервый индекс среза;\nпоследний индекс среза.\n\n\nroot, lst_box = get_l_box()\ninsert_123(lst_box)\n    \nlst_box.delete(1,2)\n\nroot.mainloop()\n\n\n\n\ncurselection\nПолучение в виде картежа выделенных индексов.\n\nroot, lst_box = get_l_box()\ninsert_123(lst_box)\nlst_box[\"selectmode\"] = EXTENDED\n\ndef print_sel_ind():\n    sel_lab[\"text\"] = lst_box.curselection()\n\nButton(\n    text = \"Вывести индексы\",\n    command = print_sel_ind\n).pack()\n\nsel_lab = Label()\nsel_lab.pack()\n\nroot.mainloop()\n\n\n\n\n\nПоля\n\nselectmode\nОпределяет будет доступен ли множествнный выбор. В следующем примере создаются 2, ListBox в одном из которых доступен множественный выбор во втором нет.\n\nroot, lst_box1 = get_l_box()\nlst_box2 = Listbox(selectmode = EXTENDED)\nlst_box2.pack()\n\nfor i in (\"one\", \"two\", \"three\"):\n    lst_box1.insert(0, i)\n    lst_box2.insert(0,i)\n\nroot.mainloop()"
  },
  {
    "objectID": "python/basics/regex/regex.html",
    "href": "python/basics/regex/regex.html",
    "title": "Источники",
    "section": "",
    "text": "Регулярные выражения (regex)\nТут разберем реализацию регулярных выражений в python. Вообще, конечно, регулярные выражения используются во многих языках программирования и выходят за контекст python. Но никаким языком программирования я и близко так не владею, как владею python (на сегодняшний день). Потому тут будут разбораны и общие идеи лежащие в синтаксисе регулярных выражений. Разбор общих элементов регулярных выражений я надеюсь вынести на уровень выше.\n\nhttps://docs.python.org/3/howto/regex.html#regex-howto статья в официальной докумментации python в которой описаны принципы использования regex."
  },
  {
    "objectID": "python/basics/excel_export.html",
    "href": "python/basics/excel_export.html",
    "title": "To excel import",
    "section": "",
    "text": "from IPython.display import HTML\nHTML('''\n&lt;style&gt;\n    h1 {text-align:center}\n&lt;/style&gt;\n''')\n\n\n\n\n\n\nSeveral pd.DataFrame on list\n\nimport pandas as pd\n\ndf1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\ndf2 = pd.DataFrame({'C': [7, 8, 9], 'D': [10, 11, 12]})\n\nwriter = pd.ExcelWriter('excel_export_files/output.xlsx')\n\ndf1.to_excel(writer, sheet_name='Sheet1')\ndf2.to_excel(writer, sheet_name='Sheet1', startrow=df1.shape[0] + 2)\n\ndf1.to_excel(writer, sheet_name='Sheet2')\ndf2.to_excel(writer, sheet_name='Sheet2', startrow=df1.shape[0] + 2)\n\nwriter.close()"
  },
  {
    "objectID": "python/basics/multi_threads.html",
    "href": "python/basics/multi_threads.html",
    "title": "Multithreads in python",
    "section": "",
    "text": "Sources\n\nOfficial documentarion for threading module;\nThird-party tutorial with examples (python2).\n\n\n\nExample1 - runtime messages\nIn following exmaple:\n\nDefine the myThread class as an ancestor of the threading.Thread class - it will describe the behaviour of the thread:\n\nThe run method is executed when the thread is started - in this case method:\n\nSpends time according to the delay parameter of the class;\nIncreases the value of counter by one.\n\n\nCreate and run two instances of myThread:\n\nWith delay 0.5 and 1;\nWith name “first” and “second”;\n\nIn cycle every 0.5 seconds check is threads still alife and print counter values for each instance;\nResult:\n\ncounter of instance named “first” updated at each step;\ncounter of instance named “second” is updated once every two steps.\n\n\n\nimport threading\nimport time\n\nsteps_count = 5\n\nclass myThread(threading.Thread):\n    def __init__(self, delay, name):\n        super().__init__()\n        self.counter = 0\n        self.delay = delay\n        self.name = name\n\n    def run(self):\n        for i in range(steps_count):\n            time.sleep(self.delay)\n            self.counter += 1\n\nthreads = []\n\n# Create new threads\nthread1 = myThread(0.5, \"first\")\nthread2 = myThread(1, \"second\")\n\nbegin_time = time.time()\n# Start new Threads\nthread1.start()\nthread2.start()\n\n# Add threads to thread list\nthreads.append(thread1)\nthreads.append(thread2)\n\nis_any_thread_live = True\nwhile is_any_thread_live:\n    time.sleep(0.5)\n\n    dislpay_line = \\\n        f\"====={round(time.time() - begin_time, 1)}\" + \\\n        \" seconds after begining=====\"\n    print(dislpay_line)\n    for t in threads:\n        print(t.name + \" counter = \" + str(t.counter))\n    \n    for t in threads:\n        if t.is_alive():\n            # if any thread alife\n            # i leave the cycle\n            break\n    else:\n        # if we tried all threads\n        # and there aren't any alife \n        # set flag for cycle leaving\n        is_any_thread_live = False\n\n=====0.5 seconds after begining=====\nfirst counter = 1\nsecond counter = 0\n=====1.0 seconds after begining=====\nfirst counter = 2\nsecond counter = 1\n=====1.5 seconds after begining=====\nfirst counter = 3\nsecond counter = 1\n=====2.0 seconds after begining=====\nfirst counter = 4\nsecond counter = 2\n=====2.5 seconds after begining=====\nfirst counter = 5\nsecond counter = 2\n=====3.0 seconds after begining=====\nfirst counter = 5\nsecond counter = 3\n=====3.5 seconds after begining=====\nfirst counter = 5\nsecond counter = 3\n=====4.0 seconds after begining=====\nfirst counter = 5\nsecond counter = 4\n=====4.5 seconds after begining=====\nfirst counter = 5\nsecond counter = 4\n=====5.0 seconds after begining=====\nfirst counter = 5\nsecond counter = 5"
  },
  {
    "objectID": "python/basics/class_interface/python_class_interface.html",
    "href": "python/basics/class_interface/python_class_interface.html",
    "title": "Иточники",
    "section": "",
    "text": "Изучение того как в python работать с интерфесми (как концепцией)\n\nhttps://realpython.com/python-interface/\n\nИнтерфейс - некоторая абстакция, которая позволяет определить какими методы должны быть обязательно реализованы в наследниках.\n\nНе формальное определение интефейса\nРассмотрим пример - класс парсер. При том там надо реализовать парсеры для pdf документов и для документов из электронной почнты (eml)\n\nclass InformalParserInterface:\n    '''\n        Класс который определят все общее \n        принадлежащее парсерам\n    '''\n    def load_data_source(self, path: str, file_name : str) -&gt; str:\n        '''\n            Пусть пасерам надо доставать данные из различных\n            файлов по пути path\n        '''\n        pass\n    \n    def extrac_text(self, full_file_name: str):\n        '''\n            Пусть всем парсерам надо уметь доставать данные из\n            диррекстивно указанного пути\n        ''' \n        pass\n\nИтак, были описаны возможности которыми должен обладать любой парсер. Далее конктеретизация.\n\nclass PdfParser(InformalParserInterface):\n    '''\n        Конкредная реализация парсера для pdf документов\n    '''\n    def load_data_source(self, path: str, file_name:str) -&gt; str:\n        '''\n            Определяем как именно должен работать парсинг\n            для pdf документов\n        '''\n        pass\n    \n    def extract_text(self, full_file_path:str) -&gt; dict:\n        '''\n            Тут также определяем как именно должен работать \n            парсинг для pdf документов\n        '''\n        pass\n    \nclass EmlParser(InformalParserInterface):\n    '''\n        Конкретная реализация для документов электронной почты\n    '''\n    def load_data_source(self, path:str, file_name:str)-&gt;str:\n        '''\n            Определяем как именно должен работать парсинг для email документов\n        '''\n        pass\n    \n    def extract_text_from_email(self, full_file_path:str)-&gt;str:\n        '''\n            Метод определенный только для документов email,\n            но он по прежнему определяет как должен работать\n            парсинг для email документов\n        '''\n        pass\n\nУбедимся, что подклассы созданные реализации являются классами-наследниками для базового класса InformalParserInterface с использованием функции issubclass\n\nissubclass(PdfParser, InformalParserInterface)\n\nTrue\n\n\n\nissubclass(EmlParser, InformalParserInterface)\n\nTrue\n\n\nИдея, которую доносят в источнике 1, состоит в том, что хорошо чтобы issubclass(EmlParser, InformalParserInterface) возвращало False так как, мы не переопределили extract_text и EmlParser не может считаться полноценной реализацией интерфейса InformalParserInterface.\n\n\nИспользование Метаклассов\nИдея создания интерфейса через метакласс, сосотои в том, что интерфейс имеет метакласс, в котором переопределены. __instancecheck__ и __subclasscheck__ (подробнее об этих базовых методах можно узать тут https://github.com/Dranikf/knowledge_bank/blob/main/python_class_spesials/python_class_specials.ipynb в разделе “Методы-&gt;Методы метаклассов”). Приведенным ниже образом.\n\nclass ParserMeta(type):\n    '''\n        Мета-парсер который будет использоваться для\n        создания парсеров\n    '''\n    def __subclasscheck__(cls, subclass):\n        '''\n            Все классы наследующие этот класс \n            в качесве мета класса будут, будут своими \n            экземплярами (в смысле функции issubclass) \n            воспринимать лишь те классы, в которых объявлены \n            и определены методы load_data_source и extract_text.\n        '''\n        return (\n            hasattr(subclass, 'load_data_source') and\n            callable(subclass.load_data_source) and\n            hasattr(subclass, 'extract_text') and\n            callable(subclass.extract_text)\n        )\n    \n    \n    def __instancecheck__(cls, instance):\n        '''\n            Все классы наследующие это класс в качестве\n            мета класса, своими экземплярами будут воспринимпть\n            лишь те объекты, классы которых воспинимаются\n            наследниками\n        '''\n        return cls.__subclasscheck__(type(instance))\n    \n\n    \nclass UpdatedInformalParserInterface(metaclass = ParserMeta):\n    '''\n        Объявляем обновленный парсер-интерфейс\n    '''\n    pass\n\nРассмотрим, тот-же пример.\n\nclass PdfParserNew():\n    '''\n        Новая конкредная реализация парсера для pdf документов\n    '''\n    def load_data_source(self, path: str, file_name:str) -&gt; str:\n        '''\n            Определяем как именно должен работать парсинг\n            для pdf документов\n        '''\n        pass\n    \n    def extract_text(self, full_file_path:str) -&gt; dict:\n        '''\n            Тут также определяем как именно должен работать \n            парсинг для pdf документов\n        '''\n        pass\n    \nclass EmlParserNew:\n    '''\n        Конкретная реализация для документов электронной почты\n    '''\n    def load_data_source(self, path:str, file_name:str)-&gt;str:\n        '''\n            Определяем как именно должен работать парсинг для email документов\n        '''\n        pass\n    \n    def extract_text_from_email(self, full_file_path:str)-&gt;str:\n        '''\n            Метод определенный только для документов email,\n            но он по прежнему определяет как должен работать\n            парсинг для email документов\n        '''\n        pass\n\nПроверяем результат выполнения функции issubclass для новосозданных классов.\n\nissubclass(PdfParserNew, UpdatedInformalParserInterface)\n\nTrue\n\n\n\nissubclass(EmlParserNew, UpdatedInformalParserInterface)\n\nFalse\n\n\nТак формально UpdatedInformalParserInterface не является реализацией интерфейса EmlParserNew.\nНо такая реализация по прежнему не являтся правильной Рассмотрим результат метода __mro__ для PdfParserNew (__mro__ - одно из специальных полей).\n\nPdfParserNew.__mro__\n\n(__main__.PdfParserNew, __main__.UpdatedInformalParserInterface, object)\n\n\nТак в __mro__ для класса PdfParserNew, не видно, что он как-либо связан с UpdatedInformalParserInterface. Такую ситуалию еще описывают, что UpdatedInformalParserInterface является виртуальным базовым классом для класса PdfParserNew.\nВпрочем, новерное, это можно преодолеть следующей реализацией pdf парсера.\n\nclass PdfParserNew2(UpdatedInformalParserInterface):\n    '''\n        Новая конкредная реализация парсера для pdf документов\n    '''\n    def load_data_source(self, path: str, file_name:str) -&gt; str:\n        '''\n            Определяем как именно должен работать парсинг\n            для pdf документов\n        '''\n        pass\n    \n    def extract_text(self, full_file_path:str) -&gt; dict:\n        '''\n            Тут также определяем как именно должен работать \n            парсинг для pdf документов\n        '''\n        pass\n\n\nissubclass(PdfParserNew2, UpdatedInformalParserInterface)\n\nTrue\n\n\n\nPdfParserNew2.__mro__\n\n(__main__.PdfParserNew2, __main__.UpdatedInformalParserInterface, object)\n\n\n\n\nФормальная реализация интерфейса\nДля формальной реализации интерфейсов используется модуль abc\n\nimport abc"
  },
  {
    "objectID": "python/basics/virtual_environment.html",
    "href": "python/basics/virtual_environment.html",
    "title": "Virutal environment in python",
    "section": "",
    "text": "Official documentation on virtual invironment in python;\nExtended tutorial;\nJupyter Notebook Kernels: How to Add, Change, Remove."
  },
  {
    "objectID": "python/basics/virtual_environment.html#wrong-way",
    "href": "python/basics/virtual_environment.html#wrong-way",
    "title": "Virutal environment in python",
    "section": "Wrong way",
    "text": "Wrong way\nThe wrong way to do this is to just copy the virtual environment folder. It will lead to broken paths for the Python interpreter.\nIn the following example, I copy the python3 environment from venv1 to venv2, but when I run python from the copied environment and check sys.path, it’s still pointing to the path for venv1.\n\n%%bash\ncd venv_files\n\nmkdir venv1 venv2\n\npython3.10 -m venv venv1/venv\ncp -r venv1/venv venv2/venv\n\nsource venv2/venv/bin/activate\necho \"=====sys.path[-1]=====\"\npython3 -c \"import sys; print(sys.path[-1])\"\n\nrm -r venv1 venv2\n\n=====sys.path[-1]=====\n/home/fedor/Documents/knowledge_bank/python/venv_files/venv1/venv/lib/python3.10/site-packages"
  },
  {
    "objectID": "python/basics/virtual_environment.html#correct-way",
    "href": "python/basics/virtual_environment.html#correct-way",
    "title": "Virutal environment in python",
    "section": "Correct way",
    "text": "Correct way\nhttps://stackoverflow.com/questions/7438681/how-to-duplicate-virtualenv"
  },
  {
    "objectID": "python/basics/virtual_environment.html#add-to-kernelspec",
    "href": "python/basics/virtual_environment.html#add-to-kernelspec",
    "title": "Virutal environment in python",
    "section": "Add to kernelspec",
    "text": "Add to kernelspec\nFor more information, click here.\n\nCreate:\n\nInstall jupyter in environment pip install jupyter;\nRun for environment ipython kernel install --name \"&lt;environment name&gt;\" --user;\n\nList all available environments jupyter kernelspec list;\nDelete jupyter kernelspec remove &lt;kernel-name&gt;\n\nThe following example shows the use of all the above commands.\n\n%%bash\ncd venv_files\npython3 -m venv test_venv\n\necho \"=====instalation=====\"\nsource test_venv/bin/activate\npip install jupyter &&gt; /dev/null\nipython kernel install --name \"test-env\" --user\ndeactivate\n\necho \"=====list available kernels=====\"\njupyter kernelspec list\n\necho \"====delete test_environment=====\"\njupyter kernelspec remove -y test-env\n\nrm -r test_venv\n\n=====instalation=====\nInstalled kernelspec test-env in /home/fedor/.local/share/jupyter/kernels/test-env\n=====list available kernels=====\nAvailable kernels:\n  python3     /home/fedor/.local/share/jupyter/kernels/python3\n  test-env    /home/fedor/.local/share/jupyter/kernels/test-env\n====delete test_environment=====\nRemoved /home/fedor/.local/share/jupyter/kernels/test-env\n\n\nNote after reloading for example jupyter lab you will have refreshed list of kernels."
  },
  {
    "objectID": "python/basics/virtual_environment.html#run-from-environment",
    "href": "python/basics/virtual_environment.html#run-from-environment",
    "title": "Virutal environment in python",
    "section": "Run from environment",
    "text": "Run from environment\nWhen you run jupyter ... in your system, it will run from the base system python, whether or not any environment is enabled. But jupyter is actually just a Python runnable package, and you can do python3 -m jupyter ..., in which case it will use the appropriate environment to run a jupyter ....\nI can’t show it using notebook cells. But you should use such commands:\n# create environment\npython3 -m venv some_venv\n# activate environment\nsource some_venv/bin/activate\n# install jupyter\npip install jupyter\n# run jupyter using direct call of jupyter from python\npython3 -m jupyter lab"
  },
  {
    "objectID": "python/basics/logging.html",
    "href": "python/basics/logging.html",
    "title": "Logging",
    "section": "",
    "text": "Logging in python: developer guide (rus);\n\n\nimport os\nimport sys\nimport logging\nimport random"
  },
  {
    "objectID": "python/basics/logging.html#error-types",
    "href": "python/basics/logging.html#error-types",
    "title": "Logging",
    "section": "Error types",
    "text": "Error types\nThere are five levels of logging:\n\nDebug;\nInfo;\nWarning;\nError;\nCritical.\n\nYou can call them by using the relevant functions:\n\nlogging.debug(\"A DEBUG Message\")\nlogging.info(\"An INFO\")\nlogging.warning(\"A WARNING\")\nlogging.error(\"An ERROR\")\nlogging.critical(\"A message of CRITICAL severity\")\n\nWARNING:root:A WARNING\nERROR:root:An ERROR\nCRITICAL:root:A message of CRITICAL severity\n\n\nIn previous examle debug and info errors wasn’t printed. It happened becaulse default value for logging.level setted to logging.WARNING, therefore only those messages above WARNING will be displayed."
  },
  {
    "objectID": "python/basics/logging.html#basicconfig",
    "href": "python/basics/logging.html#basicconfig",
    "title": "Logging",
    "section": "basicConfig",
    "text": "basicConfig\n\nlogging.basicConfig(level=logging.INFO)\n\nlogging.debug(\"A DEBUG Message\")\nlogging.info(\"An INFO\")\nlogging.warning(\"A WARNING\")\nlogging.error(\"An ERROR\")\nlogging.critical(\"A message of CRITICAL severity\")\n\nINFO:root:An INFO\nWARNING:root:A WARNING\nERROR:root:An ERROR\nCRITICAL:root:A message of CRITICAL severity"
  },
  {
    "objectID": "python/basics/logging.html#getlogger---creating-loggers",
    "href": "python/basics/logging.html#getlogger---creating-loggers",
    "title": "Logging",
    "section": "getLogger - creating loggers",
    "text": "getLogger - creating loggers\nFor some reason you can’t set basic config twice with logging lib. I showing it in the following example:\n\nSet level=logging.DEBUG and, as expected, got every type of message;\nSet level=logging.ERROR and, but any way got every type of message.\n\n\nprint(\"=====logging run1=====\", file=sys.stderr)\nlogging.basicConfig(level=logging.DEBUG)\nlogging.debug(\"A DEBUG Message\")\nlogging.info(\"An INFO\")\nlogging.warning(\"A WARNING\")\nlogging.error(\"An ERROR\")\nlogging.critical(\"A message of CRITICAL severity\")\n\nprint(\"=====logging run2=====\", file=sys.stderr)\nlogging.basicConfig(level=logging.ERROR)\nlogging.debug(\"A DEBUG Message\")\nlogging.info(\"An INFO\")\nlogging.warning(\"A WARNING\")\nlogging.error(\"An ERROR\")\nlogging.critical(\"A message of CRITICAL severity\")\n\n=====logging run1=====\nDEBUG:root:A DEBUG Message\nINFO:root:An INFO\nWARNING:root:A WARNING\nERROR:root:An ERROR\nCRITICAL:root:A message of CRITICAL severity\n=====logging run2=====\nDEBUG:root:A DEBUG Message\nINFO:root:An INFO\nWARNING:root:A WARNING\nERROR:root:An ERROR\nCRITICAL:root:A message of CRITICAL severity\n\n\nThe solution for different situations is to create different loggers with different options. In the following example, I create different loggers with different level options, so that logger2 successfully sets the ERROR option.\n\nlogger1 = logging.getLogger(\"logger1\")\nlogger1.setLevel(logging.INFO)\n\nprint(\"=====logger1=====\", file=sys.stderr)\nlogger1.debug(\"A DEBUG Message\")\nlogger1.info(\"An INFO\")\nlogger1.warning(\"A WARNING\")\nlogger1.error(\"An ERROR\")\nlogger1.critical(\"A message of CRITICAL severity\")\n\n\nlogger2 = logging.getLogger(\"logger2\")\nlogger2.setLevel(logging.ERROR)\n\nprint(\"=====logger2=====\", file=sys.stderr)\nlogger2.debug(\"A DEBUG Message\")\nlogger2.info(\"An INFO\")\nlogger2.warning(\"A WARNING\")\nlogger2.error(\"An ERROR\")\nlogger2.critical(\"A message of CRITICAL severity\")\n\n=====logger1=====\nINFO:logger1:An INFO\nWARNING:logger1:A WARNING\nERROR:logger1:An ERROR\nCRITICAL:logger1:A message of CRITICAL severity\n=====logger2=====\nERROR:logger2:An ERROR\nCRITICAL:logger2:A message of CRITICAL severity"
  },
  {
    "objectID": "python/fastapi/return_json.html",
    "href": "python/fastapi/return_json.html",
    "title": "Return JSON",
    "section": "",
    "text": "Container for the examples in this page.\n!docker run --rm -itd\\\n    --name test_container\\\n    -v ./return_json_files/app.py:/app.py\\\n    -p 8000:8000 \\\n    fastapi_experiment \\\n    uvicorn --host 0.0.0.0 --reload app:app &&gt;/dev/null\nNote Don’t forget to stop the container.\n!docker stop test_container &&gt;/dev/null"
  },
  {
    "objectID": "python/fastapi/return_json.html#example",
    "href": "python/fastapi/return_json.html#example",
    "title": "Return JSON",
    "section": "Example",
    "text": "Example\nTo return json from fastapi endpoin you should just return dictionary. It will be converted to the appropriate json and passed as a response.\nIf you send a request to the corresponding URL, you will get exactly the same as dict, except that all keys will be converted to strings. In the example, I deliberately create one of the keys of a numeric data type to demonstrate that it will be converted to a string when queried.\n\n%%writefile return_json_files/app.py\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\ndef json_as_answer():\n    return {\n        \"key1\" : \"value1\",\n        \"key2\" : \"value2\",\n        6 : 34\n    }\n\nOverwriting return_json_files/app.py\n\n\n\n!curl localhost:8000\n\n{\"key1\":\"value1\",\"key2\":\"value2\",\"6\":34}"
  },
  {
    "objectID": "python/fastapi/run_application.html",
    "href": "python/fastapi/run_application.html",
    "title": "Run application",
    "section": "",
    "text": "In this page I will introduce how to run fastapi applications in general and in particular how to run examples related to fastapi in the site.\nHere you can find out more details about using fastapi in the docker."
  },
  {
    "objectID": "python/fastapi/run_application.html#sec-dockerfile",
    "href": "python/fastapi/run_application.html#sec-dockerfile",
    "title": "Run application",
    "section": "dockerfile",
    "text": "dockerfile\nIn the next cell is the docker file I am using for this example.\n\n# %load run_application_files/dockerfile\nFROM python:3.11\nCOPY requrements.txt requrements.txt\nRUN pip3 install -r requrements.txt\nEXPOSE 8000"
  },
  {
    "objectID": "python/fastapi/run_application.html#requrements.txt",
    "href": "python/fastapi/run_application.html#requrements.txt",
    "title": "Run application",
    "section": "requrements.txt",
    "text": "requrements.txt\nPython libraries you only needed to run the fastapi server. It is supposed to be used in the dockerfile described above.\n\n# %load run_application_files/requrements.txt\nfastapi==0.103.1\nuvicorn==0.23.2"
  },
  {
    "objectID": "python/fastapi/run_application.html#sec-prog",
    "href": "python/fastapi/run_application.html#sec-prog",
    "title": "Run application",
    "section": "Programme",
    "text": "Programme\nYou need to declare an object of class fastapi.fastAPI. Then use its decorators to add to your functions the ability to respond to certain requests.\nSo in the following example, I create fastapi.fastAPI under the name my_first_app, and create a function that will always respond hello to a get request.\n\n%%writefile run_application_files/get_started.py\nfrom fastapi import FastAPI\n\nmy_first_app = FastAPI()\n\n@my_first_app.get(\"/\")\ndef say_hello():\n    return \"hello\"\n\nOverwriting run_application_files/get_started.py"
  },
  {
    "objectID": "python/fastapi/run_application.html#run",
    "href": "python/fastapi/run_application.html#run",
    "title": "Run application",
    "section": "Run",
    "text": "Run\nTo run the fastapi official documentation recomend to use uvicorn as web-server. So you need to use command:\nuvicon &lt;path to python file with program&gt;:&lt;name of fastapi.fastAPI object in your program&gt;.\nSo in the following example, a docker container is run, tested and stopped:\n\nCreated from the image named fastapi_experiment described in the docker file above;\nWith the name test_container for container;\nThe default port for fastapi is 8000, so port 8000 on the container is connected to port 8000 on the local machine;\nWith volume that allows to read programme;\nAnd with the command created from the required pattern:\n\n--host 0.0.0.0 is used to make the application visible from the container, it’s not necessary if you are using uvicorn without docker.\n\n\n\n!docker run --rm -itd\\\n    --name test_container\\\n    -v ./run_application_files/get_started.py:/get_started.py\\\n    -p 8000:8000 \\\n    fastapi_experiment \\\n    uvicorn --host 0.0.0.0 get_started:my_first_app &gt;/dev/null\n\nSo now you can try it in your browser, but here I use the curl utility - it returns “hello”, just as I declared in the programme.\n\n!curl localhost:8000\n\n\"hello\"\n\n\nAnd we can also check what is happening inside the container. Note that the last line here is the log line for the http request from the previous cell.\n\n!docker logs test_container\n\nINFO:     Started server process [1]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\nINFO:     172.17.0.1:45308 - \"GET / HTTP/1.1\" 200 OK\n\n\nDon’t forget to stop the image when you’ve finished playing with the container.\n\n!docker stop test_container &&gt; /dev/null"
  },
  {
    "objectID": "python/fastapi/run_application.html#update-program",
    "href": "python/fastapi/run_application.html#update-program",
    "title": "Run application",
    "section": "Update program",
    "text": "Update program\nThe most convenient way to experiment with a container containing fastapi is to swap the program on the fly, so you can run many examples through one container. That’s why I usually connect the used executing py file as a volume (so that changes on the computer get into the container at once).\nBut to implement it, you also need to run uvicorn with the --reload flag, which will make it track changes in the programme and update with it.\nSo, in the following cells:\n\nThe container stats with a program that sends initial line as a response;\nTry in with curl - all right, got initial line;\nThen change the reload.py file to respond with updated line;\nImmediately try again with the same curl - we’ve got an updated line as response.\n\n\n%%writefile run_application_files/reload.py\nfrom fastapi import FastAPI\n\nmy_first_app = FastAPI()\n\n@my_first_app.get(\"/\")\ndef say_hello():\n    return \"initial line\"\n\nOverwriting run_application_files/reload.py\n\n\n\n!docker run --rm -itd\\\n    --name test_container\\\n    -v ./run_application_files/reload.py:/reload.py\\\n    -p 8000:8000 \\\n    fastapi_experiment \\\n    uvicorn --host 0.0.0.0 --reload reload:my_first_app\n\n752d9632c61a1927a227daf2a8b3de375385e107af1213a0df98c2b7d482d2ef\n\n\n\n!curl localhost:8000\n\n\"initial line\"\n\n\n\n%%writefile run_application_files/reload.py\nfrom fastapi import FastAPI\n\nmy_first_app = FastAPI()\n\n@my_first_app.get(\"/\")\ndef say_hello():\n    return \"updated line\"\n\nOverwriting run_application_files/reload.py\n\n\n\n!curl localhost:8000\n\n\"updated line\"\n\n\n\n!docker stop test_container"
  },
  {
    "objectID": "python/fastapi/pass_arguments.html",
    "href": "python/fastapi/pass_arguments.html",
    "title": "Pass arguments",
    "section": "",
    "text": "To make your programs useful, you need to give them some arguments. On this page I’ll describe how to do that."
  },
  {
    "objectID": "python/fastapi/pass_arguments.html#preparing",
    "href": "python/fastapi/pass_arguments.html#preparing",
    "title": "Pass arguments",
    "section": "Preparing",
    "text": "Preparing\nTo run the examples on this page, you will need:\n\nStart a docker container with fastapi;\nImport some libraries.\n\n\n# requests is cnetral library\n# to try make requests from python\nimport requests\n\n!docker run --rm -itd\\\n    --name test_container\\\n    -v ./pass_arguments_files/app.py:/app.py\\\n    -p 8000:8000 \\\n    fastapi_experiment \\\n    uvicorn --host 0.0.0.0 --reload app:app\n\nb5432e9d63f5335872a3b63b1ae765cf681d794a3e0421d279ec1c0ac2c9e6bc\n\n\nDon’t forget to stop the container when you’ve finished playing with the examples on this page.\n\n!docker stop test_container\n\ntest_container"
  },
  {
    "objectID": "python/fastapi/pass_arguments.html#query-params",
    "href": "python/fastapi/pass_arguments.html#query-params",
    "title": "Pass arguments",
    "section": "Query params",
    "text": "Query params\nTo define url with parameters in fastapi, you need to define method with parameters and wrap it with fastapi object decorators.\nIn order to pass an argument using ulr we need to write a construction ?param1=argument1&param2=argument2&...&paramN=argumentN at the end of url (in web development, the name for this construction is query params).\nSo in the following example I have written a program to divide two numbers and use the syntax /divide?a=10&b=2 in the url to complete the division.\n\n%%writefile pass_arguments_files/app.py\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/divide\")\ndef divide(a:int, b:int) -&gt; int:\n    return a/b\n\nOverwriting pass_arguments_files/app.py\n\n\n\nresponse = requests.get(\"http://localhost:8000/divide?a=10&b=2\")\nresponse.text\n\n'5'"
  },
  {
    "objectID": "python/fastapi/pass_arguments.html#json-input",
    "href": "python/fastapi/pass_arguments.html#json-input",
    "title": "Pass arguments",
    "section": "JSON input",
    "text": "JSON input\nTo pass json data to your endpoint, you need to declare a descendant class of pydantic.BaseModel where you describe fields and their pytes to be passed to the endpoint as json. And use an instance of that class as a parameter to your endpoint.\nSo the following fastapi program defines Item which expects json with keys param1 and param2 and just returns line describing what data we’ve got.\n\n%%writefile pass_arguments_files/app.py\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nclass Item(BaseModel):\n    param1: int\n    param2: str\n\napp = FastAPI()\n\n@app.post(\"/\")\ndef read_json(item:Item):\n    return f\"\"\"I have got:\n    param1={item.param1};\n    param2={item.param2}.\"\"\"\n\nOverwriting pass_arguments_files/app.py\n\n\nAnd here is an example of how you can send a query to such an end point and process its result.\n\nimport requests\nimport json\n\ndata = {\"param1\" : 2, \"param2\": \"test line\"}\nresponse = requests.post(\n    \"http://localhost:8000/\", \n    json=data\n)\nprint(response.content.decode(\"utf-8\").replace(\"\\\\n\", \"\\n\"))\n\n\"I have got:\n    param1=2;\n    param2=test line.\""
  },
  {
    "objectID": "python/fastapi/pass_arguments.html#data-types",
    "href": "python/fastapi/pass_arguments.html#data-types",
    "title": "Pass arguments",
    "section": "Data types",
    "text": "Data types\n\nParameter types\nYou need to declare data types for the arguments otherwise the call will not work correctly.\nThe following example describes a programme without input datatypes. The request to the server causes the error:\n\n%%writefile pass_arguments_files/app.py\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/divide\")\ndef divide(a, b) -&gt; int:\n    return a/b\n\nOverwriting pass_arguments_files/app.py\n\n\n\nresponse = requests.get(\"http://localhost:8000/divide?a=10&b=2\")\nresponse.text\n\n'Internal Server Error'\n\n\n\n\nOutput datatype\nIt does not have to be specified. So in the following example the output data type is not specified and the query is executed without problems.\n\n%%writefile pass_arguments_files/app.py\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/divide\")\ndef divide(a : int, b : int):\n    return a/b\n\nOverwriting pass_arguments_files/app.py\n\n\n\nresponse = requests.get(\"http://localhost:8000/divide?a=10&b=2\")\nresponse.text\n\n'5.0'\n\n\nBut if you have specified a type, you must follow it.\nIn the following example, the GET response function is configured to use int as output.\n\nThe first request called in such a way as to return float - that’s why you got the error;\nThe result of the second request can be interpreted as int, so all is well.\n\n\n%%writefile pass_arguments_files/app.py\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/divide\")\ndef divide(a : int, b : int) -&gt; int:\n    return a/b\n\nOverwriting pass_arguments_files/app.py\n\n\n\nresponse = requests.get(\"http://localhost:8000/divide?a=1&b=2\")\nresponse.text\n\n'Internal Server Error'\n\n\n\nresponse = requests.get(\"http://localhost:8000/divide?a=4&b=2\")\nresponse.text\n\n'2'"
  },
  {
    "objectID": "python/sqlalchemy/query.html",
    "href": "python/sqlalchemy/query.html",
    "title": "Query",
    "section": "",
    "text": "In this page I’ll describe how to load records from the database using sqlalchemy."
  },
  {
    "objectID": "python/sqlalchemy/query.html#start-container",
    "href": "python/sqlalchemy/query.html#start-container",
    "title": "Query",
    "section": "Start container",
    "text": "Start container\nContainer with a postgres database, and creating tables that will be useful for the examples described on this page.\n\n%%bash\ndocker run -d --rm\\\n    --name read_table_example\\\n    -e POSTGRES_PASSWORD=postgres\\\n    -p 5000:5432\\\n    postgres:15.4 &&gt; /dev/null\nsleep 5\ndocker exec -i read_table_example psql -U postgres -d postgres\n\nCREATE TABLE test_table (\n    numeric_var INT PRIMARY KEY,\n    text_var VARCHAR\n);\n\nINSERT INTO test_table (numeric_var, text_var) VALUES\n(1, 'a'),\n(2, 'a'),\n(3, 'b'),\n(4, 'c');\n\nCREATE TABLE\nINSERT 0 4\n\n\nDon’t forget to stop the container when you’ve finished playing with the examples on this page.\n\n!docker stop read_table_example\n\nread_table_example"
  },
  {
    "objectID": "python/sqlalchemy/query.html#creating-map",
    "href": "python/sqlalchemy/query.html#creating-map",
    "title": "Query",
    "section": "Creating map",
    "text": "Creating map\nIt’s a preparatory step:\n\nCreate session;\nRecreate the data model corresponding to the database you are working in.\n\n\nfrom sqlalchemy import (\n    create_engine, \n    Column, \n    Integer,\n    String\n)\nfrom sqlalchemy.orm import sessionmaker, declarative_base\n\nURL = \"postgresql://postgres:postgres@localhost:5000/postgres\"\nengine = create_engine(URL)\nLocalSession = sessionmaker(\n    autocommit=False,\n    autoflush=False,\n    bind=engine\n)\nsession = LocalSession()\n\nBase = declarative_base()\nclass TestTable(Base):\n    __tablename__ = \"test_table\"\n    numeric_var = Column(Integer, primary_key = True)\n    text_var = Column(String)"
  },
  {
    "objectID": "python/sqlalchemy/query.html#extract-all-records",
    "href": "python/sqlalchemy/query.html#extract-all-records",
    "title": "Query",
    "section": "Extract all records",
    "text": "Extract all records\nYou need:\n\nUse session.query(&lt;table class&gt;) to extract values from a table related to &lt;table class&gt;;\nsession.query.all() returns a list of instances of &lt;table class&gt; corresponding to each record in the database:\n\nIn the example, the list was printed;\nAnd in the example, all fields were printed.\n\n\n\nquery_res = session.query(TestTable)\n\nprint(\"list of TestTable -\", query_res.all())\n\nprint(\"\\nExtract fields:\")\nfor record in query_res.all():\n    print(record.numeric_var, record.text_var)\n\nlist of TestTable - [&lt;__main__.TestTable object at 0x7f8fd0f6d720&gt;, &lt;__main__.TestTable object at 0x7f8fd0f6da50&gt;, &lt;__main__.TestTable object at 0x7f8fd0f6e530&gt;, &lt;__main__.TestTable object at 0x7f8fd0f6ee30&gt;]\n\nExtract fields:\n1 a\n2 a\n3 b\n4 c"
  },
  {
    "objectID": "python/sqlalchemy/query.html#filters",
    "href": "python/sqlalchemy/query.html#filters",
    "title": "Query",
    "section": "Filters",
    "text": "Filters\nTo add filters to the query, you need to call the fiter method on the result of the query method. As an argument you must pass conditions in syntax such as &lt;table class&gt;.&lt;field name&gt; == &lt;value&gt;.\nSo in the following example all these tips are used to query all records that have a as the value of the text_var.\n\nfor record in (\n    session.\n    query(TestTable).\n    filter(TestTable.text_var==\"a\").\n    all()\n):\n    print(record.numeric_var, record.text_var)\n\n1 a\n2 a"
  },
  {
    "objectID": "python/sqlalchemy/create_table.html",
    "href": "python/sqlalchemy/create_table.html",
    "title": "Create table",
    "section": "",
    "text": "On this page I will show how to move the data model declared in sqlalchemy to a database."
  },
  {
    "objectID": "python/sqlalchemy/create_table.html#create-container",
    "href": "python/sqlalchemy/create_table.html#create-container",
    "title": "Create table",
    "section": "Create container",
    "text": "Create container\nFor example, the postgres container is used. It also shows that in the initial list of tables is emtpy.\n\n%%bash\ndocker run -d --rm\\\n    --name create_table_example\\\n    -e POSTGRES_PASSWORD=postgres\\\n    -p 5000:5432\\\n    postgres:15.4 &&gt; /dev/null\nsleep 5\n\ndocker exec create_table_example \\\n    psql -U postgres -d postgres -c \"\\dt\"\n\nDid not find any relations."
  },
  {
    "objectID": "python/sqlalchemy/create_table.html#python-code",
    "href": "python/sqlalchemy/create_table.html#python-code",
    "title": "Create table",
    "section": "Python code",
    "text": "Python code\nIn the following cell, the data model is defined and moved to the database. Key code is Base.metadata.create_all(...) - duplicate data model in the database.\n\nfrom sqlalchemy import (\n    create_engine, \n    Column, \n    Integer,\n    String\n)\nfrom sqlalchemy.orm import sessionmaker, declarative_base\n\nURL = \"postgresql://postgres:postgres@localhost:5000/postgres\"\nengine = create_engine(URL)\n\nSessionLocal = sessionmaker(\n    autoflush=False,\n    autocommit=False,\n    bind=engine\n)\n\n# defining data model\nBase = declarative_base()\nclass TestTable(Base):\n    __tablename__=\"test_table\"\n    id = Column(Integer, primary_key=True)\n    numeric_var = Column(Integer)\n    text_var = Column(String)\n\n# duplicate datamodel in the database\nBase.metadata.create_all(engine)"
  },
  {
    "objectID": "python/sqlalchemy/create_table.html#check-result",
    "href": "python/sqlalchemy/create_table.html#check-result",
    "title": "Create table",
    "section": "Check result",
    "text": "Check result\nThe following cell from the container with database runs:\n\n\\dt to list created tables;\nSELECT * FROM test_table; - to get head of the created table.\n\nThe results in the database correspond to the declared data model.\n\n%%bash\ndocker exec -i create_table_example \\\n    psql -U postgres -d postgres\n\n\\dt\nSELECT * FROM test_table;\n\n           List of relations\n Schema |    Name    | Type  |  Owner   \n--------+------------+-------+----------\n public | test_table | table | postgres\n(1 row)\n\n id | numeric_var | text_var \n----+-------------+----------\n(0 rows)"
  },
  {
    "objectID": "python/sqlalchemy/create_table.html#stop-the-container",
    "href": "python/sqlalchemy/create_table.html#stop-the-container",
    "title": "Create table",
    "section": "Stop the container",
    "text": "Stop the container\n\n!docker stop create_table_example\n\ncreate_table_example"
  },
  {
    "objectID": "python/sqlalchemy/relations.html",
    "href": "python/sqlalchemy/relations.html",
    "title": "Relations",
    "section": "",
    "text": "In this page I want to describe the mechanism of sqlalchemy that allows to perform sql JOIN operation in a really natural for python way. For each “main” table, you can define related essentials and you’ll be able to access them only from queries on the “main” table."
  },
  {
    "objectID": "python/sqlalchemy/relations.html#prepare",
    "href": "python/sqlalchemy/relations.html#prepare",
    "title": "Relations",
    "section": "Prepare",
    "text": "Prepare\nIn the following cell we have just defined basic things for sqlalchemy.\n\n!docker run -d --rm\\\n    --name relations_example\\\n    -e POSTGRES_PASSWORD=postgres\\\n    -p 5000:5432\\\n    postgres:15.4 &&gt; /dev/null\n!sleep 5\n\nfrom sqlalchemy import (\n    create_engine, \n    Column, \n    Integer,\n    String,\n    ForeignKey\n)\nfrom sqlalchemy.orm import (\n    sessionmaker, \n    declarative_base, \n    relationship\n)\nfrom random import randint\n\nURL = \"postgresql://postgres:postgres@localhost:5000/postgres\"\nengine = create_engine(URL)\n\nSessionLocal = sessionmaker(\n    autoflush=False,\n    autocommit=False,\n    bind=engine\n)\nsession = SessionLocal()\n\n# defining data model\nBase = declarative_base()"
  },
  {
    "objectID": "python/sqlalchemy/relations.html#data-model",
    "href": "python/sqlalchemy/relations.html#data-model",
    "title": "Relations",
    "section": "Data model",
    "text": "Data model\nData model is a key feature of this page. There are:\n\nMainTable, which contains\n\nSome information that is unique to each record - id and text_var;\nSome information that can be mapped to the other describe table;\n\nDescribeTable - auxiliary table that describes certain states of the MainTable.\n\nSo we need a mechanism to tell sqlalcemy that it needs to join some infromation from DescribeTable into MainTable.\nWith DescribeTable it’s very simple, you just define primary key and text_var that simulate some content to be joined.\nMainTable has:\n\nid as primary key;\ntext_var that simulate some content;\ndescribe_id in its declaration contains ForeignKey which indicates which field of their third-party table this field is associated with;\ndescribe is a field where objects of DescribeTable class will be written to so that they can be accessed.\n\n\nclass DescribeTable(Base):\n    __tablename__=\"describe_table\"\n    id = Column(Integer, primary_key=True)\n    text_var=Column(String)\n\nclass MainTable(Base):\n    __tablename__=\"main_table\"\n    id = Column(Integer, primary_key=True)\n    text_var = Column(String)\n    describe_id = Column(\n        Integer, ForeignKey(\"describe_table.id\")\n    )\n    describe = relationship(\"DescribeTable\")\n\n# duplicate datamodel in the database\nBase.metadata.create_all(engine)"
  },
  {
    "objectID": "python/sqlalchemy/relations.html#filling-of-the-table",
    "href": "python/sqlalchemy/relations.html#filling-of-the-table",
    "title": "Relations",
    "section": "Filling of the table",
    "text": "Filling of the table\nBelow content of the tables is created. Few records that defines mapping for the descriptions. And some random content for the MainTable.\n\nfor i in range(2):\n    session.add(DescribeTable(\n        text_var = f\"descrion {i+1}\"\n    ))\n\nfor i in range(10):\n    session.add(MainTable(\n        text_var = \"\".join([chr(randint(97,107)) for i in range(10)]),\n        describe_id = randint(1,2)\n    ))\n\nsession.commit()\n\n\n%%bash\ndocker exec -i relations_example psql -U postgres -d postgres\nSELECT * FROM describe_table;\nSELECT * FROM main_table;\n\n id |  text_var  \n----+------------\n  1 | descrion 1\n  2 | descrion 2\n(2 rows)\n\n id |  text_var  | describe_id \n----+------------+-------------\n  1 | kciihbjiii |           1\n  2 | cgdebdabhh |           1\n  3 | bichegaghb |           2\n  4 | kkaidfdiki |           1\n  5 | icicbkcihj |           1\n  6 | eijbdfjkff |           1\n  7 | dhacdkgahd |           2\n  8 | hhiebijhbc |           2\n  9 | dccdgfkiee |           2\n 10 | fhbgideidg |           2\n(10 rows)"
  },
  {
    "objectID": "python/sqlalchemy/relations.html#query",
    "href": "python/sqlalchemy/relations.html#query",
    "title": "Relations",
    "section": "Query",
    "text": "Query\nAn object that describes the entity of the linked table has been declared in the main table, it is through this object that the content of the linked table can be retrieved.\nSo despite the fact that the query was made in MainTable the corresponding data from DescribeTable are automatically pulled into the results.\n\nfor main_table_instance in session.query(MainTable).all():\n    print(\"============================\")\n    print(\n        \"text_var:\", main_table_instance.text_var, \"\\n\"\n        \"describe_id:\", main_table_instance.describe_id, \"\\n\"\n        \"description content:\", main_table_instance.describe.text_var\n    )\n\n============================\ntext_var: kciihbjiii \ndescribe_id: 1 \ndescription content: descrion 1\n============================\ntext_var: cgdebdabhh \ndescribe_id: 1 \ndescription content: descrion 1\n============================\ntext_var: bichegaghb \ndescribe_id: 2 \ndescription content: descrion 2\n============================\ntext_var: kkaidfdiki \ndescribe_id: 1 \ndescription content: descrion 1\n============================\ntext_var: icicbkcihj \ndescribe_id: 1 \ndescription content: descrion 1\n============================\ntext_var: eijbdfjkff \ndescribe_id: 1 \ndescription content: descrion 1\n============================\ntext_var: dhacdkgahd \ndescribe_id: 2 \ndescription content: descrion 2\n============================\ntext_var: hhiebijhbc \ndescribe_id: 2 \ndescription content: descrion 2\n============================\ntext_var: dccdgfkiee \ndescribe_id: 2 \ndescription content: descrion 2\n============================\ntext_var: fhbgideidg \ndescribe_id: 2 \ndescription content: descrion 2"
  },
  {
    "objectID": "python/sqlalchemy/relations.html#stop-container",
    "href": "python/sqlalchemy/relations.html#stop-container",
    "title": "Relations",
    "section": "Stop container",
    "text": "Stop container\n\n!docker stop relations_example\n\nrelations_example"
  },
  {
    "objectID": "python/sqlalchemy/add_record.html",
    "href": "python/sqlalchemy/add_record.html",
    "title": "Add record",
    "section": "",
    "text": "In this page I’ll show you how to add a record to a database using sqlachemy."
  },
  {
    "objectID": "python/sqlalchemy/add_record.html#create-database",
    "href": "python/sqlalchemy/add_record.html#create-database",
    "title": "Add record",
    "section": "Create database",
    "text": "Create database\nFor this page postgres docker container is used. In the following cell I will create database schema just in sqlalchemy and push it into database.\n\n!docker run -d --rm\\\n    --name add_record_example\\\n    -e POSTGRES_PASSWORD=postgres\\\n    -p 5000:5432\\\n    postgres:15.4 &&gt; /dev/null\n!sleep 5\n\nfrom sqlalchemy import (\n    create_engine, \n    Column, \n    Integer,\n    String\n)\nfrom sqlalchemy.orm import sessionmaker, declarative_base\n\nURL = \"postgresql://postgres:postgres@localhost:5000/postgres\"\nengine = create_engine(URL)\n\nSessionLocal = sessionmaker(\n    autoflush=False,\n    autocommit=False,\n    bind=engine\n)\n\n# defining data model\nBase = declarative_base()\nclass TestTable(Base):\n    __tablename__=\"test_table\"\n    id = Column(Integer, primary_key=True)\n    numeric_var = Column(Integer)\n    text_var = Column(String)\n\n# duplicate datamodel in the database\nBase.metadata.create_all(engine)\n\nMake sure that the created table is initially empty.\n\n!docker exec add_record_example psql -U postgres -d postgres -c \"SELECT * FROM test_table;\"\n\n id | numeric_var | text_var \n----+-------------+----------\n(0 rows)"
  },
  {
    "objectID": "python/sqlalchemy/add_record.html#example",
    "href": "python/sqlalchemy/add_record.html#example",
    "title": "Add record",
    "section": "Example",
    "text": "Example\nTo add a record to the database, you must use the session’s add method. As an argument you must pass an instance of the &lt;table class&gt; that describes the record.\nIn the following example, a few records with random content have been added to the database.\nNote In this example, I don’t set a value for the id field of TestTable because it is the primary key and the table will set it itself.\nNote At the end, session.commit is called - it is needed because of features of the session declaration.\n\nfrom random import randint\nsession = SessionLocal()\nfor i in range(10):\n    session.add(\n        TestTable(\n            numeric_var=randint(0,100),\n            text_var=\"\".join([chr(randint(97, 107)) for i in range(10)])\n        )\n    )\nsession.commit()\n\nLet’s check the contents of the test_table.\n\n!docker exec add_record_example psql -U postgres -d postgres -c \"SELECT * FROM test_table;\"\n\n id | numeric_var |  text_var  \n----+-------------+------------\n  1 |           6 | ejkagfkdgi\n  2 |           3 | ddfaaedjfd\n  3 |           4 | gjchfeahhi\n  4 |          54 | kcfkbfjhjj\n  5 |          56 | gbfejdaecf\n  6 |          14 | cigagdihha\n  7 |          49 | kfcfcjgkej\n  8 |          65 | ajhahgcgff\n  9 |          20 | jgchadeedj\n 10 |          89 | jdkhfdefdc\n(10 rows)"
  },
  {
    "objectID": "python/sqlalchemy/add_record.html#stop-container",
    "href": "python/sqlalchemy/add_record.html#stop-container",
    "title": "Add record",
    "section": "Stop container",
    "text": "Stop container\n\n!docker stop add_record_example\n\nadd_record_example"
  },
  {
    "objectID": "python/jinja2/generate_html.html",
    "href": "python/jinja2/generate_html.html",
    "title": "Generate HTML",
    "section": "",
    "text": "You can easily generate some html using jinja templates. For example, in the following cell I have displayed python dict as html using jinja templates.\n\nfrom jinja2 import Template\nfrom IPython.display import HTML\n\ndata = {'apple': 3, 'banana': 5, 'orange': 2}\n\ntemplate = Template('''\n    &lt;table&gt;\n        &lt;thead&gt;\n            &lt;tr&gt;\n                &lt;th&gt;Fruit&lt;/th&gt;\n                &lt;th&gt;Quantity&lt;/th&gt;\n            &lt;/tr&gt;\n        &lt;/thead&gt;\n        &lt;tbody&gt;\n            {% for key, value in data.items() %}\n                &lt;tr&gt;\n                    &lt;td&gt;{{ key }}&lt;/td&gt;\n                    &lt;td&gt;{{ value }}&lt;/td&gt;\n                &lt;/tr&gt;\n            {% endfor %}\n        &lt;/tbody&gt;\n    &lt;/table&gt;\n''')\n\nhtml = template.render(data=data)\nHTML(html)\n\n\n    \n\n\n\nFruit\nQuantity\n\n\n\n\napple\n3\n\n\nbanana\n5\n\n\norange\n2"
  },
  {
    "objectID": "python/pandas/iloc.html",
    "href": "python/pandas/iloc.html",
    "title": "<DataFrame/Series>.iloc",
    "section": "",
    "text": "iloc is a way of selecting elements from DataFrames/Series using it index position like this [&lt;row number&gt;,&lt;column number&gt;].\nIn the next cell I create the data frame for the experiments.\n\nimport pandas as pd\nimport numpy as np\nfrom IPython.display import HTML\n\nsample_size = 10\n\ntest_df = pd.DataFrame(\n    {\n        \"a\":np.random.choice(range(10), sample_size),\n        \"b\":np.random.choice(range(10), sample_size)\n    },\n    index = [chr(i) for i in range(ord(\"a\"), ord(\"a\")+sample_size)]\n)\ntest_df\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\na\n5\n8\n\n\nb\n1\n4\n\n\nc\n7\n3\n\n\nd\n1\n3\n\n\ne\n4\n1\n\n\nf\n1\n5\n\n\ng\n9\n1\n\n\nh\n8\n0\n\n\ni\n9\n4\n\n\nj\n2\n3\n\n\n\n\n\n\n\n\nEditable\nYou can edit element that you access throw .iloc.\nSo in following example I edited one element by accessing it through iloc.\n\nedit_df_test = test_df.copy()\ndisplay(HTML(\"&lt;b&gt;Initial df&lt;/b&gt;\"))\ndisplay(edit_df_test)\n\nedit_df_test.iloc[1,1] = \"hello\"\ndisplay(HTML(\"&lt;b&gt;Edited df&lt;/b&gt;\"))\ndisplay(edit_df_test)\n\nInitial df\n\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\na\n5\n8\n\n\nb\n1\n4\n\n\nc\n7\n3\n\n\nd\n1\n3\n\n\ne\n4\n1\n\n\nf\n1\n5\n\n\ng\n9\n1\n\n\nh\n8\n0\n\n\ni\n9\n4\n\n\nj\n2\n3\n\n\n\n\n\n\n\nEdited df\n\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\na\n5\n8\n\n\nb\n1\nhello\n\n\nc\n7\n3\n\n\nd\n1\n3\n\n\ne\n4\n1\n\n\nf\n1\n5\n\n\ng\n9\n1\n\n\nh\n8\n0\n\n\ni\n9\n4\n\n\nj\n2\n3\n\n\n\n\n\n\n\nNote You can only edit an item via iloc if you access it directly. If you get a table column via df.iloc[&lt;row&gt;] and then apply the [&lt;column&gt;] operator to it, it won’t work.\nSo in the following example I try to edit pandas.DataFrame using df.iloc[&lt;row&gt;][&lt;column&gt;] to edit the dataframe, but find out that the dataframe has not been edited.\n\nedit_df_test = test_df.copy()\ndisplay(HTML(\"&lt;b&gt;Initial df&lt;/b&gt;\"))\ndisplay(edit_df_test)\n\nedit_df_test.iloc[1][1] = \"hello\"\ndisplay(HTML(\"&lt;b&gt;Edited df&lt;/b&gt;\"))\ndisplay(edit_df_test)\n\nInitial df\n\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\na\n5\n8\n\n\nb\n1\n4\n\n\nc\n7\n3\n\n\nd\n1\n3\n\n\ne\n4\n1\n\n\nf\n1\n5\n\n\ng\n9\n1\n\n\nh\n8\n0\n\n\ni\n9\n4\n\n\nj\n2\n3\n\n\n\n\n\n\n\nEdited df\n\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\na\n5\n8\n\n\nb\n1\n4\n\n\nc\n7\n3\n\n\nd\n1\n3\n\n\ne\n4\n1\n\n\nf\n1\n5\n\n\ng\n9\n1\n\n\nh\n8\n0\n\n\ni\n9\n4\n\n\nj\n2\n3"
  },
  {
    "objectID": "python/pandas/data_visualisation.html",
    "href": "python/pandas/data_visualisation.html",
    "title": "Data visualisation",
    "section": "",
    "text": "Pandas has some integration with matplotlib. It’s difficult to create advanced plots from pandas, but for purposes of instant visualisation it can be helpful.\n\nplot\npandas.DataFrame has a plot function that is only for line plots using variables from the dataframe. You can specify:\n\nx variable name for x-axis, x-axis title will be the same;\ny variable name for y-axis, y-axis title will be the same;\nfigsize to adjust the size of the diagram;\nMany parameters used in the classic matplotlib.pyplot.plot function.\n\n\nimport numpy as np\nimport pandas as pd\n\n\nx = np.arange(0, 10, 0.1)\ndf = pd.DataFrame({\n    \"x\" : x, 'y':x*3 + np.random.normal(0, 1, len(x)),\n})\n\nans = df.plot(\n    x=\"x\", y=\"y\",\n    figsize = (14,5),\n    grid = True\n)\n\n\n\n\n\n\nhist\nYou can create a histogram based on the values of some pandas.Series from this object only.\nThe arguments are really close to matplotlib.hist except that:\n\nfigsize you can set figure size just from that function.\n\nSo in the following example, I use all these features to show the skewness of a normally distributed variable.\n\nimport numpy as np\nimport pandas as pd\n\nvis_ser = pd.Series(np.random.normal(0, 1, 1000), name = \"some variable\")\nans = vis_ser.hist(bins = 20, figsize = (3, 3))"
  },
  {
    "objectID": "python/pandas/loc.html",
    "href": "python/pandas/loc.html",
    "title": "<DataFrame/Series>.loc",
    "section": "",
    "text": "loc is a way of selecting elements from DataFrames/Series using index/column names.\nIn the next cell I create the data frame for the experiments.\nimport pandas as pd\nimport numpy as np\nfrom IPython.display import HTML\n\nsample_size = 10\n\ntest_df = pd.DataFrame(\n    {\n        \"a\":np.random.choice(range(10), sample_size),\n        \"b\":np.random.choice(range(10), sample_size)\n    },\n    index = [chr(i) for i in range(ord(\"a\"), ord(\"a\")+sample_size)]\n)\ntest_df\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\na\n1\n3\n\n\nb\n0\n6\n\n\nc\n7\n7\n\n\nd\n1\n6\n\n\ne\n3\n9\n\n\nf\n4\n8\n\n\ng\n4\n6\n\n\nh\n1\n0\n\n\ni\n9\n1\n\n\nj\n8\n5"
  },
  {
    "objectID": "python/pandas/loc.html#basic",
    "href": "python/pandas/loc.html#basic",
    "title": "<DataFrame/Series>.loc",
    "section": "Basic",
    "text": "Basic\nYou can apply slices by index values.\nNote Although basic python slices use don’t include the last element, pandas slices ignore this rule and will include it.\nSo the following example just shows it - I’ve got a slice from e to h including h:\n\ntest_df[\"e\":\"h\"]\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\ne\n6\n6\n\n\nf\n1\n8\n\n\ng\n4\n0\n\n\nh\n6\n7"
  },
  {
    "objectID": "python/pandas/loc.html#only-df-order",
    "href": "python/pandas/loc.html#only-df-order",
    "title": "<DataFrame/Series>.loc",
    "section": "Only df order",
    "text": "Only df order\nYou should only mention elements in the order in which they appear in the dataframe - there’s no ascending rule for slicing.\nIn the following example I’m trying to apply the same slicing as before to inverted dataframe and got the empty slice because in dataframe’s order “h” element is higher than “e”.\n\ninv_df = test_df.iloc[::-1]\ndisplay(HTML(\"&lt;b&gt;Indersed dataframe&lt;/b&gt;\"))\ndisplay(inv_df)\ndisplay(HTML(\"&lt;b&gt;Slice&lt;/b&gt;\"))\ndisplay(inv_df[\"e\":\"h\"])\n\nIndersed dataframe\n\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\nj\n9\n7\n\n\ni\n5\n3\n\n\nh\n6\n7\n\n\ng\n4\n0\n\n\nf\n1\n8\n\n\ne\n6\n6\n\n\nd\n0\n9\n\n\nc\n8\n8\n\n\nb\n9\n8\n\n\na\n0\n9\n\n\n\n\n\n\n\nSlice\n\n\n\n\n\n\n\n\n\na\nb"
  },
  {
    "objectID": "python/pandas/datetime.html",
    "href": "python/pandas/datetime.html",
    "title": "datetime",
    "section": "",
    "text": "In this section I will pay special attention to working with dates and times in Pandas.\nimport numpy as np\nimport pandas as pd\n\ntest_series = pd.Series(\n    np.random.choice(\n        pd.date_range(\"2021-01-01\", \"2022-12-31\"), \n        size=40\n))"
  },
  {
    "objectID": "python/pandas/datetime.html#freq",
    "href": "python/pandas/datetime.html#freq",
    "title": "datetime",
    "section": "freq",
    "text": "freq\nThis parameter allows you to set the step at which observations are added to the array. So in the following dataframe I have shown some options with arguments that should be passed as values of this parameter.\n\npd.DataFrame({\n    \"Days 'd'\" : pd.date_range(\"2021-01-01\", \"2021-01-10\", freq=\"d\")\n    \"Weeks 'W'\" : pd.date_range(\"2021-01-01\", \"2021-3-7\", freq=\"W\"),\n})\n\n\n\n\n\n\n\n\nWeeks 'W'\nDays 'd'\n\n\n\n\n0\n2021-01-03\n2021-01-01\n\n\n1\n2021-01-10\n2021-01-02\n\n\n2\n2021-01-17\n2021-01-03\n\n\n3\n2021-01-24\n2021-01-04\n\n\n4\n2021-01-31\n2021-01-05\n\n\n5\n2021-02-07\n2021-01-06\n\n\n6\n2021-02-14\n2021-01-07\n\n\n7\n2021-02-21\n2021-01-08\n\n\n8\n2021-02-28\n2021-01-09\n\n\n9\n2021-03-07\n2021-01-10"
  },
  {
    "objectID": "python/pandas/datetime.html#dt.day_of_week",
    "href": "python/pandas/datetime.html#dt.day_of_week",
    "title": "datetime",
    "section": "dt.day_of_week",
    "text": "dt.day_of_week\nYou can get days of the week.\nBy default it returns numbers representing the days of the week: 0-Monday,…,6-Sunday.\nSo in the following example I show the case for the week this page was created.\n\nweek_range = pd.date_range(\"2023-08-28\", \"2023-09-03\").to_series()\n\npd.DataFrame({\n    \"Original date\" : week_range,\n    \"Day of the week\" : week_range.dt.day_of_week\n})\n\n\n\n\n\n\n\n\nOriginal date\nDay of the week\n\n\n\n\n2023-08-28\n2023-08-28\n0\n\n\n2023-08-29\n2023-08-29\n1\n\n\n2023-08-30\n2023-08-30\n2\n\n\n2023-08-31\n2023-08-31\n3\n\n\n2023-09-01\n2023-09-01\n4\n\n\n2023-09-02\n2023-09-02\n5\n\n\n2023-09-03\n2023-09-03\n6"
  },
  {
    "objectID": "python/pandas/datetime.html#week-of-year",
    "href": "python/pandas/datetime.html#week-of-year",
    "title": "datetime",
    "section": "week of year",
    "text": "week of year\n\ndt.isocalendar().week\nYou can use the above function to find the week number for any date.\n\ntest_weeks = pd.date_range(\"2021-01-01\", \"2021-04-1\", freq=\"W\").to_series()\ntest_weeks.dt.isocalendar().week.rename(\"week number\").to_frame()\n\n\n\n\n\n\n\n\nweek number\n\n\n\n\n2021-01-03\n53\n\n\n2021-01-10\n1\n\n\n2021-01-17\n2\n\n\n2021-01-24\n3\n\n\n2021-01-31\n4\n\n\n2021-02-07\n5\n\n\n2021-02-14\n6\n\n\n2021-02-21\n7\n\n\n2021-02-28\n8\n\n\n2021-03-07\n9\n\n\n2021-03-14\n10\n\n\n2021-03-21\n11\n\n\n2021-03-28\n12\n\n\n\n\n\n\n\nNote The first days of a certain year may refer to the 54th week of the previous year. Documentation about this feature not really reach. The documentation about this function is not very extensive and does not mention in detail the exact algorithm for calculating the value in question. But in the next cell, I went through the dates of the border months of different summers. It turns out that the week refers to the year in which lies more number of its days and is numbered accordingly.\n\nfrom IPython.display import HTML\nfor y in range(2012, 2017):\n\n    next_y = y+1\n    \n    days = pd.date_range(\n        datetime(y, 12, 28), \n        datetime(next_y, 1, 3), freq=\"d\"\n    ).to_series()\n\n    display(HTML(f\"&lt;p style='font-size:150%'&gt;======{y}-{next_y}======&lt;/p&gt;\"))\n    display(pd.DataFrame({\n        \"Day\":days,\n        \"Day of week\":days.dt.day_of_week,\n        \"Week of year\":days.dt.isocalendar().week\n    }))\n\n======2012-2013======\n\n\n\n\n\n\n\n\n\nDay\nDay of week\nWeek of year\n\n\n\n\n2012-12-28\n2012-12-28\n4\n52\n\n\n2012-12-29\n2012-12-29\n5\n52\n\n\n2012-12-30\n2012-12-30\n6\n52\n\n\n2012-12-31\n2012-12-31\n0\n1\n\n\n2013-01-01\n2013-01-01\n1\n1\n\n\n2013-01-02\n2013-01-02\n2\n1\n\n\n2013-01-03\n2013-01-03\n3\n1\n\n\n\n\n\n\n\n======2013-2014======\n\n\n\n\n\n\n\n\n\nDay\nDay of week\nWeek of year\n\n\n\n\n2013-12-28\n2013-12-28\n5\n52\n\n\n2013-12-29\n2013-12-29\n6\n52\n\n\n2013-12-30\n2013-12-30\n0\n1\n\n\n2013-12-31\n2013-12-31\n1\n1\n\n\n2014-01-01\n2014-01-01\n2\n1\n\n\n2014-01-02\n2014-01-02\n3\n1\n\n\n2014-01-03\n2014-01-03\n4\n1\n\n\n\n\n\n\n\n======2014-2015======\n\n\n\n\n\n\n\n\n\nDay\nDay of week\nWeek of year\n\n\n\n\n2014-12-28\n2014-12-28\n6\n52\n\n\n2014-12-29\n2014-12-29\n0\n1\n\n\n2014-12-30\n2014-12-30\n1\n1\n\n\n2014-12-31\n2014-12-31\n2\n1\n\n\n2015-01-01\n2015-01-01\n3\n1\n\n\n2015-01-02\n2015-01-02\n4\n1\n\n\n2015-01-03\n2015-01-03\n5\n1\n\n\n\n\n\n\n\n======2015-2016======\n\n\n\n\n\n\n\n\n\nDay\nDay of week\nWeek of year\n\n\n\n\n2015-12-28\n2015-12-28\n0\n53\n\n\n2015-12-29\n2015-12-29\n1\n53\n\n\n2015-12-30\n2015-12-30\n2\n53\n\n\n2015-12-31\n2015-12-31\n3\n53\n\n\n2016-01-01\n2016-01-01\n4\n53\n\n\n2016-01-02\n2016-01-02\n5\n53\n\n\n2016-01-03\n2016-01-03\n6\n53\n\n\n\n\n\n\n\n======2016-2017======\n\n\n\n\n\n\n\n\n\nDay\nDay of week\nWeek of year\n\n\n\n\n2016-12-28\n2016-12-28\n2\n52\n\n\n2016-12-29\n2016-12-29\n3\n52\n\n\n2016-12-30\n2016-12-30\n4\n52\n\n\n2016-12-31\n2016-12-31\n5\n52\n\n\n2017-01-01\n2017-01-01\n6\n52\n\n\n2017-01-02\n2017-01-02\n0\n1\n\n\n2017-01-03\n2017-01-03\n1\n1\n\n\n\n\n\n\n\n\n\nweekofyear\nPandas datetime unit timestamp has a weekofyear parameter that you can combine with the apply method as in the next example.\n\ntest_weeks = pd.date_range(\"2021-01-01\", \"2021-04-1\", freq=\"W\").to_series()\ntest_weeks.apply(lambda val: val.weekofyear).rename(\"week number\").to_frame()\n\n\n\n\n\n\n\n\nweek number\n\n\n\n\n2021-01-03\n53\n\n\n2021-01-10\n1\n\n\n2021-01-17\n2\n\n\n2021-01-24\n3\n\n\n2021-01-31\n4\n\n\n2021-02-07\n5\n\n\n2021-02-14\n6\n\n\n2021-02-21\n7\n\n\n2021-02-28\n8\n\n\n2021-03-07\n9\n\n\n2021-03-14\n10\n\n\n2021-03-21\n11\n\n\n2021-03-28\n12"
  },
  {
    "objectID": "python/pandas/groupby.html",
    "href": "python/pandas/groupby.html",
    "title": "Groupby",
    "section": "",
    "text": "pd.DataFrame.groupby is a very useful tool, but sometimes working with it can be a bit confusing. So in this page I want to pay more attention to some functions and cases.\nThe most useful page for learning is GroupBy object in pandas documentation."
  },
  {
    "objectID": "python/pandas/groupby.html#basic-frame",
    "href": "python/pandas/groupby.html#basic-frame",
    "title": "Groupby",
    "section": "Basic frame",
    "text": "Basic frame\nThere are many examples of the same type in this section, so unless specified by default I will use the dataset declared below.\n\nimport pandas as pd\nfrom IPython.display import HTML\n\nbasic_frame = pd.DataFrame({'A': ['a', 'a', 'b', 'b', 'c', 'c'],\n                   'B': [2, 1, 3, 4, 6, 5],\n                   'C': [10, 20, 30, 40, 50, 60]})\n\nbasic_frame\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\na\n2\n10\n\n\n1\na\n1\n20\n\n\n2\nb\n3\n30\n\n\n3\nb\n4\n40\n\n\n4\nc\n6\n50\n\n\n5\nc\n5\n60"
  },
  {
    "objectID": "python/pandas/groupby.html#pd.groupby",
    "href": "python/pandas/groupby.html#pd.groupby",
    "title": "Groupby",
    "section": "pd.groupby",
    "text": "pd.groupby\nHere I describe basic usage of pandas.groupby function. For a formal description, see the official pandas documntation for this function.\n\nas_idnex\nSetting this value to True allows you to say that the aggregation variable should not be used as an index.\nSo in the following example I show the difference.\nNote In the first case the return is padnas.Series just because I called it that way, but in the second case it’s not a dataframe that pandas has to use as a result.\n\ndisplay(HTML(\"&lt;b&gt;as_index=True&lt;/b&gt;\"))\ndisplay(basic_frame.groupby(\"A\", as_index=True)[\"C\"].sum())\ndisplay(HTML(\"&lt;b&gt;as_index=False&lt;/b&gt;\"))\ndisplay(basic_frame.groupby(\"A\", as_index=False)[\"C\"].sum())\n\nas_index=True\n\n\nA\na     30\nb     70\nc    110\nName: C, dtype: int64\n\n\nas_index=False\n\n\n\n\n\n\n\n\n\nA\nC\n\n\n\n\n0\na\n30\n\n\n1\nb\n70\n\n\n2\nc\n110\n\n\n\n\n\n\n\n\n\nobserved\nIn the categorical datatype there is a possible case where a category exists but never appears in series'. This parameter describes whether unobserved catetories will be used ingroupby` results (False) or only observed categories will be used (True).\nSo in the following example I changed a datatype for the A column to category, added a new category l but no new observation corresponding to this category, and finally tried all options for the observed parameter. In the first case we don’t have l in the groupby result index, in the second we do.\n\nexample_frame = basic_frame.copy()\nexample_frame[\"A\"] = example_frame[\"A\"].\\\n                        astype(\"category\").cat.\\\n                        add_categories(\"l\")\n\ndisplay(\n    HTML(\"&lt;b style=\\\"font-size:120%\\\"&gt;=====observed=True=====&lt;/b&gt;\")\n)\ndisplay(\n    example_frame.groupby(\"A\", observed=True).sum()\n)\n\ndisplay(\n    HTML(\"&lt;b style=\\\"font-size:120%\\\"&gt;=====observed=False=====&lt;/b&gt;\")\n)\ndisplay(\n    example_frame.groupby(\"A\", observed=False).sum()\n)\n\n=====observed=True=====\n\n\n\n\n\n\n\n\n\nB\nC\n\n\nA\n\n\n\n\n\n\na\n3\n30\n\n\nb\n7\n70\n\n\nc\n11\n110\n\n\n\n\n\n\n\n=====observed=False=====\n\n\n\n\n\n\n\n\n\nB\nC\n\n\nA\n\n\n\n\n\n\na\n3\n30\n\n\nb\n7\n70\n\n\nc\n11\n110\n\n\nl\n0\n0"
  },
  {
    "objectID": "python/pandas/groupby.html#iterating",
    "href": "python/pandas/groupby.html#iterating",
    "title": "Groupby",
    "section": "Iterating",
    "text": "Iterating\nYou can iterate trow pandas.DataFrame.groupby retults. In each eteration you will get tuple of two values:\n\nValue of the grouping variable for this iteration;\nSub-sampling from the original data set corresponding to the considered value of the grouping variable.\n\nSo in the following example I show the result of the first iteration under pandas.DataFrameGroupby result and then show a case of using it in the cycle.\n\ndisplay(HTML(\"&lt;b&gt;Some iteration returns&lt;/b&gt;\"))\ndisplay(next(basic_frame.groupby(\"A\").__iter__()))\n\ndisplay(HTML(\"&lt;b&gt;Whole cycle&lt;/b&gt;\"))\nfor a_val, subframe in basic_frame.groupby(\"A\"):\n    print(\"====\" + a_val + \"=====\")\n    display(subframe)\n\nSome iteration returns\n\n\n('a',\n    A  B   C\n 0  a  2  10\n 1  a  1  20)\n\n\nWhole cycle\n\n\n====a=====\n====b=====\n====c=====\n\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\na\n2\n10\n\n\n1\na\n1\n20\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n2\nb\n3\n30\n\n\n3\nb\n4\n40\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n4\nc\n6\n50\n\n\n5\nc\n5\n60"
  },
  {
    "objectID": "python/pandas/groupby.html#external-group-array",
    "href": "python/pandas/groupby.html#external-group-array",
    "title": "Groupby",
    "section": "External group array",
    "text": "External group array\nYou can use an arbitrary array (that is not a column of the dataframe being grouped) for grouping.\nSo in the following example I use list shat markers to split the dataframe into two groups x and y.\n\ngroup_list = [\"x\", \"x\", \"x\", \"y\", \"y\", \"y\"]\ndisplay(HTML(\"&lt;b&gt;Input dataframe&lt;/b&gt;\"))\ndisplay(basic_frame)\ndisplay(HTML(\"&lt;b&gt;Group variable&lt;/b&gt;\"))\ndisplay(group_list)\nbasic_frame.groupby(group_list).sum()\n\nInput dataframe\n\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\na\n2\n10\n\n\n1\na\n1\n20\n\n\n2\nb\n3\n30\n\n\n3\nb\n4\n40\n\n\n4\nc\n6\n50\n\n\n5\nc\n5\n60\n\n\n\n\n\n\n\nGroup variable\n\n\n['x', 'x', 'x', 'y', 'y', 'y']\n\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\nx\naab\n6\n60\n\n\ny\nbcc\n15\n150\n\n\n\n\n\n\n\nYou can even mix two external variables.\n\ngroup_list1 = [\"x\", \"x\", \"x\", \"y\", \"y\", \"y\"]\ngroup_list2 = [1,1,2,2,2,1]\ndisplay(HTML(\"&lt;b&gt;Group variables&lt;/b&gt;\"))\ndisplay(group_list1, group_list2)\nbasic_frame.groupby([group_list1, group_list2]).sum()\n\nGroup variables\n\n\n['x', 'x', 'x', 'y', 'y', 'y']\n\n\n[1, 1, 2, 2, 2, 1]\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\nx\n1\naa\n3\n30\n\n\n2\nb\n3\n30\n\n\ny\n1\nc\n5\n60\n\n\n2\nbc\n10\n90\n\n\n\n\n\n\n\nOr mix external and internal variables in a groupby.\n\ngroup_list = [\"x\", \"x\", \"x\", \"y\", \"y\", \"y\"]\ndisplay(HTML(\"&lt;b&gt;Group variable&lt;/b&gt;\"))\ndisplay(group_list)\nbasic_frame.groupby([group_list1, \"A\"]).sum()\n\nGroup variable\n\n\n['x', 'x', 'x', 'y', 'y', 'y']\n\n\n\n\n\n\n\n\n\n\nB\nC\n\n\n\nA\n\n\n\n\n\n\nx\na\n3\n30\n\n\nb\n3\n30\n\n\ny\nb\n4\n40\n\n\nc\n11\n110"
  },
  {
    "objectID": "python/pandas/groupby.html#apply---combine-results",
    "href": "python/pandas/groupby.html#apply---combine-results",
    "title": "Groupby",
    "section": "apply - combine results",
    "text": "apply - combine results\nPandas documentation about apply function.\n\nBasic idea\nThe peculiarity of this method is that it uses pandas.DataFrame as the input for the aggregation function.\nThe following example shows this: `example_funtion’ just prints the input and it always prints a DataFrame for each “A” variable option.\n\ndef example_funtion(subdf):\n    print(\"=========\")\n    print(subdf)\n    return 5\n\nres = basic_frame.groupby(\"A\")[\n    [\"A\", \"B\", \"C\"]\n].apply(example_funtion)\n\n=========\n   A  B   C\n0  a  2  10\n1  a  1  20\n=========\n   A  B   C\n2  b  3  30\n3  b  4  40\n=========\n   A  B   C\n4  c  6  50\n5  c  5  60\n\n\n\n\nUse case\nSo it’s perfect for cases where you need to get, for each variant of variable A, some value of variable C conditioned on the value of variable B.\nIn particular, the following example shows how to obtain for each option of “A” the “C” value corresponding to the minimum “B” value.\n\nFor \"A\" == \"a\" I got \"C\" == 20, because it corresponds to \"B\"== 1, which is the minimum for every \"A\" == \"a\";\nFor \"A\" == \"b\" I got \"C\" == 30, because it corresponds to \"B\"== 3, which is the minimum for every \"A\" == \"b\";\nFor \"A\" == \"c\" I got \"C\" == 60, because it corresponds to \"B\"== 5, which is the minimum for every \"A\" == \"c\".\n\n\nresult = basic_frame.groupby(\"A\")[[\"B\", \"C\"]].apply(\n    lambda subset: subset.loc[subset[\"B\"].idxmin(), \"C\"]\n)\ndisplay(HTML(\"&lt;b&gt;Result&lt;/b&gt;\"))\nresult.rename(\"C\").to_frame()\n\nResult\n\n\n\n\n\n\n\n\n\nC\n\n\nA\n\n\n\n\n\na\n20\n\n\nb\n30\n\n\nc\n60\n\n\n\n\n\n\n\n\n\nvs agg\nOther common function may seem useless because this function can do everything they can. However, according to the pandas documentation, they may work a little faster. I have not been able to test this yet."
  },
  {
    "objectID": "python/pandas/groupby.html#transform",
    "href": "python/pandas/groupby.html#transform",
    "title": "Groupby",
    "section": "transform",
    "text": "transform\nThis is a function that allows you to get aggregations as pandas.Series/pandas.DataFrame indexed like the original pandas.DataFrame.\nFor example, in the following cell, throw the transform function, for each record in the original pandas.DataFrame I got the mean value of B for each group in A.\n\ntemp_frame = basic_frame.copy()\n\ntemp_frame[\"mean B by A\"] = (\n    temp_frame.\n    groupby(\"A\")[\"B\"].\n    transform(\"mean\")\n)\ndisplay(temp_frame)\n\n\n\n\n\n\n\n\nA\nB\nC\nmean B by A\n\n\n\n\n0\na\n2\n10\n1.5\n\n\n1\na\n1\n20\n1.5\n\n\n2\nb\n3\n30\n3.5\n\n\n3\nb\n4\n40\n3.5\n\n\n4\nc\n6\n50\n5.5\n\n\n5\nc\n5\n60\n5.5\n\n\n\n\n\n\n\nHere I have a pandas.DataFrame that for each record from the original pandas.DataFrame matches the mean value of the B and C columns to the A column in a command.\n\ndisplay(\n    temp_frame.\n    groupby(\"A\")[[\"B\", \"C\"]].\n    transform(\"mean\")\n)\n\n\n\n\n\n\n\n\nB\nC\n\n\n\n\n0\n1.5\n15.0\n\n\n1\n1.5\n15.0\n\n\n2\n3.5\n35.0\n\n\n3\n3.5\n35.0\n\n\n4\n5.5\n55.0\n\n\n5\n5.5\n55.0"
  },
  {
    "objectID": "python/pandas/groupby.html#sum",
    "href": "python/pandas/groupby.html#sum",
    "title": "Groupby",
    "section": "sum",
    "text": "sum\nThe basic function that allows you to get sums by groups.\n\nFor str dtype\nIf you apply the sum function to a variable containing a str datatype, it will concatenate observations by groups.\nSo in the following example, this just happened with the group text column of the test dataframe.\n\ntest_df = pd.DataFrame({\n    \"group class\" : [\"a\", \"a\", \"b\", \"b\"],\n    \"group numeric\" : [3,4,5,1],\n    \"group text\" : [\"hello\", \"test\", \"line3\", \"superline\"]\n})\ndisplay(HTML(\"&lt;b&gt;Initial frame&lt;/b&gt;\"))\ndisplay(test_df)\ndisplay(HTML(\"&lt;b&gt;Aggregation result&lt;/b&gt;\"))\ntest_df.groupby(\"group class\").sum()\n\nInitial frame\n\n\n\n\n\n\n\n\n\ngroup class\ngroup numeric\ngroup text\n\n\n\n\n0\na\n3\nhello\n\n\n1\na\n4\ntest\n\n\n2\nb\n5\nline3\n\n\n3\nb\n1\nsuperline\n\n\n\n\n\n\n\nAggregation result\n\n\n\n\n\n\n\n\n\ngroup numeric\ngroup text\n\n\ngroup class\n\n\n\n\n\n\na\n7\nhellotest\n\n\nb\n6\nline3superline"
  },
  {
    "objectID": "python/pandas/read_sql.html",
    "href": "python/pandas/read_sql.html",
    "title": "pandas.read_sql",
    "section": "",
    "text": "In this section I will describe the pandas.read_sql function as a basic way to load data from databases into pandas.\nThe next cell starts a database in a docker container, which will be used as an example.\nSQL script for initialisation postgres datase used in this example.\nimport pandas as pd\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.engine import URL \n\n!docker run --rm -d\\\n    -v ./postgres_inter_files/simple_example_db:/docker-entrypoint-initdb.d\\\n    -e POSTGRES_PASSWORD=docker_app\\\n    --name read_postgres_to_pandas_to_pandas\\\n    -p 5431:5432\\\n    postgres:15.4 &&gt; /dev/null\nNote Don’t forget to stop the cantainer when you have finished playing with the examples.\n!docker stop read_postgres_to_pandas &&gt; /dev/null"
  },
  {
    "objectID": "python/pandas/read_sql.html#sqlalchemy",
    "href": "python/pandas/read_sql.html#sqlalchemy",
    "title": "pandas.read_sql",
    "section": "SQLAlchemy",
    "text": "SQLAlchemy\nThere is a very important library for organising the interaction between the database and the pandas - SQLAlchemy.\n\nCreate engine in SQlAlchemy."
  },
  {
    "objectID": "python/pandas/read_sql.html#basic",
    "href": "python/pandas/read_sql.html#basic",
    "title": "pandas.read_sql",
    "section": "Basic",
    "text": "Basic\nYou can use pandas.read_sql and pass the created SQLAlchemy engine as con argument.\nSo in the following example, I start the postgres database in the docker container and then read information from it directly to pandas.\n\nurl_object = URL.create(\n    \"postgresql+psycopg2\",\n    username=\"postgres\",\n    password=\"docker_app\",\n    host=\"localhost\",\n    port=5431,\n    database=\"postgres\",\n)\nengine = create_engine(url_object)\n\ndf = pd.read_sql('SELECT * FROM main_table', con=engine, index_col = \"id\")\ndisplay(df)\n\n\n\n\n\n\n\n\ntext\n\n\nid\n\n\n\n\n\n0\nText1\n\n\n1\ntExT2\n\n\n3\nTEXT3"
  },
  {
    "objectID": "python/pandas/read_sql.html#connection-as-line",
    "href": "python/pandas/read_sql.html#connection-as-line",
    "title": "pandas.read_sql",
    "section": "Connection as line",
    "text": "Connection as line\nIt is possible not to create connection as strictly as shown in the previous example - you can use a string that contains all the necessary information in itself. And pass it as the connection argument. The pattern for this line will looks like dialect+driver://username:password@host:port/database.\nSo in the following example I just use this feature:\n\ndf = pd.read_sql(\n    'SELECT * FROM main_table', \n    con=\"postgresql+psycopg2://postgres:docker_app@localhost:5431/postgres\", \n    index_col = \"id\"\n)\ndisplay(df)\n\n\n\n\n\n\n\n\ntext\n\n\nid\n\n\n\n\n\n0\nText1\n\n\n1\ntExT2\n\n\n3\nTEXT3\n\n\n\n\n\n\n\nIn the case of postgres sql, you don’t even need to mention psycopg2 - it will be used by default. So the next cell is identical to the previous one, except that `driver’ isn’t mentioned.\n\ndf = pd.read_sql(\n    'SELECT * FROM main_table', \n    con=\"postgresql://postgres:docker_app@localhost:5431/postgres\", \n    index_col = \"id\"\n)\ndisplay(df)\n\n\n\n\n\n\n\n\ntext\n\n\nid\n\n\n\n\n\n0\nText1\n\n\n1\ntExT2\n\n\n3\nTEXT3\n\n\n\n\n\n\n\n\nNo SQLAlchemy\nActually, it’s possible to use the Postgres database without using SQLAlchemy - just pass the connection object from psycopg2 to the con parameter of the read_sql function.\nIn the following example, that’s exactly what I did - but I got a warning that the pandas connection was only tested with sqlAlchemy, so it’s better to use it.\n\nimport psycopg2\n\nconn = psycopg2.connect(\n    port = \"5431\", # same as when creating a postgres container\n    dbname = \"postgres\",\n    user = \"postgres\",\n    password = \"docker_app\",\n    host= \"localhost\"\n)\n\ndf = pd.read_sql('SELECT * FROM main_table', con=conn)\ndisplay(df)\nconn.close()\n\n/tmp/ipykernel_16808/3075988519.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  df = pd.read_sql('SELECT * FROM main_table', con=conn)\n\n\n\n\n\n\n\n\n\nid\ntext\n\n\n\n\n0\n0\nText1\n\n\n1\n1\ntExT2\n\n\n2\n3\nTEXT3"
  },
  {
    "objectID": "python/pandas/read_sql.html#list-tables",
    "href": "python/pandas/read_sql.html#list-tables",
    "title": "pandas.read_sql",
    "section": "List tables",
    "text": "List tables\nYou cannot use \\dt to list available tables for the current database. Looks like it’s a peculiarity of sqlachemy - so you have to use pg_catalog.pg_tables.\nSo in the following cells I try both options, as you can see dt causes errors related to syntax.\n\ntry:\n    pd.read_sql(\"\\dt;\", con=engine)\nexcept Exception as e:\n    print(e)\n\n(psycopg2.errors.SyntaxError) syntax error at or near \"\\\"\nLINE 1: \\dt;\n        ^\n\n[SQL: \\dt;]\n(Background on this error at: https://sqlalche.me/e/14/f405)\n\n\n\npd.read_sql(\n    \"SELECT * FROM pg_catalog.pg_tables WHERE schemaname=\\'public\\'\",\n    con = engine\n)\n\n\n\n\n\n\n\n\nschemaname\ntablename\ntableowner\ntablespace\nhasindexes\nhasrules\nhastriggers\nrowsecurity\n\n\n\n\n0\npublic\nmain_table\npostgres\nNone\nFalse\nFalse\nFalse\nFalse"
  },
  {
    "objectID": "python/airflow/run_airflow.html",
    "href": "python/airflow/run_airflow.html",
    "title": "Run airflow",
    "section": "",
    "text": "To play with airflow we run airflow. In this section I will describe how to get airflow up in a docker container, and by default I will use this method in any airflow related questions onthis site."
  },
  {
    "objectID": "python/airflow/run_airflow.html#image",
    "href": "python/airflow/run_airflow.html#image",
    "title": "Run airflow",
    "section": "Image",
    "text": "Image\nThe following docker file should be used to build the image.\nFeatures an image built from this dockerfile:\n\nAdmin username is admin and password is admin;\nCofigure disables automatic loading of example dags, so it will be more convenient to concentrate on writing your own dags.\n\n\n%%writefile run_airflow/dockerfile\nFROM python:3.10\n\n# Script for airflow installation\n# described below\nCOPY install_airflow.sh install_airflow.sh\nRUN bash install_airflow.sh\n\n# we need to create user in other case\n# airflow will create it by itself with\n# random password\n# for some reason it asks to run airflow db init\n# before creating a user\nRUN airflow db init; \\\n    airflow users create \\\n        --username admin \\\n        --password admin \\\n        --firstname Fedor \\\n        --lastname Kobak \\\n        --role Admin \\\n        --email spiderman@superhero.org;\n\n# Here is the command that replaces the load_examples\n# parameter from True to False. So if you\n# airflow, you won't get any examples in the list of dags.\nRUN sed -i 's/load_examples = True/load_examples = False/g' /root/airflow/airflow.cfg\n\nCMD [\"airflow\", \"standalone\"]\n\nOverwriting run_airflow/dockerfile\n\n\ninstall_airflow.sh just copied from airflow quick start page.\n\n%%writefile run_airflow/isntall_airflow.sh\nAIRFLOW_VERSION=2.7.1\n\n# Extract the version of Python you have installed. If you're currently using Python 3.11 you may want to set this manually as noted above, Python 3.11 is not yet supported.\nPYTHON_VERSION=\"$(python --version | cut -d \" \" -f 2 | cut -d \".\" -f 1-2)\"\n\nCONSTRAINT_URL=\"https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt\"\n# For example this would install 2.7.1 with python 3.8: https://raw.githubusercontent.com/apache/airflow/constraints-2.7.1/constraints-3.8.txt\n\npip install \"apache-airflow==${AIRFLOW_VERSION}\" --constraint \"${CONSTRAINT_URL}\"\n\nWriting run_airflow/isntall_airflow.sh"
  },
  {
    "objectID": "python/airflow/run_airflow.html#start-the-container",
    "href": "python/airflow/run_airflow.html#start-the-container",
    "title": "Run airflow",
    "section": "Start the container",
    "text": "Start the container\nIn the following cell command to start the container. We need port 8080 to get access to the airflow browser client.\n\n!docker run -itd --rm\\\n    --name start_airflow\\\n    -p 8080:8080\\\n    airflow_tests &&gt; /dev/null\n\nNow you can try localhost:8080 on your browser (use username - admin and password - admin).\nDon’t forget to stop the container when you don’t need it.\n\n!docker stop start_airflow &&gt; /dev/null"
  },
  {
    "objectID": "python/airflow/bash_tasks.html",
    "href": "python/airflow/bash_tasks.html",
    "title": "Bash tasks",
    "section": "",
    "text": "This page will cover the peculiarities of using bash to describe tasks in airflow."
  },
  {
    "objectID": "python/airflow/bash_tasks.html#dag",
    "href": "python/airflow/bash_tasks.html#dag",
    "title": "Bash tasks",
    "section": "DAG",
    "text": "DAG\n\n%%writefile bash_tasks/bash_tasks.py\n\nfrom datetime import datetime, timedelta\nfrom textwrap import dedent\n\nfrom airflow import DAG\n\nfrom airflow.operators.bash import BashOperator\nwith DAG(\n    \"bash_tasks\",\n    default_args={\n        \"depends_on_past\": False,\n    },\n    description=\"A simple tutorial DAG\",\n    schedule=timedelta(days=1),\n    start_date=datetime(2021, 1, 1),\n    catchup=False,\n    tags=[\"example\"],\n) as dag:\n\n    print_bash_date = BashOperator(\n        task_id=\"print_date\",\n        bash_command=\"\"\"\n        for i in {0..3}\n        do\n            echo \"current date: $(date)\"\n        done\n        \"\"\"\n    )\n\n    run_external_script = BashOperator(\n        task_id=\"external_script\",\n        bash_command=\"\"\"\n        for i in {0..3}\n        do\n            echo \"current date: $(date)\"\n        done\n        \"\"\"\n    )\n\nOverwriting bash_tasks/bash_tasks.py"
  },
  {
    "objectID": "python/airflow/bash_tasks.html#container",
    "href": "python/airflow/bash_tasks.html#container",
    "title": "Bash tasks",
    "section": "Container",
    "text": "Container\n\n%%bash\ndocker run -d --rm\\\n    --name bash_tasks\\\n    -p 8080:8080\\\n    -v ./bash_tasks:/root/airflow/dags\\\n    airflow_tests &&gt; /dev/null\n\ndocker exec bash_tasks airflow dags list\n\ndag_id     | filepath      | owner   | paused\n===========+===============+=========+=======\nbash_tasks | bash_tasks.py | airflow | True  \n                                             \n\n\n\n!docker exec bash_tasks airflow db migrate\n\nDB: sqlite:////root/airflow/airflow.db\nPerforming upgrade to the metadata database sqlite:////root/airflow/airflow.db\n[2023-09-25T11:23:17.657+0000] {migration.py:213} INFO - Context impl SQLiteImpl.\n[2023-09-25T11:23:17.658+0000] {migration.py:216} INFO - Will assume non-transactional DDL.\n[2023-09-25T11:23:17.659+0000] {db.py:1622} INFO - Creating tables\nINFO  [alembic.runtime.migration] Context impl SQLiteImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\nDatabase migrating done!\n\n\n\n!docker stop bash_tasks\n\nbash_tasks"
  },
  {
    "objectID": "python/airflow/bash_tasks.html#print_bash_date",
    "href": "python/airflow/bash_tasks.html#print_bash_date",
    "title": "Bash tasks",
    "section": "print_bash_date",
    "text": "print_bash_date\n\n!docker exec bash_tasks airflow tasks test bash_tasks print_date 2015-06-01\n#| grep \" - current date\"\n\n[2023-09-25T11:23:20.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /root/airflow/dags\n[2023-09-25T11:23:20.558+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=&lt;TaskInstance: bash_tasks.print_date __airflow_temporary_run_2023-09-25T11:21:25.160046+00:00__ [None]&gt;\n[2023-09-25T11:23:20.561+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=&lt;TaskInstance: bash_tasks.print_date __airflow_temporary_run_2023-09-25T11:21:25.160046+00:00__ [None]&gt;\n[2023-09-25T11:23:20.562+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2\n[2023-09-25T11:23:20.562+0000] {taskinstance.py:1428} WARNING - cannot record queued_duration for task print_date because previous state change time has not been saved\n[2023-09-25T11:23:20.562+0000] {taskinstance.py:1380} INFO - Executing &lt;Task(BashOperator): print_date&gt; on 2015-06-01 00:00:00+00:00\n[2023-09-25T11:23:20.581+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='bash_tasks' AIRFLOW_CTX_TASK_ID='print_date' AIRFLOW_CTX_EXECUTION_DATE='2015-06-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='__airflow_temporary_run_2023-09-25T11:21:25.160046+00:00__'\n[2023-09-25T11:23:20.582+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp\n[2023-09-25T11:23:20.582+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', '\\n        for i in {0..3}\\n        do\\n            echo \"current date: $(date)\"\\n        done\\n        ']\n[2023-09-25T11:23:20.586+0000] {subprocess.py:86} INFO - Output:\n[2023-09-25T11:23:20.587+0000] {subprocess.py:93} INFO - current date: Mon Sep 25 11:23:20 UTC 2023\n[2023-09-25T11:23:20.588+0000] {subprocess.py:93} INFO - current date: Mon Sep 25 11:23:20 UTC 2023\n[2023-09-25T11:23:20.588+0000] {subprocess.py:93} INFO - current date: Mon Sep 25 11:23:20 UTC 2023\n[2023-09-25T11:23:20.589+0000] {subprocess.py:93} INFO - current date: Mon Sep 25 11:23:20 UTC 2023\n[2023-09-25T11:23:20.589+0000] {subprocess.py:97} INFO - Command exited with return code 0\n[2023-09-25T11:23:20.599+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=bash_tasks, task_id=print_date, execution_date=20150601T000000, start_date=, end_date=20230925T112320"
  },
  {
    "objectID": "python/airflow/tutorial_dag.html",
    "href": "python/airflow/tutorial_dag.html",
    "title": "Tutorial DAG",
    "section": "",
    "text": "Using this jupyter notebook you can run DAG from this example."
  },
  {
    "objectID": "python/airflow/tutorial_dag.html#dag-code",
    "href": "python/airflow/tutorial_dag.html#dag-code",
    "title": "Tutorial DAG",
    "section": "DAG code",
    "text": "DAG code\nThe following is the DAG code that we just copied from the example into the prepared folder.\n\n%%writefile tutorial_dag/tutorial_dug.py\n\nfrom datetime import datetime, timedelta\nfrom textwrap import dedent\n\n# The DAG object; we'll need this to instantiate a DAG\nfrom airflow import DAG\n\n# Operators; we need this to operate!\nfrom airflow.operators.bash import BashOperator\nwith DAG(\n    \"tutorial\",\n    # These args will get passed on to each operator\n    # You can override them on a per-task basis during operator initialization\n    default_args={\n        \"depends_on_past\": False,\n        \"email\": [\"airflow@example.com\"],\n        \"email_on_failure\": False,\n        \"email_on_retry\": False,\n        \"retries\": 1,\n        \"retry_delay\": timedelta(minutes=5),\n        # 'queue': 'bash_queue',\n        # 'pool': 'backfill',\n        # 'priority_weight': 10,\n        # 'end_date': datetime(2016, 1, 1),\n        # 'wait_for_downstream': False,\n        # 'sla': timedelta(hours=2),\n        # 'execution_timeout': timedelta(seconds=300),\n        # 'on_failure_callback': some_function, # or list of functions\n        # 'on_success_callback': some_other_function, # or list of functions\n        # 'on_retry_callback': another_function, # or list of functions\n        # 'sla_miss_callback': yet_another_function, # or list of functions\n        # 'trigger_rule': 'all_success'\n    },\n    description=\"A simple tutorial DAG\",\n    schedule=timedelta(days=1),\n    start_date=datetime(2021, 1, 1),\n    catchup=False,\n    tags=[\"example\"],\n) as dag:\n\n    # t1, t2 and t3 are examples of tasks created by instantiating operators\n    t1 = BashOperator(\n        task_id=\"print_date\",\n        bash_command=\"date\",\n    )\n\n    t2 = BashOperator(\n        task_id=\"sleep\",\n        depends_on_past=False,\n        bash_command=\"sleep 5\",\n        retries=3,\n    )\n    t1.doc_md = dedent(\n        \"\"\"\\\n    #### Task Documentation\n    You can document your task using the attributes `doc_md` (markdown),\n    `doc` (plain text), `doc_rst`, `doc_json`, `doc_yaml` which gets\n    rendered in the UI's Task Instance Details page.\n    ![img](http://montcs.bloomu.edu/~bobmon/Semesters/2012-01/491/import%20soul.png)\n    **Image Credit:** Randall Munroe, [XKCD](https://xkcd.com/license.html)\n    \"\"\"\n    )\n\n    dag.doc_md = __doc__  # providing that you have a docstring at the beginning of the DAG; OR\n    dag.doc_md = \"\"\"\n    This is a documentation placed anywhere\n    \"\"\"  # otherwise, type it like this\n    templated_command = dedent(\n        \"\"\"\n    {% for i in range(5) %}\n        echo \"{{ ds }}\"\n        echo \"{{ macros.ds_add(ds, 7)}}\"\n    {% endfor %}\n    \"\"\"\n    )\n\n    t3 = BashOperator(\n        task_id=\"templated\",\n        depends_on_past=False,\n        bash_command=templated_command,\n    )\n\n    t1 &gt;&gt; [t2, t3]\n\nOverwriting tutorial_dag/tutorial_dug.py"
  },
  {
    "objectID": "python/airflow/tutorial_dag.html#container",
    "href": "python/airflow/tutorial_dag.html#container",
    "title": "Tutorial DAG",
    "section": "Container",
    "text": "Container\nBy running the following cell you start an instance of ariflow with the prepared example dug in.\n\n!docker run -itd --rm\\\n    --name tutorial_dag\\\n    -p 8080:8080\\\n    -v ./tutorial_dag:/root/airflow/dags\\\n    airflow_tests &&gt; /dev/null\n\nLet’s check that the tutorial dag has been added to the airflow.\n\n!docker exec tutorial_dag airflow dags list\n\ndag_id   | filepath        | owner   | paused\n=========+=================+=========+=======\ntutorial | tutorial_dug.py | airflow | True  \n                                             \n\n\nDon’t forget to stop the container when you have finished playing with the example.\n\n!docker stop tutorial_dag &&gt; /dev/null"
  },
  {
    "objectID": "python/airflow/tutorial_dag.html#test-task",
    "href": "python/airflow/tutorial_dag.html#test-task",
    "title": "Tutorial DAG",
    "section": "Test task",
    "text": "Test task\nBy using the command airflow tasks test you can execute the task and get it’s output just in terminal. Like in the example below.\nNone For some unknown reason, the first execution of this command causes a Python error. This shouldn’t affect us for now - the logs are fine, but I need to look into it more.\n\n%%bash\necho \"=====test=====\"\ndocker exec tutorial_dag airflow tasks test tutorial print_date 2015-06-01\n\n=====test=====\n[2023-09-24T13:00:55.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /root/airflow/dags\n[2023-09-24T13:00:55.986+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=&lt;TaskInstance: tutorial.print_date __airflow_temporary_run_2023-09-24T13:00:44.709050+00:00__ [None]&gt;\n[2023-09-24T13:00:55.990+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=&lt;TaskInstance: tutorial.print_date __airflow_temporary_run_2023-09-24T13:00:44.709050+00:00__ [None]&gt;\n[2023-09-24T13:00:55.990+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 2\n[2023-09-24T13:00:55.990+0000] {taskinstance.py:1428} WARNING - cannot record queued_duration for task print_date because previous state change time has not been saved\n[2023-09-24T13:00:55.991+0000] {taskinstance.py:1380} INFO - Executing &lt;Task(BashOperator): print_date&gt; on 2015-06-01 00:00:00+00:00\n[2023-09-24T13:00:56.017+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='tutorial' AIRFLOW_CTX_TASK_ID='print_date' AIRFLOW_CTX_EXECUTION_DATE='2015-06-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='__airflow_temporary_run_2023-09-24T13:00:44.709050+00:00__'\n[2023-09-24T13:00:56.019+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp\n[2023-09-24T13:00:56.020+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'date']\n[2023-09-24T13:00:56.027+0000] {subprocess.py:86} INFO - Output:\n[2023-09-24T13:00:56.028+0000] {subprocess.py:93} INFO - Sun Sep 24 13:00:56 UTC 2023\n[2023-09-24T13:00:56.028+0000] {subprocess.py:97} INFO - Command exited with return code 0\n[2023-09-24T13:00:56.043+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=tutorial, task_id=print_date, execution_date=20150601T000000, start_date=, end_date=20230924T130056"
  },
  {
    "objectID": "python/geopy/distances.html",
    "href": "python/geopy/distances.html",
    "title": "Distances",
    "section": "",
    "text": "Geopy calculate distances.\nGeopy provides a tool for calculating distances on maps.\nfrom geopy import distance\nfrom geopy.geocoders import Nominatim"
  },
  {
    "objectID": "python/geopy/distances.html#compution",
    "href": "python/geopy/distances.html#compution",
    "title": "Distances",
    "section": "Compution",
    "text": "Compution\nYou need to use the geopy.distance.distance function to calculate the distance between two points. In the following example the distance between Minsk and Molodechno has been calculated - it looks quite close.\n\ngeolocator = Nominatim(user_agent = \"knowledge\")\n\nlocation1 = geolocator.geocode(\"Minsk\")\nlocation2 = geolocator.geocode(\"Molodechno\")\n\nmy_distance = distance.distance(\n    (location1.latitude, location1.longitude),\n    (location2.latitude, location2.longitude)\n)\nprint(f\"Minsk&lt;-&gt;Molodechno distance is {my_distance.kilometers} km\")\n\nMinsk&lt;-&gt;Molodechno distance is 64.89474666491046 km"
  },
  {
    "objectID": "python/geopy/distances.html#distance-object",
    "href": "python/geopy/distances.html#distance-object",
    "title": "Distances",
    "section": "Distance object",
    "text": "Distance object\ngeopy.distance.distance returns an object of type geopy.distance.geodesic. The main properties of the object are displayed in the following cell.\n\nfor field in dir(my_distance):\n    if field[0] != \"_\":\n        print(field)\n\nELLIPSOID\ndestination\nellipsoid_key\nfeet\nft\ngeod\nkilometers\nkm\nm\nmeasure\nmeters\nmi\nmiles\nnautical\nnm\nset_ellipsoid"
  },
  {
    "objectID": "python/geopy/request.html",
    "href": "python/geopy/request.html",
    "title": "Request",
    "section": "",
    "text": "In this page I will describe how to make different types of requests to geopy.\nGeopy documentation.\nTo use it you need to create a Nominatim object and pass it user_agent. In my opinion you can pass whatever you want as user_agent, I don’t really understand how this option is used.\nfrom geopy.geocoders import Nominatim\ngeolocator = Nominatim(user_agent = \"knowledge\")"
  },
  {
    "objectID": "python/geopy/request.html#arbitrary-request",
    "href": "python/geopy/request.html#arbitrary-request",
    "title": "Request",
    "section": "Arbitrary request",
    "text": "Arbitrary request\nUsing the geocode method, you can query the system address as text.\n\ngeolocator.geocode(\"Minsk\", language = \"en\").raw\n\n{'place_id': 184576951,\n 'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright',\n 'osm_type': 'relation',\n 'osm_id': 59195,\n 'lat': '53.9024716',\n 'lon': '27.5618225',\n 'class': 'boundary',\n 'type': 'administrative',\n 'place_rank': 7,\n 'importance': 0.6699404177567978,\n 'addresstype': 'city',\n 'name': 'Minsk',\n 'display_name': 'Minsk, Belarus',\n 'boundingbox': ['53.7938470', '53.9717897', '27.3740176', '28.0799469']}"
  },
  {
    "objectID": "python/geopy/request.html#request-as-coordinates",
    "href": "python/geopy/request.html#request-as-coordinates",
    "title": "Request",
    "section": "Request as coordinates",
    "text": "Request as coordinates\nUsing reverse method you can pass any coordinates you like as tuple and got answer.\n\ngeolocator.reverse((43, 23), language = \"ru\").raw\n\n{'place_id': 82486720,\n 'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright',\n 'osm_type': 'way',\n 'osm_id': 706822395,\n 'lat': '42.999751989667615',\n 'lon': '23.000019012462104',\n 'class': 'highway',\n 'type': 'tertiary',\n 'place_rank': 26,\n 'importance': 0.10000999999999993,\n 'addresstype': 'road',\n 'name': '813',\n 'display_name': '813, Бондин хан, Туден, Годеч, Софийская область, 2240, Болгария',\n 'address': {'road': '813',\n  'neighbourhood': 'Бондин хан',\n  'village': 'Туден',\n  'municipality': 'Годеч',\n  'county': 'Софийская область',\n  'ISO3166-2-lvl6': 'BG-23',\n  'postcode': '2240',\n  'country': 'Болгария',\n  'country_code': 'bg'},\n 'boundingbox': ['42.9936767', '42.9998986', '22.9871460', '23.0008811']}"
  },
  {
    "objectID": "python/geopy/request.html#location-object",
    "href": "python/geopy/request.html#location-object",
    "title": "Request",
    "section": "Location object",
    "text": "Location object\nRequests to geopy will return the geopy.location.Location object.\nThe next cell lists the interesting fields.\n\nlocation_opject = geolocator.geocode(\"Minsk\", language = \"ru\")\n\nfor field in dir(location_opject): \n    if field[0] != \"_\": print(field)\n\naddress\naltitude\nlatitude\nlongitude\npoint\nraw\n\n\nraw field is crusical it contains original answer from api.\n\nlocation_opject.raw\n\n{'place_id': 152512099,\n 'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright',\n 'osm_type': 'relation',\n 'osm_id': 59195,\n 'lat': '53.9024716',\n 'lon': '27.5618225',\n 'class': 'boundary',\n 'type': 'administrative',\n 'place_rank': 7,\n 'importance': 0.6699404177567978,\n 'addresstype': 'city',\n 'name': 'Минск',\n 'display_name': 'Минск, Беларусь',\n 'boundingbox': ['53.7938470', '53.9717897', '27.3740176', '28.0799469']}"
  },
  {
    "objectID": "python/dash/select_clear_all.html",
    "href": "python/dash/select_clear_all.html",
    "title": "Select/Clear All",
    "section": "",
    "text": "It’s a common task to organise a mechanism to select or disable all available options. So here I describe possible ways to do it.\n\nSelect\nIn the following example, there is a checklist and all the boxes can be selected by pressing the “Select all” button. You should use prevent_initial_call = True for select all button callback in order to avoid all options in dashboard starting.\n\nfrom jupyter_dash import JupyterDash\nfrom dash import (\n    html,\n    dcc,\n    callback, \n    Input, \n    Output, \n    State\n)\nfrom IPython.display import clear_output\n\napp = JupyterDash(__name__)\n\napp.layout = html.Div([\n    html.Button(\n        \"Select All\",\n        id=\"select-all-button\",\n    ),\n    dcc.Checklist(\n        [\n            \"BelarusSales\",\n            \"SalesNetworkBelarus\",\n            \"BelSalesNetwork\",\n            \"SalesNetworkBel\",\n            \"SalesOfBelarus\",\n            \"BelSalesNetworks\",\n            \"BelarusSalesNetwork\",\n            \"SalesInBelarus\",\n        ],\n        id = \"check-list\",\n        value = []\n    )\n])\n\n@callback(\n    Output(\"check-list\", \"value\"),\n    State(\"check-list\", \"options\"),\n    Input(\"select-all-button\", \"n_clicks\"),\n    prevent_initial_call = True\n)\ndef select_all_button(\n    options: list,\n    n_clicks: int\n) -&gt; list:\n    '''\n        Callback that allows you to do \n        select all options in CheckList\n        from pressing \"select-all-button\".\n\n        Arguments\n        -----------\n\n        options : (list) list with options of Checkbox;\n        n_clicks: (int) number of clicks on button.\n\n        Returns\n        -----------\n        (list) list of selected options of Checklist.\n    '''\n    return options\n        \n\napp.run_server(debug=True, port = 8051)\nclear_output()\n\n\n\n\nClear\nIn the following example, I create a button that deselects all values in the checklist. It’s really similar ideas to “Select all” and even easier. You have to set prevent_initial_call = True as well.\n\nfrom jupyter_dash import JupyterDash\nfrom dash import (\n    html,\n    dcc,\n    callback,\n    Input,\n    Output,\n    State\n)\nfrom IPython.display import clear_output\n\ninitial_clicks = 0\n\napp = JupyterDash(__name__)\napp.layout = html.Div([\n    html.Button(\n        \"Clear\", id = \"clear-button\", \n        n_clicks = initial_clicks\n    ),\n    dcc.Checklist(\n        [\n            \"BelarusSales\",\n            \"SalesNetworkBelarus\",\n            \"BelSalesNetwork\",\n            \"SalesNetworkBel\",\n            \"SalesOfBelarus\",\n            \"BelSalesNetworks\",\n            \"BelarusSalesNetwork\",\n            \"SalesInBelarus\",\n        ],\n        id = \"check-list\",\n        value = []\n    )\n])\n\n@callback(\n    Output(\"check-list\", \"value\"),\n    Input(\"clear-button\", \"n_clicks\"),\n    prevent_initial_call = True\n)\ndef button_click(n_clicks: int) -&gt; list:\n    '''\n        The callback for clear button.\n\n        Arguments\n        -----------\n        value : (list) the value of Checklist;\n\n        Returns\n        -----------\n\n        (list) a list of options to be selected in \n               the Checklist after pressing the call button;\n    '''\n    return []\n\napp.run(port=8052)\nclear_output()"
  },
  {
    "objectID": "python/dash/components.html",
    "href": "python/dash/components.html",
    "title": "Components",
    "section": "",
    "text": "On this page I’ll be exploring the possibilities of using different Plotly components."
  },
  {
    "objectID": "python/dash/components.html#basic-example",
    "href": "python/dash/components.html#basic-example",
    "title": "Components",
    "section": "Basic example",
    "text": "Basic example\ndash.html.Details allows you to define a group of elements that hide some other components and show them on click.\n\nfrom jupyter_dash import JupyterDash\nfrom dash import dcc, html\nfrom IPython.display import clear_output\n\nmy_list = [\n    \"BelarusSales\",\n    \"SalesNetworkBelarus\",\n    \"BelSalesNetwork\",\n    \"SalesNetworkBel\",\n    \"SalesOfBelarus\",\n    \"BelSalesNetworks\",\n    \"BelarusSalesNetwork\",\n    \"SalesInBelarus\",\n]\n\napp = JupyterDash(__name__)\n\napp.layout = html.Details(\n    [html.H3(i) for i in my_list],\n)\n\napp.run_server(debug=False, port = 8053)\nclear_output()"
  },
  {
    "objectID": "python/dash/components.html#summary-caption",
    "href": "python/dash/components.html#summary-caption",
    "title": "Components",
    "section": "Summary (caption)",
    "text": "Summary (caption)\nIf you want to change the caption of the details (text near the arrow), you should create a Summary object as a child of the Details tag. The important feature is that you can put other objects (like buttons and so on) in the Summary.\nRead more:\n\nMDN web docs about Details tag;\nDash documentation about dash.html.Details;\nDash documentation about dash.html.Summary.\n\nSo in the following example there is a Details with the caption “My details” and an additional button in the header.\n\nfrom jupyter_dash import JupyterDash\nfrom dash import dcc, html\nfrom IPython.display import clear_output\n\nmy_list = [\n    \"BelarusSales\",\n    \"SalesNetworkBelarus\",\n    \"BelSalesNetwork\",\n    \"SalesNetworkBel\",\n    \"SalesOfBelarus\",\n    \"BelSalesNetworks\",\n    \"BelarusSalesNetwork\",\n    \"SalesInBelarus\",\n]\n\napp = JupyterDash(__name__)\n\ncontents = [html.H3(i) for i in my_list]\nsummary = [\n    html.Summary([\n        \"My details\", \n        html.Button(\"Summary button\")\n    ])\n]\n\napp.layout = html.Details(contents + summary)\n\napp.run_server(debug=False, port = 8054)\nclear_output()"
  },
  {
    "objectID": "python/dash/components.html#overlapping",
    "href": "python/dash/components.html#overlapping",
    "title": "Components",
    "section": "Overlapping",
    "text": "Overlapping\nYou can put any content in the Details section, and when the element is scrolled it should move any content that follows it. So in the example below I use both simple strings and other dash components.\n\nfrom jupyter_dash import JupyterDash\nfrom dash import dcc, html\nfrom IPython.display import clear_output\n\napp = JupyterDash(__name__)\n\ncontents1 = [elem for i in range(10) for elem in [f\"line{i}\", html.Br()]]\n\ncontents2 = [dcc.Checklist(\n    options = [f\"Checkbox{i}\" for i in range(10)]\n)]\n\napp.layout = html.Div([\n        html.Details(contents1 + contents2),\n    \"Some other contents\"\n])\n\napp.run_server(debug=False, port = 8055)\nclear_output()"
  },
  {
    "objectID": "python/dash/multipage_applications.html",
    "href": "python/dash/multipage_applications.html",
    "title": "Multipage applications",
    "section": "",
    "text": "Official information about creating multi-page applications in dash can be found here. In this page I just want to write down some of my experiments related to this feature."
  },
  {
    "objectID": "python/dash/multipage_applications.html#dash.page_registry",
    "href": "python/dash/multipage_applications.html#dash.page_registry",
    "title": "Multipage applications",
    "section": "dash.page_registry",
    "text": "dash.page_registry\ndash.page_registry is a special dictionary that contains information about the pages in the current application. So in the following example an application with two pages has been created. Page with button has a special button that stores dash.page_registry.\n\n%%writefile multipage_applications_files/app.py\nimport dash\nfrom dash import Dash, html, dcc\n\napp = Dash(__name__, use_pages=True)\n\napp.layout = html.Div([\n    html.H1('Multi-page app with Dash Pages'),\n    html.Div([\n        html.Div(\n            dcc.Link(f\"{page['name']} - {page['path']}\", href=page[\"relative_path\"])\n        ) for page in dash.page_registry.values()\n    ]),\n    dash.page_container\n])\n\nif __name__ == '__main__':\n    app.run(debug=True)\n\nOverwriting multipage_applications_files/app.py\n\n\n\n%%writefile multipage_applications_files/pages/some_page.py\nimport dash\nfrom dash import html, callback, Input, Output\n\nimport pickle\n\ndash.register_page(__name__)\nlayout = html.Div([\n    html.H1('Page with button'),\n    html.Button(\n        \"Save page_registry\",\n        id=\"save-button\",\n    ),\n    html.Div(id='dummy')\n])\n\n@callback(\n    Output(\"dummy\", \"children\"),\n    Input(\"save-button\", \"n_clicks\")\n)\ndef save_callback(n_clicks):\n    with open(\"page_registry\", \"wb\") as f:\n        pickle.dump(dash.page_registry, f)\n\nOverwriting multipage_applications_files/pages/some_page.py\n\n\n\n%%writefile multipage_applications_files/pages/home.py\nimport dash\nfrom dash import html\n\ndash.register_page(__name__, path=\"/\")\nlayout = html.Div([\n    html.H1('Basic home page')\n])\n\nOverwriting multipage_applications_files/pages/home.py\n\n\nBy running the following cell, you can run the dash application described in the previous three cells.\n\n%%bash\ncd multipage_applications_files\npython3 app.py\n\nDash is running on http://127.0.0.1:8050/\n\n * Serving Flask app 'app'\n * Debug mode: on\nError while terminating subprocess (pid=19264): \n\n\nHere you can explore the layers of the dash.page_registry.\n\nimport pickle\nfrom IPython.display import JSON, HTML\n\nwith open(\"multipage_applications_files/page_registry\", \"rb\") as f:\n    j = pickle.load(f)\n\nJSON(j)\n\n&lt;IPython.core.display.JSON object&gt;"
  },
  {
    "objectID": "python/dash/callbacks.html",
    "href": "python/dash/callbacks.html",
    "title": "Callbacks",
    "section": "",
    "text": "It is a mechanism that allows you to create a function that will be called when you perform an action. It realised. This is implemented via the dash.callback decorator. More details in the documentation. I will focus on some practical features.\n\nSources\n\nUsing dash inside jupyter;\nCheck list component in dash;\nDash basic callbacks;\nCallback without output - github discussion.\n\n\n\nInput/output format\nInput/Output, implemented by dash.Input/dash.Output, which should be passed as arguments to the callback decorator. Constructors of the classes require the following syntax (\"&lt;object-id&gt;\", \"&lt;property&gt;\"), so you can choose which property to pass to the callback and which to change.\nIn the following example, I simply take dcc.Checklist.values and link it to ddc.Slider.marks - the markers on the dcc.slider will exactly match the selected checkboxes on the dcc.checklist.\n\nfrom dash import dcc, html, Input, Output, callback\nfrom jupyter_dash import JupyterDash\nfrom IPython.display import clear_output\n\napp = JupyterDash(__name__)\noptions = list(range(0,20))\nvalue = [1,5]\n\nlst_val_to_slider_marks = lambda value: {val:str(val) for val in value}\n\napp.layout =  html.Div(\n    [\n        dcc.Checklist(\n            options,\n            value = value,\n            id = \"check-lst\",\n            inline = True\n        ),\n        dcc.Slider(\n            min(options), max(options),\n            step = None,\n            marks = lst_val_to_slider_marks(value),\n            id = \"slider\"\n        )\n    ],\n    style={'display': 'flex', 'flex-direction': 'column'}\n)\n\n@callback(\n    Output(\"slider\", \"marks\"),\n    Input(\"check-lst\", \"value\")\n)\ndef my_callback(val:list) -&gt; dict:\n    return lst_val_to_slider_marks(val)\n\nif __name__ == '__main__':\n    app.run_server(debug=True, port=8051)\nclear_output()\n\nIn site it will looks like:  Any check box you click - it will add one more marker on slider.\n\n\nState callbacks\nAny dash.dcc.Input will trigger the callback when the related item has changed. But sometimes it’s useful to have an element that sends its state, but only when some other element triggers the callback. Such purpose should be completed by dash.dcc.State.\nSo the following example is the same as in the Input/Output Format section, but it updates the slider not when the new checkbox is selected, but only when the button is pressed.\n\nfrom dash import dcc, html, Input, Output, callback, State\nfrom jupyter_dash import JupyterDash\nfrom IPython.display import clear_output\n\napp = JupyterDash(__name__)\noptions = list(range(0,20))\nvalue = [1,5]\n\nlst_val_to_slider_marks = lambda value: {val:str(val) for val in value}\n\napp.layout =  html.Div(\n    [\n        dcc.Checklist(\n            options,\n            value = value,\n            id = \"check-lst\",\n            inline = True\n        ),\n        dcc.Slider(\n            min(options), max(options),\n            step = None,\n            marks = lst_val_to_slider_marks(value),\n            id = \"slider\"\n        ),\n        html.Button(\n            \"Update bar\", id = \"button\"\n        )\n    ],\n    style={'display': 'flex', 'flex-direction': 'column'}\n)\n\n@callback(\n    Output(\"slider\", \"marks\"),\n    State(\"check-lst\", \"value\"),\n    Input(\"button\", \"n_clicks\")\n)\ndef my_callback(val: list, n_clicks : int) -&gt; dict:\n    '''\n        Callback for button.\n\n        Arguments\n        -----------\n        \n        val : (list) value passed from check list by State\n                caontains camptions of selected boxes;\n        n_clicks : (int) n_clicks of button passed by Input;\n\n        Returns\n        -----------\n\n        (dict) which maps values and it's markers on slider.\n    '''\n    return lst_val_to_slider_marks(val)\n\napp.run_server(debug=True)\nclear_output()\n\n\n\n\nChained callbacks\nThis section is just a variant of that material. But better described.\nThis example shows how one event can trigger a chain of different callbacks.\n\nSo we have a button that adds a new option to the checkbox list with a button_click callback;\nWhen something changes options in the checklist, it triggers check_list_options_changed, which only sets the last option selected;\nWhen something changes selected options, check_list_values_changed will be triggered and show selected options like line.\n\n\nfrom dash import dcc, html, Input, Output, callback\nfrom IPython.display import clear_output\nfrom jupyter_dash import JupyterDash\n\napp = JupyterDash(__name__)\napp.layout = html.Div([\n    html.Button(\"Add new box\", id = \"add-button\", n_clicks = 0),\n    dcc.Checklist(id=\"check-list\"),\n    html.P(id=\"disp-sel-boxes\")\n])\n\n@callback(\n    Output(\"check-list\", \"options\"),\n    Input(\"add-button\", \"n_clicks\")\n)\ndef button_click(n_clicks):\n    '''\n        Callback makes in listbox exactly\n        number of boxes as the number of\n        button is clicked.\n\n        Arguments\n        ------------\n\n        n_clicks : (int) count of clicks on button;\n\n        Returns\n        -----------\n\n        (list) captions of boxes which will \n        be displayed in check-list.\n    '''\n    return [f\"box {i}\" for i in range(n_clicks+1)]\n\n@callback(\n    Output(\"check-list\", \"value\"),\n    Input(\"check-list\", \"options\")\n)\ndef check_list_options_changed(options):\n    '''\n        Callback that will be called when the list of\n        of options in the checklist is updated. It sets\n        only the last option as a value.\n\n        Arguments\n        -----------\n\n        options : (list) list of available options.\n\n        Returns\n        -----------\n\n        (list) contains only the last option.\n    '''\n    return [options[-1]]\n\n@callback(\n    Output(\"disp-sel-boxes\", \"children\"),\n    Input(\"check-list\", \"value\")\n)\ndef check_list_values_changed(value):\n    '''\n        Called when you select/unselect a check.\n\n        Arguments\n        -----------\n        \n        value : (list) captions of selected boxes;\n\n        Returns\n        -----------\n        \n        (str) line that describes selected options\n        as \"Selected boxes: &lt;box1&gt;, ..., &lt;boxn&gt;\".\n    '''\n    return \"Selected boxes: \" + \", \".join([val for val in value])\n\napp.run(debug=True)\nclear_output()\n\n\n\n\nCallback without output\nIt turns out that dash has no callback mechanism without output. So the only tricky way is to create a dummy object and set it as the output object. In the following example, I use html.Div(id='dummy'), or rather its children property. I also print out some messages with changes to dcc.Checklist to prove that everything is working. You can find py file with the following example in “callbacks_examples/no_output_callback.py”.\n\nfrom dash import dcc, html, Input, Output, callback, Dash\nfrom IPython.display import clear_output\nfrom jupyter_dash import JupyterDash\n\napp = Dash(__name__)\n\ncheck_values = [\"value1\", \"value2\", \"value3\"]\n\napp.layout = html.Div([\n    html.Div(id='dummy'),\n    dcc.Checklist(\n        check_values,\n        id = \"check-lst\"\n    )\n])\n\nclicks_counter = 0\n\n@callback(\n    Output(\"dummy\", \"children\"),\n    Input(\"check-lst\", \"value\")\n)\ndef test_callback(checklist_value):\n    global clicks_counter\n    clicks_counter += 1\n\n    print(\"==========================\")\n    print(f\"    CLICK {clicks_counter}     \")\n    print(\"==========================\")\n    \n    print(\"-------value-------\")\n    print(checklist_value)\n    return None\n\nif __name__ == '__main__':\n    app.run_server(debug=False)\n\nclear_output()"
  },
  {
    "objectID": "machine_learning/var_vs_bias/quadratic.html",
    "href": "machine_learning/var_vs_bias/quadratic.html",
    "title": "Knowledge",
    "section": "",
    "text": "import numpy as np\nimport scipy.interpolate as inter\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\nnp.random.seed(4)\n\n# data generation\nx_p = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ny_p = np.array([2, 4, 3, 5, 4, 6, 5, 7, 6, 8, 10])\npoly = inter.lagrange(x_p, y_p)\ndef f(x):\n    X = np.concatenate(\n        [(x**a)[:, np.newaxis] for a in range(len(poly.coef))],\n        axis = 1\n    )\n    return np.dot(X, poly.coef[::-1][:, np.newaxis]).ravel()\n\ny = lambda x: f(x) + np.random.normal(0, 1, x.shape)\n\nX_sample = np.sort(np.random.uniform(0, 10, 200)).astype(np.longdouble)\nY_sample = y(X_sample)\n\n\n# models\ndef get_poly_matrix(X, p = 2):\n    return np.concatenate(\n        [np.array(X)[:, np.newaxis]**(i) for i in range(p+1)],\n        axis = 1\n    )\ndef get_poly_predict(X, y, p = 2):\n    \n    X_matr = get_poly_matrix(X, p)\n    return LinearRegression(\n        fit_intercept=False\n    ).fit(X_matr, y).predict(X_matr)\n\n\nCHANGE_ME = 17\nplt.scatter(X_sample, Y_sample, color = \"black\")\nplt.title(\"polynomial degree \" + str(CHANGE_ME))\nplt.plot(\n    X_sample,\n    get_poly_predict(X_sample, Y_sample, CHANGE_ME),\n    linewidth = 4\n)\nplt.savefig(\"poly16.png\")"
  },
  {
    "objectID": "machine_learning/var_vs_bias/var_vs_bias.html",
    "href": "machine_learning/var_vs_bias/var_vs_bias.html",
    "title": "Введение",
    "section": "",
    "text": "Компромисс дисперсии и смещения\nВ этом notebook я надеюсь подробно разобрать вопрос компромиса между смещением (bias) и дисперсией (variance) в машинном обучении.\nВдохновлено соотсветсвующим разделом в ISLR.\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\n\nimport scipy.interpolate as inter\n\nn = 1000\n\nУтверждается что средне квадратическую ошибку модели (Mean Square Error, MSE) можно разложить на три составляющие: - Дисперсию; - Квардрат смещения; - Неустранимую ошибку.\nИли записывая серез формулу:\n\\[\\mathbb{E}(y_0 - \\hat{f}(x_0))^2 = Var(\\hat{f}(x_0)) + [Bias(\\hat{f}(x_0))]^2 + Var(\\varepsilon). \\tag{1}\\]\nГде: - \\(\\hat{f}(x)\\) - некоторая модель описывающая данные; - \\(x_0\\) - некоторое произвольное контрольное значение предикторов; - \\(y_0\\) - некоторое произвольное контрольное значение оклика; - \\(\\varepsilon\\) - неустранимая ошибка модели (irreducible error); в нее вкладывается та информация о описываемом процессе, которой нет в полученной выборке; - \\(Var(\\hat{f}(x_0))\\) - дисперсия полученной модели; эта величина должна быть тем больше, чем сильнее предстказания модели будут меняться от измениния выбоки; - \\(Bias(\\hat{f}(x_0))\\) - смещение модели эта величина тем меньше, чем точнее модель подогнанна к описываемому просцессу; - \\(Var(\\varepsilon)\\) - дисперсия неустранимой ошибки; чем полнее и точнее наши данные, тем меньше эта величина; - \\(\\mathbb{E}(y_0 - \\hat{f}(x_0))^2\\) - математическое ожидание ошибки полученной модели.\nВ различных источниках к этой теме очень часто прикладывают график подобный этому:\n\nx_plot_range = np.arange(0,0.8, 0.05)\nvariance = 3*(x_plot_range)**2 + x_plot_range\nbias = 3*(x_plot_range)**2 - 4.8*x_plot_range + 2\nirrecible_error = 1\nmodel_error = variance + bias + irrecible_error\n\nplt.figure(figsize = [10, 6])\nplt.plot(x_plot_range, variance)\nplt.plot(x_plot_range, bias)\nplt.axhline(irrecible_error, color = \"gray\", linestyle = \"dashed\")\nplt.plot(x_plot_range, model_error)\n\nplt.xticks([])\nplt.yticks([])\n\nplt.xlabel(\"Сложность модели\", fontsize = 15)\nplt.ylabel(\"Ошибка\", fontsize = 15)\n\nans = plt.legend([\n    \"$Var(\\hat{f}(x_0))$\",\n    \"$Bias(\\hat{f}(x_0))$\",\n    \"$Var(\\\\varepsilon)$\",\n    \"$\\mathbb{E}(y_0 - \\hat{f}(x_0))^2$\"\n])\n\n\n\n\nДалее я на примере простой задачи регрессии попытаюсь провести такой вычислитеньный эксперимент, который приведет именно к такому графику.\n\nИдея эксперимента\nПусть имеется некоторе уравнение которое обисывает некоторых достаточно сложный полином. В следующей ячейке происходит его генерация.\n\nx_p = np.array([0, 1, 2, 3, 4])\ny_p = np.array([2, 4, 3, 5, 4])\npoly = inter.lagrange(x_p, y_p)\n\nИтак, полученный полином записывается в форме:\n\n\\[f(x)=-0.0002+0.0105x^{1}-0.2263x^{2}+2.7223x^{3}-20.1388x^{4}+94.3996x^{5}-278.1615x^{6}+491.6866x^{7}-466.4732x^{8}+178.181x^{9}+2.0x^{10}\\]\n\ndef f(x):\n    X = np.concatenate(\n        [(x**a)[:, np.newaxis] for a in range(len(poly.coef))],\n        axis = 1\n    )\n    return np.dot(X, poly.coef[::-1][:, np.newaxis]).ravel()\n    \nx_range = np.arange(0, 4.01, 0.01)\nans = plt.plot(x_range, f(x_range))\n\n\n\n\nПусть зачение объясняемой переменной объясняется так:\n\\(y = f(x) + \\varepsilon\\)\nПусть для нашего примера \\(\\varepsilon \\sim N(0, 0.5)\\). То есть, по определениею нормального распределения \\(Var(\\varepsilon) = 0.5^2=0.25\\). Таким образом мы можем сгенерировать множество выборок подобных \\((x_i,y_i), i \\in \\overline{1,n}\\). Некторые из них предствлены на рисунке:\n\ny = lambda x: f(x) + np.random.normal(0, 0.5, x.shape)\n\n\nnp.random.seed(20)\nsample_size = 100\nexamples_count = 3\n\nX_samples = np.random.uniform(0, 4, [sample_size, examples_count])\nY_samples = np.concatenate(\n    [\n        y(X_samples[:, col_i])[:, np.newaxis] for col_i in range(examples_count)\n    ],\n    axis = 1\n)\n\nplt.figure(figsize = [5, 10])\nfor i in range(examples_count):\n    plt.subplot(examples_count, 1, i+1)\n    plt.scatter(\n        X_samples[:, i], Y_samples[:,i]\n    )\n    plt.xlabel(\"x\");ans = plt.ylabel(\"y\")\n\n\n\n\nОбычно об \\(f(x)\\) нам ничего, кроме выборки неизвестно. Потому задачу по формированию модели можно поставить следующим образом - найти такое \\(\\hat{f}(x)\\) что-бы оно максимально походило на дейсвительное \\(f(x)\\) располагая только выборкой. Методы подгонки моделей решают задачу оптимальным (или близким к оптимальному) образом при условии, что исследователь определился с идентификационной формой модели. Таким образом, задача, обычно, сводится именно к определению идентификационной формы модели.\n\ndef get_poly_matrix(X, p = 2):\n    return np.concatenate(\n        [np.array(X)[:, np.newaxis]**(i) for i in range(p+1)],\n        axis = 1\n    )\n\ndef get_poly_model(X, y, p = 2):\n    \n    X_matr = get_poly_matrix(X, p)\n    \n    return LinearRegression(\n        fit_intercept=False\n    ).fit(X_matr, y)\n\ndef get_poly_predict(X, y, p = 2):\n    \n    X_matr = get_poly_matrix(X, p)\n    return LinearRegression(\n        fit_intercept=False\n    ).fit(X_matr, y).predict(X_matr)\n\nnp.random.seed(21)\nsample_size = 100\npoly_max = 5\n\nX_sample = np.sort(np.random.uniform(0, 4, sample_size))\nY_sample = y(X_sample)\n\nplt.figure(figsize = [10, 8])\n\nlegend_line = \"\"\nlegend_list = []\n\nfor i in range(poly_max):\n    \n    X_matr = get_poly_matrix(X_sample, p = i)\n    model = LinearRegression(\n        fit_intercept=False\n    ).fit(X_matr, Y_sample)\n    pred = model.predict(X_matr)\n    plt.plot(X_sample, pred, linewidth = 5)\n    \n    eq = \"$f(x)=\"\n    for i, c in enumerate(model.coef_.round(3)):\n        if c != 0:\n            eq += \\\n                (\"+\" if c &gt; 0 and i != 0 else \"\") + \\\n                str(c) + \\\n                (\"x^{{{}}}\".format(i) if i != 0 else \"\")\n    eq += \"$\"\n    legend_list += [eq]\n\n    \nans = plt.scatter(X_sample, Y_sample, color = \"black\")\nplt.legend(legend_list)\n\nplt.xlabel(\"x\", fontsize = 13);ans = plt.ylabel(\"y\", fontsize = 13)\n\n\n\n\n\nplt.figure(figsize = [15, 7])\n\nsample_size = 30\n\nfor i in range(3):\n    for j, p in enumerate([0,4, 10]):\n        \n        plt.subplot(3,3,i+1+3*j)\n        X_sample = np.sort(np.random.uniform(0, 4, sample_size))\n        Y_sample = y(X_sample)\n        X_matrix = np.zeros([sample_size, poly_max])\n\n        plt.scatter(X_sample, Y_sample)\n        plt.plot(\n            X_sample,\n            get_poly_predict(X_sample, Y_sample, p),\n            color = \"black\"\n        )\n\n\n\n\n\nnp.random.seed(30)\nexp_count = 2000\nsample_size = 30\npoly_max = 14\n\nX_matrix = np.zeros([sample_size, poly_max])\n# x_ij - результат i-го эксперимента для j-го полинома\nprediction = np.zeros([exp_count, poly_max])\nresidual = np.zeros([exp_count, poly_max])\n\nfor i in range(exp_count):\n    # генерирую выборку актуальную на этой итерации\n    X_sample = np.random.uniform(0, 4, sample_size)\n    Y_sample = y(X_sample)\n    X_matrix = np.zeros([sample_size, poly_max])\n    \n    # индекс того наблюдения которое будет использоваться для проверки\n    i_0 = 0\n    \n    # пробегаюсь по возможным коэффициентам полинома\n    # подгонаяю соответсвующие модели\n    for j in range(poly_max):\n        pred = get_poly_predict(X_sample, Y_sample, j)\n        prediction[i,j] = pred[i_0]\n        residual[i,j] = (pred[i_0] - Y_sample[i_0])\n\n\nplt.plot(np.var(prediction, axis = 0))\nplt.plot(np.mean(residual**2, axis = 0))\nplt.plot(np.var(prediction, axis = 0) + np.mean(residual**2, axis = 0))\n\n\n\n\n\nnp.argsort(\n    (np.var(prediction, axis = 0) + np.mean(residual**2, axis = 0))\n)\n\narray([ 0,  1, 12, 13, 11,  9, 10,  8,  3,  4,  2,  6,  7,  5])\n\n\nnp.random.seed(30) exp_count = 2000 sample_size = 100 poly_max = 14\nX_matrix = np.zeros([sample_size, poly_max]) # x_ij - результат i-го эксперимента для j-го полинома prediction = np.zeros([exp_count, poly_max]) residual = np.zeros([exp_count, poly_max])"
  },
  {
    "objectID": "machine_learning/metrix/chisquare.html",
    "href": "machine_learning/metrix/chisquare.html",
    "title": "Knowledge",
    "section": "",
    "text": "Разбор статистики \\(\\chi^2\\)\nИсточники: - расстояние Пирсона от Анатолия Карпова; - анализ таблиц сопряженности от Анатолия Карпова."
  },
  {
    "objectID": "machine_learning/models_selection_methods/scaling_and_regularisation.html",
    "href": "machine_learning/models_selection_methods/scaling_and_regularisation.html",
    "title": "Scaling and regularisation",
    "section": "",
    "text": "It is recommended to scale the data before performing regularisation. In this page I want to show why.\nThe reason is quite simple - popular components of the target function responsible for regularisation of the model look like this.\n\n\\(\\sum{\\beta_i^2}\\);\n\\(\\sum{\\left|\\beta_i\\right|}\\).\n\nAll coefficients have the same contribution to the target function, regardless of their magnitude, so the optimisation algorithm naturally benefits from reducing first those coefficients that make a greater contribution to the target function, regardless of the economic/physical sense of the variables.\nThus regularisation may compress the coefficients too much at large scales without any intelligible reason for doing so. It is to counteract these phenomena that it is recommended to bring the data to a uniform scale by any available means.\nBelow is a small experiment that confirms this idea.\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Ridge\n\nLet’s say you have a data frame with two features and their scaling is dramatically different.\nSo in the following cell I reproduce such a case. There are two functions and the numbers in the first function are usually 100 times smaller than in the second. But on the target variable, they out of order have about the same effect - each unit in the first variable contributes 100 times more to the value of the explained variable.\n\nnp.random.seed(10)\nsample_size = 200\n\nX = np.concatenate(\n    [\n        np.random.normal(1, 0.5, (sample_size, 1)),\n        np.random.normal(100, 50, (sample_size, 1))\n    ],\n    axis = 1\n)\n\ny = np.dot(X, np.array([500, 5])) + np.random.normal(0, 10, sample_size)\n\nWe will now gradually increase the scaling. Note that the higher scaling coefficient decreases much faster than the second one. Even in relative units:\n\n\\(\\beta_1(\\alpha=0) \\approx 2*\\beta_1(\\alpha=45)\\) coefficient with higher scaling became twice as low;\n\\(\\beta_1(\\alpha=0) \\approx \\beta_1(\\alpha=45)\\) coefficient with lower scaling will decrease a little, but not twice as much as the first coefficient.\n\n\ndisplay_frame = pd.DataFrame(\n    {alpha:Ridge(alpha = alpha).fit(X,y).coef_ for alpha in np.arange(0, 50, 5)}\n).T\n\ndisplay_frame.index.name = \"$\\\\alpha$\"\ndisplay_frame.columns = [\"$\\\\beta_1$\", \"$\\\\beta_2$\"]\ndisplay(display_frame)\n\n\n\n\n\n\n\n\n$\\beta_1$\n$\\beta_2$\n\n\n$\\alpha$\n\n\n\n\n\n\n0\n499.305569\n5.029773\n\n\n5\n451.840445\n5.012651\n\n\n10\n412.616182\n4.998492\n\n\n15\n379.658049\n4.986585\n\n\n20\n351.575574\n4.976432\n\n\n25\n327.361354\n4.967669\n\n\n30\n306.267632\n4.960028\n\n\n35\n287.727714\n4.953306\n\n\n40\n271.304290\n4.947344\n\n\n45\n256.654507\n4.942020\n\n\n\n\n\n\n\nNow we want to do the same operation, but with a standardised feature matrix. Display the coefficients you need to multiply with the standardised and original data in different columns.\nAs the result:\n\nThe coefficients on the standardized data decrease uniformly even in absolute terms;\nIf you transform coefficients to be used directly with the original data, because of the difference in scaling, the absolute decrease is greater for the features with higher scaling, but relatively both coefficients decreases ~ 20%.\n\n\nmeans = X.mean(axis=0)\nstd = X.std(axis = 0)\n\nX_stand = (X-means)/std\n\n\ndisplay_frame = pd.DataFrame(\n    {alpha:Ridge(alpha = alpha).fit(X_stand,y).coef_ for alpha in  np.arange(0, 50, 5)}\n).T\n\ndisplay_frame.index.name = \"$\\\\alpha$\"\ndisplay_frame.columns = [\"$\\\\beta_1$\", \"$\\\\beta_2$\"]\npd.concat(\n    [\n        display_frame,\n        (display_frame+means)/std\n    ],\n    keys=[\"Standardised data\", \"Original data\"],\n    axis = 1\n)\n\n\n\n\n\n\n\n\nStandardised data\nOriginal data\n\n\n\n$\\beta_1$\n$\\beta_2$\n$\\beta_1$\n$\\beta_2$\n\n\n$\\alpha$\n\n\n\n\n\n\n\n\n0\n243.721886\n232.585223\n501.430354\n7.222430\n\n\n5\n237.582185\n226.708414\n488.852137\n7.095341\n\n\n10\n231.744246\n221.121240\n476.892129\n6.974515\n\n\n15\n226.186353\n215.802807\n465.505843\n6.859501\n\n\n20\n220.888825\n210.734182\n454.652961\n6.749890\n\n\n25\n215.833785\n205.898170\n444.296855\n6.645309\n\n\n30\n211.004954\n201.279119\n434.404177\n6.545419\n\n\n35\n206.387481\n196.862749\n424.944500\n6.449913\n\n\n40\n201.967783\n192.636007\n415.890002\n6.358508\n\n\n45\n197.733422\n188.586938\n407.215194\n6.270944"
  },
  {
    "objectID": "machine_learning/models_selection_methods/l2_regularisation.html",
    "href": "machine_learning/models_selection_methods/l2_regularisation.html",
    "title": "L2 (Ridge regularisation)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom IPython.display import clear_output"
  },
  {
    "objectID": "machine_learning/models_selection_methods/l2_regularisation.html#souces",
    "href": "machine_learning/models_selection_methods/l2_regularisation.html#souces",
    "title": "L2 (Ridge regularisation)",
    "section": "Souces",
    "text": "Souces\n\nhttps://www.statlearning.com/ 6 глава."
  },
  {
    "objectID": "machine_learning/models_selection_methods/l2_regularisation.html#description",
    "href": "machine_learning/models_selection_methods/l2_regularisation.html#description",
    "title": "L2 (Ridge regularisation)",
    "section": "Description",
    "text": "Description\nIn L2-regularisation, a component is added to the target function of the coefficient estimation method:\n\\[\\lambda\\sum_{j=1}^n\\beta^2_j\\]\nWhere: - \\(\\beta_j\\) - estimated coefficient; - \\(\\lambda\\) - parameter indicating how much the model should be regularised."
  },
  {
    "objectID": "machine_learning/models_selection_methods/l2_regularisation.html#regression",
    "href": "machine_learning/models_selection_methods/l2_regularisation.html#regression",
    "title": "L2 (Ridge regularisation)",
    "section": "Regression",
    "text": "Regression\nL2-regularisation combined with a regression model is called ridge regression.\nSo if we use MSE as a quality function, we will have a modifide function:\n\\[\\sum_{i=1}^n\\left(y_i - x_i\\beta\\right)^2 + \\lambda\\sum_{j=1}^p\\beta_j \\rightarrow min\\]\nWhere:\n\n\\(n\\) - sample size;\n\\(p\\) - data dimention;\n\\(x_i = (x_{i1}, x_{i2}, ..., x_{ip})\\) - vector describing the \\(i\\text{-}th\\) observation;\n\\(\\beta = (\\beta_1, \\beta_2, ..., \\beta_p)\\) - vector of coefficient estimates.\n\nNote To perform refularization to regression you need to ensure that your features have the same scaling. Check more here."
  },
  {
    "objectID": "machine_learning/models_selection_methods/l2_regularisation.html#compression-of-coefficients",
    "href": "machine_learning/models_selection_methods/l2_regularisation.html#compression-of-coefficients",
    "title": "L2 (Ridge regularisation)",
    "section": "Compression of coefficients",
    "text": "Compression of coefficients\nHere I reproduce the experiment from the ISLR.\nLoading Credit data.\n\nCredit = pd.read_csv(\"Credit.csv\", index_col = 0)\n\nnominal_names = [\n    \"Gender\", \"Student\", \"Married\", \"Ethnicity\"\n]\n\nohe = OneHotEncoder(\n    sparse_output = False, drop = \"first\"\n).fit(\n    Credit[nominal_names]\n)\n\nCredit = pd.concat(\n    [\n        pd.DataFrame(\n            ohe.transform(Credit[nominal_names]),\n            columns = ohe.get_feature_names_out(),\n            index= Credit.index\n        ),\n        Credit.loc[:,~Credit.columns.isin(nominal_names)]\n    ],\n    axis = 1\n)\n\nX = Credit.iloc[:,:-1]\ny = Credit.iloc[:, -1]\n\nCredit.head()\n\n\n\n\n\n\n\n\nGender_Female\nStudent_Yes\nMarried_Yes\nEthnicity_Asian\nEthnicity_Caucasian\nIncome\nLimit\nRating\nCards\nAge\nEducation\nBalance\n\n\nID\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n0.0\n0.0\n1.0\n0.0\n1.0\n14.891\n3606\n283\n2\n34\n11\n333\n\n\n2\n1.0\n1.0\n1.0\n1.0\n0.0\n106.025\n6645\n483\n3\n82\n15\n903\n\n\n3\n0.0\n0.0\n0.0\n1.0\n0.0\n104.593\n7075\n514\n4\n71\n11\n580\n\n\n4\n1.0\n0.0\n0.0\n1.0\n0.0\n148.924\n9504\n681\n3\n36\n11\n964\n\n\n5\n0.0\n0.0\n1.0\n0.0\n1.0\n55.882\n4897\n357\n2\n68\n16\n331\n\n\n\n\n\n\n\nWe will increase the regularisation parameter and take the values of the coefficients. The procedure is rather long, so it is supposed to perform the calculation and put the results in a file.\n\n# coefs_frame = pd.DataFrame(columns = X.columns)\n\n# stand_X = X/np.sqrt(((X - X.mean())**2).sum()/X.shape[0])\n\n# alphas = np.arange(0, 2000, 0.01)\n# int_count = len(alphas)\n\n# for i, alpha in enumerate(alphas):\n#     clear_output(wait=True)\n#     print(\"{}/{}\".format(i, int_count))\n#     coefs_frame.loc[alpha] = pd.Series(\n#         Ridge(alpha = alpha).fit(stand_X,y).coef_,\n#         index = X.columns\n#     )\n    \n# coefs_frame.index.name = \"alpha\"\n# coefs_frame.to_csv(\"l2_regularisation_files/l2_reg_coefs.csv\")\n\nThe obtained values of coefficients are plotted on the graphs.\n\ncoefs_frame = pd.read_csv(\"l2_regularisation_files/l2_reg_coefs.csv\", index_col = 0)\n\nplot_var_names = [\"Limit\", \"Rating\", \"Student_Yes\", \"Income\"]\nline_styles = ['-', '--', '-.', ':']\n\nbeta_0 = np.sqrt(np.sum(coefs_frame.loc[0]**2))\ncoefs_frame[\"beta_i/beta_0\"] = coefs_frame.apply(\n    lambda row: np.sqrt(np.sum(row**2))/beta_0,\n    axis = 1\n)\n\n\nplt.figure(figsize = [15, 7])\nplt.subplot(121)\n\nfor i in range(len(plot_var_names)):\n    plt.plot(\n        coefs_frame.index, \n        coefs_frame[plot_var_names[i]],\n        linestyle = line_styles[i]\n    )\n    \nfor col in coefs_frame.loc[\n    :, ~coefs_frame.columns.isin(plot_var_names)\n]:\n    plt.plot(\n        coefs_frame.index, coefs_frame[col], \n        color = \"gray\", alpha = 0.5\n    )\n    \nplt.legend(plot_var_names)\nplt.xlabel(\"$\\\\lambda$\", fontsize = 14)\n    \nplt.gca().set_xscale(\"log\")\n\nplt.subplot(122)\n\nfor i in range(len(plot_var_names)):\n    plt.plot(\n        coefs_frame[\"beta_i/beta_0\"], \n        coefs_frame[plot_var_names[i]],\n        linestyle = line_styles[i]\n    )\n    \nfor col in coefs_frame.loc[\n    :, ~coefs_frame.columns.isin(plot_var_names)\n]:\n    plt.plot(\n        coefs_frame[\"beta_i/beta_0\"], coefs_frame[col], \n        color = \"gray\", alpha = 0.5\n    )\n\nans = plt.xlabel(\n    \"$\\\\frac{||\\\\hat{\\\\beta}_{\\\\lambda}^R||_2}{||\\\\hat{\\\\beta}||_2}$\",\n    fontsize = 15\n)\n\n\n\n\n\nThe graph on the left shows how the coefficients converge as the regularisation parameter increases. For clarity, a logarithmic scale for the regularisation parameter is taken. The most prominent coefficients are highlighted in colour and line style - the data are standardised, so the scale of the values does not matter;\nThe vergence is plotted to the right on the ordinate:\n\n\\[\\frac{||\\hat{\\beta}_{\\lambda}^R|_2}{||\\hat{\\beta}||_2}\\]\nWhere: - \\(||\\beta||_2 = \\sqrt{\\sum_{j=1}^p \\beta^2_j}\\) - is the Euclidean distance of the coefficients \\(\\beta\\) from the origin; - \\(\\hat{\\beta}\\) - coefficients obtained by the least squares method (equivalent to the coefficients obtained at \\(\\lambda = 0\\)); - \\(\\hat{\\beta}^R_{\\lambda}\\) - coefficients obtained using regularisation."
  },
  {
    "objectID": "machine_learning/classification_task/metrics/GINI/GINI.html",
    "href": "machine_learning/classification_task/metrics/GINI/GINI.html",
    "title": "Сдержание:",
    "section": "",
    "text": "Описание того, что мне известно о показателе GINI (в задаче классификации)\nGINI метрика используемая для определения качества классификационной модели.\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics import roc_curve, auc\n\nimport matplotlib.pyplot as plt\n\nfrom statsmodels.distributions.empirical_distribution import ECDF\nnp.random.seed(10)\n\n\nБазовое опеределение GINI;\nСвязь GINI c ROC.\n\n\nБазовое определение GINI\n Обычно GINI определяют через CAP кривую. GINI для некоторой модели, это отношение площадей между CAP кривой модели и случайной CAP кривой к площади между идеальной CAP и случайной CAP.\n\nПокажем на рисунке:\n\nplot_ss = 10000\n\nnp.random.seed(3)\nrandom_range = np.random.rand(plot_ss)\n\nplot_data = pd.DataFrame({\n    \"p_hat\" : random_range,\n    \"y\" : map(\n        lambda r_val: np.random.choice(\n            [0, 1], p = [1 - r_val, r_val]\n        ), \n        random_range\n    )\n})\n\nplot_data.sort_values(\"y\",inplace = True, ascending = False)\nplot_data[\"p_hat_ideal\"] = np.linspace(1,0, plot_data.shape[0])\n\n\nfpr, or_tpr, t = roc_curve(\n    plot_data[\"y\"], plot_data[\"p_hat\"],\n    drop_intermediate = False\n)\nfpr, id_tpr, t = roc_curve(\n    plot_data[\"y\"], plot_data[\"p_hat_ideal\"],\n    drop_intermediate = False\n)\n\nCAP_x = np.arange(len(or_tpr))/len(or_tpr)\n\n\nplt.figure(figsize = [10,7])\nplt.plot(CAP_x, or_tpr, linewidth = 5)\nplt.plot(CAP_x, id_tpr, linewidth = 5)\nplt.plot(\n    [0,1], [0,1], color = \"red\", \n    linestyle = \"dashed\",\n    linewidth = 5\n)\n\nplt.fill_between(\n    np.arange(len(or_tpr))/len(or_tpr),\n    or_tpr,\n    np.arange(len(or_tpr))/len(or_tpr),\n    hatch = \"//\",\n    alpha = 0\n)\nplt.fill_between(\n    np.arange(len(or_tpr))/len(or_tpr),\n    id_tpr,\n    np.arange(len(or_tpr))/len(or_tpr),\n    hatch = \"\\\\\\\\\",\n    alpha = 0\n)\n\nplt.xlabel(\"Доля наблюдений\", fontsize = 15)\nplt.ylabel(\"$TPR$\", fontsize = 15)\n\nplt.xlim([0,1])\nplt.ylim([-0.005,1.005])\n\nplt.legend(\n    [\n        \"CAP модели\", \"Идеальная CAP\", \n        \"Случайная CAP\", \"A\", \"B\"\n    ],\n    fontsize = 14\n)\n\n&lt;matplotlib.legend.Legend at 0x7ff53d4a7fa0&gt;\n\n\n\n\n\nСледуя обозначениям площадей на рисунке, получаем:\n\\[GINI = \\frac{A}{B}\\]\nИли испозуя альтернативное обозначение площадей (по, пока, незвенстной причине особенно популярное)\n\nplt.figure(figsize = [10,7])\nplt.plot(CAP_x, or_tpr, linewidth = 5)\nplt.plot(CAP_x, id_tpr, linewidth = 5)\nplt.plot(\n    [0,1], [0,1], color = \"red\", \n    linestyle = \"dashed\",\n    linewidth = 5\n)\n\nplt.fill_between(\n    np.arange(len(or_tpr))/len(or_tpr),\n    or_tpr,\n    np.arange(len(or_tpr))/len(or_tpr),\n    hatch = \"//\",\n    alpha = 0\n)\nplt.fill_between(\n    np.arange(len(or_tpr))/len(or_tpr),\n    id_tpr,\n    or_tpr,\n    hatch = \"\\\\\\\\\",\n    alpha = 0\n)\n\nplt.xlabel(\"Доля наблюдений\", fontsize = 15)\nplt.ylabel(\"$TPR$\", fontsize = 15)\n\nplt.xlim([0,1])\nplt.ylim([-0.005,1.005])\n\nans = plt.legend(\n    [\n        \"CAP модели\", \"Идеальная CAP\", \n        \"Случайная CAP\", \"A\", \"B\"\n    ],\n    fontsize = 14\n)\n\n\n\n\n\\[GINI = \\frac{A}{B+A}\\]\n\n\n\nСвязь GINI c ROC\n Есть альтернативный способ подсчитать \\(GINI\\) - через ROC кривую.\n\nАналитическое доказательсво\nВ качесве примера возьмем таблицу которую использовали при рассмотрении CAP кирвой. Каждое полученное тождество буду сверять с этим примером, для того, что-бы быть уверенным, в том, что в процессе не допущено ошибок.\n\n\n\n\\(i\\)\n\\(\\hat{p}_i\\)\n\\[y_i\\]\n\\[i/n\\]\n\\[TPR_i\\]\n\\[FPR_i\\]\n\n\n\n\n1\n0.8\n1\n0.2\n1/3\n0\n\n\n2\n0.7\n1\n0.4\n2/3\n0\n\n\n3\n0.6\n0\n0.6\n2/3\n1/2\n\n\n4\n0.4\n0\n0.8\n2/3\n1\n\n\n5\n0.2\n1\n1\n1\n1\n\n\n\nСразу обозначим, что \\(FPR_0=TPR_0=0\\).\nВсе массивы примера, что на м понадобиться, загоняем в память компьютера.\n\nn = 5\nTPR = np.array([0, 1/3, 2/3, 2/3, 2/3, 1])\nFPR = np.array([0, 0, 0, 1/2, 1, 1])\ni = np.arange(6)\ny = np.array([1,1,0,0,1])\n\nЗапишем площадь под ROC кривой, что и будет показателем \\(AUC_{roc}\\):\n\\[AUC_{roc} = \\sum_{i=0}^{n-1} (FPR_{i+1} - FPR_i)(TPR_{i+1} + TPR_i)/2. \\tag{1}\\]\n\\(GINI\\) от сюда выражается:\n\\[GINI = 2AUC_{roc}-1. \\tag{2}\\]\n\nauc_roc = np.sum((FPR[1:] - FPR[:-1])*(TPR[1:] + TPR[:-1])/2)\n2*auc_roc - 1\n\n0.33333333333333326\n\n\nЗапишем площадь под дейсвтительной CAP кривой:\n\\[AUC_{cap} = \\sum_{i=0}^{n-1}([i+1]/n - i/n)(TPR_{i+1} + TPR_i)/2 = \\sum_{i=0}^{n-1}(TPR_{i+1} + TPR_i)/2n.\\]\nТогда площадь между случайной CAP кривой и действительной CAP кривой будет выражаться так:\n\\[AUC_{cap}' = \\sum_{i=0}^{n-1}(TPR_{i+1} + TPR_i)/2n - 0.5.\\tag{3}\\]\nПодсчитаем эту величину, для нашего примера:\n\nAUC_cap = sum((i[1:]/n - i[:-1]/n)*(TPR[1:] + TPR[:-1])/2) - 0.5\nAUC_cap\n\n0.06666666666666654\n\n\nК записи площади под идеальной CAP кривой лучше подойти с геометрической точки зрения:\n\ny_rel_ideal = [0, 1/3, 2/3, 1, 1, 1]\nx_rel = [i/5 for i in range(6)]\n\nplt.figure(figsize = [10, 7])\n\nplt.plot(x_rel, y_rel_ideal)\nplt.fill_between(\n    [0, 0.6], [0, 1], [0,0],\n    alpha = 0, hatch = \"//\"\n)\nplt.fill_between(\n    [0.6, 1], [0, 0], [1,1],\n    alpha = 0, hatch = \"\\\\\\\\\"\n)\n\nplt.yticks([0, 1])\nplt.xticks(\n    [0, 0.6, 1],\n    [\"0\", \"$\\gamma$\", \"1\"],\n    fontsize = 14\n)\n\nplt.title(\n    \"Идеальная CAP кривая\",\n    fontsize = 15\n)\n\nplt.grid()\nplt.xlabel(\"Доля наблюдений\", fontsize = 15)\n\nText(0.5, 0, 'Доля наблюдений')\n\n\n\n\n\nГде \\(\\gamma\\) - доля наблюдений с проявлением признака:\n\\[\\gamma = \\frac{\\sum_{i=1}^ny_i}{n}.\\]\nЭта площадь раскладывается на 2 фигуры: - Треугольник, выделенный штриховкой наклоненной влево; - Прямоугольник, выделейнный штрифовной наклоненной вправо.\nОчевидно такую площадь можно записать:\n\\[AUC^I = \\gamma/2 + (1-\\gamma) = 1 - \\gamma/2.\\]\nТогда площадь можду идеальной CAP кривой и случайной CAP кривой составит:\n\\[AUC'^I = 1 + \\gamma/2 - 0.5=0.5 - \\gamma/2.\\]\nИли подставляя \\(\\gamma\\):\n\\[AUC'^I = 0.5 - \\frac{\\sum_{i=1}^{n}y_i}{2n}.\\tag{4}\\]\nПодсчитаем значение, принимаемое данной величиной, для нашего примера:\n\nAUC_I = 0.5-sum(y)/(2*n)\nAUC_I\n\n0.2\n\n\nТогда \\(GINI\\) через CAP кривую:\n\\[GINI = \\frac{AUC_{cap}'}{AUC'^I}. \\tag{5}\\]\nУбедимся, что он совпадает с числом полученным через ROC:\n\nAUC_cap/AUC_I\n\n0.3333333333333327\n\n\nИ так, для доказательства нам следуем показать равенство выражений \\((2),(5)\\), подставив туда \\((1),(3),(4)\\) или:\n\\[2AUC_{roc}-1 = \\frac{AUC_{cap}'}{AUC'^I} \\Leftrightarrow\\] \\[\\Leftrightarrow 2\\left[\\sum_{i=0}^{n-1} (FPR_{i+1} - FPR_i)(TPR_{i+1} + TPR_i)/2\\right] -1 =\n\\frac{\n    \\sum_{i=0}^{n-1}(TPR_{i+1} + TPR_i)/2n - \\frac{1}{2}\n}{\n    \\frac{1}{2} - \\frac{\\sum_{i=1}^{n}y_i}{2n}\n} \\Leftrightarrow \\tag{6}\\]\n\\[\\Leftrightarrow \\left[\\sum_{i=0}^{n-1} (FPR_{i+1} - FPR_i)(TPR_{i+1} + TPR_i)\\right] -1 =\n\\frac{\n    \\sum_{i=0}^{n-1}(TPR_{i+1} + TPR_i)/2n - \\frac{1}{2}\n}{\n    \\frac{1}{2} - \\frac{\\sum_{i=1}^{n}y_i}{2n}\n}\\]\nБудем работать с правой частью тождества:\n\\[\\frac{\n    \\sum_{i=0}^{n-1}(TPR_{i+1} + TPR_i)/2n - \\frac{1}{2}\n}{\n    \\frac{1}{2} - \\frac{\\sum_{i=1}^{n}y_i}{2n}\n}=\\]\n\\[=\\frac{\n    \\sum_{i=0}^{n-1}(TPR_{i+1} + TPR_i)/2n - \\frac{1}{2}\n}{\n    \\frac{n - \\sum_{i=1}^{n}y_i}{2n}\n}=\\]\n\\[=\\frac{\n    \\left[\\sum_{i=0}^{n-1}(TPR_{i+1} + TPR_i)\\right] - n\n}{\n    n - \\sum_{i=1}^{n}y_i\n}=\\]\n\\[\n=\\left[\\sum^{n-1}_{i=0}\n    \\frac{1}{n - \\sum_{i=1}^{n}y_i}(TPR_{i+1}+TPR_i)\n    \\right] - \\frac{n}{n - \\sum_{i=1}^{n}y_i}\n\\tag{7}\n\\]\nУбедимся на числах, что проделанные пребразования корректны.\n\n(sum(TPR[1:] + TPR[:-1])-n)/(n-sum(y))\n\n0.33333333333333304\n\n\nБудем работать с левой частью тождества:\n\\[\n\\left[\\sum_{i=0}^{n-1} (FPR_{i+1} - FPR_i)(TPR_{i+1} + TPR_i)\\right] -1 \\tag{8}\n\\]\nОбсудим свойсва выражения:\n\\[\n(FPR_{i+1} - FPR_i)\n\\]\n\\(FPR\\) (доля ложно положительных предсказаний) прирастает только для предсказаний без проявления признака. А, для наблюдения без проявления признака, прирастает на долю, которую занимает одно набллюдение без проявления признка:\n\\[\n(FPR_{i+1} - FPR_i)=\\begin{cases}\n    0, y_i=1;\\\\\n    \\frac{1}{n-\\sum_i^n y_i}, y_i=0.\n\\end{cases}\n\\]\nГде \\(n-\\sum_i^n y_i\\) - число наблюдений без проявления признака, тогда:\n\\[\\frac{1}{n-\\sum_i^n y_i}\\]\nдоля в одного наблюдения в наблюдениях с проявлением признака.\nТогда выражение \\((8)\\) может быть переписано следующим образом:\n\\[\n\\left[\\sum_{i|y_{i+1}=0} \\frac{1}{\\sum_{i=1}^n n-y_i}(TPR_{i+1} + TPR_i)\\right] -1\n\\tag{9}\n\\]\nТо есть суммирование можно произвести только для членов, для которых \\(y_{i+1}=0\\), все остальные будут равняться нулю. При том в не нулевых членнах один из множителей - константа относительно оператора суммирования.\nУбедимся, что проделанные преобразования корректны:\n\nnp.sum(\n    (1/(n - sum(y)))*\\\n    (TPR[1:][y==0] + TPR[:-1][y==0])\n) - 1\n\n0.33333333333333326\n\n\nТеперь допустим, что тождество \\((6)\\) верно. Тогда, учитвая во внимание, последние результаты \\((7), (9)\\):\n\\[\n\\left[\\sum^{n-1}_{i=0}\n    \\frac{1}{n - \\sum_{i=1}^{n}y_i}(TPR_{i+1}+TPR_i)\n    \\right] - \\frac{n}{n - \\sum_{i=1}^{n}y_i}\n=\n\\left[\\sum_{i|y_{i+1}=0} \\frac{1}{n-\\sum_{i=1}^n y_i}(TPR_{i+1} + TPR_i)\\right] -1\n\\Leftrightarrow \\tag{10}\\]\n\\[\n\\Leftrightarrow\n\\left[\\sum^{n-1}_{i=0}\n    \\frac{1}{n - \\sum_{i=1}^{n}y_i}(TPR_{i+1}+TPR_i)\n    \\right] -\n    \\left[\\sum_{i|y_{i+1}=0} \\frac{1}{n-\\sum_{i=1}^n y_i}(TPR_{i+1} + TPR_i)\\right] -\n    \\frac{n}{n - \\sum_{i=1}^{n}y_i} + 1\n= 0\n\\]\nОбратите внимание на выражения в квадратных скобках - они полностью совпадают, отличается лишь число компонент суммирования, т.е. после вычитания остануться только те компоненты которых нет в вычитаемом:\n\\[\n\\left[\n    \\sum_{i|y_{i+1}=1} \\frac{1}{n-\\sum_{i=1}^n y_i}(TPR_{i+1} + TPR_i)\n\\right] -\n    \\frac{n}{n - \\sum_{i=1}^{n}y_i} + 1\n= 0\n\\]\nУбедисмя, что представленное равенстно верно:\n\nsum(\n   (1/(n-sum(y)))*(TPR[1:][y==1] + TPR[:-1][y==1])\n) -\\\nn/(n-sum(y)) + 1\n\n0.0\n\n\nДалее можно провести рад преобразований над полученным выражением:\n\\[\n\\left[\n    \\sum_{i|y_{i+1}=1} \\frac{1}{n-\\sum_{i=1}^n y_i}(TPR_{i+1} + TPR_i)\n\\right] -\n    \\frac{n}{n - \\sum_{i=1}^{n}y_i} + 1\n= 0 \\Leftrightarrow\n\\]\n\\[\n\\Leftrightarrow\n\\left[\n    \\sum_{i|y_{i+1}=1} \\frac{1}{n-\\sum_{i=1}^n y_i}(TPR_{i+1} + TPR_i)\n\\right] -\n    \\frac{\\sum_{i=1}^{n}y_i}{n - \\sum_{i=1}^{n}y_i}\n= 0\n\\Leftrightarrow\n\\]\n\\[\n\\Leftrightarrow\n\\frac{1}{n-\\sum_{i=1}^n y_i}\n\\left\\{\n    \\left[\n        \\sum_{i|y_{i+1}=1} (TPR_{i+1} + TPR_i)\n    \\right] -\n       \\sum_{i=1}^{n}y_i\n\\right\\}\n= 0\n\\]\nУчитывая, что выражение \\(\\frac{1}{n-\\sum_{i=1}^n y_i}\\) не отрицательное. То для выполнения последнего тождества необходимо, чтобы:\n\\[\n\\left[\n    \\sum_{i|y_{i+1}=1} (TPR_{i+1} + TPR_i)\n\\right] -\n   \\sum_{i=1}^{n}y_i\n=0 \\tag{11}\\]\nРассмотрим сумму в квадратных скобрах:\n\\[\\sum_{i|y_{i+1}=1} (TPR_{i+1} + TPR_i)\\]\nПерепишем её проще, но держа в памяти, что суммирование проводится только по наблюдениям с проявлением признака:\n\\[\\sum_{i=0}^{m-1} (TPR_{i+1} + TPR_i)\\]\nГде \\(m=\\sum_{i=1}^{n}y_i\\).\nТеперь вспомним, что \\(TPR\\) это доля клиентов, с проявлением, признака для которых было предсказано проявление признака. Получается, что для каждого клиента с проявлением признака \\(TPR\\) возрастает на \\(\\frac{1}{m}\\). Тогда в данной сумме. можно записать, что:\n\\[\n\\sum_{i=0}^{m-1} \\left(\\frac{i+1}{m} + \\frac{i}{m}\\right)=\n\\sum_{i=0}^{m-1} \\left(\\frac{2i+1}{m}\\right)\n\\]\nВозвращаясь к тождеству \\((10)\\) и используя нововведенные обозначения:\n\\[\n\\sum_{i=0}^{m-1} \\left(\\frac{2i+1}{m}\\right)=m\\Leftrightarrow\n\\sum_{i=0}^{m-1} 2i+1 = m^2\n\\tag{12}\n\\]\nДоказав это пождество мы докажем, что выполняется вся цепочка тождеств выше. Есть уже очень похожее доказательсво, представленное тут. Но мы его приведдем для нашего примера:\nРаспишем выражение:\n\\[\\sum_{i=0}^{m-1} 2i+1 = 1 + 3 + 5 + ... + 2(m-1)+1.\\]\nТут не хватает четных чисел в суммации добавим и отнимем их:\n\\[\\sum_{i=0}^{m-1} 2i+1 = \\{1 + 3 + 5 + ... + [2(m-1)+1]\\} + \\{2 + 4 + 6 + ... + 2(m-1)\\} - \\{2 + 4 + 6 + ... + 2(m-1)\\}.\\]\nОбъединим и упрядочим компоненты первых и вторых фигурных скобок и вынесем 2 из вторых:\n\\[\\sum_{i=0}^{m-1} 2i+1 = \\{1 + 2 + 3 + 4 + ... + 2(m-1) + [2(m-1)+1]\\} - 2\\{1 + 2 + 3 + ... + (m-1)\\}.\\]\nВозвращаясь к оператом суммирования получаем:\n\\[\\sum_{i=0}^{m-1} 2i+1 = \\left[\\sum_{i=1}^{2(m-1)+1}i\\right] - 2\\left[\\sum_{i=1}^{m-1}i\\right]. \\tag{13}\\]\nДалее надо выразить:\n\\[\\sum_{i=1}^\\nu i.\\]\nТут можно найти, что:\n\\[2\\sum_{i=1}^\\nu i = \\sum_{i=1}^\\nu i + \\sum_{i=1}^\\nu i = [1 + 2 + ... + (\\nu-1) + \\nu] + [\\nu + (\\nu-1) + ... + 2 + 1]=\\] \\[=(\\nu+1) + (\\nu-1+2) + ... + (2 + \\nu - 1) + (\\nu+1)=\\] \\[=(\\nu+1) + (\\nu+1) + ... + (\\nu+1)=\\] \\[=\\sum_{i=1}^n (\\nu+1) = \\nu(\\nu+1)\\]\nИ так:\n\\[2\\sum_{i=1}^\\nu i = \\nu(\\nu+1) \\Leftrightarrow \\sum_{i=1}^\\nu i = \\frac{\\nu(\\nu +1)}{2}\\]\nТогда, возвращаясь к \\((13)\\) получаем: \\[\n\\sum_{i=0}^{m-1} 2i+1 =\n\\] \\[\n=\\frac{[2(m-1)+1]([2(m-1)+1] + 1)}{2} - 2\\frac{[m-1]([m-1]+1)}{2}=.\n\\] \\[\n=\\frac{2m[2m+1]}{2} - [m-1]([m-1]+1)=\n\\] \\[\n=m[2m+1] - m[m-1] =\n\\] \\[\n= 2m^2+m-m^2-m=\n\\] \\[\n= m^2\n\\]\nИ так получается, что:\n\\[\\sum_{i=0}^{m-1} 2i+1 = m^2\\]\nТаким образом, выполняется тождество \\((12)\\), получается справедливым \\((11)\\), за ним \\((10)\\) и окончательно \\((6)\\boxtimes\\).\n\n\nВычислительный экперимент\nПредполагается сэмитировать результаты не которого классификатора и подсчитать для него \\(GINI\\) обоими методами, для того, чтобы убедиться, что результат одинаковый.\nЭмитация результата модели\n\nplot_ss = 10000\n\nnp.random.seed(3)\nrandom_range = np.random.rand(plot_ss)\n\nplot_data = pd.DataFrame({\n    \"p_hat\" : random_range,\n    \"y\" : map(\n        lambda r_val: np.random.choice(\n            [0, 1], p = [1 - r_val, r_val]\n        ), \n        random_range\n    )\n})\n\nplot_data.head()\n\n\n\n\n\n\n\n\np_hat\ny\n\n\n\n\n0\n0.550798\n0\n\n\n1\n0.708148\n1\n\n\n2\n0.290905\n1\n\n\n3\n0.510828\n0\n\n\n4\n0.892947\n1\n\n\n\n\n\n\n\nВычисление через ROC\n\n# вычисление точек ROC-кривой\nfpr, tpr, t = roc_curve(\n    plot_data[\"y\"], plot_data[\"p_hat\"],\n    drop_intermediate = False\n)\n# вычисление GINI через площадь точек под\n# ROC кривой\n2*auc(fpr, tpr) - 1\n\n0.6599391056843444\n\n\nВычисление через CAP\n\nplot_data.sort_values(\"y\",inplace = True, ascending = False)\nplot_data[\"p_hat_ideal\"] = np.linspace(1,0, plot_data.shape[0])\n\n\n# вычисление ординат наблюдаемой CAP кривой\n_, tpr_real, _= roc_curve(\n    plot_data[\"y\"], plot_data[\"p_hat\"],\n    drop_intermediate = False\n)\n# вычисление площади под CAP\nideal_CAP_auc = plot_data[\"y\"].sum()/plot_data.shape[0]/2 + \\\n(plot_data[\"y\"] == 0).sum()/plot_data.shape[0]\n# вычисление ординат случайной CAP\ntpr_random = np.linspace(0,1, len(tpr_real))\n\nB = ideal_CAP_auc - 0.5\nA = auc(tpr_random, tpr_real) - 0.5\nA/B\n\n0.6599391056843441\n\n\nОтличие только в последнем знаке и, скорее всего, обусловлено округлением.\n(sum(tpr_real[1:] + tpr_real[:-1]) - plot_data.shape[0])/\n(plot_data.shape[0] - plot_data[“y”].sum())"
  },
  {
    "objectID": "machine_learning/classification_task/metrics/CAP/CAP.html",
    "href": "machine_learning/classification_task/metrics/CAP/CAP.html",
    "title": "Содержание:",
    "section": "",
    "text": "Как работает CAP кривая\nИсточники:\n\nhttps://en.wikipedia.org/wiki/Cumulative_accuracy_profile - статься на википедии посвященная CAP кривой;\nhttps://medium.com/geekculture/classification-model-performance-evaluation-using-auc-roc-and-cap-curves-66a1b3fc0480 - простенькая статейка но с примерами кода на python3.\n\nБибилиотеки\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import accuracy_score, auc\n\nfrom statsmodels.distributions.empirical_distribution import ECDF\n\n\nОпределение CAP кривой;\nИдеальная CAP кривая;\nСлучайная CAP кривая;\n\\(TPR\\) на оси ординат у CAP.\n\n # Определение CAP кривой\nCAP кривая представляет собой кумулятивное число положительных исходов по оси ординат по отношению к соответствующему кумулятивному числу классифицирующего параметра по оси абсцысс.\n\nБазовое понимае CAP кривой на примере\nНапример, пусть некоторая модель предсказывает вероятности \\(\\hat{p}_i\\) того, что \\(y_i=1\\) (у \\(i\\)-го клиента положительный исход, проявление признака). Допустим в тестовой выборке у нас 5 наблюдений имеются предсказания для них и настоящий класс:\n\n\n\n\\(\\hat{p}_i\\)\n\\[y_i\\]\n\n\n\n\n0.2\n1\n\n\n0.6\n0\n\n\n0.8\n1\n\n\n0.7\n1\n\n\n0.4\n0\n\n\n\nДля того чтобы построить CAP кривую надо: 1. Отсортировать наблюдения по убыванию \\(\\hat{p}_i\\);\n\n\n\n\\(\\hat{p}_i\\)\n\\[y_i\\]\n\n\n\n\n0.8\n1\n\n\n0.7\n1\n\n\n0.6\n0\n\n\n0.4\n0\n\n\n0.2\n1\n\n\n\n2. Пронумеровать каждое наблюедение начиная от 1;\n\n\n\n\\(i\\)\n\\(\\hat{p}_i\\)\n\\[y_i\\]\n\n\n\n\n1\n0.8\n1\n\n\n2\n0.7\n1\n\n\n3\n0.6\n0\n\n\n4\n0.4\n0\n\n\n5\n0.2\n1\n\n\n\n3. Вычислить кумулятивную сумму \\(y_i\\) (\\(\\hat{S}_{\\hat{y}}\\));\n\n\n\n\\(i\\)\n\\(\\hat{p}_i\\)\n\\[y_i\\]\n\\[\\hat{S}_{\\hat{y}}\\]\n\n\n\n\n1\n0.8\n1\n1\n\n\n2\n0.7\n1\n2\n\n\n3\n0.6\n0\n2\n\n\n4\n0.4\n0\n2\n\n\n5\n0.2\n1\n3\n\n\n\nНачиная с точки (0,0) и продолжая пременными \\(i\\) и \\(\\hat{S}_{\\hat{y}}\\) на график наносят CAP кривую.\n\nplt.figure(figsize = [10,7])\n\nx = list(range(6))\ny = [0,1,2,2,2,3]\n\nplt.plot(x, y, marker = \".\")\n\nplt.xlabel(\"Число наблюдений\", fontsize = 15)\nplt.ylabel(\"$\\hat{S}_{\\hat{y}}$\", fontsize = 15)\n\nfor x_val, y_val in zip(x, y):\n    plt.text(x_val, y_val + 0.05, x_val, fontsize = 14)\n\nplt.yticks(y)\nplt.grid()\n\n\n\n\nИнтерпритация у \\(i\\)-й точки следующая: в \\(i\\) худших, по мнению модели, наблюдениях лежит \\(\\hat{S}_{\\hat{y}_i}\\) проявлений признака. Или для каждой точки:\n\nВ 1 худших, по менинию модели, наблюдениях лежит 1 проявлений признака;\nВ 2 худших, по менинию модели, наблюдениях лежит 2 проявлений признака;\nВ 3 худших, по менинию модели, наблюдениях лежит 2 проявлений признака;\nВ 4 худших, по менинию модели, наблюдениях лежит 2 проявлений признака;\nВ 5 худших, по менинию модели, наблюдениях лежит 3 проявлений признака.\n\n\n\nОтносительная CAP кривая\nЕсли по оси абсцысс откладывать не номер наблюдения \\(i\\) а \\(i/n\\) (где \\(n\\) - число наблюдений на которых вычисляется CUP кривая) и по оси ординат откладывать не кумулятивную сумму, но кумулятивный процент (величина, совпадающся с \\(TPR\\), подробнее), то получиться, так мной названная, относительная CAP кривая, такая же по форме, но ограниченная в единичном квадрате: \n\n\n\n\\(i\\)\n\\(\\hat{p}_i\\)\n\\[y_i\\]\n\\[\\hat{S}_{\\hat{y}}\\]\n\\[i/n\\]\n\\[TPR_i\\]\n\n\n\n\n1\n0.8\n1\n1\n0.2\n1/3\n\n\n2\n0.7\n1\n2\n0.4\n2/3\n\n\n3\n0.6\n0\n2\n0.6\n2/3\n\n\n4\n0.4\n0\n2\n0.8\n2/3\n\n\n5\n0.2\n1\n3\n1\n1\n\n\n\n\nplt.figure(figsize = [10,7])\n\ny_rel = [0, 1/3, 2/3, 2/3, 2/3, 1]\nx_rel = [i/5 for i in range(6)]\n\nplt.plot(\n    x_rel, y_rel, marker = \".\"\n)\n\nplt.xlabel(\"Доля наблюдений\", fontsize = 15)\n\nplt.ylabel(\"$TPR$\", fontsize = 15)\n\nfor i, (x_val, y_val) in enumerate(zip(x_rel, y_rel)):\n    plt.text(x_val, y_val + 0.02, i, fontsize = 14)\n    \nplt.yticks(y_rel)\nplt.grid()\n\n\n\n\nИнтерпритация \\(i\\)-й точки будет следующая: в \\(i/n*100\\%\\) худших, по мнению модели, наблюдениях лежит \\(\\hat{F}_{\\hat{y}i}*100\\%\\) проявлений признака. Или для каждой точки в рассматриваемом примере:\n\nВ 0% худших, по мнению модели, наблюдениях лежит 0% проявлений признака;\nВ 20% худших, по мнению модели, наблюдениях лежит 33% проявлений признака;\nВ 40% худших, по мнению модели, наблюдениях лежит 67% проявлений признака;\nВ 60% худших, по мнению модели, наблюдениях лежит 67% проявлений признака;\nВ 80% худших, по мнению модели, наблюдениях лежит 67% проявлений признака;\nВ 100% худших, по мнению модели, наблюдениях лежит 100% проявлений признака.\n\nДалее, по умолчанию, будет обсуждаться именно относительная CAP кривая, потому как она мне видится более применимой.\n # Идеальная CAP кривая\nИграет важную роль в понимании механизма CAP кривой.\n\n\nОписание\nИдеальный классификатор обладает следующим совойсвом - он из входной комбинации переменных, отписывающих наблюдение, \\(X_i\\) может сделать такую дискриминирующую переменную \\(p_i\\), чтобы:\n\\[y_i=1,y_j=0 \\Rightarrow p_i&gt;p_j; \\forall i,j; i\\neq j\\]\nТо есть для любых двух наблюдений (\\(i\\)-го и \\(j\\)-го) если одно имеет проявление признака а другое нет, то предсказание для перовго должно быть больше.\nВ таких условиях, после сортировки по убыванию, все наблюдения с проявлением признака окажуться выше чем все наблюдения без проялвения признака. Следовательно CAP кривая будет расти только в начале, пока идут только наблюдения с проявлением признака. Так пока она не достигнет 1 - в точке соответсвующей самому низкому предсказанию для наблюдения с проявлением признака. Затем будет неизменна для всех наблюдений без проявления признака.\n\n\nДемонстрация на примере\nВозвращаясь к примеру из прошлого раздела, последняя рассмотренная таблица, в случае идеального классификатора должна была бы быть отсортирована так:\n\n\n\n\\(i\\)\n\\(\\hat{p}_i\\)\n\\[y_i\\]\n\\[\\hat{S}_{\\hat{y}}\\]\n\\[i/n\\]\n\\[TPR\\]\n\n\n\n\n1\n0.8\n1\n1\n0.2\n1/3\n\n\n2\n0.7\n1\n2\n0.4\n2/3\n\n\n3\n0.2\n1\n2\n0.6\n1\n\n\n4\n0.6\n0\n2\n0.8\n1\n\n\n5\n0.4\n0\n3\n1\n1\n\n\n\nВсе наблюдения с \\(y_i=1\\) выше нежели наблюдения для которых \\(y_i=0\\). Добавим идеальную CAP кривую к прошлому графику.\n\nplt.figure(figsize = [10,7])\n\ny_rel = [0, 1/3, 2/3, 2/3, 2/3, 1]\ny_rel_ideal = [0, 1/3, 2/3, 1, 1, 1]\nx_rel = [i/5 for i in range(6)]\n\nplt.plot(x_rel, y_rel, marker = \".\")\nplt.plot(x_rel, y_rel_ideal, marker = \".\", color = \"green\")\n\nplt.xlabel(\"Доля наблюдений\", fontsize = 15)\nplt.ylabel(\"$TPR$\", fontsize = 15)\n\nplt.legend(\n    [\"Действительная CAP\", \"Идеальная CAP\"],\n    fontsize = 15\n)\n\nplt.yticks(y_rel)\nplt.grid()\n\n\n\n\n # Случайная CAP кривая\nВместе с идеальной исползуется для понимания насколько хороша или плоха та или иная модель.\n\n\nОписание\nИз рассуждений, предложенных выше, становиться понятно, что чем быстрее CUP кривая растет в начале, тем лучше оциниваемый классификатор. Понятно, что случайный классификатор будет образовывать CAP которая приростает равномерно на любой области доли рассмотренных наблюдений. Потому, в случае генеральной совокупности, это будет просто прямая протянутая от точки (0,0) до точки (1,1). В случае выборки это будет кривая с очень близкими (или, в некоторых случаях, совпадающими) характеристиками.\n\n\nВычислительный эксперимент\nРассмотрим вычислительный эксперимент: сэмитируем случайный классификатор и постоим для него CAP.\n\ndef plot_random_CAP(sample_size):\n    experimental_sample = pd.DataFrame({\n        \"p_hat\" : np.random.rand(sample_size),\n        \"y\" : np.random.choice([0,1], sample_size)\n    })\n\n    experimental_sample.sort_values(\n        \"p_hat\", ascending = False,\n        inplace = True\n    )\n\n    experimental_sample[\"$$\\hat{F}_{\\hat{y}}$$\"] = ECDF(\n        1 - experimental_sample.query(\"y == 1\")[\"p_hat\"]\n    )(1 - experimental_sample[\"p_hat\"])\n    experimental_sample.head()\n\n    experimental_sample[\"$i$\"] = range(1, sample_size + 1)\n    experimental_sample[\"$i/n$\"] = experimental_sample[\"$i$\"]/sample_size\n\n    plt.plot(\n        experimental_sample[\"$i/n$\"], \n        experimental_sample[\"$$\\hat{F}_{\\hat{y}}$$\"],\n        color = \"red\"\n    )\n    plt.xlim([0,1])\n    plt.ylim([0,1])\n    plt.xlabel(\"Доля наблюдений\")\n    plt.ylabel(\"$FPR$\")\n    \n    \nsample_sizes = [500, 1000, 5000, 10000]\nplt.figure(figsize = [15, 10])\nfor i in range(4):\n    plt.subplot(2, 2, i+1)\n    plt.title(\"Размер выборки \" + str(sample_sizes[i]))\n    plot_random_CAP(sample_sizes[i])\n\n\n\n\nВидно, что такая кривая дейсвительно стремиться к диагональной прямой с увеличением объема выборки. Потому, в прикладных исследованиях, ее принимают равной диагональной прямой.\n\n\nДополняя пример прошлого раздела\nТогда полный CAP график, для рассмотренного примера, примет вид:\n\nplt.figure(figsize = [10,7])\n\ny_rel = [0, 1/3, 2/3, 2/3, 2/3, 1]\ny_rel_ideal = [0, 1/3, 2/3, 1, 1, 1]\nx_rel = [i/5 for i in range(6)]\n\nplt.plot(x_rel, y_rel, marker = \".\")\nplt.plot(\n    x_rel, y_rel_ideal, \n    marker = \".\", color = \"green\"\n)\nplt.plot(\n    [0,1], [0,1],\n    color = \"red\", marker = \".\"\n)\n\nplt.xlabel(\"Доля наблюдений\", fontsize = 15)\nplt.ylabel(\"$TPR$\", fontsize = 15)\n\nplt.legend(\n    [\n        \"Действительная CAP\", \n        \"Идеальная CAP\",\n        \"Случайная CAP\"\n    ],\n    fontsize = 15\n)\n\nplt.yticks(y_rel)\nplt.grid()\n\n\n\n\n # \\(TPR\\) на оси ординат у CAP\n\\(TPR\\) это доля правильно предсказнных наблюдений проявлений признака при точке отсчения \\(p'\\):\n\\[TPR_i(p')=\\sum_{i=1}^n\\frac{I(\\hat{p}_i \\geq p')}{n};\\]\n\\[I(\\hat{p}_i \\geq p')=\\begin{cases}\n    1, \\hat{p}_i \\geq p';\\\\\n    0, \\text{в противном случае}.\n\\end{cases}\\]\nЭта величина и будет на оси ординат CAP-кривой.\n\n\nПроверка на примере\nВесьма условноая вроверка, но все же, рассчитаем \\(TPR\\) как мы считали для CAP кривой и получим его используя sklearn.metrics.roc_curve и сравнить.\n\nfrom sklearn.metrics import roc_curve\n\nnp.random.seed(10)\n\nsample_size = 200\n\n\ntest_df = pd.DataFrame({\n    \"p_hat\" : np.random.rand(sample_size),\n    \"y\" : np.random.choice([0,1], sample_size)\n})\n\n# подсчет подобно тому как мы слитали для CAP\nCAT_TPR = np.concatenate([\n    [0],# для нулевой точки отсечния нужно добачить 0\n    np.sort(\n        ECDF(1 - test_df.query('y == 1')[\"p_hat\"])\\\n        (1 - test_df[\"p_hat\"])\n    )\n])\n\n# вычисление используя, которвый инструмент\nfpr, tpr, t = roc_curve(\n    test_df[\"y\"],\n    test_df[\"p_hat\"],\n    drop_intermediate = False\n)\n\n# сравнение - c точностью до 4-ех знаков после запятой\nall(np.round(CAT_TPR,4) == np.round(tpr,4))\n\nTrue\n\n\nВсе верно - величины совпадают."
  },
  {
    "objectID": "machine_learning/data_transformations/PCA.html",
    "href": "machine_learning/data_transformations/PCA.html",
    "title": "Первая главная компонента",
    "section": "",
    "text": "Метод главных компонент\nВсе особенности и тонкоссти исползования метода главных компонент.\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.decomposition import PCA"
  },
  {
    "objectID": "machine_learning/data_transformations/PCA.html#определение",
    "href": "machine_learning/data_transformations/PCA.html#определение",
    "title": "Первая главная компонента",
    "section": "Определение",
    "text": "Определение\nПусть имеюстся \\(n\\) наблюдений за \\(m\\) переменными - \\(x_{ij}, i\\in \\overline{1,n}, j \\in \\overline{1,m}\\). Тогда первой главной компонентой назвается функция:\n\\[Z_1(x_1, x_2, ... , x_m) = \\sum_{j=1}^m\\phi_{j}(x_j - \\bar{x}_j);\\]\nГде: - \\(\\bar{x}_j\\) - среднее выборочное \\(j\\)-й переменной \\(\\forall j\\).\nПри том \\(\\phi_j\\) подбираются так, чтобы:\n\\[(\\phi_1, \\phi_2, ... \\phi_m) = argmax_{\\varphi_1, \\varphi_2, ..., \\varphi_{m}}\\left\\{Var\\left[\\sum_{j=1}^m\\varphi_{j}(x_j - \\bar{x}_j)\\right]\\right\\};\\]\n\\[\\sum_{j=1}^m \\varphi_j^2 = 1.\\]’"
  },
  {
    "objectID": "machine_learning/data_transformations/PCA.html#пример",
    "href": "machine_learning/data_transformations/PCA.html#пример",
    "title": "Первая главная компонента",
    "section": "Пример",
    "text": "Пример\nДопустим имеются \\(5\\) наблюдений за 2-мя переменными.\n“\\(\\phi_{j}(x_{{i}, {j}} - \\\\bar{x}_{j})\\)”.format(i = 2,j = 3)\n\nfor i in range(1, len(x1) + 1):\n    formula = \"\"\n    for j in range(1,3):\n        formula += \"$\\phi_1(x_{\" + str(i) + str(j) + \"} - \\\\bar{x}_\" + str(j) + \")$\"\n    print(\"- \" + formula + \";\")\n\n- $\\phi_1(x_{11} - \\bar{x}_1)$$\\phi_1(x_{12} - \\bar{x}_2)$;\n- $\\phi_1(x_{21} - \\bar{x}_1)$$\\phi_1(x_{22} - \\bar{x}_2)$;\n- $\\phi_1(x_{31} - \\bar{x}_1)$$\\phi_1(x_{32} - \\bar{x}_2)$;\n- $\\phi_1(x_{41} - \\bar{x}_1)$$\\phi_1(x_{42} - \\bar{x}_2)$;\n\n\n\n\\(\\phi_1(x_{1,1} - \\bar{x}_1)\\)\\(\\phi_1(x_{1,2} - \\bar{x}_2)\\);\n\\(\\phi_1(x_{2,1} - \\bar{x}_1)\\)\\(\\phi_1(x_{2,2} - \\bar{x}_2)\\);\n\\(\\phi_1(x_{3,1} - \\bar{x}_1)\\)\\(\\phi_1(x_{3,2} - \\bar{x}_2)\\);\n\\(\\phi_1(x_{4,1} - \\bar{x}_1)\\)\\(\\phi_1(x_{4,2} - \\bar{x}_2)\\);\n\n\nx1 = np.array([2, 3, 5, 6])\nx2 = np.array([3, 2, 6, 5])\n\nplt.figure(figsize = [10, 7])\nplt.scatter(x1, x2, s = 100)\n\n\nfor i in range(len(x1)):\n    plt.annotate(\n        str(i+1), (x1[i], x2[i]), fontsize = 20\n    )\n\nplt.axhline(\n    np.mean(x2), color = 'red', linestyle = \"dashed\"\n)\nplt.axvline(\n    np.mean(x1), color = \"red\",linestyle = \"dashed\"\n)\n\ndef create_tiks(values, sub_index):\n    \n    ticks_vals = np.unique(np.concatenate(\n        [values, [np.mean(values)]]\n    ))\n    tick_labels = \\\n    [\n        str(tick_val) \n        if tick_val != np.mean(x1) \n        else \"$\\\\bar{x}_ \" + sub_index + \" = $\" + str(tick_val) \n        \\\n        for tick_val in ticks_vals\n    ]\n    \n    return [ticks_vals, tick_labels]\nplt.xticks(*create_tiks(x1, \"1\"), fontsize = 14)\nplt.yticks(*create_tiks(x2, \"2\"), fontsize = 14)\n\nplt.grid()\n\n\n\n\n\nx1 - np.mean(x1)\nx2 - np.mean(x2)\n\narray([-2.,  0., -1.,  2.,  1.])"
  },
  {
    "objectID": "machine_learning/data_transformations/tf_idf.html",
    "href": "machine_learning/data_transformations/tf_idf.html",
    "title": "TF-IDF",
    "section": "",
    "text": "TF-IDF is a method for extracting features for machine learning models from textual information.\nfrom math import log\n\nfrom collections import Counter\nfrom IPython.display import HTML\n\n# set of phrases that I'll be using as the example at this page\nphrases = [\n    'a penny saved is a penny earned',\n    'the quick brown fox jumps over the lazy dog',\n    'beauty is in the eye of the beholder',\n    'early to bed and early to rise makes a man healthy wealthy and wise',\n    'give credit where credit is due',\n    \"if at first you don't succeed try try again\",\n    'justice delayed is justice denied',\n    'keep your friends close and your enemies closer',\n    'no pain no gain',\n    'quickly come quickly go',\n    'united we stand divided we fall',\n    'when in rome do as the romans do'\n]"
  },
  {
    "objectID": "machine_learning/data_transformations/tf_idf.html#tf---term-frequency",
    "href": "machine_learning/data_transformations/tf_idf.html#tf---term-frequency",
    "title": "TF-IDF",
    "section": "TF - term frequency",
    "text": "TF - term frequency\nTerm frequency is a metric for words in any next. It can be calculated using a formula:\n\\[tf(t,d)=\\frac{n_t}{\\sum_i n_i}\\]\nWhere:\n\n\\(t\\) - some word;\n\\(d\\) - some text;\n\\(n_t\\) - number of occurrences of word \\(t\\) in document \\(d\\);\n\\(\\sum_i n_i\\) - number of words in text \\(d\\).\n\nSo in the following cell I calculate the term frequencies of the words for some phrases. The result here is a table that contains original phrase and Term frequency, which for each word from the Original phrase corresponds to \\(tf\\) in the form &lt;word&gt;-&lt;tf&gt;.\nSo let’s take the logic of the first phrase - “a penny saved is a penny earned” - one step at a time:\n\nTotal count of words - \\(\\sum_i n_i = 7\\);\nYou can find the word “a” twice in the phrase so - \\(n_{'a'} = 2 \\Rightarrow tf('a')=\\frac{2}{7} \\approx 0.29\\);\nYou can find the word “penny” twice in the phrase so - \\(n_{'penny'}=2 \\Rightarrow tf('penny')= \\frac{2}{7} \\approx 0.29\\);\nAll other words occur once so \\(tf\\) for them can me computed as \\(\\frac{1}{7} \\approx 0.14\\).\n\n\nhtml_table = \"&lt;tr&gt;&lt;th&gt;Original phrase&lt;/th&gt;&lt;th&gt;Terms frequency&lt;/th&gt;&lt;/tr&gt;\"\ntf_dict = {}\n\nfor p in phrases:\n\n    words_in_phrase = dict(Counter(p.split()))\n    words_count = sum(words_in_phrase.values())\n    phrase_tfs = {word:number/words_count for word, number in words_in_phrase.items()}\n    tf_dict[p] = phrase_tfs\n    \n    tf_dict\n    counts_line = \"&lt;br&gt;\".join(\n        [\n            key + \" - \" + str(round(value, 2)) \n            for key, value in phrase_tfs.items()\n        ]\n    )\n    html_table += f\"&lt;tr&gt;&lt;td&gt;{p}&lt;/td&gt;&lt;td&gt;{counts_line}&lt;/td&gt;&lt;/tr&gt;\"\n\nHTML(\"&lt;table&gt;\" + html_table + \"&lt;/table&gt;\")\n\n\n\n\n\n\n\n\nOriginal phrase\nTerms frequency\n\n\na penny saved is a penny earned\na - 0.29\npenny - 0.29\nsaved - 0.14\nis - 0.14\nearned - 0.14\n\n\nthe quick brown fox jumps over the lazy dog\nthe - 0.22\nquick - 0.11\nbrown - 0.11\nfox - 0.11\njumps - 0.11\nover - 0.11\nlazy - 0.11\ndog - 0.11\n\n\nbeauty is in the eye of the beholder\nbeauty - 0.12\nis - 0.12\nin - 0.12\nthe - 0.25\neye - 0.12\nof - 0.12\nbeholder - 0.12\n\n\nearly to bed and early to rise makes a man healthy wealthy and wise\nearly - 0.14\nto - 0.14\nbed - 0.07\nand - 0.14\nrise - 0.07\nmakes - 0.07\na - 0.07\nman - 0.07\nhealthy - 0.07\nwealthy - 0.07\nwise - 0.07\n\n\ngive credit where credit is due\ngive - 0.17\ncredit - 0.33\nwhere - 0.17\nis - 0.17\ndue - 0.17\n\n\nif at first you don't succeed try try again\nif - 0.11\nat - 0.11\nfirst - 0.11\nyou - 0.11\ndon't - 0.11\nsucceed - 0.11\ntry - 0.22\nagain - 0.11\n\n\njustice delayed is justice denied\njustice - 0.4\ndelayed - 0.2\nis - 0.2\ndenied - 0.2\n\n\nkeep your friends close and your enemies closer\nkeep - 0.12\nyour - 0.25\nfriends - 0.12\nclose - 0.12\nand - 0.12\nenemies - 0.12\ncloser - 0.12\n\n\nno pain no gain\nno - 0.5\npain - 0.25\ngain - 0.25\n\n\nquickly come quickly go\nquickly - 0.5\ncome - 0.25\ngo - 0.25\n\n\nunited we stand divided we fall\nunited - 0.17\nwe - 0.33\nstand - 0.17\ndivided - 0.17\nfall - 0.17\n\n\nwhen in rome do as the romans do\nwhen - 0.12\nin - 0.12\nrome - 0.12\ndo - 0.25\nas - 0.12\nthe - 0.12\nromans - 0.12"
  },
  {
    "objectID": "machine_learning/data_transformations/tf_idf.html#idf---inverse-document-frequency",
    "href": "machine_learning/data_transformations/tf_idf.html#idf---inverse-document-frequency",
    "title": "TF-IDF",
    "section": "IDF - inverse document frequency",
    "text": "IDF - inverse document frequency\nFor each word of a text from the given set of texts. It can be calculated using fromula:\n\\[idf(t,D)=log \\frac{\\left| D \\right|}{\\left| \\left\\{ d_i \\in D | t \\in d_i \\right\\} \\right|};\\]\nWhere:\n\n\\(D\\) - set of texts;\n\\(\\left| A \\right|\\) - number of elements in the set A;\n\\(\\left| \\left\\{ d_i \\in D | t \\in d_i \\right\\} \\right|\\) - number of documents \\(d_i\\) from set \\(D\\) that contains word \\(t\\);\nNote the denominator of the formula contains exactly the number of documents in which the word is included, not the number of occurrences of the word in any documents it’s always true \\(\\left| D \\right| \\geq \\left| \\left\\{ d_i \\in D | t \\in d_i \\right\\} \\right| \\Rightarrow idf(t,D) \\geq 0\\).\n\nSo in the following cell there is an example of calculating \\(idf\\) for a set of texts. It’s displayed like a table that contains all the words from a set of texts and for each word it calculates the occurrences of the word in the set of texts and it’s \\(idf\\).\nLet’s take word “the” for example it occurs in 3 of 12 texts so it’s \\(idf=log(\\frac{12}{5}) \\approx 1.39\\).\n\nphrases_number = len(phrases)\nword_in_documents = Counter([w for p in phrases for w in set(p.split())])\nwords_idf = {}\n\nhtml_table = (\n    \"&lt;tr&gt;&lt;th&gt;Word&lt;/th&gt;\"\n    \"&lt;th&gt;$\\left|\\left\\{d_i \\in D | t \\in d_i\\\\right\\}\\\\right|$&lt;/th&gt;\"\n    \"&lt;th&gt;Inverse document frequency&lt;/th&gt;&lt;/tr&gt;\"\n)\n\nfor word, number in word_in_documents.items():\n\n    idf = log(phrases_number/number)\n    words_idf[word] = idf\n    \n    html_table += (\n        f\"&lt;tr&gt;&lt;td&gt;{word}&lt;/td&gt;\"\n        f\"&lt;td&gt;{number}&lt;/td&gt;\"\n        f\"&lt;td&gt;{round(idf, 2)}&lt;/td&gt;&lt;/tr&gt;\"\n    )\n\nHTML(\"&lt;table&gt;\" + html_table + \"&lt;/table&gt;\")\n\n\n\n\nWord\n$\\left|\\left\\{d_i \\in D | t \\in d_i\\right\\}\\right|$\nInverse document frequency\n\n\nearned\n1\n2.48\n\n\nis\n4\n1.1\n\n\nsaved\n1\n2.48\n\n\npenny\n1\n2.48\n\n\na\n2\n1.79\n\n\nthe\n3\n1.39\n\n\nover\n1\n2.48\n\n\nquick\n1\n2.48\n\n\nfox\n1\n2.48\n\n\nlazy\n1\n2.48\n\n\njumps\n1\n2.48\n\n\ndog\n1\n2.48\n\n\nbrown\n1\n2.48\n\n\nof\n1\n2.48\n\n\neye\n1\n2.48\n\n\nbeauty\n1\n2.48\n\n\nin\n2\n1.79\n\n\nbeholder\n1\n2.48\n\n\nbed\n1\n2.48\n\n\nto\n1\n2.48\n\n\nearly\n1\n2.48\n\n\nhealthy\n1\n2.48\n\n\nmakes\n1\n2.48\n\n\nwealthy\n1\n2.48\n\n\nand\n2\n1.79\n\n\nwise\n1\n2.48\n\n\nman\n1\n2.48\n\n\nrise\n1\n2.48\n\n\nwhere\n1\n2.48\n\n\ngive\n1\n2.48\n\n\ncredit\n1\n2.48\n\n\ndue\n1\n2.48\n\n\nyou\n1\n2.48\n\n\nat\n1\n2.48\n\n\ndon't\n1\n2.48\n\n\nsucceed\n1\n2.48\n\n\ntry\n1\n2.48\n\n\nagain\n1\n2.48\n\n\nif\n1\n2.48\n\n\nfirst\n1\n2.48\n\n\ndenied\n1\n2.48\n\n\ndelayed\n1\n2.48\n\n\njustice\n1\n2.48\n\n\nyour\n1\n2.48\n\n\nfriends\n1\n2.48\n\n\nclose\n1\n2.48\n\n\ncloser\n1\n2.48\n\n\nenemies\n1\n2.48\n\n\nkeep\n1\n2.48\n\n\npain\n1\n2.48\n\n\nno\n1\n2.48\n\n\ngain\n1\n2.48\n\n\ngo\n1\n2.48\n\n\nquickly\n1\n2.48\n\n\ncome\n1\n2.48\n\n\nfall\n1\n2.48\n\n\nunited\n1\n2.48\n\n\nwe\n1\n2.48\n\n\nstand\n1\n2.48\n\n\ndivided\n1\n2.48\n\n\nromans\n1\n2.48\n\n\nwhen\n1\n2.48\n\n\nas\n1\n2.48\n\n\nrome\n1\n2.48\n\n\ndo\n1\n2.48\n\n\n\n\n\nThis metric shows how often a word occurs in general across all texts. If the word is really common, there’s a high probability that it’s just an article, pretext or something like that - it doesn’t make much sense in the sentence. For example, let’s consider the extreme value, if you find any word \\(t'\\) in any text, it means that \\(\\frac{\\left| D \\right|}{\\left| \\left\\{ d_i \\in D | t \\in d_i \\right\\} \\right|} = 1 \\Rightarrow log \\frac{\\left| D \\right|}{\\left| \\left\\{ d_i \\in D | t \\in d_i \\right\\} \\right|} = 0\\) - the presence of the word \\(t'\\) in no way makes it possible to distinguish one entry from another."
  },
  {
    "objectID": "machine_learning/data_transformations/tf_idf.html#tf-idf",
    "href": "machine_learning/data_transformations/tf_idf.html#tf-idf",
    "title": "TF-IDF",
    "section": "TF-IDF",
    "text": "TF-IDF\n\\(ft_{idf}\\) is a final metric of the TF-IDF analysis and can be calculated as the product of TF and IDF. So for each word in each text from the set of texts we compute it’s own value \\(tf_{idf}\\). So in the following cell I combine results from two previous sections to compute \\(tf_{idf}\\). For example, for word “a” in phrase “a penny saved is a penny earned” \\(tf_{idf} = 0.29*1.79 \\approx 0.51\\).\n\nhtml_table = (\n    \"&lt;tr&gt;&lt;th&gt;Phrase&lt;/th&gt;&lt;th&gt;$tf_{idf}$&lt;/th&gt;&lt;/tr&gt;\"\n)\n\nfor phrase, tfs in tf_dict.items():\n    phrase_tf_idf_line = \"&lt;br&gt;\".join([\n        (\n            word + \" - \" + \n            str(round(words_idf[word]*tf,2))\n        )\n        for word, tf in tfs.items()\n    ])\n\n    html_table += f\"&lt;tr&gt;&lt;td&gt;{phrase}&lt;/td&gt;&lt;td&gt;{phrase_tf_idf_line}&lt;/td&gt;&lt;/tr&gt;\"\nHTML(\"&lt;table&gt;\" + html_table + \"&lt;/table&gt;\")       \n\n\n\n\n\n\n\n\nPhrase\n$tf_{idf}$\n\n\na penny saved is a penny earned\na - 0.51\npenny - 0.71\nsaved - 0.35\nis - 0.16\nearned - 0.35\n\n\nthe quick brown fox jumps over the lazy dog\nthe - 0.31\nquick - 0.28\nbrown - 0.28\nfox - 0.28\njumps - 0.28\nover - 0.28\nlazy - 0.28\ndog - 0.28\n\n\nbeauty is in the eye of the beholder\nbeauty - 0.31\nis - 0.14\nin - 0.22\nthe - 0.35\neye - 0.31\nof - 0.31\nbeholder - 0.31\n\n\nearly to bed and early to rise makes a man healthy wealthy and wise\nearly - 0.35\nto - 0.35\nbed - 0.18\nand - 0.26\nrise - 0.18\nmakes - 0.18\na - 0.13\nman - 0.18\nhealthy - 0.18\nwealthy - 0.18\nwise - 0.18\n\n\ngive credit where credit is due\ngive - 0.41\ncredit - 0.83\nwhere - 0.41\nis - 0.18\ndue - 0.41\n\n\nif at first you don't succeed try try again\nif - 0.28\nat - 0.28\nfirst - 0.28\nyou - 0.28\ndon't - 0.28\nsucceed - 0.28\ntry - 0.55\nagain - 0.28\n\n\njustice delayed is justice denied\njustice - 0.99\ndelayed - 0.5\nis - 0.22\ndenied - 0.5\n\n\nkeep your friends close and your enemies closer\nkeep - 0.31\nyour - 0.62\nfriends - 0.31\nclose - 0.31\nand - 0.22\nenemies - 0.31\ncloser - 0.31\n\n\nno pain no gain\nno - 1.24\npain - 0.62\ngain - 0.62\n\n\nquickly come quickly go\nquickly - 1.24\ncome - 0.62\ngo - 0.62\n\n\nunited we stand divided we fall\nunited - 0.41\nwe - 0.83\nstand - 0.41\ndivided - 0.41\nfall - 0.41\n\n\nwhen in rome do as the romans do\nwhen - 0.31\nin - 0.22\nrome - 0.31\ndo - 0.62\nas - 0.31\nthe - 0.17\nromans - 0.31\n\n\n\n\n\nFor each record, you can perform some aggregations on the numbers received. Common aggregations are maximum and average."
  },
  {
    "objectID": "machine_learning/data_transformations/standartisation.html",
    "href": "machine_learning/data_transformations/standartisation.html",
    "title": "1. Определение",
    "section": "",
    "text": "Процедура стандартизации данных\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom statsmodels.tools.tools import add_constant\nПусть имеется множество измерений определенного признака \\(x_i, i=\\overline{1,n}\\). Тогда стандартизацией такого ряда называется преобразование по формуле:\n\\[\\tilde{x}_{i} = \\frac{x_{i} - \\bar{x}}{\\sigma_x}. \\tag{1.1}\\]\nГде: - \\(\\bar{x}\\) - среднее арифметческое рассматртваемого ряда; - \\(\\sigma_x\\) - стандартное отклонение.\nПолучется, что выражение \\((1.1)\\) может быть переписано следующим образом:\n\\[\\tilde{x}_{i} = \\frac{x_{i} - \\bar{x}}{\\sqrt{\\frac{1}{n} \\sum_{i=1}^n(x_i - \\bar{x})^2}}.\\]\nИногда предпочитают не отнимать среднее арифметическое в числителе, тогда формула \\((1.1)\\) принимает вид:\n\\[\\tilde{x}_i  = \\frac{x_i}{\\sigma}.\\]"
  },
  {
    "objectID": "machine_learning/data_transformations/standartisation.html#линейная-регрессия",
    "href": "machine_learning/data_transformations/standartisation.html#линейная-регрессия",
    "title": "1. Определение",
    "section": "Линейная регрессия",
    "text": "Линейная регрессия\n\nВведение\nМодель на исходнынх данных в матричных обозначениях примет вид:\n\\[\\hat{y} = b X. \\tag{3.1}\\]\nГде: - \\(X\\) - факторная матрица; - \\(\\hat{y}\\) - вектор столбец предсказаний модели; - \\(b\\) - вектор строка оценк коэффициентов модели.\nТогда модель на стандартизированных данных примет вид:\n\\[\\hat{y} = \\tilde{b} \\tilde{X}. \\tag{3.2}\\]\nГде: - \\(\\tilde{X}\\) - стандартизированная матрица предикоторов; - \\(\\tilde{b}\\) - оценки коэффициентов полученные при использовании стантатицованной фактороной матрицы.\nУточним, что факторную матрицу можно переписать: \\[\\tilde{X} = \\left(\\begin{array}\\\\\n    x_{11}/\\sigma_{x_1}&x_{12}/\\sigma_{x_2} & \\cdots & x_{1p}/\\sigma_{x_p}\\\\\n    x_{21}/\\sigma_{x_1}&x_{22}/\\sigma_{x_2} & \\cdots & x_{2p}/\\sigma_{x_p}\\\\\n    \\vdots & \\vdots & \\ddots & \\vdots\\\\\n    x_{n1}/\\sigma_{x_1}&x_{n2}/\\sigma_{x_2} & \\cdots & x_{np}/\\sigma_{x_p}\\\\\n\\end{array}\\right)\\]\nГде: - \\(p\\) - число переменных модели; - \\(\\sigma_{x_j}\\) - стандартное отклоненение \\(j\\)-й переменной.\nТакая матрица раскладывается:\n\\[\\tilde{X} = X*\\Sigma'. \\tag{3.3}\\]\nГде: - \\(\\Sigma' = diag(1/\\sigma_{x_1}, 1/\\sigma_{x_2}, \\cdots, 1/\\sigma_{x_p})\\).\n\n\nВлияние стандартизации на коэффициенты\n\nТеория\nТеоритически можно доказать, что предсказания линейной регрессии на исходных данных и на стандартизированных данных не отличаются. Далее представлено доказательсво.\nПредсзакания модели \\((3.1)\\) для \\(i\\)-го наблюдения формируются так:\n\\[\\hat{y}_i = \\sum_{j=1}^p b_jx_{ij}\\]\nА модели \\((3.2)\\):\n\\[\\hat{y}_i = \\sum_{j=1}^p \\tilde{b}_j\\tilde{x}_{ij}\\]\nГлавный вопрос этого раздела, дают ли эти две модели одинаковое предсказание? Поработаем с последним выражением:\n\\[\\hat{y}_i = \\sum_{j=1}^p \\tilde{b}_j \\frac{x_{ij}}{\\sigma_j}.\\]\nТаким образом, если \\(b_j = \\tilde{b}_j/\\sigma_j, \\forall j\\) - то получается, что предсказания моделей одинаковые. Покажем это.\nДля нахождения коэффициентов в \\((2.1)\\) можно воспользоваться матричной формулой:\n\\[b=\\left[X^TX\\right]^{-1}X^TY\\tag{3.4}\\]\nДля нахождения коэффициентов в \\((2.2)\\) можно воспользоваться формулой:\n\\[\\tilde{b}=\\left[\\tilde{X}^T\\tilde{X}\\right]^{-1}\\tilde{X}^TY\\]\nИспользуя \\((3.3)\\):\n\\[\\tilde{b} =\n\\left[\\left(X\\Sigma'\\right)^T\\left(X\\Sigma'\\right)\\right]^{-1}\\left(X\\Sigma'\\right)^TY\n=\\left[\\Sigma^TX^TX\\Sigma'\\right]^{-1}\\Sigma'^TX^TY\\]\nДалее используя свойсва обращения произведения \\((AB)^{-1} = B^{-1}A^{-1}\\):\n\\[\\tilde{b} = \\left[X^TX\\Sigma'\\right]^{-1}\\left[\\Sigma^T\\right]^{-1}\\Sigma'^TX^TY\\]\n\\[\\tilde{b}=\\Sigma'^{-1}\\left[X^TX\\right]^{-1}X^TY\\]\nТогда:\n\\[\\Sigma'\\tilde{b} = \\left[X^TX\\right]^{-1}X^TY\\]\nПодставляя \\((3.4)\\) получим, что:\n\\[\\Sigma'^{-1}\\tilde{b}=b.\\]\nРасписывая выражение подробнее:\n\\[\\left(\\begin{array}\\\\\n    1/\\sigma_1 & 0 & \\cdots & 0 \\\\\n    0 & 1/\\sigma_2 & \\cdots & 0 \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    0 & 0 & \\cdots & 1/\\sigma_p\n\\end{array}\\right)\n\\left(\\begin{array}\\\\\n    \\tilde{b}_1 \\\\\n    \\tilde{b}_2 \\\\\n    \\vdots \\\\\n    \\tilde{b}_p\n\\end{array}\\right) =\n\\left(\\begin{array}\\\\\n    b_1 \\\\\n    b_2 \\\\\n    \\vdots \\\\\n    b_p\n\\end{array}\\right)\n\\]\nОт куда следует, что:\n\\[\n\\left(\\begin{array}\\\\\n    \\tilde{b}_1/\\sigma_1 \\\\\n    \\tilde{b}_2/\\sigma_2 \\\\\n    \\vdots \\\\\n    \\tilde{b}_p/\\sigma_p\n\\end{array}\\right) =\n\\left(\\begin{array}\\\\\n    b_1 \\\\\n    b_2 \\\\\n    \\vdots \\\\\n    b_p\n\\end{array}\\right)\n\\]\nТогда \\(b_j = \\tilde{b}_j/\\sigma_j, \\forall j\\), что и требовалось доказать \\(\\boxtimes\\).\n\n\nЧисленный эксперимент\nОднако, на числах, рассуждения, представленные выше, не выполняются. Далее представлен эксперимент это подтверждающий.\nФормирование данных.\n\nn = 200\nnp.random.seed(15)\n\nx = pd.DataFrame({\n    \"x1\":np.random.normal(0, 0.3, n),\n    \"x2\":np.random.normal(0, 3, n)\n})\n\ny = x[\"x1\"]*3 + x[\"x2\"]*2 + (np.random.rand(n)-0.5) + 3\n\nКоэффициенты на исходных данных примут вид:\n\nbasic_model = LinearRegression(fit_intercept = False).fit(\n    add_constant(x), y)\nbasic_model.coef_\n\narray([2.95566332, 3.13373587, 2.00359775])\n\n\nКоэффициент при использованнии стандатризированных данных примет вид:\n\n# стандартизованная модель\nx_stand = (x-x.mean())/np.std(x)\n\nstand_model = LinearRegression(fit_intercept = False).fit(\n    add_constant(x_stand), y\n)\n\nstand_model.coef_\n\narray([2.60710742, 0.95731566, 5.8421477 ])\n\n\nИли, приводя коэффициент к использованию на исходных данных.\n\nstand_model.coef_/np.concatenate([[1], x.std().to_numpy()])\n\narray([2.60710742, 3.12589172, 1.99858248])\n\n\nКак видно, коэффициенты на стандартизорованных данных достаточно заметно отличаются от коэффициентов на исходных данных. Следовательно и предсказания должны отличаться в чем мы удостоверимся.\n\npd.set_option(\"display.precision\", 50)\npred_df = pd.DataFrame({\n    \"basic predict\" : basic_model.predict(add_constant(x)),\n    \"stand predict\" : stand_model.predict(add_constant(x_stand))\n})\n\npred_df\n\n\n\n\n\n\n\n\nbasic predict\nstand predict\n\n\n\n\n0\n3.53475496739942940394030301831662654876708984...\n3.53475496739942940394030301831662654876708984...\n\n\n1\n-0.47040250288071661088906694203615188598632812...\n-0.47040250288071527862143739184830337762832641...\n\n\n2\n1.19065003861016061037503277475479990243911743...\n1.19065003861016149855345247488003224134445190...\n\n\n3\n-5.00032926914154529640654800459742546081542968...\n-5.00032926914154263187128890422172844409942626...\n\n\n4\n7.54930929882019441379270574543625116348266601...\n7.54930929882019441379270574543625116348266601...\n\n\n...\n...\n...\n\n\n195\n5.73269150865232113289948756573721766471862792...\n5.73269150865232024472106786561198532581329345...\n\n\n196\n-2.20031285504599605218345459434203803539276123...\n-2.20031285504599383173740534402895718812942504...\n\n\n197\n-4.44552414243254645498382160440087318420410156...\n-4.44552414243254467862698220415040850639343261...\n\n\n198\n2.16478039072416539312371241976507008075714111...\n2.16478039072416583721292226982768625020980834...\n\n\n199\n-0.80340280563815458236831545946188271045684814...\n-0.80340280563815325010068590927403420209884643...\n\n\n\n\n200 rows × 2 columns\n\n\n\nНо оказалось, предсказания почити отличаются - различие в рамках погрешности!!!\nПоявлялась мысль, что данное различие обусровлено особенностями sklearn. Но при использовании формул привычной матричной алгебры, результат тот-же самый.\nОбычные данные\n\nnp_y = y.to_numpy().reshape([n,1])\nnp_x = add_constant(x).to_numpy()\nnp.dot(\n    np.linalg.inv(\n        np.dot(np.transpose(np_x), np_x)\n    ),\n    np.dot(np.transpose(np_x), np_y)\n).ravel()\n\narray([2.95566332, 3.13373587, 2.00359775])\n\n\nСтандартизированные данные\n\nnp_x_stand = add_constant(x_stand).to_numpy()\nnp.dot(\n    np.linalg.inv(\n        np.dot(np.transpose(np_x_stand), np_x_stand)\n    ),\n    np.dot(np.transpose(np_x_stand), np_y)\n).ravel()\n\narray([2.60710742, 0.95731566, 5.8421477 ])"
  },
  {
    "objectID": "machine_learning/tree_based_methods/tree.html",
    "href": "machine_learning/tree_based_methods/tree.html",
    "title": "Источники",
    "section": "",
    "text": "Изучение алгоритма “Решающее дерево”\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport seaborn as sns\n\nimport sklearn.tree as tree\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.model_selection import cross_val_score,\\\n                                    train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.datasets import load_breast_cancer\n\nimport graphviz\n\n\nISLR страница 336;\nUser guide от sklearn;\nАлгоритм обрезки с учётом сложности затрат в sklearn;\nПример использования алгоритма обрезки с учётом сложности затрат от sklearn;\n\n\nИдея группы методов\nРешающим деревом можно решать как задачи регрессии так и классификации. Идея в том, что исходное пространтсво предикторов разбивается на обаласти (\\(R_1, R_2, ... , R_m\\)) и на каждой области \\(R_i\\) предсказывается значение зависящее от наблюдений в ней.\nНапример для задачи регрессии можно предсказывать среднее значение отклика для выбранной области. Так в следующем примере представлено как может быть сформировано решеющее дерево для данных соответсвующий параболоиду.\nГраф сверху описывает принцип принятия решений, рисунки снизу указывают как формировались предсказания.\n\nзвенья графа в которых происходит решение называются внутренние узлы (internal nodes);\nзвенья графа которые формирут конечный результат и соответсвуют \\(R_i\\) называеются конечные узлы или листики (terminal nodes).\n\n\nЗадача регрессии\n\n# подготовка обучающей выборки\nsample_size = 500\nnp.random.seed(30)\n\nx1_lim = [-5, 5]\nx2_lim = [-5, 5]\n\nsample_df = pd.DataFrame({\n    \"$x_1$\" : np.random.uniform(*x1_lim, sample_size),\n    \"$x_2$\" : np.random.uniform(*x2_lim, sample_size),\n})\n\nsample_df[\"$y$\"] = sample_df[\"$x_1$\"]**2 + sample_df[\"$x_2$\"]**2\n\n# формирование модели\nmy_first_tree = tree.DecisionTreeRegressor(\\\n    max_depth = 3\n).fit(\n    sample_df[[\"$x_1$\", \"$x_2$\"]],\n    sample_df[\"$y$\"]\n)\n\n# сетка предстказаний\nx1_range = np.arange(*x1_lim, 0.1)\nx2_range = np.arange(*x2_lim, 0.1)\nx1_mesh, x2_mesh = np.meshgrid(x1_range, x2_range)\n\nmesh_df = pd.DataFrame({\n    \"$x_1$\" : x1_mesh.ravel(),\n    \"$x_2$\" : x2_mesh.ravel()\n})\np_mesh = np.reshape(\n    my_first_tree.predict(mesh_df),\n    x1_mesh.shape\n)\n\n# визуализация\ndot_data = tree.export_graphviz(\n    my_first_tree, out_file=None,\n    feature_names = [\"x_1\", \"x_2\"],\n    filled=True, rounded=True,  \n    special_characters=True\n)\ngraph = graphviz.Source(dot_data)\ndisplay(graph)\n\nfig = plt.figure(figsize = [20, 10])\n\nax1 = fig.add_subplot(121)\nDecisionBoundaryDisplay.from_estimator(\n    my_first_tree,\n    mesh_df,\n    cmap=cm.coolwarm,\n    response_method=\"predict\",\n    ax = ax1,\n)\nsns.scatterplot(\n    data = sample_df,\n    x = \"$x_1$\", y = \"$x_2$\",\n    size = \"$y$\",\n    ax=ax1,\n    color = \"green\"\n)\nplt.xlabel(\"$x_1$\", fontsize = 14)\nplt.ylabel(\"$x_2$\", fontsize = 14)\n\nax2 = fig.add_subplot(122, projection='3d')\nax2.scatter(\n    sample_df[\"$x_1$\"],\n    sample_df[\"$x_2$\"],\n    sample_df[\"$y$\"],\n    color = \"green\"\n)\nsurf = ax2.plot_surface(\n    x1_mesh, x2_mesh, p_mesh,\n    cmap=cm.coolwarm\n)\n\nfig.colorbar(surf, shrink=0.5, aspect=5)\n\nplt.xlabel(\"$x_1$\"); plt.ylabel(\"$x_2$\");\n\n\n\n\n\n\n\n\n\nЗадача классификации\nИдея та же - бинарное деление пространтсва предикоторов максимизируя некоторую статистику. Отдельного внимания заслуживают эти статистики:\n\nИндекс GINI:\n\n\\[G = \\sum_{k =1}^K \\hat{p}_{mk}(1-\\hat{p}_{mk});\\]\nгде \\(\\hat{p}_{mk}\\) - доля наблюдений \\(k\\) класса принадлежащих региону \\(m\\);\nИнтерестно, что в данном случае получается что чем ближе доли \\(\\hat{p}_{mk}\\) к нулю или единице (что в данном случае хорошо), тем меньше будет индекс GINI. Пока не до конца понятно как именно происходит минимизация - похоже подбирается такое отсечение, чтобы GINI был миниматен в любой из получаемых после отсечения областей.\n\nЭнтропия\n\n\\[D = -\\sum_{k=1}^{K}\\hat{p}_{mk}log(\\hat{p}_{mk})\\]\nОбладает очень похожими свойствами с индексом GINI.\n\n\n\nОбрезка дерева\nОчевидно, что слишком глубокие деревья ведут к переобучению а недостаточно глубокие к низкой гибкости модели. В результате требуется подобрать такую глибину дерева, чтобы подобрать опитимальный компромисс между дисперсией и смещением. Для того можно пробовать:\n\nИдеальном случае следовало бы провести кроссвалидацию для дерева любой длинны и выбрать ту, что на кроссвалидации выдает наилучшие результаты;\nВ [1] предлагают использовать алгоритм “обрезки с учетом сложности затрат” (cost complexity pruning).\n\n\nАлгоритм “обрезки с учетом сложности затрат”\nАлгоритм предполагает использование целевой функции:\n\\[\\sum_{m=1}^{|T|}\\sum_{x_i \\in R_m}(y_i-\\hat{y}_{R_m})^2+\\alpha|T|\\rightarrow min\\]\nМодель кроссвалидируется при разных \\(\\alpha\\). Соответсвенно подбирается оптимальный параметр \\(\\alpha\\). По сути это эквивалентно регуляризации модели.\n\nSKLearn\nПример представленный в докумментации sklearn. Основная фишка в том, что sklearn может найти эффективные \\(\\alpha\\) для каждого звена. То есть такие \\(\\alpha\\), при которых отбрасывается следущее звено за ненадобностью (то есть эффект от \\(\\alpha|T|\\) выше чем влияние узла на результат на тренировочной выборке).\nВ sklearn предзожен метод tree.DecisionTreeClassifier.cost_complexity_pruning_path. Она возвращаяет те после которых отбрасывается листик. Кроме того, можно получить соответствующую суммарную примесь листьев на каждом этапе процесса обрезки (total impurity of leaves). Так далее представлен гарфик, на котором показано, как с ростом \\(\\alpha\\) все больше и больше лисьев оказываются отброщенными.\n\nX, y = load_breast_cancer(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\nclf = tree.DecisionTreeClassifier(random_state=0)\npath = clf.cost_complexity_pruning_path(X_train, y_train)\nccp_alphas, impurities = path.ccp_alphas, path.impurities\n\nfig, ax = plt.subplots()\nax.plot(ccp_alphas[:-1], impurities[:-1], marker=\"o\", drawstyle=\"steps-post\")\nax.set_xlabel(\"эффективные $\\\\alpha$\")\nax.set_ylabel(\"суммарная примесь листьев\")\nans = ax.set_title(\"Суммарная примесь листьев и эффективные $\\\\alpha$\")\n\n\n\n\nСледующий пример учит модели на эффективных \\(\\alpha\\) и представляет как с увеличением \\(\\alpha\\) уменьшаяется гибкость модели - мельше листьев и глубины. Вплоть до одного узла.\nЭтот пример я вставил больше потому, что полезно знать как извлекать длинну глубину и число узлов полученного дерева: - tree.DecisionTreeClassifier.tree_.max_depth; - tree.DecisionTreeClassifier.tree_.node_count.\n\nclfs = []\nfor ccp_alpha in ccp_alphas:\n    clf = tree.DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n    clf.fit(X_train, y_train)\n    clfs.append(clf)\nprint(\n    \"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n        clfs[-1].tree_.node_count, ccp_alphas[-1]\n    )\n)\n\nclfs = clfs[:-1]\nccp_alphas = ccp_alphas[:-1]\n\nnode_counts = [clf.tree_.node_count for clf in clfs]\ndepthes = [clf.tree_.max_depth for clf in clfs]\nfig, ax = plt.subplots(2, 1, figsize = [14, 10])\nax[0].plot(ccp_alphas, node_counts, marker=\"o\", drawstyle=\"steps-pre\")\nax[0].set_xlabel(\"$\\\\alpha$\", fontsize = 14)\nax[0].set_ylabel(\"Число узлов\")\nax[0].set_title(\"Число узлов и $\\\\alpha$\")\nax[1].plot(ccp_alphas, depthes, marker=\"o\", drawstyle=\"steps-pre\")\nax[1].set_xlabel(\"$\\\\alpha$\", fontsize = 14)\nax[1].set_ylabel(\"Глупина дерева\")\nax[1].set_title(\"Глубина и $\\\\alpha$\")\nfig.tight_layout()\n\nfor i, (alpha, node_count, depth) in enumerate(zip(\n    ccp_alphas, node_counts, depthes\n)):\n    ax[0].text(alpha, node_count, i, fontsize = 14)\n    ax[0].axhline(node_count, color = \"gray\", linestyle = \"dashed\",alpha = 0.1)\n    ax[1].text(alpha, depth, i, fontsize = 14)\n    ax[1].axhline(depth, color = \"gray\", linestyle = \"dashed\",alpha = 0.1)\n\nax[0].set_yticks(node_counts)\nans = ax[1].set_yticks(depthes)\n\nNumber of nodes in the last tree is: 1 with ccp_alpha: 0.3272984419327777\n\n\n\n\n\nДля того, что-бы убедиться во всем описанно я решил нарисовать графы для деревьев соответсвующие 7-й и 8-й точкам. Чтобы проследить как исчезает лишний уровень глубины дерева.\n\n# визуализация\ndef plot_my_tree(clf):\n\n    dot_data = tree.export_graphviz(\n        clf, out_file=None,\n        filled=True, rounded=True,\n        special_characters=True\n    )\n    graph = graphviz.Source(dot_data)\n    display(graph)\n\nprint(\"Alpha =\", ccp_alphas[7])\nplot_my_tree(clfs[7])\nprint(\"Alpha =\", ccp_alphas[8])\nplot_my_tree(clfs[8])\n\nAlpha = 0.009114019793328328\nAlpha = 0.011443661971830986\n\n\n\n\n\n\n\n\nДалее продолжается исследование баланса между дисперсией и смещением. В следующем примере показано как растёт точность предсказаний на тестовой выборке с увеличением параметра \\(\\alpha\\).\n\ntrain_scores = [clf.score(X_train, y_train) for clf in clfs]\ntest_scores = [clf.score(X_test, y_test) for clf in clfs]\n\nfig, ax = plt.subplots()\nax.set_xlabel(\"$\\\\alpha$\")\nax.set_ylabel(\"Точность\")\nax.set_title(\"Точность и $\\\\alpha$ для терениовочной и тестовой выборки\")\nax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"Тренировачная\", drawstyle=\"steps-post\")\nax.plot(ccp_alphas, test_scores, marker=\"o\", label=\"Тестовая\", drawstyle=\"steps-post\")\nax.legend()\nplt.show()\n\n\n\n\n\n\nISLR\nПроведем на python эксперимент аналогичный представленному в [1]. В источнике не указано подробно как эксперимент проводился, потому проведу его как чуствую:\n\nВсе следующие шаги формируются в множество прогонов:\n\nФормируем train/test;\nВычиляем эффективные \\(\\alpha\\) для выбранного train;\nДля всех эффективных \\(\\alpha\\):\n\nОциниваем на train/test;\nКроссвалидируем на test.\n\n\n\nПо идее кроссвалидация тут не нужна, потому как прогоны разбиения train/test сами по себе эквиванентны кроссвалидации.\nfrom tqdm import tqdm\nnp.random.seed(25) fold_count = 6 Hitters = pd.read_csv(“Hitters.csv”).dropna()\ndef get_fit_data(f): return ( pd.get_dummies( f[[ “Years”, “RBI”, “Hits”, “PutOuts”, “Walks”, “Runs” ]] ), np.log(f[“Salary”]) )\ntree_regressor = tree.DecisionTreeRegressor()\nresults_frame = pd.DataFrame( columns = [ “alpha”, “Прогон экперимента”, “MSE тренировочное”, “MSE тестовое”, “Кроссвалидация”, “Глубина дерева”, “Число листов” ], )\nindexator = 0\n\n\n\n\nпрогоняем эксперимент\nfor i in tqdm(range(50)):\ntrain = Hitters.sample(132)\ntest = Hitters.loc[~Hitters.index.isin(train.index)]\n\ncpp_alphas = tree_regressor.cost_complexity_pruning_path(\n    *get_fit_data(train)\n)[\"ccp_alphas\"]\n\nfor alpha in cpp_alphas:\n\n    # подготовка\n    tree_regressor.set_params(ccp_alpha = alpha)\n    train_model = tree_regressor.fit(*get_fit_data(train))\n    train_X, train_y = get_fit_data(train)\n    test_X, test_y = get_fit_data(test)\n    train_model.fit(train_X, train_y)\n\n    train_pred = train_model.predict(train_X)\n    test_pred = train_model.predict(test_X)\n    cv_result = (\n        cross_val_score(\n            tree_regressor,\n            *get_fit_data(train),\n            cv = fold_count,\n            scoring=\"neg_mean_squared_error\"\n        )[:, np.newaxis]\n    )\n\n    results_frame.loc[indexator] = {\n        \"alpha\" : alpha,\n        \"Прогон экперимента\" : i,\n        \"MSE тренировочное\" : mean_squared_error(train_y, train_pred),\n        \"MSE тестовое\" : mean_squared_error(test_y, test_pred),\n        \"Кроссвалидация\" : -np.mean(cv_result),\n        \"Глубина дерева\" : train_model.tree_.max_depth,\n        \"Число листов\" : train_model.get_n_leaves()\n    }\n\n    indexator += 1\nresults_frame.to_csv(“ISLR_exeriment.csv”)\nДалее графичеки представим результаты. На следующем графике показана связь точности модели с числом листов. Палочками представлено стандарное отлоенние по различным прогонам.\n\nresults_frame = pd.read_csv(\"ISLR_exeriment.csv\")\n\ntree_depth_gb = results_frame.groupby(\"Число листов\")\n\nMSE_plots = (\n    tree_depth_gb[\"MSE тренировочное\"],\n    tree_depth_gb[\"MSE тестовое\"],\n    tree_depth_gb[\"Кроссвалидация\"]\n)\n\nfor MSE in MSE_plots:\n    plt.errorbar(tree_depth_gb.groups.keys(), MSE.mean(), MSE.std())\n\nans = plt.legend([\n    \"MSE тренировочное\",\n    \"MSE тестовое\",\n    \"Кроссвалидация\"\n])\nplt.xlabel(\"Число листов\", fontsize = 14)\nplt.ylabel(\"Точность модели\", fontsize = 14)\n\nans = plt.xlim([0,20])\n\n\n\n\nНе получается в точности воспроизвести эксперимент из ISLR. И в нашем случае лучшая модель исопльзует 4 листа. Но идея о бесконечном увеличении метрики качества на обучающей выборке понятна.\n\n\nДерево и пропуски\nВроде сказано, что дерево может по прежнему обучаться на тех наборах данных в которых присудствуют пропуски. Рассмотрим подробнее как это работатет.\nВ следующей ячейке создан набор данных на задачу классификации , в котром пропущено 100 значений для одной из переменных.\n\nnp.random.seed(20)\n\nd = pd.DataFrame({\n    \"x1\" : np.random.uniform(0, 10, 500),\n    \"x2\" : np.random.uniform(0, 10, 500)\n})\n\nr = d[\"x1\"] + d[\"x2\"]\n\nd[\"c\"] = ((r - r.min())/(r.max() - r.min())).apply(\n    lambda prob: np.random.choice([1,0], p = [prob**2, 1-(prob**2)])\n)\n\nd[\"x1 nans\"] = d[\"x1\"]\nd.loc[d.sample(100).index, \"x1 nans\"] = np.NaN\n\nans = sns.scatterplot(data=d, x=\"x1\", y=\"x2\", hue=\"c\", style=d[\"x1 nans\"].isna())\n\n\n\n\nПопробуем, такой набор данных скормить дереву и посмотрим, какое решение оно предложит:\nclf = tree.DecisionTreeClassifier(max_depth=3,random_state=0) clf.fit(d[[“x1 nans”, “x2”]], d[“c”])\ndot_data = tree.export_graphviz( clf, out_file=None, filled=True, rounded=True, special_characters=True, feature_names=[“x1”, “x2”] ) graph = graphviz.Source(dot_data) display(graph)\nВ общем, это не сработало - выдает ошибку оценщик."
  },
  {
    "objectID": "machine_learning/tree_based_methods/ensemble copy.html",
    "href": "machine_learning/tree_based_methods/ensemble copy.html",
    "title": "Баггинг",
    "section": "",
    "text": "Изучение ансамблей решающих деревьев\nИспользьвание алгоритма - решающее дерево может приводить к высокой дисперисии предсказаний. Для того, чтобы это избежать исползуются методы, которые обощают под названием ансамбли решающих деревьев. Выделяют следующие методы:\n\nBagging;\nRandom Forests;\nBoosting;\nBayesian Additive Regression Trees.\n\nИсточники\n\nISLR;\nСобрание возможностей sklearn посвященных ансамблям;\n\n\nfrom copy import copy\nimport warnings\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.ensemble import BaggingRegressor, BaggingClassifier\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n\nfrom sklearn.model_selection import cross_val_score\n\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\n\nПредполагает бутстрапирование обучающей выборки и подгонку множестава деревьев. Для получания предсказаний результаты каждого дерева аггрегируют (обычно усредняют). Вообще говоря, баггинг можно ложить не только на деревья но и на KNN модели.\n\nСравнение с единичным деревом\nСоздам выборку и на ней попробую оценить обычное дерево и баггинг на дереве. Результаты сравним.\n\nsample_size = 500\nnp.random.seed(10)\n\ndata = pd.DataFrame({\n    \"x\" : np.random.rand(sample_size)\n})\n\nf_x = lambda x: 15*x**3 - 15*x**2 + x \n\ndata[\"y\"] = f_x(data[\"x\"]) + np.random.uniform(0, 1, sample_size)\n\nДля контроля глубины дерева будет использоватся алгоритм обрезки с учетом сложности затрат. Для того, надо подобрать его парамерт \\(\\alpha\\).\n\nccp_alphas = DecisionTreeRegressor().\\\ncost_complexity_pruning_path(\n    data[[\"x\"]], data[\"y\"]\n)[\"ccp_alphas\"]\n\nclf = DecisionTreeRegressor()\nMSEs = {}\n\nfor alpha in tqdm(ccp_alphas):\n    clf.set_params(ccp_alpha = alpha)\n    MSE = cross_val_score(\n        clf, data[[\"x\"]], \n        data[\"y\"], \n        cv = 20,\n        scoring = \"neg_mean_squared_error\"\n    )\n    MSEs[alpha] = MSE\n\nMSEs = pd.DataFrame(MSEs)\n\n100%|██████████| 345/345 [00:21&lt;00:00, 15.69it/s]\n\n\n\nplt.figure(figsize = [15, 5])\n\ndef set_params():\n    plt.xlabel(\"$\\\\alpha$\")\n    plt.ylabel(\"$MSE$\")\n\nbordres = [-0.0001, 0.0035]\n\nplt.subplot(121)\nplt.plot(MSEs.columns, MSEs.mean())\nset_params()\nfor b in bordres:\n    plt.axvline(b, color = \"gray\", linestyle = \"dashed\")\nplt.title(\"Общий график\", fontsize = 14)\n\n\ncond = (MSEs.columns &gt; bordres[0]) & (MSEs.columns &lt; bordres[1])\n\nplt.subplot(122)\nplt.errorbar(MSEs.columns[cond], MSEs.mean()[cond], MSEs.std()[cond])\nplt.axvline(\n    MSEs.mean().idxmax(), \n    color = \"gray\", \n    linestyle = \"dashed\"\n)\nplt.xlim(bordres)\nset_params()\nplt.title(\"Максимум - подробно\", fontsize = 14)\nplt.xticks([MSEs.mean().idxmax()])\n\ndel set_params\n\n\n\n\nТеперь подгоням которые будем сравнивать.\n\nx_range = np.arange(0, 1, 0.005)\n\nclf = DecisionTreeRegressor(ccp_alpha=0.0076)\nclf.fit(data[[\"x\"]].to_numpy(), data[\"y\"])\ntree_predict = clf.predict(x_range[:, np.newaxis])\n\nbclf = BaggingRegressor(clf, n_estimators=200).fit(\n    data[[\"x\"]].to_numpy(), data[\"y\"]\n)\nbagging_predict = bclf.predict(x_range[:, np.newaxis])\n\nplt.figure(figsize = [15, 5])\n\nplt.subplot(121)\nplt.scatter(data[\"x\"], data[\"y\"])\nfor pred, col in zip(\n    [tree_predict, bagging_predict],\n    [\"red\", \"green\"]\n):\n    plt.plot(\n        x_range, pred,\n        color = col, linewidth = 3\n    )\n\nplt.legend([\"Наблюдения\", \"Дерево\", \"Баггинг\"])\nplt.title(\"Предсказания моделей\")\nplt.xlabel(\"x\")\n\nplt.subplot(122)\nplt.boxplot((\n    (f_x(x_range) - tree_predict)**2, \n    (f_x(x_range) - bagging_predict)**2)\n)\n\nplt.title(\"Отклонениние модели от реального закона распределения\")\nplt.ylabel(\"$RS$\")\nans = plt.xticks([1,2], [\"Дерево\", \"Баггинг\"])\n\n\n\n\nВсе складывается так, что баггированная модель “сглаживает” неготорые скачки, которые проявляются в одиночном дереве. В результате квадраты остатков (которые описывает правый график) более тучные для баггинга - меньше болших оклонений вверх но и нижняя граница выше.\n\n\nСлучайный лес (Random Forest)\nИдея как у баггинга, но, кроме того, что каждая подвыборка содержит только \\(m\\) из \\(p\\) случайных показателей. Обычно берут \\(m = \\sqrt{p}\\). А в остальном особой разницы нет.\nЕсли в выборке есть очень сильные показатели, то первое деление дерева производится часто именно по нему. В результате простой баггинг от подвыборки к подвыборке имеет очень похожие результаты. Случайное дерево справляется с этой ситуацией лучше.\n\n\nOOB\nOOB - out of bag. Способ оценки качества ансамблей моделей, при котором, оценка метрики качества модели производится на том “кусочке” выборке который не был задейсвован при обучении конкретной модели. Затем полученные величины, собранные со всей выборки агрегируют - полученное число и становится результатом.\n\nПример на котором будем экспериментировать\n\n# делаю пример классификационной задачи\nnp.random.seed(50)\n\n# vector of coefs of the discriminating curve (as a polynom)\ncoefs = np.array([0.40740741, -4.44444444, 13.88888889, -9.25925926])\n\ndef compute_poly_for_np_array(array, coefs):\n    '''\n        Calculation of the polynomial for an numpy array.\n        Inputs:\n            array - an array of any dimension to be used as an argument of the polynom;\n            coefs - polynomial coefficients (i-th for i degree);\n        Output numpy.array with gived same dimentions as array.\n    '''\n    \n    poly_degree = len(coefs)\n    return np.sum(\n        [coefs[i]*(array**i) for i in range(poly_degree)], \n        axis = 0\n    )\n\n# transition speed from one class to another\ntrans_speed = 4\ndef prob_for_bayes(x1, x2):\n    '''\n        This function describes a Bayesian \n        law that is used to divide into classes.\n        Inputs:\n            x1 - coordinate of first variable;\n            x2 - coordiante of second variable;\n        Output:\n            p - probability that observation takes class 1 \n                for given coordinates.\n    '''\n    return 1/(1 + np.exp(trans_speed*(compute_poly_for_np_array(x1, coefs) - x2)))\n\n\n\ndef create_sample():\n    '''\n        Создать случайную выборку, в соответсвии с\n        заданным законом распределения\n    '''\n\n    df = pd.DataFrame(\n        np.random.rand(1000, 2),\n        columns = [\"x1\", \"x2\"]\n    )\n    df[\"prob\"] = prob_for_bayes(df[\"x1\"], df[\"x2\"])\n    df[\"class\"] = df[\"prob\"].apply(\n        lambda p: np.random.choice([0, 1], p = [1-p, p])\n    )\n\n    return df\n\n\n# создание выборки - примера\nnp.random.seed(50)\ndf = create_sample()\n\n# создание сетки\nx1_range = np.linspace(0, 1, 500)\nx2_range = np.linspace(0, 1, 500)\n\nx1_mesh, x2_mesh = np.meshgrid(x1_range, x2_range)\nmesh_df = pd.DataFrame({\n    \"x1\" : x1_mesh.ravel(), \"x2\" : x2_mesh.ravel()\n})\n\nreal_prob = prob_for_bayes(mesh_df[\"x1\"], mesh_df[\"x2\"]).to_numpy()\nreal_prob = real_prob.reshape(x1_mesh.shape)\n\n\nplt.figure(figsize = [15, 7])\n\nplt.subplot(121)\nplt.imshow(real_prob, origin = \"lower\", extent = [0, 1, 0, 1])\nplt.title(\"Дейсвительное распредлеление\")\nplt.xlabel(\"$x_1$\"); plt.ylabel(\"$x_2$\");\n\nplt.subplot(122)\nplt.scatter(df[\"x1\"], df[\"x2\"], c=df[\"class\"])\nplt.xlabel(\"$x_1$\"); plt.ylabel(\"$x_2$\");\nans = plt.title(\"Реализация распределения\")\n\n\n\n\n\n\nРеализация в sklearn\nsklearn умеет OOB, но из метрик доступна только accuracy (доля правильно предсказанных), это тупо захардкожено тут. Например, можно провести oob для баггинга используя параметр oob_score = True констуктора класса BaggingClassifier. Ну а после обучения получить поле oob_score_ полученного объекта.\n\nclf = BaggingClassifier(\n    DecisionTreeClassifier(ccp_alpha = 0.01),\n    n_estimators=30,\n    oob_score=True,\n    random_state=50,\n).fit(df[[\"x1\", \"x2\"]], df[\"class\"])\n\nclf.oob_score_\n\n0.747\n\n\nИнтересное поле - oob_decision_function_. В исходние получается, что это среднее предсказание для каждого наблюдения, из всех его попаданий вне обучающей выборки. На нем при желании можно оценивать AUC.\n\nclf.oob_decision_function_\n\narray([[0.47801078, 0.52198922],\n       [0.35901744, 0.64098256],\n       [0.12722208, 0.87277792],\n       ...,\n       [0.15777634, 0.84222366],\n       [0.89753659, 0.10246341],\n       [0.86331456, 0.13668544]])\n\n\nИнтерестно, что если для каждого наблюдения сформировать предсказание и сравнить среднюю точность с oob_score_, то всегда будет получаться одно и тоже число. Хотя в коде sklearn oob_score_ вычисляется подругому. Если будет совсем нечего делать, можно попробовать разобраться почему так происходит.\n\n# частный случай пример \n(df[\"class\"].to_numpy() == np.argmax(clf.oob_decision_function_, axis=1)).mean()\n\n0.747\n\n\n\n# 20 других частных случаев\nlst = []\n\nfor i in range(20):\n    temp_df = create_sample()\n\n    temp_clf = BaggingClassifier(\n        DecisionTreeClassifier(ccp_alpha = 0.01),\n        n_estimators=30,\n        oob_score=True,\n        random_state=50,\n    ).fit(temp_df[[\"x1\", \"x2\"]], temp_df[\"class\"])\n\n    comp = (\n        temp_df[\"class\"].to_numpy() == \\\n        np.argmax(temp_clf.oob_decision_function_, axis=1)\n    ).mean()\n\n    lst.append(comp == temp_clf.oob_score_)\n\nall(lst)\n\nTrue\n\n\n\n\nСравнение cv и oob\n\ndef fit_estimate(X, y, ccp, n_estimators):\n\n    # приходится отключить warnings потому, что bagging\n    # ругается в случае малого числа оценщиков\n    warnings.filterwarnings(\"ignore\", category=UserWarning)\n    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n    clf = BaggingClassifier(\n        DecisionTreeClassifier(ccp_alpha = ccp),\n        n_estimators=n_estimators,\n        oob_score=True,\n        random_state=50,\n    )\n\n    cv_score = cross_val_score(\n        clf, X, y, scoring=\"accuracy\", cv = 20\n    )\n    res = cv_score.mean(), clf.fit(X,y).oob_score_\n    warnings.filterwarnings(\"ignore\", category=UserWarning)\n    warnings.filterwarnings(\"ignore\", category=RuntimeWarning\n\n    return res\n\ndef get_best_model(scores):\n    '''\n        Получить лучшую модель.\n        Под лучшей понимается модель, с самым высоким \n        значением целевой метрики, но при этом с \n        минимальными возможными числом оценщиков \n        и глубиной дерева.\n\n        Input:\n            scores - pandas.Series который содержит занчения целевой\n                     метрики, а в колонках у него:\n                        \"n_estimators\" - число оценщиков соответсвующей модели;\n                        \"ccp\" - параметр обрезки дерева.\n        Output - та строка из scores в которой заданы параметры\n                 наилучшей модели.\n    '''\n\n    main_val = scores.name\n    return scores.reset_index().sort_values(\n        [main_val, \"n_estimators\", \"ccp\"], \n        ascending=[False, True, False]\n    ).iloc[0]\n\n# создание тех комбинаций\n# параметров модели которое нужно\n# осчитать\nccp_alphas = DecisionTreeRegressor().\\\ncost_complexity_pruning_path(\n    df[[\"x1\", \"x2\"]], df[\"class\"]\n)[\"ccp_alphas\"]\n\nccp_alphas = np.linspace(ccp_alphas.min(), ccp_alphas.max(), 10)\nestimator_counts = range(30, 70)\n\ncombinations = pd.DataFrame(\n    [col.ravel() for col in np.meshgrid(ccp_alphas, estimator_counts)],\n    index=[\"ccp\", \"n_estimators\"]\n).T\n\nSyntaxError: '(' was never closed (1082649026.py, line 19)\n\n\nval_ress = combinations.apply( lambda x: fit_estimate( df[[“x1”, “x2”]], df[“class”], x[“ccp”], int(x[“n_estimators”]) ), axis = 1 )\nval_ress = val_ress.apply( lambda row: pd.Series( row, index = [“cross validation”, “OOB”] ) ) val_ress.index = pd.MultiIndex.from_frame(combinations)\nval_ress.to_csv(“cv_vs_oob.csv”)\n\nval_ress = pd.read_csv(\"cv_vs_oob.csv\", index_col=[0, 1])\n\n\nplt.scatter(val_ress[\"cross validation\"], val_ress[\"OOB\"])\nplt.xlabel(\"CV accuracy\")\nplt.title(\"OOB против CV\")\nans = plt.ylabel(\"OOB accuracy\")\n\n\n\n\n\npd.concat(\n    [\n        get_best_model(val_ress[\"cross validation\"]),\n        get_best_model(val_ress[\"OOB\"])\n    ],\n    axis=1\n)\n\n\n\n\n\n\n\n\n281\n201\n\n\n\n\nccp\n0.006929\n0.006929\n\n\nn_estimators\n58.000000\n50.000000\n\n\ncross validation\n0.763000\nNaN\n\n\nOOB\nNaN\n0.756000\n\n\n\n\n\n\n\n\n\n\nООб\n\nheart = pd.read_csv(\"Heart.csv\", index_col=0)\n\ny = (heart[\"AHD\"] == \"Yes\").astype(\"int32\")\nX = pd.get_dummies(heart.drop(\"AHD\", axis=1))\n\nX_train = X.iloc[:152]\nX_test = X.loc[~X.index.isin(X_train.index)]\ny_train = y.loc[X_train.index]\ny_test = y.loc[X_test.index]\n\nclf = RandomForestClassifier()\nfor tree_count in range(1,301):\n    clf.set_params()\n\n\n\n\n\n\n\n\nAge\nSex\nRestBP\nChol\nFbs\nRestECG\nMaxHR\nExAng\nOldpeak\nSlope\nCa\nChestPain_asymptomatic\nChestPain_nonanginal\nChestPain_nontypical\nChestPain_typical\nThal_fixed\nThal_normal\nThal_reversable\n\n\n\n\n153\n67\n0\n115\n564\n0\n2\n160\n0\n1.6\n2\n0.0\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n154\n55\n1\n160\n289\n0\n2\n145\n1\n0.8\n2\n1.0\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n155\n64\n1\n120\n246\n0\n2\n96\n1\n2.2\n3\n1.0\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n156\n70\n1\n130\n322\n0\n2\n109\n0\n2.4\n2\n3.0\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n157\n51\n1\n140\n299\n0\n0\n173\n1\n1.6\n1\n0.0\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n299\n45\n1\n110\n264\n0\n0\n132\n0\n1.2\n2\n0.0\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nTrue\n\n\n300\n68\n1\n144\n193\n1\n0\n141\n0\n3.4\n2\n2.0\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n301\n57\n1\n130\n131\n0\n0\n115\n1\n1.2\n2\n1.0\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n302\n57\n0\n130\n236\n0\n2\n174\n0\n0.0\n2\n1.0\nFalse\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\n\n\n303\n38\n1\n138\n175\n0\n0\n173\n0\n0.0\n1\nNaN\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n\n\n151 rows × 18 columns"
  },
  {
    "objectID": "git/init.html",
    "href": "git/init.html",
    "title": "Init repository",
    "section": "",
    "text": "This page is about how to initialise a git repository in a folder.\nYou should use the git init command to create a new git repository. It will just add a `.git’ folder to the folder you’re init as the git repository - this folder is a marker for git that this is the git repository.\nIn the following example I just - Create a new folder; - Run git init there; - Show that .git folder appears there.\n\n%%bash\nmkdir git_init\ncd git_init\n\necho \"=====new folder is empty=====\"\nls -a\n\necho \"=====creating git repo=====\"\ngit init\necho \"=====check what appears in git repo=====\"\nls -a\n\ncd ..\nrm -r git_init\n\n=====new folder is empty=====\n.\n..\n=====creating git repo=====\nInitialized empty Git repository in /home/fedor/Documents/knowledge/git/git_init/.git/\n=====check what appears in git repo=====\n.\n..\n.git\n\n\nhint: Using 'master' as the name for the initial branch. This default branch name\nhint: is subject to change. To configure the initial branch name to use in all\nhint: of your new repositories, which will suppress this warning, call:\nhint: \nhint:   git config --global init.defaultBranch &lt;name&gt;\nhint: \nhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\nhint: 'development'. The just-created branch can be renamed via this command:\nhint: \nhint:   git branch -m &lt;name&gt;"
  },
  {
    "objectID": "git/ignore.html",
    "href": "git/ignore.html",
    "title": "How git ignore works",
    "section": "",
    "text": "Using the syntax *&lt;symbol_combination&gt;* you can specify a symbol combination and any file with that symbol combination in the relative filepath will be ignored by git.\nThe following example shows:\n\nFiles tree and .gitignore, which tells git to ignore any file with symb_comb in it’s filepath;\nThe results of the git status of a freshly created repository, which helps us understand exactly what files git is ignoring.\n\nThere are few important fatures:\n\nOf course, some_folder2 doesn’t have symb_comb in it’s filepath, but it only has one file and that file should be ignored by git, so to git this folder appears empty;\nGit ignores files in directories started or ended with symb_comb.\n\n\n%%bash\ncd ignore_files/any_entry\ngit init &&gt; /dev/null\n\necho \"=====FILES TREE=====\"\ntree\n\necho\necho\necho \"=====.GITIGNORE FILE=====\"\ncat .gitignore\n\n\necho\necho\necho \"=====GIT STATUS=====\"\ngit status\n\nrm -r .git\n\n=====FILES TREE=====\n.\n├── some_folder\n│   └── some_file\n└── some_random_file\n\n1 directory, 2 files\n\n\n=====.GITIGNORE FILE=====\n*symb_comb*\n\n\n=====GIT STATUS=====\nOn branch master\n\nNo commits yet\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n    .gitignore\n    some_folder/\n    some_random_file\n\nnothing added to commit but untracked files present (use \"git add\" to track)"
  },
  {
    "objectID": "git/ignore.html#any-entry",
    "href": "git/ignore.html#any-entry",
    "title": "How git ignore works",
    "section": "",
    "text": "Using the syntax *&lt;symbol_combination&gt;* you can specify a symbol combination and any file with that symbol combination in the relative filepath will be ignored by git.\nThe following example shows:\n\nFiles tree and .gitignore, which tells git to ignore any file with symb_comb in it’s filepath;\nThe results of the git status of a freshly created repository, which helps us understand exactly what files git is ignoring.\n\nThere are few important fatures:\n\nOf course, some_folder2 doesn’t have symb_comb in it’s filepath, but it only has one file and that file should be ignored by git, so to git this folder appears empty;\nGit ignores files in directories started or ended with symb_comb.\n\n\n%%bash\ncd ignore_files/any_entry\ngit init &&gt; /dev/null\n\necho \"=====FILES TREE=====\"\ntree\n\necho\necho\necho \"=====.GITIGNORE FILE=====\"\ncat .gitignore\n\n\necho\necho\necho \"=====GIT STATUS=====\"\ngit status\n\nrm -r .git\n\n=====FILES TREE=====\n.\n├── some_folder\n│   └── some_file\n└── some_random_file\n\n1 directory, 2 files\n\n\n=====.GITIGNORE FILE=====\n*symb_comb*\n\n\n=====GIT STATUS=====\nOn branch master\n\nNo commits yet\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n    .gitignore\n    some_folder/\n    some_random_file\n\nnothing added to commit but untracked files present (use \"git add\" to track)"
  },
  {
    "objectID": "git/commit.html",
    "href": "git/commit.html",
    "title": "Commit",
    "section": "",
    "text": "git commit is central command for git that allows to save staged memories for ever."
  },
  {
    "objectID": "git/commit.html#a-option",
    "href": "git/commit.html#a-option",
    "title": "Commit",
    "section": "-a option",
    "text": "-a option\nThis option makes git to stage file that wasn’t staged before the commit. It’s like to do commit for edited files without execution of git add before.\n\nBasic example\nSo in the following example:\n\nCreate a repository containing a modified file;\nFirst attempt to commit without additional options - fails, log doesn’t show control commit just because there was nothing to commit;\nSecond attempt to commit -a - it works, new commit appears in git log results.\n\n\n%%bash\nmkdir commit_example\ncd commit_example\n\ngit init &&gt; /dev/null\necho \"some text\" &gt; test_file\ngit add --all\ngit commit -m \"innitial commit\"&&gt; /dev/null\necho \"some other text\" &gt; test_file\n\necho \"=====Just commit=====\"\necho \"-----commit-----\"\ngit commit -m \"control commit\"\necho \"-----log-----\"\ngit log --oneline\n\necho\necho \"=====Commit -a=====\"\necho \"-----commit-----\"\ngit commit -am \"control commit\"\necho \"-----log-----\"\ngit log --oneline\n\n\ncd ..\nrm -r commit_example\n\n=====Just commit=====\n-----commit-----\nOn branch master\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n    modified:   test_file\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n-----log-----\nb492f00 innitial commit\n\n=====Commit -a=====\n-----commit-----\n[master 1b938f2] control commit\n 1 file changed, 1 insertion(+), 1 deletion(-)\n-----log-----\n1b938f2 control commit\nb492f00 innitial commit\n\n\n\n\nUntracked files\nThis option won’t work for untracked files. You have to add it before.\nSo in the following example, I’m trying to use commit -a for a repository with only one untracked file, and getting messages that I need to add it first.\n\n%%bash\nmkdir commit_example\ncd commit_example\n\ngit init &&gt; /dev/null\necho \"some text\" &gt; test_file\n# git add --all don't add untracked file\necho \"=====commit=====\"\ngit commit -am \"innitial commit\"\necho \"=====log=====\"\ngit log\n\ncd ..\nrm -r commit_example\n\n=====commit=====\nOn branch master\n\nInitial commit\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n    test_file\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n=====log=====\n\n\nfatal: your current branch 'master' does not have any commits yet"
  },
  {
    "objectID": "git/diff.html",
    "href": "git/diff.html",
    "title": "Difference",
    "section": "",
    "text": "The git diff command allows you to chech difference between condition of repository."
  },
  {
    "objectID": "git/diff.html#untracked-files",
    "href": "git/diff.html#untracked-files",
    "title": "Difference",
    "section": "Untracked files",
    "text": "Untracked files\nUntracked files wont be displayed in git diff.\nThe following example just init git repository and add a file there and the git diff command doesn’t print anything in this case.\n\n%%bash\nmkdir diff_example\ncd diff_example\n\ngit init &&gt; /dev/null\necho \"some text\" &gt; test_file\ngit diff\n\ncd ..\nrm -r diff_example"
  },
  {
    "objectID": "git/diff.html#changed-files",
    "href": "git/diff.html#changed-files",
    "title": "Difference",
    "section": "Changed files",
    "text": "Changed files\nBy default git diff shows unstaged changes. In fact, any change to the file can be described as an insert/delete. So the following subsections show what it’s like to have insert/delete lines in the git diff results.\n\nInsert line\nMain point of the next cell is to add line \"second line\" to the file commited before. In git diff results it’ll look like +second line.\n\n%%bash\nmkdir diff_example\ncd diff_example\n\ngit init &&gt; /dev/null\necho \"first line\" &gt; test_file\ngit add test_file &&gt; /dev/null\ngit commit -m \"initial commit\" &&gt; /dev/null\n\n\necho \"second line\" &gt;&gt; test_file\ngit diff\n\ncd ..\nrm -r diff_example\n\ndiff --git a/test_file b/test_file\nindex 08fe272..06fcdd7 100644\n--- a/test_file\n+++ b/test_file\n@@ -1 +1,2 @@\n first line\n+second line\n\n\n\n\nDelete line\nIn this case I created files with two lines \"first line\" and \"second line\". After committing, I save the new version of the file without the second line. Gid diff shows it as -second line.\n\n%%bash\nmkdir diff_example\ncd diff_example\ngit init &&gt; /dev/null\n\ncat &gt; test_file &lt;&lt; EOF\nfirst line\nsecond line\nEOF\ngit add test_file\ngit commit -m \"initial commit\" &&gt; /dev/null\n\ncat &gt; test_file &lt;&lt; EOF\nfirst line\nEOF\ngit diff\n\ncd ..\nrm -r diff_example\n\ndiff --git a/test_file b/test_file\nindex 06fcdd7..08fe272 100644\n--- a/test_file\n+++ b/test_file\n@@ -1,2 +1 @@\n first line\n-second line"
  },
  {
    "objectID": "git/diff.html#new-file",
    "href": "git/diff.html#new-file",
    "title": "Difference",
    "section": "New file",
    "text": "New file\nIn this section, I’ll show you what a newly added file looks like in git diff.\n\nEmpty file\nIn the following example, I’ve added an empty second_file and compared it with the state of the repository in the previous commit, if there is no second_file' line, thenew file mode` will signal that this file has been created.\n\n%%bash\nmkdir diff_example\ncd diff_example\ngit init &&gt; /dev/null\n\ntouch first_file\ngit add first_file\ngit commit -m \"first commit\" &&gt; /dev/null\n\ntouch second_file\ngit add second_file &&gt; /dev/null\n\ngit diff --staged\ncat second_file\n\ncd ..\nrm -r diff_example\n\ndiff --git a/second_file b/second_file\nnew file mode 100644\nindex 0000000..e69de29\n\n\n\n\nFile with content\nIn this example I have created a file second_file and added some content to it. It’ll share all the details of adding empty file option - new file mode 100644 signal that new file has been created. But there is also a section with changes to the file below. Note that the source file from the commit to which we are comparing the state is marked as --- /dev/null (in Linux this directory is used for information that should simply be deleted).\n\n%%bash\nmkdir diff_example\ncd diff_example\ngit init &&gt; /dev/null\n\ntouch first_file\ngit add first_file\ngit commit -m \"first commit\" &&gt; /dev/null\n\necho \"some content\" &gt; second_file\ngit add second_file &&gt; /dev/null\n\ngit diff --staged\ncat second_file\n\ncd ..\nrm -r diff_example\n\ndiff --git a/second_file b/second_file\nnew file mode 100644\nindex 0000000..2ef267e\n--- /dev/null\n+++ b/second_file\n@@ -0,0 +1 @@\n+some content\nsome content"
  },
  {
    "objectID": "git/diff.html#staged-option",
    "href": "git/diff.html#staged-option",
    "title": "Difference",
    "section": "–staged option",
    "text": "–staged option\nBy default git diff shows only changed but not staged files. To get information about staged files use --staged option.\n\nNew file\nBy using the --staged option, you can even see the difference between a newly created (but added) file.\nSo in the following example I have created and added to the repo file and compared the results with and without the --staged option.\n\n%%bash\nmkdir diff_example\ncd diff_example\n\ngit init &&gt; /dev/null\necho \"some text\" &gt; staged_file\ngit add staged_file\n\necho \"=====just diff====\"\ngit diff\n\necho\necho \"=====diff staged=====\"\ngit diff --staged\n\ncd ..\nrm -r diff_example\n\n=====just diff====\n\n=====diff staged=====\ndiff --git a/staged_file b/staged_file\nnew file mode 100644\nindex 0000000..7b57bd2\n--- /dev/null\n+++ b/staged_file\n@@ -0,0 +1 @@\n+some text\n\n\n\n\nUnstaged changes\nIf you use the --staged option, you won’t see any difference when unstaging files. In the example:\n\nIn the first commit I just added first_file;\nI added second_file and staged it;\nI changed first_file but did not stage it;\nUsing git diff' without the–staged’ option I only got changes in first_file because it wasn’t staged;\nUsing git diff --staged I only got information about second_file but not about first_file.\n\n\n%%bash\nmkdir diff_example\ncd diff_example\ngit init &&gt; /dev/null\n\necho \"first text\" &gt; first_file\ngit add first_file\ngit commit -m \"first file add\" &&gt; /dev/null\n\necho \"sefond text\" &gt; second_file\ngit add second_file\necho \"changed first text\" &gt; first_file\n\necho \"=====just diff====\"\ngit diff\n\necho\necho \"=====diff staged=====\"\ngit diff --staged\n\ncd ..\nrm -r diff_example\n\n=====just diff====\ndiff --git a/first_file b/first_file\nindex 38181e5..fc9cf92 100644\n--- a/first_file\n+++ b/first_file\n@@ -1 +1 @@\n-first text\n+changed first text\n\n=====diff staged=====\ndiff --git a/second_file b/second_file\nnew file mode 100644\nindex 0000000..422845a\n--- /dev/null\n+++ b/second_file\n@@ -0,0 +1 @@\n+sefond text"
  },
  {
    "objectID": "git/diff.html#compare-two-commits",
    "href": "git/diff.html#compare-two-commits",
    "title": "Difference",
    "section": "Compare two commits",
    "text": "Compare two commits\nYou can compare two arbitrary commits using the syntax git diff &lt;basic commit&gt; &lt;comparison commit&gt;.\nNote basic commit not necessary to be earlier that comparison commit.\nSo in the following example:\n\nIn cycle created few commits each add some line to file:\n\nNote line val \"hash$i=$(git rev-parse HEAD)\" just saves hash of last commit to variable hash&lt;i&gt;, so, for example, you can get hash of first commit from variable $hash1;\n\ngit log just help to understand current state of the repository;\nThen I copare commits Line 1 added and Line 2 added in both options:\n\nLine 1 added as basic commit and Line 2 added as comparison commit - +Line 2show that it was added in comparison commit relatively basic commit;\nLine 2 added as basic commit and Line 1 added as comparison commit - -Line 2show that it was deleted in comparison commit relatively basic commit.\n\n\n\n%%bash\nmkdir diff_example\ncd diff_example\ngit init &&gt; /dev/null\n\nfor i in {1..3}\ndo\n  echo \"Line $i\" &gt;&gt; file\n  git add file\n  git commit -m \"Line $i added\" &&gt; /dev/null\n  eval \"hash$i=$(git rev-parse HEAD)\"\ndone\n\necho \"=====git log=====\"\ngit log --oneline --decorate\n\necho\necho \"=====git diff \\$hash1 \\$hash2=======\"\ngit diff $hash1 $hash2\necho\necho \"=====git diff \\$hash2 \\$hash1=======\"\ngit diff $hash2 $hash1\n\ncd ..\nrm -r diff_example\n\n=====git log=====\nc9578cb (HEAD -&gt; master) Line 3 added\nff19e36 Line 2 added\nbd6fd11 Line 1 added\n\n=====git diff $hash1 $hash2=======\ndiff --git a/file b/file\nindex 3be9c81..c82de6a 100644\n--- a/file\n+++ b/file\n@@ -1 +1,2 @@\n Line 1\n+Line 2\n\n=====git diff $hash2 $hash1=======\ndiff --git a/file b/file\nindex c82de6a..3be9c81 100644\n--- a/file\n+++ b/file\n@@ -1,2 +1 @@\n Line 1\n-Line 2"
  },
  {
    "objectID": "git/previous_commit.html",
    "href": "git/previous_commit.html",
    "title": "Previous commit ~",
    "section": "",
    "text": "You can use the &lt;commit&gt;~n construction to reference a commit that is n steps back in the commit chain."
  },
  {
    "objectID": "git/previous_commit.html#basic-example",
    "href": "git/previous_commit.html#basic-example",
    "title": "Previous commit ~",
    "section": "Basic example",
    "text": "Basic example\nIn the following example:\n\nTwo commits were created;\ngit log shows that HEAD refer to second commit;\ngit show HEAD~1 show the idea:\n\ngit show is a command that displays information about a passed commit;\nHEAD~1 is passed as an argument to git show, which means that a commit back from commit HEAD refers to;\nSo we got information about first commit, which is correct, it is a commit back from second commit.\n\n\n\n%%bash\nmkdir operations_examples\ncd operations_examples\ngit init &&gt; /dev/null\n\ntouch file1\ngit add --all\ngit commit -am \"first commit\" &&gt; /dev/null\n\ntouch file2\ngit add --all\ngit commit -am \"second commit\" &&gt; /dev/null\n\necho \"=====git log=====\"\ngit log --oneline --decorate\necho \"=====git show=====\"\ngit show HEAD~1\n\ncd ..\nrm -r operations_examples\n\n=====git log=====\ne94d28e (HEAD -&gt; master) second commit\n73e5ca8 first commit\n=====git show=====\ncommit 73e5ca80b04925b1f03d6b9e0b164a796439ff71\nAuthor: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\nDate:   Sun Sep 10 10:25:44 2023 +0300\n\n    first commit\n\ndiff --git a/file1 b/file1\nnew file mode 100644\nindex 0000000..e69de29"
  },
  {
    "objectID": "git/previous_commit.html#use-hash",
    "href": "git/previous_commit.html#use-hash",
    "title": "Previous commit ~",
    "section": "Use hash",
    "text": "Use hash\nI was wondering if it is possible to use the commit hash in this construct, i.e. &lt;hash&gt;~1? Yes, you can! The following example confirms it:\n\nCreated two commits, first commit and second commit;\nStored hash of second commit in variable\nI used variable with syntax ~1;\nAll is well - I got info on first commit, which is one before second commit.\n\n\n%%bash\nmkdir operations_examples\ncd operations_examples\ngit init &&gt; /dev/null\n\ntouch file1\ngit add --all\ngit commit -am \"first commit\" &&gt; /dev/null\n\ntouch file2\ngit add --all\ngit commit -am \"second commit\" &&gt; /dev/null\nsecond_hash=$(git rev-parse HEAD)\n\necho \"=====git log=====\"\ngit log --oneline --decorate\necho \"=====git show=====\"\ngit show $second_hash~1\n\ncd ..\nrm -r operations_examples\n\n=====git log=====\ne79a082 (HEAD -&gt; master) second commit\n3d2a63f first commit\n=====git show=====\ncommit 3d2a63fcbd20eb9730ae250cef9ab6133e60ef19\nAuthor: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\nDate:   Sun Sep 10 10:35:54 2023 +0300\n\n    first commit\n\ndiff --git a/file1 b/file1\nnew file mode 100644\nindex 0000000..e69de29"
  },
  {
    "objectID": "git/checkout.html",
    "href": "git/checkout.html",
    "title": "Checkout",
    "section": "",
    "text": "git checkout is a command that allows you to swich current state of project to the another commit."
  },
  {
    "objectID": "git/checkout.html#back-up-commit",
    "href": "git/checkout.html#back-up-commit",
    "title": "Checkout",
    "section": "Back up commit",
    "text": "Back up commit\nIn the next example:\n\nTwo commits have been created:\n\nfirst commit add first_file.\nsecond commit edits first file and adds second file;\n\nI used git log to show these commits:\n\nNote the (HEAD-&gt;master) near second commit, this means you are staying on second commit and the master branch is pointing to it;\nNote To print HEAD-&gt;master in jupyter notebook output you have to use the --decorate option for some reason, in terminal this is not necessary;\n\nI stored the hash of the first commit in the first_hash variable and printed it;\nUsing git checkout $first_hash I moved HEAD to first commit, which means it’s now an active commit:\n\nNote In real work you can use the hash of the commit and don’t use a variable to store the commit hash;\nNote by default git checkout prints it’s message to the error stream, so I used 2&gt;&1 to redirect it to the out stream;\n\nBy calling git log again, I showed:\n\nThat (HEAD) is now next to the first commit message;\nThe second commit isn’t even shown now - git’s default behaviour for git log is to show the history of the commit that created the head commit. Use the --all option to show all messages;\n\nls will show that there is no second file in the project folder now - it’s ok, we’ve moved to a commit where there is no such file;\ncat first_file shows that the first file is still the same as it was in the second commit:\n\nThis is because we reverted git to first_commit but not the working directory. In git status you can see that first_file is marked as modified, it is indeed different from the commit that HEAD is currently referring to;\nTo return a file to the state as in first commit you simply need to do a git restore for that file, which is what I am doing and demonstrating the first_file from first commit.\n\n\n\n%%bash\nmkdir checkout_example\ncd checkout_example\n\ngit init &&gt; /dev/null\n\necho \"some text\" &gt; first_file\ngit add first_file\ngit commit -m \"first commit\" &&gt; /dev/null\nfirst_hash=$(git rev-parse HEAD)\n\necho \"some text\" &gt; second_file\necho \"this is the text for second commit\" &gt; first_file\ngit add second_file\ngit commit -m \"second commit\" &&gt; /dev/null\n\necho \"=====log=====\"\ngit log --decorate\n\necho\necho \"=====first commit hash=====\"\necho $first_hash\n\necho\necho \"=====git chechout to first commit=====\"\ngit checkout $first_hash 2&gt;&1\n\necho\necho \"=====log=====\"\ngit log --decorate\necho \"=====ls=====\"\nls\necho \"=====first_file=====\"\ncat first_file\n\necho\necho \"====status=====\"\ngit status\ngit restore first_file\necho \"=====first_file after restore=====\"\ncat first_file\n\n\ncd ..\nrm -r checkout_example\n\n=====log=====\ncommit 23e858c0a0924f75ef4f1a9eddf0c357f9d865b5 (HEAD -&gt; master)\nAuthor: Dranikf &lt;kobfedsur@gmail.com&gt;\nDate:   Thu Sep 7 22:45:41 2023 +0300\n\n    second commit\n\ncommit f42455672912f0347c9e29165583ddc5accf9b25\nAuthor: Dranikf &lt;kobfedsur@gmail.com&gt;\nDate:   Thu Sep 7 22:45:41 2023 +0300\n\n    first commit\n\n=====first commit hash=====\nf42455672912f0347c9e29165583ddc5accf9b25\n\n=====git chechout to first commit=====\nNote: switching to 'f42455672912f0347c9e29165583ddc5accf9b25'.\n\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by switching back to a branch.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -c with the switch command. Example:\n\n  git switch -c &lt;new-branch-name&gt;\n\nOr undo this operation with:\n\n  git switch -\n\nTurn off this advice by setting config variable advice.detachedHead to false\n\nHEAD is now at f424556 first commit\nM   first_file\n\n=====log=====\ncommit f42455672912f0347c9e29165583ddc5accf9b25 (HEAD)\nAuthor: Dranikf &lt;kobfedsur@gmail.com&gt;\nDate:   Thu Sep 7 22:45:41 2023 +0300\n\n    first commit\n=====ls=====\nfirst_file\n=====first_file=====\nthis is the text for second commit\n\n====status=====\nHEAD detached at f424556\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n    modified:   first_file\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n=====first_file after restore=====\nsome text"
  },
  {
    "objectID": "git/merge.html",
    "href": "git/merge.html",
    "title": "Merge",
    "section": "",
    "text": "Branches merge is opertion that allows you to get changes from intependend branches in one common commit. The git merge command is crucial for this page.\nTo merge branches you need to git checkout to brunch to which we merge all the changes, and execute command git merge &lt;branch to be merged&gt;."
  },
  {
    "objectID": "git/merge.html#sec-to_ancestor",
    "href": "git/merge.html#sec-to_ancestor",
    "title": "Merge",
    "section": "To ancestor",
    "text": "To ancestor\nThe simplest case is when you create a branch, make a few commits, and want to add those changes from an ancestor branch that hasn’t changed.\nSimply put, you just tell the parent branch to just start referencing the last commit of the branch you want to merge into the parent branch.\nIn the next cell:\n\nCreated repository where there is basic commit;\nFrom basic commit branch example_branch was created;\nbranch_commit was commited to example_branch, first git log display exactly this state of the repository;\nThen example_branch was merged to master - on git log it just desplayed as master moved to same commit as example_branch.\n\n\n%%bash\nmkdir merge_example\ncd merge_example\ngit init &&gt; /dev/null\n\necho \"content\" &gt; test_file\ngit add --all\ngit commit -m \"basic commit\" &&gt; /dev/null\n\necho\necho \"=====creating branch=====\"\ngit checkout -b example_branch 2&gt;&1\necho \"content2\" &gt; test_file\ngit commit -am \"branch commit\" &&gt; /dev/null\ngit log --decorate --graph\n\necho\necho \"=====merging to master=====\"\ngit checkout master 2&gt;&1\n\necho \"-----git merge-----\"\ngit merge example_branch\necho \"-----git log-----\"\ngit log --decorate --graph\n\ncd ..\nrm -r merge_example\n\n\n=====creating branch=====\nSwitched to a new branch 'example_branch'\n* commit bbd3463120a7fc513429a75ca2ebfff325571f84 (HEAD -&gt; example_branch)\n| Author: Dranikf &lt;kobfedsur@gmail.com&gt;\n| Date:   Sun Sep 10 16:20:47 2023 +0300\n| \n|     branch commit\n| \n* commit c42d7deed4d71b0f5c9036816fe65e7295a5e227 (master)\n  Author: Dranikf &lt;kobfedsur@gmail.com&gt;\n  Date:   Sun Sep 10 16:20:47 2023 +0300\n  \n      basic commit\n\n=====merging to master=====\nSwitched to branch 'master'\n-----git merge-----\nUpdating c42d7de..bbd3463\nFast-forward\n test_file | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n-----git log-----\n* commit bbd3463120a7fc513429a75ca2ebfff325571f84 (HEAD -&gt; master, example_branch)\n| Author: Dranikf &lt;kobfedsur@gmail.com&gt;\n| Date:   Sun Sep 10 16:20:47 2023 +0300\n| \n|     branch commit\n| \n* commit c42d7deed4d71b0f5c9036816fe65e7295a5e227\n  Author: Dranikf &lt;kobfedsur@gmail.com&gt;\n  Date:   Sun Sep 10 16:20:47 2023 +0300\n  \n      basic commit"
  },
  {
    "objectID": "git/merge.html#sec-basic_case",
    "href": "git/merge.html#sec-basic_case",
    "title": "Merge",
    "section": "Basic case",
    "text": "Basic case\nHere I’ll play with the case when you have to branches but one doesn’t refer to any ancestor of other (like it was in To ancestor) section, so we have two separate branches.\nNote in this example I don’t pay any attention ot conflicts, the example is made in such a way as to avoid conflicts.\nIn the example:\n\nI created a repository where there are two branches that have independent commits in them, this is shown in the first git log output;\nThen I merge example_branch into master;\nIn the final git log output:\n\nThere is a new commit where the two branches merge;\nThe message of the commit is Merge branch 'example_branch' - automatically generated by git, in practice you’ll be able to set the message you want.\n\n\n\n%%bash\nmkdir merge_example\ncd merge_example\ngit init &&gt; /dev/null\n\necho \"content\" &gt; file\ngit add --all\ngit commit -m \"basic commit\" &&gt; /dev/null\n\ngit checkout -b example_branch &&gt; /dev/null\necho \"content\" &gt; branch_file\ngit add --all\ngit commit -m \"branch commit\" &&gt; /dev/null\n\ngit checkout master &&gt; /dev/null\necho \"master content\" &gt; file\ngit commit -am \"master commit\" &&gt; /dev/null\n\necho\necho \"=====log=====\"\ngit log --decorate --graph --all\n\necho\necho \"=====merge=====\"\ngit merge example_branch\n\necho\necho \"=====log=====\"\ngit log --decorate --graph --all\n\ncd ..\nrm -r merge_example\n\n\n=====log=====\n* commit 6ea69b66f6c2a49ea60a3a6b5b3de66181274234 (example_branch)\n| Author: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\n| Date:   Sun Sep 10 13:00:54 2023 +0300\n| \n|     branch commit\n|   \n| * commit 8b9f875b80b9d44020dedf40a39b1894f4a406d6 (HEAD -&gt; master)\n|/  Author: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\n|   Date:   Sun Sep 10 13:00:54 2023 +0300\n|   \n|       master commit\n| \n* commit 15149be74a6d219dac74624c94bd7aeda0691e9d\n  Author: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\n  Date:   Sun Sep 10 13:00:54 2023 +0300\n  \n      basic commit\n\n=====merge=====\nMerge made by the 'ort' strategy.\n branch_file | 1 +\n 1 file changed, 1 insertion(+)\n create mode 100644 branch_file\n\n=====log=====\n*   commit 96f925a2adbada606ba4678c71460cf697fd8590 (HEAD -&gt; master)\n|\\  Merge: 8b9f875 6ea69b6\n| | Author: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\n| | Date:   Sun Sep 10 13:00:54 2023 +0300\n| | \n| |     Merge branch 'example_branch'\n| | \n| * commit 6ea69b66f6c2a49ea60a3a6b5b3de66181274234 (example_branch)\n| | Author: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\n| | Date:   Sun Sep 10 13:00:54 2023 +0300\n| | \n| |     branch commit\n| | \n* | commit 8b9f875b80b9d44020dedf40a39b1894f4a406d6\n|/  Author: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\n|   Date:   Sun Sep 10 13:00:54 2023 +0300\n|   \n|       master commit\n| \n* commit 15149be74a6d219dac74624c94bd7aeda0691e9d\n  Author: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\n  Date:   Sun Sep 10 13:00:54 2023 +0300\n  \n      basic commit"
  },
  {
    "objectID": "git/merge.html#solve-conflict",
    "href": "git/merge.html#solve-conflict",
    "title": "Merge",
    "section": "Solve conflict",
    "text": "Solve conflict\nIn the section basic case the example shows the case where the brances to be merged modify different files. But how does git deal with the case where branches being merged have changes in the same files?\nGit will enter a special state - a merge conflict. It will be necessary to edit the files that caused the conflict, add changes to the stage, and commit the changes.\nWhen there is a conflict, git will make some changes to the conflicting files. It will record where there is a conflict:\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n&lt;content of the branch we are merging into&gt;\n===========\n&lt;content of the branch we merge into another&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; &lt;branch ot be merged name&gt;\nWe can put any content there: we can put content from one of the branches, or we can put completely different content.\nSo in the following example\n\nCreate a repository;\nCommit with the message basic commit;\nFrom basic commit commit created example branch commit of which file has content for example branch;\nThe master branch continues it’s way with a commit which has file with content for example branch;\nThe first git log output shows the state of the repository at this step, so for now we have two branches where file has different contents;\nTried to merge example_branch into the master branch and got a message that there was a merge conflict;\nShows what the git status of the repository looks like in this state:\n\nPrints possible solutions;\nPrints the files that caused the merge conflict;\n\nSuppose we want to fix a conflict. Our actions are to write into the conflict files how they should be fixed as a result, add them to the stage, and then commit;\nInterestingly, git will overwrite the files involved in the conflict. The example shows what our file will look like, see =====conflict file=====;\nI set the file to after merge content and just commit the changes - this commit will become the merge point for the conflicting branches.\n\n\n%%bash\nmkdir merge_example\ncd merge_example\ngit init &&gt; /dev/null\n\necho \"content for basic commit\" &gt; file\ngit add --all\ngit commit -m \"basic commit\" &&gt; /dev/null\n\ngit checkout -b example_branch &&gt; /dev/null\necho \"content for example branch\" &gt; file\ngit commit -am \"commit in example_branch\" &&gt; /dev/null\n\ngit checkout master &&gt; /dev/null\necho \"content for master branch\" &gt; file\ngit commit -am \"commit in master\" &&gt; /dev/null\n\necho \"=====git log=====\"\ngit log --decorate --graph --all\n\necho\necho \"=====merge try=====\"\ngit merge example_branch\necho\necho \"=====git status=====\"\ngit status\necho\necho \"=====conflict file=====\"\ncat file\n\necho \"after merge content\" &gt; file\ngit add file\ngit commit -am \"my after merge commit\" &&gt; /dev/null\n\necho\necho \"=====git log=====\"\ngit log --all --decorate --graph\n\n\ncd ..\nrm -r merge_example\n\n=====git log=====\n* commit 69a666cd3dc1c3f0b436a1ecbeb58ea32eb080c1 (example_branch)\n| Author: Dranikf &lt;kobfedsur@gmail.com&gt;\n| Date:   Sun Sep 10 16:43:44 2023 +0300\n| \n|     commit in example_branch\n|   \n| * commit 51377f0e8c2f305bfcab9c4a97a6a36d8e44c99f (HEAD -&gt; master)\n|/  Author: Dranikf &lt;kobfedsur@gmail.com&gt;\n|   Date:   Sun Sep 10 16:43:44 2023 +0300\n|   \n|       commit in master\n| \n* commit 7307ad26c4cc29bbb0eac4b9ad2420aeab716f0b\n  Author: Dranikf &lt;kobfedsur@gmail.com&gt;\n  Date:   Sun Sep 10 16:43:44 2023 +0300\n  \n      basic commit\n\n=====merge try=====\nAuto-merging file\nCONFLICT (content): Merge conflict in file\nAutomatic merge failed; fix conflicts and then commit the result.\n\n=====git status=====\nOn branch master\nYou have unmerged paths.\n  (fix conflicts and run \"git commit\")\n  (use \"git merge --abort\" to abort the merge)\n\nUnmerged paths:\n  (use \"git add &lt;file&gt;...\" to mark resolution)\n    both modified:   file\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\n=====conflict file=====\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\ncontent for master branch\n=======\ncontent for example branch\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; example_branch\n\n=====git log=====\n*   commit acb33c07dd270ac0ff04f29c37303d10ecb2ed0c (HEAD -&gt; master)\n|\\  Merge: 51377f0 69a666c\n| | Author: Dranikf &lt;kobfedsur@gmail.com&gt;\n| | Date:   Sun Sep 10 16:43:44 2023 +0300\n| | \n| |     my after merge commit\n| | \n| * commit 69a666cd3dc1c3f0b436a1ecbeb58ea32eb080c1 (example_branch)\n| | Author: Dranikf &lt;kobfedsur@gmail.com&gt;\n| | Date:   Sun Sep 10 16:43:44 2023 +0300\n| | \n| |     commit in example_branch\n| | \n* | commit 51377f0e8c2f305bfcab9c4a97a6a36d8e44c99f\n|/  Author: Dranikf &lt;kobfedsur@gmail.com&gt;\n|   Date:   Sun Sep 10 16:43:44 2023 +0300\n|   \n|       commit in master\n| \n* commit 7307ad26c4cc29bbb0eac4b9ad2420aeab716f0b\n  Author: Dranikf &lt;kobfedsur@gmail.com&gt;\n  Date:   Sun Sep 10 16:43:44 2023 +0300\n  \n      basic commit"
  },
  {
    "objectID": "git/branches.html",
    "href": "git/branches.html",
    "title": "Branches",
    "section": "",
    "text": "A branch is a reference to a commit which has the following property - it can be shifted to some next commit."
  },
  {
    "objectID": "git/branches.html#master",
    "href": "git/branches.html#master",
    "title": "Branches",
    "section": "Master",
    "text": "Master\nmaster is the name of the default git brunch that’s created when the repository is initialised.\nIn the example below, I show that in the git log output there is the word master in branches next to the hash of the first commit module just created.\n\n%%bash\nmkdir branches_example\ncd branches_example\ngit init &&gt; /dev/null\n\necho \"some text\" &&gt; some_file\ngit add --all\ngit commit -m \"first commit\" &&gt; /dev/null\ngit log --decorate\n\ncd ..\nrm -r branches_example\n\ncommit 2a72b456a3dbdfcdff5ad1dfdb65abed55b8a54b (HEAD -&gt; master)\nAuthor: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\nDate:   Sat Sep 9 13:21:48 2023 +0300\n\n    first commit"
  },
  {
    "objectID": "git/branches.html#create-branch",
    "href": "git/branches.html#create-branch",
    "title": "Branches",
    "section": "Create branch",
    "text": "Create branch\nThe git branch \"&lt;branch name&gt;\" command creates a new branch on the commit that HEAD refers to.\nIn the next cell I used this command to create new_branch:\n\nIn the git log output you can see that there are now two branch names in the parentheses next to the commit hash;\nNote that by default git does not move HEAD to the created branch. The message HEAD -&gt; master in the git log output and the message On branch master in the git status output will indicate this. To create brunch an immediately move to it use git checkout with -b option.\n\n\n%%bash\nmkdir branches_example\ncd branches_example\ngit init &&gt; /dev/null\n\necho \"some text\" &&gt; some_file\ngit add --all\ngit commit -m \"first commit\" &&gt; /dev/null\ngit branch \"new_branch\"\n\n\necho \"=====git log=====\"\ngit log --decorate --oneline\necho \"=====git status=====\"\ngit status\n\ncd ..\nrm -r branches_example\n\n=====git log=====\n54231d2 (HEAD -&gt; master, new_branch) first commit\n=====git status=====\nOn branch master\nnothing to commit, working tree clean"
  },
  {
    "objectID": "git/branches.html#list-branches",
    "href": "git/branches.html#list-branches",
    "title": "Branches",
    "section": "List branches",
    "text": "List branches\nTo list all available branches, use git branch (without the positional argument, which refers to the name of the new branch).\nThe branch to which HEAD will be linked is indicated by an asterisk (*).\n\nBasic example\nIn the following example\n\nI create a few branches;\nThen use the git branch' command to print out a list of branches - all the branches I created and the automatically generatedmaster’ branch are shown. * indicates master;\nThen I switch HEAD to another branch;\nNow git branch prints almost the same, except that * indicates the branch I have selected.\n\n\n%%bash\nmkdir branches_example\ncd branches_example\ngit init &&gt; /dev/null\n\nfor i in {1..5}\ndo\n  echo \"Line $i\" &gt;&gt; file\n  git add file\n  git commit -m \"Branch $i add.\" &&gt; /dev/null\n  git branch \"branch_$i\"\ndone\n\necho \"=====git branch=====\"\ngit branch\n\necho\ngit checkout branch_3 2&gt;&1\necho \"=====git branch=====\"\ngit branch\n\ncd ..\nrm -r branches_example\n\n=====git branch=====\n  branch_1\n  branch_2\n  branch_3\n  branch_4\n  branch_5\n* master\n\nSwitched to branch 'branch_3'\n=====git branch=====\n  branch_1\n  branch_2\n* branch_3\n  branch_4\n  branch_5\n  master\n\n\n\n\nHEAD arbitrary\nYou can use git checkout for optional commits. This subsection shows how git branch will display the case where you have selected some commit (not branch) to be referenced by HEAD - which branch will * display?\nIn the following example:\n\nI generated few branches;\nI make a random commit and remember its hash. And to this hash I make git checkout - now HEAD refers to an arbitrary commit and not to some branch;\nThen I execute git branch. For * created special line * (HEAD detached at &lt;hash&gt;) which makes it clear that HEAD points to an arbitrary commit and not to any of the branches.\n\n\n%%bash\nmkdir branches_example\ncd branches_example\ngit init &&gt; /dev/null\n\nfor i in {1..5}\ndo\n  echo \"Line $i\" &gt;&gt; file\n  git add file\n  git commit -m \"Branch $i add.\" &&gt; /dev/null\n  git branch \"branch_$i\"\ndone\n\necho \"Temp line\" &gt;&gt; file\ngit add file\ngit commit -m \"Commit without branch.\" &&gt; /dev/null\nno_branch_commit_hash=$(git rev-parse HEAD)\n\necho\ngit checkout $no_branch_commit_hash 2&gt;&1\necho $no_branch_commit_hash\necho \"=====git branch=====\"\ngit branch\n\ncd ..\nrm -r branches_example\n\n\nNote: switching to '5b8059a0c1a47cdb0fcd6233a58ea7cf159ebf15'.\n\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by switching back to a branch.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -c with the switch command. Example:\n\n  git switch -c &lt;new-branch-name&gt;\n\nOr undo this operation with:\n\n  git switch -\n\nTurn off this advice by setting config variable advice.detachedHead to false\n\nHEAD is now at 5b8059a Commit without branch.\n5b8059a0c1a47cdb0fcd6233a58ea7cf159ebf15\n=====git branch=====\n* (HEAD detached at 5b8059a)\n  branch_1\n  branch_2\n  branch_3\n  branch_4\n  branch_5\n  master"
  },
  {
    "objectID": "git/branches.html#commit-to-branch",
    "href": "git/branches.html#commit-to-branch",
    "title": "Branches",
    "section": "Commit “to” branch",
    "text": "Commit “to” branch\nIt is not correct to say commit “to” a branch, it is correct to say make a commit and move a branch into it. Every time a commit is made, it is written somewhere in git and the branch that HEAD is currently bound to is simply moved to that commit.\nThe following example shows how I switched to new_branch while HEAD was on the first commit. And after the second commit, the text HEAD-&gt;new_branch automatically moved to the second commit.\n\n%%bash\nmkdir branches_example\ncd branches_example\ngit init &&gt; /dev/null\n\necho \"first line\" &gt; some_file\ngit add --all\ngit commit -m \"first commit\" &&gt; /dev/null\ngit checkout -b \"new_branch\"\n\necho \"=====first commit=====\"\necho \"-----git log-----\"\ngit log --decorate --oneline\n\necho\necho \"second line\" &gt;&gt; some_file\ngit commit -am \"second commit\" &&gt; /dev/null\necho \"=====second commit=====\"\necho \"-----git log-----\"\ngit log --decorate --oneline\n\ncd ..\nrm -r branches_example\n\nSwitched to a new branch 'new_branch'\n\n\n=====first commit=====\n-----git log-----\n21bed3c (HEAD -&gt; new_branch, master) first commit\n\n=====second commit=====\n-----git log-----\naf9c0df (HEAD -&gt; new_branch) second commit\n21bed3c (master) first commit"
  },
  {
    "objectID": "git/branches.html#idea-of-branching",
    "href": "git/branches.html#idea-of-branching",
    "title": "Branches",
    "section": "Idea of branching",
    "text": "Idea of branching\nWhen you talk about branches, you assume that they can grow independently of each other; in git, that is the idea.\nCommits made to one branch are not included in the history of the other branches. So in the following example:\n\nIn the beginning:\n\nbasic commit was created;\nFrom basic commit two branches were created, first_branch and second_branch;\nA log of this state of the repository was printed after the message =====initial log=====;\n\nThen commits have been made to both branches;\nWith the command git log --all --graph --decorate I printed the log:\n\nBy default, git log only prints history for the commit that HEAD refers to, so we need the --all option to print all history;\nThe --graph option is a feature that allows us to visualise branches - so we have `basic commit’ and two brunches of it;\nThe --decocate option is just needed for correct dislpay in jupyter.\n\n\n\n%%bash\nmkdir branches_example\ncd branches_example\ngit init &&gt; /dev/null\n\necho \"basic content\" &gt; file\ngit add --all\ngit commit -m \"basic commit\" &&gt; /dev/null\n\ngit branch first_branch\ngit branch second_branch\n\necho \"=====initial log=====\"\ngit log --decorate --oneline\n\necho \"=====work with first_branch=====\"\ngit checkout first_branch\necho \"first branch content\" &gt; file\ngit commit -am \"first branch commit\" &&gt; /dev/null\necho \"=====work with second_branch=====\"\ngit checkout second_branch\necho \"second branch content\" &gt; file\ngit commit -am \"second branch commit\" &&gt; /dev/null\n\necho\necho \"=====git log=====\"\ngit log --graph --all --decorate\n\ncd ..\nrm -r branches_example\n\n=====initial log=====\ne544f85 (HEAD -&gt; master, second_branch, first_branch) basic commit\n=====work with first_branch=====\n=====work with second_branch=====\n\n=====git log=====\n* commit c5c73f3cf1903d3ff3360c3454fff0bca21c7616 (first_branch)\n| Author: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\n| Date:   Sun Sep 10 11:27:18 2023 +0300\n| \n|     first branch commit\n|   \n| * commit a377c623cb616c02193a5f2ef6d8389ddd5cbc1a (HEAD -&gt; second_branch)\n|/  Author: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\n|   Date:   Sun Sep 10 11:27:18 2023 +0300\n|   \n|       second branch commit\n| \n* commit e544f8579d51b9383defa2b83f31e58ffc614569 (master)\n  Author: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\n  Date:   Sun Sep 10 11:27:18 2023 +0300\n  \n      basic commit\n\n\nSwitched to branch 'first_branch'\nSwitched to branch 'second_branch'"
  },
  {
    "objectID": "git/file_stages.html",
    "href": "git/file_stages.html",
    "title": "File statuses",
    "section": "",
    "text": "In git, files can take on different states with respect to the current commit. The following picture mention central idea."
  },
  {
    "objectID": "git/file_stages.html#get-status",
    "href": "git/file_stages.html#get-status",
    "title": "File statuses",
    "section": "Get status",
    "text": "Get status\nThe git status command allows you to get some information about the current status of the git repository. This command is very common on this site, so you can find many different examples of how to use it."
  },
  {
    "objectID": "git/file_stages.html#untracked-files",
    "href": "git/file_stages.html#untracked-files",
    "title": "File statuses",
    "section": "Untracked files",
    "text": "Untracked files\nIf git hasn’t seen a file before, it will correspond to this category. You can find files on this stage in Untracked files section of git status command.\nIn the following example, I am simply trying to add a some text file to the freshly created git repo, and when I call git status, I can find it in the untracked files section.\n\n%%bash\nmkdir status_test\ncd status_test\ngit init &&gt; /dev/null\n\necho \"=====Empty repo=====\"\ngit status\necho \"some text\" &gt; test_file\necho\necho \"=====One file added=====\"\ngit status\n\ncd ..\nrm -r  status_test\n\n=====Empty repo=====\nOn branch master\n\nNo commits yet\n\nnothing to commit (create/copy files and use \"git add\" to track)\n\n=====One file added=====\nOn branch master\n\nNo commits yet\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n    test_file\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n\n\nTo make git track some file you should use command git add &lt;filemane&gt;."
  },
  {
    "objectID": "git/file_stages.html#staged",
    "href": "git/file_stages.html#staged",
    "title": "File statuses",
    "section": "Staged",
    "text": "Staged\nThese are the files for the next commit.\nIn git status they’re shown in the Changes to be committed section.\nSo in the following example, I have created and added a file to be tracked in the git repo, and show the result of git status for such a repository.\n\n%%bash\nmkdir status_test\ncd status_test\ngit init &&gt; /dev/null\n\necho \"some text\" &gt; test_file\ngit add test_file\necho\necho \"=====File to be commited=====\"\ngit status\n\ncd ..\nrm -r  status_test\n\n\n=====File to be commited=====\nOn branch master\n\nNo commits yet\n\nChanges to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n    new file:   test_file\n\n\n\nYou can commit changes by using git commit command."
  },
  {
    "objectID": "git/file_stages.html#commited-files",
    "href": "git/file_stages.html#commited-files",
    "title": "File statuses",
    "section": "Commited files",
    "text": "Commited files\nIf you just commit all the files and check git status, you will always get the same message.\nYou can also check the list of commits using git log.\nSo in the following example, I will try git commit and git log on the repository with a single commit and no changes since that commit.\n\n%%bash\nmkdir status_test\ncd status_test\ngit init &&gt; /dev/null\n\necho \"some text\" &gt; test_file\ngit add test_file\ngit commit -m \"my message\" &&gt; /dev/null\necho\necho \"=====git status=====\"\ngit status\necho \"=====git log=====\"\ngit log\n\n\ncd ..\nrm -r  status_test\n\n\n=====git status=====\nOn branch master\nnothing to commit, working tree clean\n=====git log=====\ncommit 6e0339d191892a011e66351179c1b7cb9b08b292\nAuthor: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\nDate:   Wed Sep 6 15:02:05 2023 +0300\n\n    my message"
  },
  {
    "objectID": "git/file_stages.html#changed",
    "href": "git/file_stages.html#changed",
    "title": "File statuses",
    "section": "Changed",
    "text": "Changed\nAny file that has been changed since the last commit will appear in the Changes not staged to commit section, so if you try to commit in this momed, any changes made to these files won’t be committed.\nTo commit these changes you need to use git add or git commit -a.\nThe following example shows the difference:\n\nThe first print shows test_file as modified in the Changes not staged for commit block;\nSecond block corresponds to case if you’re trying to commit unstaged files. Interestingly, if you’re trying to commit without any changes, it won’t commit and will print as for git status;\nLast block is same as previous, but before committing I did git add &lt;filename&gt; - so new commit was added, which is displayed in the git status and git log results.\n\n\n%%bash\nmkdir status_test\ncd status_test\ngit init &&gt; /dev/null\n\necho \"some text\" &gt; test_file\ngit add test_file &&gt; /dev/null\ngit commit -m \"first commit\" &&gt; /dev/null\necho \"some other text\" &gt; test_file\n\necho \"=====Changed file=====\"\ngit status\n\necho\necho \"=====Not added commit=====\"\necho \"-----git commit-----\"\ngit commit -m \"unsuccessful commit\"\necho \"-----git log-----\"\ngit log --oneline\n\necho\necho \"=====Add file=====\"\ngit add test_file\necho \"-----git commit-----\"\ngit commit -m \"second commit\"\necho \"-----git status-----\"\ngit status\necho \"-----git log-----\"\ngit log --oneline\n\ncd ..\nrm -r  status_test\n\n=====Changed file=====\nOn branch master\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n    modified:   test_file\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\n=====Not added commit=====\n-----git commit-----\nOn branch master\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n    modified:   test_file\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n-----git log-----\naaad9bc first commit\n\n=====Add file=====\n-----git commit-----\n[master 4dba109] second commit\n 1 file changed, 1 insertion(+), 1 deletion(-)\n-----git status-----\nOn branch master\nnothing to commit, working tree clean\n-----git log-----\n4dba109 second commit\naaad9bc first commit"
  },
  {
    "objectID": "git/log.html",
    "href": "git/log.html",
    "title": "Log",
    "section": "",
    "text": "git log is a command that allows you to check some information about:"
  },
  {
    "objectID": "git/log.html#oneline",
    "href": "git/log.html#oneline",
    "title": "Log",
    "section": "oneline",
    "text": "oneline\ngit log --oneline allows you to get information about each commit in just one line, without any extra information.\nSo the following example shows the difference - git log without --oneline and with it, used for repositories with few commits.\n\n%%bash\nmkdir log_examples\ncd log_examples\ngit init &&gt; /dev/null\n\n\nfor i in {1..5}\ndo\n  echo \"Line $i\" &gt;&gt; file\n  git add file\n  git commit -m \"Line $i added\" &&gt; /dev/null\ndone\n\necho \"=====git log=====\"\ngit log\necho\necho \"=====git log --oneline=====\"\ngit log --oneline\n\ncd ..\nrm -r log_examples\n\n=====git log=====\ncommit 0ce330290ccbf23709c21b9ab2f954735ecd03b3\nAuthor: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\nDate:   Sat Sep 9 14:15:46 2023 +0300\n\n    Line 5 added\n\ncommit 80e85aa88db21f3f50baf377614b9eb485f258bb\nAuthor: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\nDate:   Sat Sep 9 14:15:46 2023 +0300\n\n    Line 4 added\n\ncommit 65a9790a5234f3fc4d0f4d954c76b60db30fc8ce\nAuthor: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\nDate:   Sat Sep 9 14:15:46 2023 +0300\n\n    Line 3 added\n\ncommit 4df96a83e43be23415c0b0023d10b2e0282188ff\nAuthor: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\nDate:   Sat Sep 9 14:15:46 2023 +0300\n\n    Line 2 added\n\ncommit 7bdb94f91398e7cd4bcb431dc4a98557629ad202\nAuthor: Fedor Kobak &lt;kobfedsur@gmail.com&gt;\nDate:   Sat Sep 9 14:15:46 2023 +0300\n\n    Line 1 added\n\n=====git log --oneline=====\n0ce3302 Line 5 added\n80e85aa Line 4 added\n65a9790 Line 3 added\n4df96a8 Line 2 added\n7bdb94f Line 1 added"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Knowledge",
    "section": "",
    "text": "Website provided by Fedor Kobak, with various studies in data science, computer science and related fields."
  },
  {
    "objectID": "other/basic_apache2.html",
    "href": "other/basic_apache2.html",
    "title": "Basic work with apache2 web server",
    "section": "",
    "text": "Sources\n\nInstalation https://httpd.apache.org/docs/2.4/install.html;\n\n\n\nRun/stop server\nTo start the Apache web server you can use service apache2 start. After successful execution of this command you should get response from localhost:80 - in browser it would be Apache2 Default Page. service apache2 stop therefore stops the server.\nIn fllowing example: - Before the server starts, I access the web server via curl - but get no response; - I start the server with service apache2 start, after starting curl return apache start page; - I stop the server with service apache2 stop - this stops the apache welcome page from appearing.\n\n%%bash\necho \"=====Curl before server start=====\"\ncurl -s localhost:80 | head -n 50\n\nservice apache2 start\necho \"=====Curl after server start=====\"\ncurl -s localhost:80 | head -n 50\n\nservice apache2 stop\necho \"=====Curl after server stop=====\"\ncurl -s localhost:80 | head -n 50\n\n=====Curl before server start=====\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\"&gt;\n  &lt;!--\n    Modified from the Debian original for Ubuntu\n    Last updated: 2022-03-22\n    See: https://launchpad.net/bugs/1966004\n  --&gt;\n  &lt;head&gt;\n    &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /&gt;\n    &lt;title&gt;Apache2 Ubuntu Default Page: It works&lt;/title&gt;\n    &lt;style type=\"text/css\" media=\"screen\"&gt;\n  * {\n    margin: 0px 0px 0px 0px;\n    padding: 0px 0px 0px 0px;\n  }\n\n  body, html {\n    padding: 3px 3px 3px 3px;\n\n    background-color: #D8DBE2;\n\n    font-family: Ubuntu, Verdana, sans-serif;\n    font-size: 11pt;\n    text-align: center;\n  }\n\n  div.main_page {\n    position: relative;\n    display: table;\n\n    width: 800px;\n\n    margin-bottom: 3px;\n    margin-left: auto;\n    margin-right: auto;\n    padding: 0px 0px 0px 0px;\n\n    border-width: 2px;\n    border-color: #212738;\n    border-style: solid;\n\n    background-color: #FFFFFF;\n\n    text-align: center;\n  }\n\n  div.page_header {\n    height: 180px;\n    width: 100%;\n\n=====Curl after server start=====\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\"&gt;\n  &lt;!--\n    Modified from the Debian original for Ubuntu\n    Last updated: 2022-03-22\n    See: https://launchpad.net/bugs/1966004\n  --&gt;\n  &lt;head&gt;\n    &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /&gt;\n    &lt;title&gt;Apache2 Ubuntu Default Page: It works&lt;/title&gt;\n    &lt;style type=\"text/css\" media=\"screen\"&gt;\n  * {\n    margin: 0px 0px 0px 0px;\n    padding: 0px 0px 0px 0px;\n  }\n\n  body, html {\n    padding: 3px 3px 3px 3px;\n\n    background-color: #D8DBE2;\n\n    font-family: Ubuntu, Verdana, sans-serif;\n    font-size: 11pt;\n    text-align: center;\n  }\n\n  div.main_page {\n    position: relative;\n    display: table;\n\n    width: 800px;\n\n    margin-bottom: 3px;\n    margin-left: auto;\n    margin-right: auto;\n    padding: 0px 0px 0px 0px;\n\n    border-width: 2px;\n    border-color: #212738;\n    border-style: solid;\n\n    background-color: #FFFFFF;\n\n    text-align: center;\n  }\n\n  div.page_header {\n    height: 180px;\n    width: 100%;\n\n=====Curl after server stop====="
  },
  {
    "objectID": "other/linux_backup.html",
    "href": "other/linux_backup.html",
    "title": "How to linux backup",
    "section": "",
    "text": "rsync usage example;\nrsync documentation;\n backup with rsync;\n official ubuntu backup instructions;\noffical ubutntu backup instructions - section about tar.\n\n\ntar\nIn the following cell I just try to follow the instructions from official ubutntu backup instructions - section about tar, to make a backup - and test how it works in different cases.\nI want to try:\n\nstep 1 - backup creating:\n\nrun docker container with ubuntu;\ninstall curl, abache2;\nrun the apache2 service;\ncheck apache2 with curl;\nuse tar to make a backup of the current system;\nstop the container;\n\nstep2 - recovery from back up:\n\nrun a new empty ubuntu container;\ncopy the backup archive from the previous container;\nrestore the backup in empty ubuntu system;\ncheck curl and apache2.\n\n\nstep 1 - backup creating\n\n%%bash\nmkdir backups\ndocker run --rm --name ubun_cont -i -v $(pwd)/backups:/backups ubuntu\n\necho \"=====install=====\"\napt-get update &&gt; /dev/null\napt-get install curl apache2 -y &&gt; /dev/null\nservice apache2 start &&gt; /dev/null\n\n\necho\necho \"=====check=====\"\ncurl -s localhost:80 | head -n 20\n\necho\necho \"=====make backup=====\"\ntar \\\n    -cvpzf \\\n    /backups/backup.tar.gz \\\n    --exclude=/backups/backup.tar.gz \\\n    --one-file-system / &&gt; /dev/null\nexit\n\n=====install=====\n\n=====check=====\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\"&gt;\n  &lt;!--\n    Modified from the Debian original for Ubuntu\n    Last updated: 2022-03-22\n    See: https://launchpad.net/bugs/1966004\n  --&gt;\n  &lt;head&gt;\n    &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /&gt;\n    &lt;title&gt;Apache2 Ubuntu Default Page: It works&lt;/title&gt;\n    &lt;style type=\"text/css\" media=\"screen\"&gt;\n  * {\n    margin: 0px 0px 0px 0px;\n    padding: 0px 0px 0px 0px;\n  }\n\n  body, html {\n    padding: 3px 3px 3px 3px;\n\n    background-color: #D8DBE2;\n\n=====make backup=====\n\n\nThere is not much to say - it saves the backup in the “backups” folder.\nstep2 - recovery from backup\n\n%%bash\ndocker run --rm --name ubun_cont -i -v $(pwd)/backups:/backups ubuntu\ntar -xvpzf /backups/backup.tar.gz -C / --numeric-owner &&gt; /dev/null\n\necho \"=====culr --help=====\"\ncurl --help\necho \"=====curl localhost:80=====\"\nculr -s localhost:80\n\necho\necho \"=====curl localhost:80 after apache=====\"\nservice apache2 start\ncurl -s localhost:80 | head -n 20\n\nexit\n\n=====culr --help=====\nUsage: curl [options...] &lt;url&gt;\n -d, --data &lt;data&gt;          HTTP POST data\n -f, --fail                 Fail silently (no output at all) on HTTP errors\n -h, --help &lt;category&gt;      Get help for commands\n -i, --include              Include protocol response headers in the output\n -o, --output &lt;file&gt;        Write to file instead of stdout\n -O, --remote-name          Write output to a file named as the remote file\n -s, --silent               Silent mode\n -T, --upload-file &lt;file&gt;   Transfer local FILE to destination\n -u, --user &lt;user:password&gt; Server user and password\n -A, --user-agent &lt;name&gt;    Send User-Agent &lt;name&gt; to server\n -v, --verbose              Make the operation more talkative\n -V, --version              Show version number and quit\n\nThis is not the full help, this menu is stripped into categories.\nUse \"--help category\" to get an overview of all categories.\nFor all options use the manual or \"--help all\".\n=====curl localhost:80=====\n\n=====curl localhost:80 after apache=====\n * Starting Apache httpd web server apache2\n * \n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\"&gt;\n  &lt;!--\n    Modified from the Debian original for Ubuntu\n    Last updated: 2022-03-22\n    See: https://launchpad.net/bugs/1966004\n  --&gt;\n  &lt;head&gt;\n    &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /&gt;\n    &lt;title&gt;Apache2 Ubuntu Default Page: It works&lt;/title&gt;\n    &lt;style type=\"text/css\" media=\"screen\"&gt;\n  * {\n    margin: 0px 0px 0px 0px;\n    padding: 0px 0px 0px 0px;\n  }\n\n  body, html {\n    padding: 3px 3px 3px 3px;\n\n    background-color: #D8DBE2;\n\n\n/bin/bash: line 6: culr: command not found\nAH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 172.17.0.2. Set the 'ServerName' directive globally to suppress this message\n\n\nNote Even without downloading curl and apache2 I can use it after unpacking. To use apache2 you had to start the corresponding service - but it was still really easy.\n\n\nrsync basics\nActually rsync is just a copy tool, but if you compare it with cp it has much more options and features.\n\nBasic syntax\nrsync &lt;copied file&gt; &lt;destination of copying&gt;\nExample follows\n\n%%bash\n# creating to directories\nmkdir dir1 dir2\n# creating file in dir1\necho \"hello new file\" &gt; dir1/test_file\n# rsynk file from dir1 to dir2\nrsync dir1/test_file dir2/test_file\n# check the message\ncat dir2/test_file\n\nrm -r dir1 dir2\n\nhello new file\n\n\n\n\nr - copy recursive\nAllow to copy a folder with all its contents.\nIn the following example I’m trying to copy contents from dir1 to dir2, as you can see I couldn’t do it without the r option.\n\n%%bash\n\nmkdir dir1 dir2\ntouch dir1/file{1..5}.txt\n\necho \"=====content of dir1=====\"\nls dir1\n\necho \"=====no r option=====\"\nrsync dir1/ dir2\nls dir2\n\necho \"=====r option=====\"\nrsync -r dir1/ dir2\nls dir2\n\nrm -r dir1 dir2\n\n=====content of dir1=====\nfile1.txt\nfile2.txt\nfile3.txt\nfile4.txt\nfile5.txt\n=====no r option=====\nskipping directory .\n=====r option=====\nfile1.txt\nfile2.txt\nfile3.txt\nfile4.txt\nfile5.txt\n\n\n\n\n-a - attributes\nIt works just like r, but also deals with file attributes (like creation time, user and so on). So in the following example:\n\nFew files was created in dir1;\nThe user for these files has been changed from root to user1;\nThen I use rsync twice:\n\nFirst with the r option, which puts the user back in root;\nSecond, with the a option, which saves the user attribute as user1 from source.\n\n\n\n%%bash\n# docker container for usperuser access\ndocker run --rm --name test_container -i ubuntu\napt-get update &&gt; /dev/null\napt-get install -y rsync &&gt; /dev/null\n# creating file with some specific user\nuseradd user1\nmkdir dir1 dir2\ntouch dir1/file{1..5}.txt\nchown user1 dir1/file*\n\necho \"=====dir1=====\"\nls -l dir1\n\necho\necho \"=====dir2 after rsync -r=====\"\nrsync -r dir1/ dir2\nls -l dir2\n\necho\necho \"=====dir2 after rsync -a=====\"\nrsync -a dir1/ dir2\nls -l dir2\n\nexit\n\n=====dir1=====\ntotal 0\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file1.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file2.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file3.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file4.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file5.txt\n\n=====dir2 after rsync -r=====\ntotal 0\n-rw-r--r-- 1 root root 0 Jun 17 15:31 file1.txt\n-rw-r--r-- 1 root root 0 Jun 17 15:31 file2.txt\n-rw-r--r-- 1 root root 0 Jun 17 15:31 file3.txt\n-rw-r--r-- 1 root root 0 Jun 17 15:31 file4.txt\n-rw-r--r-- 1 root root 0 Jun 17 15:31 file5.txt\n\n=====dir2 after rsync -a=====\ntotal 0\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file1.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file2.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file3.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file4.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file5.txt\n\n\n\n\n--delete - delete extraneous\nIf you don’t use this option rsync will save files wich are in destination directory. Оtherwise all files that are not in the source will be deleted in the destination folder. The following exampe show: - In dir2 I created file test.txt; - First I rsync files from dir1 to dir2 without the --delete option - test.txt is still in dir2; - Second I rsync files from dir1 to dir2 using the --delete option - test.txt disappears from dir2.\n\n%%bash\nmkdir dir1 dir2\ntouch dir1/file{1..5}.txt\ntouch dir2/test.txt\n\necho \"====initial dir2=====\"\nls dir2\n\necho \"=====dir2 after rsync no --delete=====\"\nrsync -r dir1/ dir2\nls dir2\n\necho \"=====dir2 after rsync with --delete=====\"\nrsync -r --delete dir1/ dir2\nls dir2\n\nrm -r dir1 dir2\n\n====initial dir2=====\ntest.txt\n=====dir2 after rsync no --delete=====\nfile1.txt\nfile2.txt\nfile3.txt\nfile4.txt\nfile5.txt\ntest.txt\n=====dir2 after rsync with --delete=====\nfile1.txt\nfile2.txt\nfile3.txt\nfile4.txt\nfile5.txt"
  },
  {
    "objectID": "other/python_apache.html",
    "href": "other/python_apache.html",
    "title": "Python with apache",
    "section": "",
    "text": "For examples in this notebook I use special docker containers - docker file for container shown in python_apache_files folder. So to run examples from this section you should build image by running command docker build -t my_apache . from python_apache_files directory. This docker image will contain:"
  },
  {
    "objectID": "other/python_apache.html#ports.conf",
    "href": "other/python_apache.html#ports.conf",
    "title": "Python with apache",
    "section": "ports.conf",
    "text": "ports.conf\nConfig that describes which ports to listen on. By default, apache2 ports.conf only uses ports 80 and 443. But for some examples I need port 8050, so I use it as well.\n\n%%bash\ncat python_apache_files/ports.conf\n\n# If you just change the port or add more ports here, you will likely also\n# have to change the VirtualHost statement in\n# /etc/apache2/sites-enabled/000-default.conf\n\nListen 80\nListen 8050\n\n&lt;IfModule ssl_module&gt;\n        Listen 443\n&lt;/IfModule&gt;\n\n&lt;IfModule mod_gnutls.c&gt;\n        Listen 443\n&lt;/IfModule&gt;"
  },
  {
    "objectID": "other/python_apache.html#launching",
    "href": "other/python_apache.html#launching",
    "title": "Python with apache",
    "section": "Launching",
    "text": "Launching\nBy running this section on our local host, a number of sites will be hosted:\n\n%%bash\ncd python_apache_files\n\ndocker run --rm --name test_apache -d -p 81:80 -p 82:8050 my_apache &&gt; /dev/null\n\n\ndocker cp ports.conf test_apache:/etc/apache2/ports.conf\n\n# wsgi basics\ndocker cp wsgi_example/wsgi_basic.wsgi test_apache:/var/www/application/wsgi_basic.wsgi\ndocker cp wsgi_example/suburl.wsgi test_apache:/var/www/application/suburl.wsgi\ndocker cp wsgi_example/wsgi_basic.conf test_apache:/etc/apache2/sites-available/wsgi_basic.conf\ndocker exec test_apache a2ensite wsgi_basic\n\n# specific port\ndocker cp use_specific_port/spec_port.wsgi test_apache:/var/www/application/spec_port.wsgi\ndocker cp use_specific_port/spec_port.conf test_apache:/etc/apache2/sites-available/spec_port.conf\ndocker exec test_apache a2ensite spec_port\n\n# dash application\n# docker exec test_apache mkdir /var/www/dash\ndocker cp dash/dash.wsgi test_apache:/var/www/application/dash.wsgi\ndocker cp dash/app.py test_apache:/var/www/application/app.py\n# docker cp dash/dash.wsgi test_apache:/var/www/dash/dash.wsgi\n# docker cp dash/app.py test_apache:/var/www/dash/app.py\n# docker cp dash/dash.conf test_apache:/etc/apache2/sites-available/dash.conf\n# docker exec test_apache a2ensite dash\n\n# docker exec test_apache chown -R :www-data /var/www/application\n# docker exec test_apache chmod -R o-rw /var/www/application\n\n\ndocker exec test_apache a2dissite 000-default\ndocker exec test_apache service apache2 reload\n\nEnabling site wsgi_basic.\nTo activate the new configuration, you need to run:\n  service apache2 reload\nEnabling site spec_port.\nTo activate the new configuration, you need to run:\n  service apache2 reload\nSite 000-default disabled.\nTo activate the new configuration, you need to run:\n  service apache2 reload\n * Reloading Apache httpd web server apache2\n * \n\n\nNote: for the site to work for any reason, it’s extremely important to stop apache2 default page with a2dissite 000-default command.\nBy runnig the following cell - sites will be stopped:\n\n%%bash\ndocker stop test_apache\n\ntest_apache"
  },
  {
    "objectID": "other/python_apache.html#wsgi-application",
    "href": "other/python_apache.html#wsgi-application",
    "title": "Python with apache",
    "section": "wsgi application",
    "text": "wsgi application\nWe need a WSGI application - this is a Python program that is used when you ask for a specific URL. It should have essance with name application, in basic option it can be just function. So in the following example I show exactly this option:\n\n%%bash\ncat python_apache_files/wsgi_example/wsgi_basic.wsgi\n\ndef application(environ, start_response):\n    status = '200 OK'\n    output = b\"I'm application from root. Basic example of wsgi\"\n\n    response_headers = [('Content-type', 'text/plain'),\n                        ('Content-Length', str(len(output)))]\n    start_response(status, response_headers)\n\n    return [output]"
  },
  {
    "objectID": "other/python_apache.html#site-config",
    "href": "other/python_apache.html#site-config",
    "title": "Python with apache",
    "section": "Site config",
    "text": "Site config\nReally important file that describe site behavior. Crusial information:\n\nShould be placed in /ect/apache2/apailible-sites;\nWSGIScriptAlias directive to describe which Python file will be used as the entry point, and which suburl of the site it will use;\nWSGIDaemonProcess -&gt; python-path describe which Python interpreter should be used.;\n\n\n%%bash\ncat python_apache_files/wsgi_example/wsgi_basic.conf\n\n&lt;VirtualHost *:80&gt;\n        ServerName application\n        ServerAdmin webmaster@localhost\n        DocumentRoot /var/www/application\n\n        ErrorLog ${APACHE_LOG_DIR}/error.log\n        CustomLog ${APACHE_LOG_DIR}/access.log combined\n\n        WSGIDaemonProcess application threads=5 user=www-data group=www-data python-path=/var/www/application/venv/lib/python3.11/site-packages python-home=/var/www/application/venv\n\n        WSGIScriptAlias /suburl /var/www/application/suburl.wsgi\n        WSGIScriptAlias / /var/www/application/wsgi_basic.wsgi\n        \n        &lt;Directory /var/www/application&gt;\n                Order deny,allow\n                Allow from all\n        &lt;/Directory&gt;\n\n&lt;/VirtualHost&gt;"
  },
  {
    "objectID": "other/python_apache.html#dash-application-1",
    "href": "other/python_apache.html#dash-application-1",
    "title": "Python with apache",
    "section": "dash application",
    "text": "dash application\n\n%%bash\ncat python_apache_files/dash/app.py\n\nfrom dash import Dash, html\n\napp = Dash(__name__, requests_pathname_prefix='/dash/')\napp.layout = html.Div(\"Hello world\")\n\nserver = app.server\n\nif __name__ == \"__main__\":\n    app.run_server(debug=True, port=8051)\n\n\nNote: - server = app.server is very important - it is loaded in wsgi; - requests_pathname_prefix='/dash/' in Dash constructor will allow to run application with suburl dash."
  },
  {
    "objectID": "other/python_apache.html#wsgi-file",
    "href": "other/python_apache.html#wsgi-file",
    "title": "Python with apache",
    "section": "wsgi file",
    "text": "wsgi file\nThe main purpose of the wsgi file here is to load dash.Dash as an application essence for wsgi.\n\n%%bash\ncat python_apache_files/dash/dash.wsgi\n\nimport sys\nsys.path.insert(0,\"/var/www/application/\")\nfrom app import server as application"
  },
  {
    "objectID": "latex/latex.html",
    "href": "latex/latex.html",
    "title": "Символы",
    "section": "",
    "text": "Тут разбраны самые часто забываемые мной возможности latex\nВсевозможнейшие символы и конструкции latex. Источниками полсужили: - http://tex.imm.uran.ru/tex/2e/lshort2e/node52.html; - https://ido.tsuab.ru/mod/book/view.php?id=62&chapterid=23; - https://ru.overleaf.com/learn/latex/List_of_Greek_letters_and_math_symbols.\nЗдесь для бысторого доступа я приведу лишь те сиволы, которые мне пригождались."
  },
  {
    "objectID": "latex/latex.html#буквы-с-пустым-пространством",
    "href": "latex/latex.html#буквы-с-пустым-пространством",
    "title": "Символы",
    "section": "Буквы с пустым пространством",
    "text": "Буквы с пустым пространством\nОбычно используются для обозначения можеств. Для того, чтобы букву написать таким образом используется команда \\mathbb{...}.\n\\[\\mathbb{ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz}\\]"
  },
  {
    "objectID": "Docker/docker_commands.html",
    "href": "Docker/docker_commands.html",
    "title": "Docker commands",
    "section": "",
    "text": "Here we describe those docker commands that do not merit a separate discussion."
  },
  {
    "objectID": "Docker/docker_commands.html#ps---show-containers",
    "href": "Docker/docker_commands.html#ps---show-containers",
    "title": "Docker commands",
    "section": "ps - show containers",
    "text": "ps - show containers\nTo view active containers, you should use the docker ps command.\n\n%%bash\ndocker run -itd --rm --name test_container python:3.10 &&gt; /dev/null\ndocker ps\ndocker stop test_container &&gt; /dev/null\n\nCONTAINER ID   IMAGE         COMMAND     CREATED        STATUS                  PORTS     NAMES\nb17984f2b882   python:3.10   \"python3\"   1 second ago   Up Less than a second             test_container\n\n\n\n-a - show all\nBy default, inactive containers are hidden.\n\n%%bash\ndocker run --name temp_container ubuntu &&gt; /dev/null\necho \"========no option -a==============\"\ndocker ps\necho \"=========with option -a=============\"\ndocker ps -a\ndocker rm temp_container &&gt; /dev/null\n\n========no option -a==============\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n=========with option -a=============\nCONTAINER ID   IMAGE     COMMAND       CREATED                  STATUS                              PORTS     NAMES\nad0439c23847   ubuntu    \"/bin/bash\"   Less than a second ago   Exited (0) Less than a second ago             temp_container"
  },
  {
    "objectID": "Docker/docker_commands.html#history---show-layers-of-the-image",
    "href": "Docker/docker_commands.html#history---show-layers-of-the-image",
    "title": "Docker commands",
    "section": "history - show layers of the image",
    "text": "history - show layers of the image"
  },
  {
    "objectID": "Docker/docker_commands.html#start---activate-exited-container",
    "href": "Docker/docker_commands.html#start---activate-exited-container",
    "title": "Docker commands",
    "section": "start - activate exited container",
    "text": "start - activate exited container\nIn the next cell, I build a ubuntu container that prints “hello world” when it starts. Like all standard ubuntu containers it quits, which we can see in the STATUS of the ps command. Then by docker start the container is reactivated.\nFor some reason it only works when I use the -i option for docker start.\n\n%%bash\ncd containers_files\ndocker build -t test_ubuntu . &&gt; /dev/null\necho \"=====First start=====\"\ndocker run --name u1 test_ubuntu\necho \"=====List of all containers=====\"\ndocker ps -a\necho \"=====Restart=====\"\ndocker start -i u1\ndocker rm u1 &&gt; /dev/null\ndocker rmi test_ubuntu &&gt; /dev/null\n\n=====First start=====\nhello world\n=====List of all containers=====\nCONTAINER ID   IMAGE         COMMAND                CREATED        STATUS                              PORTS     NAMES\naf533b577c94   test_ubuntu   \"echo 'hello world'\"   1 second ago   Exited (0) Less than a second ago             u1\n=====Restart=====\nhello world"
  },
  {
    "objectID": "Docker/docker_commands.html#stop---stop-some-container",
    "href": "Docker/docker_commands.html#stop---stop-some-container",
    "title": "Docker commands",
    "section": "stop - stop some container",
    "text": "stop - stop some container\nIn the following example, I start a container with Ubuntu in such a way that it stays running, which was proven by using docker ps. But after using docker stop the same container is in the state “Exited”.\n\n%%bash\ndocker run -itd --name test_ubuntu ubuntu &&gt; /dev/null\necho \"=====Just started container=====\"\ndocker ps -a\ndocker stop test_ubuntu &&gt; /dev/null\necho \"=====Stoped container (STATUS \\\"Exited\\\")=====\"\ndocker ps -a\ndocker rm test_ubuntu &&gt; /dev/null\n\n=====Just started container=====\nCONTAINER ID   IMAGE     COMMAND       CREATED                  STATUS                  PORTS     NAMES\ne175ae336dcb   ubuntu    \"/bin/bash\"   Less than a second ago   Up Less than a second             test_ubuntu\n=====Stoped container (STATUS \"Exited\")=====\nCONTAINER ID   IMAGE     COMMAND       CREATED          STATUS                                PORTS     NAMES\ne175ae336dcb   ubuntu    \"/bin/bash\"   10 seconds ago   Exited (137) Less than a second ago             test_ubuntu"
  },
  {
    "objectID": "Docker/docker_commands.html#exec---run-in-the-container",
    "href": "Docker/docker_commands.html#exec---run-in-the-container",
    "title": "Docker commands",
    "section": "exec - run in the container",
    "text": "exec - run in the container\nIn the next command I start ubuntu conteiner. Then using docker exec' I run thels’ command in the container and get a typical Linux result for that command.\n\n%%bash\ndocker run -itd --rm --name test_ubuntu ubuntu &&gt; /dev/null\ndocker exec test_ubuntu ls\ndocker stop test_ubuntu &&gt; /dev/null\n\nbin\nboot\ndev\netc\nhome\nlib\nlib32\nlib64\nlibx32\nmedia\nmnt\nopt\nproc\nroot\nrun\nsbin\nsrv\nsys\ntmp\nusr\nvar\n\n\n\n-it - take control\nIt looks like the options individually have the same properties as in the docker run command. But the important thing is that you can take control of the detached container with this command. The following example shows how I can get control in detached ubuntu by running the bash command with named options."
  },
  {
    "objectID": "Docker/docker_commands.html#logs---get-container-console",
    "href": "Docker/docker_commands.html#logs---get-container-console",
    "title": "Docker commands",
    "section": "logs - get container console",
    "text": "logs - get container console\nDesrtiption of the command you can find here."
  },
  {
    "objectID": "Docker/docker_commands.html#rm---automatic-container-removal",
    "href": "Docker/docker_commands.html#rm---automatic-container-removal",
    "title": "Docker commands",
    "section": "-rm - automatic container removal",
    "text": "-rm - automatic container removal\nAfter stopping, the container is removed. In the following example there are two containers of ubuntu, one with the --rm option and the other without. Both containers stops by default - but only one stays with STATUS == Exited.\n\n%%bash\ndocker run --name no_rm_ubuntu ubuntu\ndocker run --rm --name ubuntu_with_rm ubuntu\ndocker ps -a\ndocker rm no_rm_ubuntu &&gt; /dev/null\n\nCONTAINER ID   IMAGE     COMMAND       CREATED        STATUS                              PORTS     NAMES\n7acc3cc0c61c   ubuntu    \"/bin/bash\"   1 second ago   Exited (0) Less than a second ago             no_rm_ubuntu"
  },
  {
    "objectID": "Docker/docker_commands.html#name---set-name-for-the-container",
    "href": "Docker/docker_commands.html#name---set-name-for-the-container",
    "title": "Docker commands",
    "section": "--name - set name for the container",
    "text": "--name - set name for the container\n\n%%bash\ndocker run --rm --name unbuntu_container -d ubuntu\ndocker ps\ndocker stop unbuntu_container\n\n7116dcdaa0a131a8507f9cbe149719498456fe356a23f1ddfc48f65080cfe660\nCONTAINER ID   IMAGE     COMMAND       CREATED        STATUS                  PORTS     NAMES\n7116dcdaa0a1   ubuntu    \"/bin/bash\"   1 second ago   Up Less than a second             unbuntu_container\nunbuntu_container"
  },
  {
    "objectID": "Docker/docker_commands.html#d---make-container-not-to-lock-cli",
    "href": "Docker/docker_commands.html#d---make-container-not-to-lock-cli",
    "title": "Docker commands",
    "section": "-d - make container not to lock CLI",
    "text": "-d - make container not to lock CLI\n\n%%bash\ndocker run --rm -d --name temp_nginx nginx &&gt; /dev/null\ndocker ps\ndocker stop temp_nginx &&gt; /dev/null\n\nCONTAINER ID   IMAGE     COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n09175cb8c6d9   nginx     \"/docker-entrypoint.…\"   Less than a second ago   Up Less than a second   80/tcp    temp_nginx"
  },
  {
    "objectID": "Docker/docker_commands.html#i---interactive-mode",
    "href": "Docker/docker_commands.html#i---interactive-mode",
    "title": "Docker commands",
    "section": "-i - interactive mode",
    "text": "-i - interactive mode\nMode that allows to interapt with container.\nUnfortunately it is not possible to show how this mode will work in jupyter. So here is a gif of me experimenting with the following command:\ndocker run -i --rm --name test_ubuntu ubuntu\n\nIn the example, the ubuntu container has been started and is stopped by default. The -i option causes it to lock the terminal. Extremely interesting that you will be able to send messages to the container and get results (as I showed with ls and exit commands), but you won’t get the description of the user common for Linux terminal."
  },
  {
    "objectID": "Docker/docker_commands.html#t---turn-on-tty",
    "href": "Docker/docker_commands.html#t---turn-on-tty",
    "title": "Docker commands",
    "section": "-t - turn on TTY",
    "text": "-t - turn on TTY\nTTY is something on backend language. The point here is that in combination with the -i option you can make will show you the “description” of the user which was mentioned in the previous section. And the terminal will be blocked waiting for input. But this option don’t allow you to send anything to the container.\nThe following .gif show what you will get in case using command docker run -t --rm --name temp_ubuntu ubuntu."
  },
  {
    "objectID": "Docker/docker_commands.html#it---combination",
    "href": "Docker/docker_commands.html#it---combination",
    "title": "Docker commands",
    "section": "-it - combination",
    "text": "-it - combination\nBoth options were discovered above, but they are really often used in combination. So Ubuntu provides full CLI interface with this options."
  },
  {
    "objectID": "Docker/docker_commands.html#commands-from-jupyter",
    "href": "Docker/docker_commands.html#commands-from-jupyter",
    "title": "Docker commands",
    "section": "Commands from jupyter",
    "text": "Commands from jupyter\nUsing only the i option (without t), you can send commands to the container from the Jupyter cell.\nSo in the following example, I can easily run the ls program from the newly created ubuntu container.\n\n%%bash\ndocker run --rm -i --name test_container ubuntu\nls\nexit\n\nbin\nboot\ndev\netc\nhome\nlib\nlib32\nlib64\nlibx32\nmedia\nmnt\nopt\nproc\nroot\nrun\nsbin\nsrv\nsys\ntmp\nusr\nvar\n\n\nIt’s a pity I didn’t understand this before I wrote most of the Docker description. So don’t be surprised if you see something like this:\n\n\ndocker exec … docker exec … docker exec …\n\nIn some section of docker description."
  },
  {
    "objectID": "Docker/docker_commands.html#e---environment-variables",
    "href": "Docker/docker_commands.html#e---environment-variables",
    "title": "Docker commands",
    "section": "-e - environment variables",
    "text": "-e - environment variables\nYou can also pass the values of the variables of the system you are calling from.\n\n%%bash\ndocker run --rm -i --name e_example -e FEDOR_TEST_VAR=$HOME ubuntu\necho $FEDOR_TEST_VAR\nexit\n\n/home/fedor"
  },
  {
    "objectID": "Docker/docker_commands.html#sec-docker_run_com_on_start",
    "href": "Docker/docker_commands.html#sec-docker_run_com_on_start",
    "title": "Docker commands",
    "section": "Command on container start",
    "text": "Command on container start\nIn the docker run command, after the name of the base image, you can specify a command that will be executed when the container starts. So in the next example I will show you how to run echo \"hello world\" in a new ubuntu container.\n\n%%bash\ndocker run --rm ubuntu echo \"hello world\"\n\nhello world\n\n\n\nIf you want to run several commands you have to use bash -c \"&lt;command&gt;\", like in following example:\n\n\n%%bash\ndocker run --rm ubuntu bash -c \"\n    echo \\\"hello world\\\"; \n    echo \\\"hello world2\\\"\n\"\n\nhello world\nhello world2\n\n\n\nNote that when containers are in interactive mode, the command executed should take input, otherwise it will just leave container anyway, the follwing gif describe how it looks like: \n\nIn the example, I ran the echo command with container starts and showed that there were no containers created - because the container was stopped and removed just after it was started. But immediately I created a new container, but now with the command bash -c \"echo \\\"hello world\\\"; bash - in this case the last command is bash which waits for input, so I’m comming back into the container."
  },
  {
    "objectID": "Docker/docker_commands.html#v---map-folder-on-container-to-folder-on-host",
    "href": "Docker/docker_commands.html#v---map-folder-on-container-to-folder-on-host",
    "title": "Docker commands",
    "section": "-v - map folder on container to folder on host",
    "text": "-v - map folder on container to folder on host\nThis is wide topic detailed in this section;"
  },
  {
    "objectID": "Docker/docker_commands.html#u---set-user",
    "href": "Docker/docker_commands.html#u---set-user",
    "title": "Docker commands",
    "section": "-u - set user",
    "text": "-u - set user\nBy default, all docker containers have root privileges, but it can be useful to set user. For a more detailed description in the context of filesystem access, see here."
  },
  {
    "objectID": "Docker/docker_commands.html#p---use-port",
    "href": "Docker/docker_commands.html#p---use-port",
    "title": "Docker commands",
    "section": "-p - use port",
    "text": "-p - use port\nFor mode details see this."
  },
  {
    "objectID": "Docker/docker_commands.html#pull---download-image-from-dockerhub.com",
    "href": "Docker/docker_commands.html#pull---download-image-from-dockerhub.com",
    "title": "Docker commands",
    "section": "pull - download image from dockerhub.com",
    "text": "pull - download image from dockerhub.com\nIt is obligatory to pass on one of the:\n\n&lt;image name&gt;:&lt;tag&gt; (&lt;tag&gt; - by default is latest);\nIMAGE ID - image id.\n\n\n%%bash\ndocker images | grep hello-world\necho \"===============beforre pull======================\"\ndocker pull hello-world:latest &&gt; /dev/null\necho \"===============after pull======================\"\ndocker images | grep hello-world\ndocker rmi hello-world &&gt; /dev/null\n\n===============beforre pull======================\n===============after pull======================\nhello-world                latest    9c7a54a9a43c   2 weeks ago     13.3kB"
  },
  {
    "objectID": "Docker/docker_commands.html#images---show-list-of-available-images",
    "href": "Docker/docker_commands.html#images---show-list-of-available-images",
    "title": "Docker commands",
    "section": "images - show list of available images",
    "text": "images - show list of available images\n\n%%bash\ndocker images\n\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\nhello-world   latest    feb5d9fea6a5   16 months ago   13.3kB\n\n\n\n--a,--all - show all images\nBy default, so called “intermediate”, images are hiden. Nowadays I don’t know what “intermediate” images are.\n\n%%bash\ndocker images --all\n\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\nhello-world   latest    feb5d9fea6a5   16 months ago   13.3kB\n\n\n\n\n--digests - show digests\n\n%%bash\ndocker images --digests\n\nREPOSITORY    TAG       DIGEST                                                                    IMAGE ID       CREATED         SIZE\nhello-world   latest    sha256:aa0cc8055b82dc2509bed2e19b275c8f463506616377219d9642221ab53cf9fe   feb5d9fea6a5   16 months ago   13.3kB\n\n\n\n\n--format - format output\nAllows output to be formatted using GO templates.\n\n%%bash\ndocker images --format '{{.Repository}}:{{.Tag}}'\n\nhello-world:latest\n\n\n\n\n--no-trunc - full output\n\n%%bash\ndocker images --no-trunc\n\nREPOSITORY    TAG       IMAGE ID                                                                  CREATED         SIZE\nhello-world   latest    sha256:feb5d9fea6a5e9606aa995e879d862b825965ba48de054caab5ef356dc6b3412   16 months ago   13.3kB\n\n\n\n\n-q, --quiet - print only images ids\n\n%%bash\ndocker images -q\n\nfeb5d9fea6a5"
  },
  {
    "objectID": "Docker/docker_commands.html#rmi---delete-images",
    "href": "Docker/docker_commands.html#rmi---delete-images",
    "title": "Docker commands",
    "section": "rmi - delete images",
    "text": "rmi - delete images\nIt is obligatory to pass on one of the:\n\n&lt;image name&gt;:&lt;tag&gt; (&lt;tag&gt; - by default is latest);\nIMAGE ID - image id.\n\n\n%%bash\ndocker images\necho \"===========================\"\ndocker rmi hello-world:latest\necho \"===========================\"\ndocker images\n\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\nhello-world   latest    feb5d9fea6a5   16 months ago   13.3kB\n===========================\nUntagged: hello-world:latest\nUntagged: hello-world@sha256:aa0cc8055b82dc2509bed2e19b275c8f463506616377219d9642221ab53cf9fe\nDeleted: sha256:feb5d9fea6a5e9606aa995e879d862b825965ba48de054caab5ef356dc6b3412\nDeleted: sha256:e07ee1baac5fae6a26f30cabfe54a36d3402f96afda318fe0a96cec4ca393359\n===========================\nREPOSITORY   TAG       IMAGE ID   CREATED   SIZE"
  },
  {
    "objectID": "Docker/docker_commands.html#build---build-image-from-dockerfile",
    "href": "Docker/docker_commands.html#build---build-image-from-dockerfile",
    "title": "Docker commands",
    "section": "build - build image from dockerfile",
    "text": "build - build image from dockerfile\nThis command has description here"
  },
  {
    "objectID": "Docker/docker_commands.html#commit---save-container-state",
    "href": "Docker/docker_commands.html#commit---save-container-state",
    "title": "Docker commands",
    "section": "commit - save container state",
    "text": "commit - save container state\nThis command has description here."
  },
  {
    "objectID": "Docker/docker_commands.html#host---container",
    "href": "Docker/docker_commands.html#host---container",
    "title": "Docker commands",
    "section": "host -> container",
    "text": "host -&gt; container\nThere is the following syntax:\ndocker cp &lt;host path&gt; &lt;cantainer name&gt;:&lt;container path&gt;\nThe following example shows how to copy a file into a container."
  },
  {
    "objectID": "Docker/docker_commands.html#container---host",
    "href": "Docker/docker_commands.html#container---host",
    "title": "Docker commands",
    "section": "container -> host",
    "text": "container -&gt; host\nThere is syntax for m\n\n%%bash\ncd filesystem_example\ndocker run --rm --name test_ubuntu -itd ubuntu &&gt; /dev/null\n\ndocker cp copied_message.txt test_ubuntu:copied_message.txt\n\necho \"=====copied to container=====\"\ndocker exec test_ubuntu cat copied_message.txt\necho \"\"\n\ndocker cp test_ubuntu:copied_message.txt new_message.txt\necho \"=====copied from container=====\"\ncat new_message.txt\n\nrm new_message.txt\ndocker stop test_ubuntu &&gt; /dev/null\n\n=====copied to container=====\nThis message is for checking the copy functions.\n=====copied from container=====\nThis message is for checking the copy functions."
  },
  {
    "objectID": "Docker/docker_commands.html#basic-examples",
    "href": "Docker/docker_commands.html#basic-examples",
    "title": "Docker commands",
    "section": "Basic examples",
    "text": "Basic examples\nThis command provide information about docker ojects in json format such as:\n\nimages:\n\n\n%%bash\ndocker inspect ubuntu\n\n[\n    {\n        \"Id\": \"sha256:74f2314a03de34a0a2d552b805411fc9553a02ea71c1291b815b2f645f565683\",\n        \"RepoTags\": [\n            \"ubuntu:latest\"\n        ],\n        \"RepoDigests\": [\n            \"ubuntu@sha256:2adf22367284330af9f832ffefb717c78239f6251d9d0f58de50b86229ed1427\"\n        ],\n        \"Parent\": \"\",\n        \"Comment\": \"\",\n        \"Created\": \"2023-03-01T04:38:49.239257335Z\",\n        \"Container\": \"298f60554671ae2f5bf43b9892526aaa221e8093c9cee1ca68ef65fc3ac67600\",\n        \"ContainerConfig\": {\n            \"Hostname\": \"298f60554671\",\n            \"Domainname\": \"\",\n            \"User\": \"\",\n            \"AttachStdin\": false,\n            \"AttachStdout\": false,\n            \"AttachStderr\": false,\n            \"Tty\": false,\n            \"OpenStdin\": false,\n            \"StdinOnce\": false,\n            \"Env\": [\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n            ],\n            \"Cmd\": [\n                \"/bin/sh\",\n                \"-c\",\n                \"#(nop) \",\n                \"CMD [\\\"/bin/bash\\\"]\"\n            ],\n            \"Image\": \"sha256:6088cf91777e3b0190e579c7c7cab9c65626f5ff625373bcdb02ae877a9118d8\",\n            \"Volumes\": null,\n            \"WorkingDir\": \"\",\n            \"Entrypoint\": null,\n            \"OnBuild\": null,\n            \"Labels\": {\n                \"org.opencontainers.image.ref.name\": \"ubuntu\",\n                \"org.opencontainers.image.version\": \"22.04\"\n            }\n        },\n        \"DockerVersion\": \"20.10.12\",\n        \"Author\": \"\",\n        \"Config\": {\n            \"Hostname\": \"\",\n            \"Domainname\": \"\",\n            \"User\": \"\",\n            \"AttachStdin\": false,\n            \"AttachStdout\": false,\n            \"AttachStderr\": false,\n            \"Tty\": false,\n            \"OpenStdin\": false,\n            \"StdinOnce\": false,\n            \"Env\": [\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n            ],\n            \"Cmd\": [\n                \"/bin/bash\"\n            ],\n            \"Image\": \"sha256:6088cf91777e3b0190e579c7c7cab9c65626f5ff625373bcdb02ae877a9118d8\",\n            \"Volumes\": null,\n            \"WorkingDir\": \"\",\n            \"Entrypoint\": null,\n            \"OnBuild\": null,\n            \"Labels\": {\n                \"org.opencontainers.image.ref.name\": \"ubuntu\",\n                \"org.opencontainers.image.version\": \"22.04\"\n            }\n        },\n        \"Architecture\": \"amd64\",\n        \"Os\": \"linux\",\n        \"Size\": 77810712,\n        \"VirtualSize\": 77810712,\n        \"GraphDriver\": {\n            \"Data\": {\n                \"MergedDir\": \"/var/lib/docker/overlay2/dfcfb531746a088aaf673a8bc04602c8c8e19b1114680ff8164a95abfef8a0e6/merged\",\n                \"UpperDir\": \"/var/lib/docker/overlay2/dfcfb531746a088aaf673a8bc04602c8c8e19b1114680ff8164a95abfef8a0e6/diff\",\n                \"WorkDir\": \"/var/lib/docker/overlay2/dfcfb531746a088aaf673a8bc04602c8c8e19b1114680ff8164a95abfef8a0e6/work\"\n            },\n            \"Name\": \"overlay2\"\n        },\n        \"RootFS\": {\n            \"Type\": \"layers\",\n            \"Layers\": [\n                \"sha256:202fe64c3ce39b94d8beda7d7506ccdfcf7a59f02f17c915078e4c62b5c2ed11\"\n            ]\n        },\n        \"Metadata\": {\n            \"LastTagTime\": \"0001-01-01T00:00:00Z\"\n        }\n    }\n]\n\n\n\ncontainers:\n\n\n%%bash\ndocker run --rm --name test -itd ubuntu &&gt; /dev/null\ndocker inspect test\ndocker stop test &&gt; /dev/null\n\n[\n    {\n        \"Id\": \"020c99a8fbdca844a78956c0f7b2aba4fcd53e4f299112894dd0c0b7aca246c5\",\n        \"Created\": \"2023-06-12T13:37:52.23307605Z\",\n        \"Path\": \"/bin/bash\",\n        \"Args\": [],\n        \"State\": {\n            \"Status\": \"running\",\n            \"Running\": true,\n            \"Paused\": false,\n            \"Restarting\": false,\n            \"OOMKilled\": false,\n            \"Dead\": false,\n            \"Pid\": 32562,\n            \"ExitCode\": 0,\n            \"Error\": \"\",\n            \"StartedAt\": \"2023-06-12T13:37:52.471660971Z\",\n            \"FinishedAt\": \"0001-01-01T00:00:00Z\"\n        },\n        \"Image\": \"sha256:74f2314a03de34a0a2d552b805411fc9553a02ea71c1291b815b2f645f565683\",\n        \"ResolvConfPath\": \"/var/lib/docker/containers/020c99a8fbdca844a78956c0f7b2aba4fcd53e4f299112894dd0c0b7aca246c5/resolv.conf\",\n        \"HostnamePath\": \"/var/lib/docker/containers/020c99a8fbdca844a78956c0f7b2aba4fcd53e4f299112894dd0c0b7aca246c5/hostname\",\n        \"HostsPath\": \"/var/lib/docker/containers/020c99a8fbdca844a78956c0f7b2aba4fcd53e4f299112894dd0c0b7aca246c5/hosts\",\n        \"LogPath\": \"/var/lib/docker/containers/020c99a8fbdca844a78956c0f7b2aba4fcd53e4f299112894dd0c0b7aca246c5/020c99a8fbdca844a78956c0f7b2aba4fcd53e4f299112894dd0c0b7aca246c5-json.log\",\n        \"Name\": \"/test\",\n        \"RestartCount\": 0,\n        \"Driver\": \"overlay2\",\n        \"Platform\": \"linux\",\n        \"MountLabel\": \"\",\n        \"ProcessLabel\": \"\",\n        \"AppArmorProfile\": \"docker-default\",\n        \"ExecIDs\": null,\n        \"HostConfig\": {\n            \"Binds\": null,\n            \"ContainerIDFile\": \"\",\n            \"LogConfig\": {\n                \"Type\": \"json-file\",\n                \"Config\": {}\n            },\n            \"NetworkMode\": \"default\",\n            \"PortBindings\": {},\n            \"RestartPolicy\": {\n                \"Name\": \"no\",\n                \"MaximumRetryCount\": 0\n            },\n            \"AutoRemove\": true,\n            \"VolumeDriver\": \"\",\n            \"VolumesFrom\": null,\n            \"ConsoleSize\": [\n                0,\n                0\n            ],\n            \"CapAdd\": null,\n            \"CapDrop\": null,\n            \"CgroupnsMode\": \"private\",\n            \"Dns\": [],\n            \"DnsOptions\": [],\n            \"DnsSearch\": [],\n            \"ExtraHosts\": null,\n            \"GroupAdd\": null,\n            \"IpcMode\": \"private\",\n            \"Cgroup\": \"\",\n            \"Links\": null,\n            \"OomScoreAdj\": 0,\n            \"PidMode\": \"\",\n            \"Privileged\": false,\n            \"PublishAllPorts\": false,\n            \"ReadonlyRootfs\": false,\n            \"SecurityOpt\": null,\n            \"UTSMode\": \"\",\n            \"UsernsMode\": \"\",\n            \"ShmSize\": 67108864,\n            \"Runtime\": \"runc\",\n            \"Isolation\": \"\",\n            \"CpuShares\": 0,\n            \"Memory\": 0,\n            \"NanoCpus\": 0,\n            \"CgroupParent\": \"\",\n            \"BlkioWeight\": 0,\n            \"BlkioWeightDevice\": [],\n            \"BlkioDeviceReadBps\": [],\n            \"BlkioDeviceWriteBps\": [],\n            \"BlkioDeviceReadIOps\": [],\n            \"BlkioDeviceWriteIOps\": [],\n            \"CpuPeriod\": 0,\n            \"CpuQuota\": 0,\n            \"CpuRealtimePeriod\": 0,\n            \"CpuRealtimeRuntime\": 0,\n            \"CpusetCpus\": \"\",\n            \"CpusetMems\": \"\",\n            \"Devices\": [],\n            \"DeviceCgroupRules\": null,\n            \"DeviceRequests\": null,\n            \"MemoryReservation\": 0,\n            \"MemorySwap\": 0,\n            \"MemorySwappiness\": null,\n            \"OomKillDisable\": null,\n            \"PidsLimit\": null,\n            \"Ulimits\": null,\n            \"CpuCount\": 0,\n            \"CpuPercent\": 0,\n            \"IOMaximumIOps\": 0,\n            \"IOMaximumBandwidth\": 0,\n            \"MaskedPaths\": [\n                \"/proc/asound\",\n                \"/proc/acpi\",\n                \"/proc/kcore\",\n                \"/proc/keys\",\n                \"/proc/latency_stats\",\n                \"/proc/timer_list\",\n                \"/proc/timer_stats\",\n                \"/proc/sched_debug\",\n                \"/proc/scsi\",\n                \"/sys/firmware\"\n            ],\n            \"ReadonlyPaths\": [\n                \"/proc/bus\",\n                \"/proc/fs\",\n                \"/proc/irq\",\n                \"/proc/sys\",\n                \"/proc/sysrq-trigger\"\n            ]\n        },\n        \"GraphDriver\": {\n            \"Data\": {\n                \"LowerDir\": \"/var/lib/docker/overlay2/06b3ab167c3c359841177a3bc998d8bc5c32c1c8893d7518e2df4193a1dc98ee-init/diff:/var/lib/docker/overlay2/dfcfb531746a088aaf673a8bc04602c8c8e19b1114680ff8164a95abfef8a0e6/diff\",\n                \"MergedDir\": \"/var/lib/docker/overlay2/06b3ab167c3c359841177a3bc998d8bc5c32c1c8893d7518e2df4193a1dc98ee/merged\",\n                \"UpperDir\": \"/var/lib/docker/overlay2/06b3ab167c3c359841177a3bc998d8bc5c32c1c8893d7518e2df4193a1dc98ee/diff\",\n                \"WorkDir\": \"/var/lib/docker/overlay2/06b3ab167c3c359841177a3bc998d8bc5c32c1c8893d7518e2df4193a1dc98ee/work\"\n            },\n            \"Name\": \"overlay2\"\n        },\n        \"Mounts\": [],\n        \"Config\": {\n            \"Hostname\": \"020c99a8fbdc\",\n            \"Domainname\": \"\",\n            \"User\": \"\",\n            \"AttachStdin\": false,\n            \"AttachStdout\": false,\n            \"AttachStderr\": false,\n            \"Tty\": true,\n            \"OpenStdin\": true,\n            \"StdinOnce\": false,\n            \"Env\": [\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n            ],\n            \"Cmd\": [\n                \"/bin/bash\"\n            ],\n            \"Image\": \"ubuntu\",\n            \"Volumes\": null,\n            \"WorkingDir\": \"\",\n            \"Entrypoint\": null,\n            \"OnBuild\": null,\n            \"Labels\": {\n                \"org.opencontainers.image.ref.name\": \"ubuntu\",\n                \"org.opencontainers.image.version\": \"22.04\"\n            }\n        },\n        \"NetworkSettings\": {\n            \"Bridge\": \"\",\n            \"SandboxID\": \"422100341f6b603db62a0c616fa614091b66ac5a06796fa577503fd469b4ce56\",\n            \"HairpinMode\": false,\n            \"LinkLocalIPv6Address\": \"\",\n            \"LinkLocalIPv6PrefixLen\": 0,\n            \"Ports\": {},\n            \"SandboxKey\": \"/var/run/docker/netns/422100341f6b\",\n            \"SecondaryIPAddresses\": null,\n            \"SecondaryIPv6Addresses\": null,\n            \"EndpointID\": \"b2440d2f1d13674c667458fd051354ec32d2e11475db2308e20cd057e3b16037\",\n            \"Gateway\": \"172.17.0.1\",\n            \"GlobalIPv6Address\": \"\",\n            \"GlobalIPv6PrefixLen\": 0,\n            \"IPAddress\": \"172.17.0.2\",\n            \"IPPrefixLen\": 16,\n            \"IPv6Gateway\": \"\",\n            \"MacAddress\": \"02:42:ac:11:00:02\",\n            \"Networks\": {\n                \"bridge\": {\n                    \"IPAMConfig\": null,\n                    \"Links\": null,\n                    \"Aliases\": null,\n                    \"NetworkID\": \"cf037e1d3aeb308ae603f8028da3343134d92e79462fdcb5390b196a9e49c87d\",\n                    \"EndpointID\": \"b2440d2f1d13674c667458fd051354ec32d2e11475db2308e20cd057e3b16037\",\n                    \"Gateway\": \"172.17.0.1\",\n                    \"IPAddress\": \"172.17.0.2\",\n                    \"IPPrefixLen\": 16,\n                    \"IPv6Gateway\": \"\",\n                    \"GlobalIPv6Address\": \"\",\n                    \"GlobalIPv6PrefixLen\": 0,\n                    \"MacAddress\": \"02:42:ac:11:00:02\",\n                    \"DriverOpts\": null\n                }\n            }\n        }\n    }\n]\n\n\n\nnetworks:\n\n\n%%bash\ndocker inspect bridge\n\n[\n    {\n        \"Name\": \"bridge\",\n        \"Id\": \"cf037e1d3aeb308ae603f8028da3343134d92e79462fdcb5390b196a9e49c87d\",\n        \"Created\": \"2023-06-12T08:14:24.801403507+03:00\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": null,\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.17.0.0/16\",\n                    \"Gateway\": \"172.17.0.1\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Attachable\": false,\n        \"Ingress\": false,\n        \"ConfigFrom\": {\n            \"Network\": \"\"\n        },\n        \"ConfigOnly\": false,\n        \"Containers\": {},\n        \"Options\": {\n            \"com.docker.network.bridge.default_bridge\": \"true\",\n            \"com.docker.network.bridge.enable_icc\": \"true\",\n            \"com.docker.network.bridge.enable_ip_masquerade\": \"true\",\n            \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\",\n            \"com.docker.network.bridge.name\": \"docker0\",\n            \"com.docker.network.driver.mtu\": \"1500\"\n        },\n        \"Labels\": {}\n    }\n]"
  },
  {
    "objectID": "Docker/docker_commands.html#special-cases",
    "href": "Docker/docker_commands.html#special-cases",
    "title": "Docker commands",
    "section": "Special cases",
    "text": "Special cases\n\nFor more information about the path to container logs, you can look here."
  },
  {
    "objectID": "Docker/docker_compose.html",
    "href": "Docker/docker_compose.html",
    "title": "Docker-compose",
    "section": "",
    "text": "Docker-Compose is a tool that is presented as the next step of abstraction under Docker - a tool that allows to organise interactions between containers.\n\nYAML\nThe language used to describe the behaviour of docker-compose.\nYAML allows you to describe data structures consisting of lists and dictionaries:\n\nEach item in the list starts with the symbol -;\nEach new key in the dictionary sets like &lt;key&gt;;\nTemplates (anchors) - the possibility to create the link to some essential and then use it in any place;\nThe nesting of the structure is formed by indents.\n\nFurther examples will make it clearer.\nPython has a library called “yaml” that allows you to convert “yaml” markup to the corresponding Python data structures.\n\nimport yaml\n\nIn the following example, I create the dictionary with the keys names, ages, which contains the corresponding lists:\n\nyaml_str = \\\n'''\nnames:\n    - peter\n    - olga\nages:\n    - 22\n    - 18\n'''\n\nyaml.full_load(yaml_str)\n\n{'names': ['peter', 'olga'], 'ages': [22, 18]}\n\n\nNote that there should be a space between &lt;key&gt; and &lt;value&gt;. Here, for comparison, is a correctly created dictionary under the key postgres and a dictionary under the key clickhouse which was created incorrectly."
  },
  {
    "objectID": "Docker/multistage_build/multistage_build.html",
    "href": "Docker/multistage_build/multistage_build.html",
    "title": "База",
    "section": "",
    "text": "Многоэтапная сборка в docker\nВ docker есть особый тип сборки, который позволяет оставить в финальном образе только те элементы, что нам нужны. Это, в некоторых случаях, позволит сэкономить размер docker образа.\nФормально это делается следующим образом:\nFROM &lt;название образа&gt; AS &lt;название сборки1&gt;\n\nFROM &lt;название образа&gt;\nCOPY --from=&lt;название сборки1&gt; &lt;файл из перовой сборки&gt; &lt;файл из второй сборки&gt;\n\nПример\nТак допуским ситуацию, где нам в финальной сборке надо иметь результаты обработки некоторого большого файла example.csv проводимой программой generation.py (в данном случае это просто взятие средних).\nЕсли делать это по простому, то мы сделаем dockerfile вида (simple_dockerfile):\n# простой dockerfile\nFROM python:3.10 AS BUILD\n\nWORKDIR some_dir\nCOPY example.csv example.csv\nCOPY requirements.txt requirements.txt\nCOPY generation.py generation.py\n\nRUN python -m pip install --upgrade pip && pip install -r requirements.txt\nRUN python generation.py\n\nCMD [\"cat\", \"means.csv\"]\nДалее: - Собираю образ; - Поднимаю контейнер на его основе, чтобы показать, что все работает номрмально; - Показываю размер образа.\n\n%%bash\ndocker build -q -t simple -f simple_dockerfile .\necho ==============================\ndocker run --rm simple\necho ==============================\ndocker images simple\necho ==============================\ndocker rmi simple\n\nsha256:daea387ec3b5bb08725927e3cf8a8274d8c535fbdebd7905760ebeeb6aec0156\n==============================\n,0\n0,0.49801512771615053\n1,0.5005384992657755\n2,0.5016440913126519\n3,0.49893742832936905\n4,0.5006416292879786\n5,0.500604403582076\n6,0.5024090926131595\n7,0.500360289940759\n8,0.4995687156844078\n9,0.4993301862968266\n10,0.4996320601371099\n11,0.49936364688453744\n12,0.4996892437983095\n13,0.5003040557416716\n14,0.5008896760787612\n15,0.49834042413261304\n16,0.5002565939707307\n17,0.499441058229968\n18,0.4994494362971878\n19,0.5000038702075555\n==============================\nREPOSITORY   TAG       IMAGE ID       CREATED          SIZE\nsimple       latest    daea387ec3b5   43 minutes ago   1.11GB\n==============================\nUntagged: simple:latest\nDeleted: sha256:daea387ec3b5bb08725927e3cf8a8274d8c535fbdebd7905760ebeeb6aec0156\n\n\nВ итоге мы вывели результат расчета. Ну и размер образа составляет титанические 1.11GB.\nА теперь сделаем тоже самое, только правильно. dockerfile в случае использоваиня многоэтапной сборке примет вид (multistage_dockerfile):\nFROM python:3.10 AS BUILDER\n\nWORKDIR some_dir\nCOPY example.csv example.csv\nCOPY requirements.txt requirements.txt\nCOPY generation.py generation.py\n\nRUN python -m pip install --upgrade pip && pip install -r requirements.txt\nRUN python generation.py\n\nFROM ubuntu:22.04\nWORKDIR some_dir\nCOPY --from=BUILDER /some_dir/means.csv /some_dir/means.csv\nCMD [\"cat\", \"means.csv\"]\nБуквально повторяю процедуры, которые проделал для предыдущего образа.\n\n%%bash\ndocker build -q -t multistage -f multistage_dockerfile .\necho ==============================\ndocker run --rm multistage\necho ==============================\ndocker images multistage\necho ==============================\ndocker rmi multistage\n\nsha256:15096f1d81baa6c46dadf24558dfa0c39ffcebb248495c779f1334b4b75a2eca\n==============================\n,0\n0,0.49801512771615053\n1,0.5005384992657755\n2,0.5016440913126519\n3,0.49893742832936905\n4,0.5006416292879786\n5,0.500604403582076\n6,0.5024090926131595\n7,0.500360289940759\n8,0.4995687156844078\n9,0.4993301862968266\n10,0.4996320601371099\n11,0.49936364688453744\n12,0.4996892437983095\n13,0.5003040557416716\n14,0.5008896760787612\n15,0.49834042413261304\n16,0.5002565939707307\n17,0.499441058229968\n18,0.4994494362971878\n19,0.5000038702075555\n==============================\nREPOSITORY   TAG       IMAGE ID       CREATED             SIZE\nmultistage   latest    15096f1d81ba   About an hour ago   77.8MB\n==============================\nUntagged: multistage:latest\nDeleted: sha256:15096f1d81baa6c46dadf24558dfa0c39ffcebb248495c779f1334b4b75a2eca\n\n\nИ так, в результате, все тоже самое но размером в 77.8MB.\n\n\nОстановка на нужном этапе\nПри многоэтапной сборке, например, для отладки, может понадобиться отсновится в сборке образа. Это делается с помощью опции --target &lt;название этапа&gt;. Так, в примере далее, я останавливаю сборку описанного выше образа multistage на этапе BUILDER и убеждаюсь, что это именно тот этап (файлы то его).\n\n%%bash\ndocker build -q -t multistage -f multistage_dockerfile --target BUILDER .\ndocker run --rm --name multistage -itd multistage\necho ==============================\ndocker exec multistage ls\necho ==============================\ndocker stop multistage\ndocker rmi multistage\n\nsha256:19ec4683d03994e2f466696a18fbd3db8deda7f1f251185feddb1d568b116a02\n0e9309e419e5c47647beb7005ecd0bb2d6c8c771eb96c216fcb24294781c4ff1\n==============================\nexample.csv\ngeneration.py\nmeans.csv\nrequirements.txt\n==============================\nmultistage\nUntagged: multistage:latest\nDeleted: sha256:19ec4683d03994e2f466696a18fbd3db8deda7f1f251185feddb1d568b116a02"
  },
  {
    "objectID": "Docker/docker_volumes.html",
    "href": "Docker/docker_volumes.html",
    "title": "Volumes",
    "section": "",
    "text": "In order to connect a folder on the host to the container, use the -v option of the docker run command. The full syntax is as follows:\ndocker run \\\n    -v &lt;older on host1&gt;:&lt;folder in container1&gt; \\\n    -v &lt;older on host2&gt;:&lt;folder in container2&gt; \\\n    ...\nBy &lt;folder on hosti&gt; it can be understood as:\n\nA path to some folder on the host, this is commonly referred to as bind mount, and is used more commonly to pass something specific to that host into the container;\nA volume, this is the preferred mount method, and is used to store information that is “created” by the container; it is essentially the same as a folder on the host but controlled by a docker.\n\n\nBind mount\nIn the following example I create folder temp_folder, put it into container named temp_folder_inc_count. From container create file there, exited from container and even deleted it, I can get file from host folder.\n\n%%bash\ncd filesystem_example\nmkdir temp_folder\n\ndocker run \\\n    -v $(pwd)/temp_folder:/temp_folder_in_cont \\\n    --rm -itd --name temp_example \\\n    ubuntu &&gt; /dev/null\ndocker exec temp_example bash -c \"echo \\'hello from container\\' &gt;&gt; temp_folder_in_cont/hello\"\ndocker stop temp_example &&gt; /dev/null\n\ncat temp_folder/hello\nrm -r temp_folder\n\n'hello from container'\n\n\n\n\nVolume\nIs a file that resides on the host and doesn’t depend on an image, but depends on Docker. Its primary purpose is to store data.\n\ndocker volume service\ndocker volume is a separate service for managing volumes.\n\nls - show volumes;\ncreate - create volume;\nrm - remove volume;\nprune - remove volumes not used in any container;\nisnpect - allows you to retrieve information about volume (including where it lies on the host).\n\nThe following example shows how to use volumes. Step-by-step description: - temp_volume is created; - ubuntu container named example_container running, and volume created earlier attached to container as temp_volume_cont folder; - file writes to the temp_volume_cont from container; - example_container stops and removes automatically (because the --rm' option was setted); - next,inspectshows where you can find the volume on the host (Mountpointdirectory), but I can't get access from Jupyter - you should have root privileges for this folder; -example_container` was started in the same way as before; - and in the folder associated with the container, you can still find the file created in the previous steps.\n\n%%bash\ndocker volume create temp_volume &&gt; /dev/null\n\ndocker run \\\n    -v temp_volume:/temp_volume_cont\\\n    --rm --name example_container -itd\\\n    ubuntu &&gt; /dev/null\ndocker exec example_container bash -c \"echo \\'hello from volume\\' &gt;&gt; temp_volume_cont/hello\"\ndocker stop example_container &&gt; /dev/null\n\ndocker volume inspect temp_volume\n\ndocker run \\\n    -v temp_volume:/temp_volume_cont\\\n    --rm --name example_container -itd\\\n    ubuntu &&gt; /dev/null\ndocker exec example_container cat temp_volume_cont/hello\ndocker stop example_container &&gt; /dev/null\n\ndocker volume rm temp_volume &&gt; /dev/null\n\n[\n    {\n        \"CreatedAt\": \"2023-06-03T19:15:02+03:00\",\n        \"Driver\": \"local\",\n        \"Labels\": null,\n        \"Mountpoint\": \"/var/lib/docker/volumes/temp_volume/_data\",\n        \"Name\": \"temp_volume\",\n        \"Options\": null,\n        \"Scope\": \"local\"\n    }\n]\n'hello from volume'\n\n\n\n\n\nAccess\n\nContainers always have root\nEven if host has root access to some folder/file, container always works under root. So if you mount a folder/file in this way, it may lead to unauthorised changes. The following cell contains the example.\n\n%%bash\ncd filesystem_example\n\n# creating fodler and file with super secret message\nmkdir secret_dir\ntouch secret_dir/secret_file\necho \"super secret info\" &gt; secret_dir/secret_file\n# Close access to the folder\nchmod 000 secret_dir\n\n\n# make sure we can't access or delte the file\necho \"=====From host=====\"\ncat secret_dir/secret_file\nrm secret_dir/secret_file\n\n\n# run container and mount created folder\ndocker run --rm -itd --name perm_ex\\\n    -v $(pwd)/secret_dir:/experimental/secret_dir \\\n    ubuntu &&gt; /dev/null\n# and voila ealily extract secret info\necho \"=====From docker====\"\ndocker exec perm_ex cat experimental/secret_dir/secret_file\n# or even can delete secret file\ndocker exec perm_ex rm experimental/secret_dir/secret_file\ndocker exec perm_ex ls experimental/secret_dir\n\ndocker stop perm_ex &&gt; /dev/null\n\n=====From host=====\n=====From docker====\nsuper secret info\n\n\ncat: secret_dir/secret_file: Permission denied\nrm: cannot remove 'secret_dir/secret_file': Permission denied\n\n\n\n\nro (read only) option\nContinuing from the previous section, note that when you move the folder to the container, you can set the ro option, which will prevent the container from modifying the file.\n\n%%bash\necho \"some data\" &gt; ro_ex\n# running container with ro option\ndocker run --rm -idt --name ro_ex\\\n    -v $(pwd)/ro_ex:/experimental/ro_ex:ro\\\n    ubuntu &&gt; /dev/null\n# change the file\ndocker exec ro_ex bash -c \"echo \\\"new some data\\\" &gt; ro_ex\"\n# print new file\ncat ro_ex\n\ndocker stop ro_ex &&gt; /dev/null\nrm -r ro_ex\n\nsome data\n\n\nSo I tried to change file from container, but even after operation file sill have initial message.\n\n\nRunnig with setting user -u{sec-run_u_option}\nThe problem with access can be solved by setting the user when starting the container (-u option). Using the example from the section “Containers always have root”, you can do this.\n\n%%bash\ncd filesystem_example\n# создаем папку и в ней файл и даже в него записываем\n# сверхсекретное сообщение\nmkdir secret_dir\ntouch secret_dir/secret_file\necho \"super secret info\" &gt; secret_dir/secret_file\n# закрываю доступ в папку\nchmod 000 secret_dir\n\n# поднимаем контейнер и монтируем в него данную папку\ndocker run --rm -itd --name perm_ex -u=1000\\\n    -v $(pwd)/secret_dir:/experimental/secret_dir \\\n    ubuntu &&gt; /dev/null\necho \"=====Trying to access from a container=====\"\ndocker exec perm_ex cat secret_dir/secret_file\n\ndocker stop perm_ex &&gt; /dev/null\n\nmkdir: cannot create directory ‘secret_dir’: File exists\ntouch: cannot touch 'secret_dir/secret_file': Permission denied\nbash: line 6: secret_dir/secret_file: Permission denied\ncat: secret_dir/secret_file: No such file or directory\n\n\n=====Trying to access from a container=====\n\n\n\n\nMounting .dockerignore files\nEven if you mount the file described in .dockerignore, we will still have it in the container.\nIn the following example, I create app/ignore_file.txt and mention it in dockerignore. Build image using this .dockerignore, but in container based on this image I mount app folder. And as a result I can see contents of ignore_file.txt regardless of what I specified in the .dockerignore.\n\n%%bash\ncd filesystem_example\nmkdir app\necho \"message in ignore_file.txt\" &gt; app/ignore_file.txt\necho \"=====.dockerignore=====\"\necho \"app/ignore_file.txt\" &gt; .dockerignore\ncat .dockerignore\necho \"=====dockerfile=====\"\necho \"FROM ubuntu\" &gt; dockerfile\ncat dockerfile\n\n# build image with setted .dockerignore\ndocker build -t test_image &&gt; /dev/null\n\n# start container mountig file mentioned in .dockerignore\ndocker run --rm -itd --name ignore_ex\\\n    -v $(pwd)/app:/app\\\n    ubuntu &&gt; /dev/null\n\necho \"=====ignore-file from container=====\"\n# make sure that this secret file is in the container\ndocker exec ignore_ex cat app/ignore_file.txt\n\ndocker stop ignore_ex &&gt; /dev/null\ndocker rmi test_image &&gt; /dev/null\nrm -r app\nrm .dockerignore\nrm dockerfile\n\n=====.dockerignore=====\napp/ignore_file.txt\n=====dockerfile=====\nFROM ubuntu\n=====ignore-file from container=====\nmessage in ignore_file.txt\n\n\n\n\n\nVolume by default\nSome containers create their own volumes by default when they run, so you may find that your entire hard drive is flooded.\nFor example yandex/clickhouse-server. In the following cell I have some containers yandex/clickhouse-server running and show that each container has created a volume.\n\n%%bash\n\necho \"=====docker volume ls before=====\"\ndocker volume ls\n\n# run clickhouse\ndocker run -d --name db_1 --rm yandex/clickhouse-server &&gt; /dev/null\ndocker run -d --name db_2 --rm yandex/clickhouse-server &&gt; /dev/null\ndocker run -d --name db_3 --rm yandex/clickhouse-server &&gt; /dev/null\n\n# list volumes\necho \"=====docker volume ls after=====\"\ndocker volume ls\ndocker stop db_1 db_2 db_3 &&gt; /dev/null\n\n=====docker volume ls before=====\nDRIVER    VOLUME NAME\n=====docker volume ls after=====\nDRIVER    VOLUME NAME\nlocal     66e881449c54eb455e1a0e16b6b1cfff0aac6fbe31739ea59d307d5631c04fa2\nlocal     b6d2ba76cf901665684319a3197166a61d8da5d75b8804945a8f0368de0c89ec\nlocal     d3ba9de2668e8e3f68d43ccfb02db72738f2c2b7048ed2bfc94b3134d00f53f1\n\n\n\n\nSeveral volumes in one command\nYou can repeat -v option in docker run many times as you need.\nBasic example.\n\n%%bash\ncd filesystem_example\n\nmkdir test1 test2\necho \"message in test1\" &gt; test1/my_file\necho \"message in test2\" &gt; test2/my_file\n\ndocker run --rm --name example_cont -itd\\\n    -v $(pwd)/test1:/test1\\\n    -v $(pwd)/test2:/test2\\\n    ubuntu &&gt; /dev/null\n\necho \"=====files from container=====\"\ndocker exec example_cont cat test1/my_file\ndocker exec example_cont cat test2/my_file\n\ndocker stop example_cont &&gt; /dev/null\nrm -r test1 test2\n\n=====files from container=====\nmessage in test1\nmessage in test2\n\n\nBut you can’t mount a directory on the container twice.\n\n%%bash\ncd filesystem_example\n\nmkdir test1 test2\necho \"message in test1\" &gt; test1/my_file\necho \"message in test2\" &gt; test2/my_file\n\ndocker run --rm --name example_cont -itd\\\n    -v $(pwd)/test1:/test\\\n    -v $(pwd)/test2:/test\\\n    ubuntu\n\nrm -r test1 test2\n\ndocker: Error response from daemon: Duplicate mount point: /test.\nSee 'docker run --help'.\n\n\nA directory from host to different folders in container is available. But you need to know that they are actually the same directory with different names - any change in one will happen in the other.\nIn the following example, we mount test in host to test1 and test2 in container. Then we add the file new_file to test1, but it will appear not only in test1 but also in test2 and test.\n\n%%bash\ncd filesystem_example\n\nmkdir test\n\ndocker run --rm --name example_cont -itd\\\n    -v $(pwd)/test:/test1\\\n    -v $(pwd)/test:/test2\\\n    ubuntu &&gt; /dev/null\n\ndocker exec example_cont bash -c \"echo \\\"hello from container\\\" &gt; test1/new_file\"\necho \"=====ls test1 from container=====\"\ndocker exec example_cont ls test1\necho \"=====ls test2 from container=====\"\ndocker exec example_cont ls test2\n\ndocker stop example_cont &&gt; /dev/null\n\n\necho \"=====ls test=====\"\nls test\nrm -r test\n\n=====ls test1 from container=====\nnew_file\n=====ls test2 from container=====\nnew_file\n=====ls test=====\nnew_file"
  },
  {
    "objectID": "Docker/image_creation.html",
    "href": "Docker/image_creation.html",
    "title": "Image creation",
    "section": "",
    "text": "build - build image\nThis is the command used to create a new docker image.\nBasic arguments:\n\nthe last mandatory argument sets the build directory - you should use . to set the current directory.\n-t - set the name and tag of the image.\n\n\n%%bash\ncd build_command_files\necho \"=====building process=====\"\ndocker build -t custom_ubuntu:test .\necho \"=====check image=====\"\ndocker images | grep custom_ubuntu\ndocker rmi custom_ubuntu:test &&gt; /dev/null\n\n=====building process=====\nSending build context to Docker daemon  18.94kB\nStep 1/1 : FROM ubuntu\n ---&gt; 99284ca6cea0\nSuccessfully built 99284ca6cea0\nSuccessfully tagged custom_ubuntu:test\n=====check image=====\ncustom_ubuntu   test      99284ca6cea0   2 weeks ago     77.8MB\n\n\n\n-f - allow to chose the dockerfile\nYou should see a difference between building directory and dockerfile. The dockerfile is only taken from the building directory if it is not specified in the -f option. But the files used for the build will in any case come from the build directory.\nSo let’s try some experiments with these details. I have prepared some folders for experiments with these options, in the following cell I show tree and file contents.\n\n%%bash\ncd build_command_files/f_option_examples\ntree\n\necho\necho\necho\n\nfor file in $(find -type f | grep -v \"\\/\\.\"); do\n    echo \"\"\n    echo \"=====File: $file=====\"\n    cat $file\n    echo \"\"\ndone\n\n.\n├── dockerfile\n├── script.sh\n├── specialdockerfile\n└── test_folder\n    ├── dockerfile\n    └── script.sh\n\n1 directory, 5 files\n\n\n\n\n=====File: ./dockerfile=====\nFROM ubuntu:latest\nCOPY script.sh script.sh\nRUN echo \"\\necho message from basic dockerfile\" &gt;&gt; script.sh\n\n=====File: ./script.sh=====\necho \"It's a script.sh from the run folder\"\n\n=====File: ./specialdockerfile=====\nFROM ubuntu:latest\nCOPY script.sh script.sh\nRUN echo \"\\necho message from specialdockerfile\" &gt;&gt; script.sh\n\n=====File: ./test_folder/dockerfile=====\nFROM ubuntu:latest\nCOPY script.sh script.sh\nRUN echo \"\\necho message from test_folder/dockerfile\" &gt;&gt; script.sh\n\n=====File: ./test_folder/script.sh=====\necho \"It's a script from test_folder\"\n\n\nWe have:\n\nscripts:\n\nfrom run folder - prints \"It's a script.sh from the run folder\";\nfrom test_folder - prints \"It's a script from test_folder\";\n\ndockerfiles:\n\nbasic dockerfile from run directory - adds to printing script line \"message from basic dockerfile\";\nspecisaldocker file from run dicrecotry but with special name - adds to printing script line \"message from specialdockerfile\";\ndockerfile from test_folder directory - adds to printing script line \"message from test_folder/dockerfile\";\nspecialdockerfile from test_folder directory - adds to printing script line \"message from test_folder/specialdockerfile\";\n\n\nThis way we can always tell from the output of script.sh from the container in which folder and from which dockerfile the image was built. Let’s try different options:\n\nThe most basic case no -f option and . as build directory - will lead to using docker file from run directory and script.sh was copiet from run dicrecory as well;\n\n\n%%bash\ncd build_command_files/f_option_examples\ndocker build -t test_ubuntu . &&gt; /dev/null\ndocker run --rm -itd \\\n    --name test_ubuntu \\\n    test_ubuntu &&gt; /dev/null\necho \"=====message from container=====\"\ndocker exec test_ubuntu bash script.sh\n\ndocker stop test_ubuntu &&gt; /dev/null\ndocker rmi test_ubuntu &&gt; /dev/null\n\n=====message from container=====\nIt's a script.sh from the run folder\nmessage from basic dockerfile\n\n\n\nIf you do not set the -f option but specify the build folder as test_folder everythig will be taken from test_folder;\n\n\n%%bash\ncd build_command_files/f_option_examples\ndocker build -t test_ubuntu test_folder &&gt; /dev/null\ndocker run --rm -itd \\\n    --name test_ubuntu \\\n    test_ubuntu &&gt; /dev/null\necho \"=====message from container=====\"\ndocker exec test_ubuntu bash script.sh\n\ndocker stop test_ubuntu &&gt; /dev/null\ndocker rmi test_ubuntu &&gt; /dev/null\n\n=====message from container=====\nIt's a script from test_folder\nmessage from test_folder/dockerfile\n\n\n\nIf you set -f specialdockerfile and specify the build folder as test_folder - everything is obvious;\n\n\n%%bash\ncd build_command_files/f_option_examples\ndocker build \\\n    -t test_ubuntu \\\n    -f specialdockerfile \\\n    test_folder &&gt; /dev/null\ndocker run --rm -itd \\\n    --name test_ubuntu \\\n    test_ubuntu &&gt; /dev/null\necho \"=====message from container=====\"\ndocker exec test_ubuntu bash script.sh\n\ndocker stop test_ubuntu &&gt; /dev/null\ndocker rmi test_ubuntu &&gt; /dev/null\n\n=====message from container=====\nIt's a script from test_folder\nmessage from specialdockerfile\n\n\n\nBit exotic case - dockerfile from test_folder, but build directory is run directory;\n\n\n%%bash\ncd build_command_files/f_option_examples\ndocker build \\\n    -t test_ubuntu \\\n    -f test_folder/dockerfile \\\n    . &&gt; /dev/null\ndocker run --rm -itd \\\n    --name test_ubuntu \\\n    test_ubuntu &&gt; /dev/null\necho \"=====message from container=====\"\ndocker exec test_ubuntu bash script.sh\n\ndocker stop test_ubuntu &&gt; /dev/null\ndocker rmi test_ubuntu &&gt; /dev/null\n\n=====message from container=====\nIt's a script.sh from the run folder\nmessage from test_folder/dockerfile\n\n\nNote even if you have specified a folder as some assembly folder, you must still pass in the -f parameter the path relative to the run folder.\nThe next two points show the difference:\n\nHere I set building directory as test_folder but -f specialdockerfile - specialdockerfile from run folder will be used;\n\n\n%%bash\ncd build_command_files/f_option_examples\ndocker build \\\n    -t test_ubuntu \\\n    -f specialdockerfile \\\n    test_folder &&gt; /dev/null\ndocker run --rm -itd \\\n    --name test_ubuntu \\\n    test_ubuntu &&gt; /dev/null\necho \"=====message from container=====\"\ndocker exec test_ubuntu bash script.sh\n\ndocker stop test_ubuntu &&gt; /dev/null\ndocker rmi test_ubuntu &&gt; /dev/null\n\n=====message from container=====\nIt's a script from test_folder\nmessage from specialdockerfile\n\n\n\nHere I set building directory as test_folder but -f test_folder/specialdockerfile - specialdockerfile from test_folder will be used;\n\n\n%%bash\ncd build_command_files/f_option_examples\ndocker build \\\n    -t test_ubuntu \\\n    -f test_folder/specialdockerfile \\\n    test_folder &&gt; /dev/null\ndocker run --rm -itd \\\n    --name test_ubuntu \\\n    test_ubuntu &&gt; /dev/null\necho \"=====message from container=====\"\ndocker exec test_ubuntu bash script.sh\n\ndocker stop test_ubuntu &&gt; /dev/null\ndocker rmi test_ubuntu &&gt; /dev/null\n\n=====message from container=====\nIt's a script from test_folder\nmessage from test_folder/specialdockerfile\n\n\n\n\n\n.dockerignore - select files ignored during image building\nIn docker ignore, you should specify files to be ignored when building the image.\nFor example lets try to build image with followig paremeters:\n\n%%bash\ncd dockerignore\necho \"=====dockerfile=====\"\ncat dockerfile1\necho\necho \"=====.dockerignore=====\"\ncat .dockerignore\n\n=====dockerfile=====\nFROM ubuntu\nCOPY test_file test_file\n=====.dockerignore=====\ntest_file\ntest_folder/banned_file\n\n\nSo in dockerfile I try to copy test_file into image, but in docker ignore I bun this file. At the next cell, I’m trying to build such image - and getting error.\n\n%%bash\ncd dockerignore\ndocker build -t test_image -f dockerfile1 .\n\n#1 [internal] load build definition from dockerfile1\n#1 transferring dockerfile: 74B done\n#1 DONE 0.0s\n\n#2 [internal] load .dockerignore\n#2 transferring context: 50B done\n#2 DONE 0.0s\n\n#3 [internal] load metadata for docker.io/library/ubuntu:latest\n#3 DONE 0.0s\n\n#4 [1/2] FROM docker.io/library/ubuntu\n#4 DONE 0.0s\n\n#5 [internal] load build context\n#5 transferring context: 2B done\n#5 DONE 0.0s\n\n#6 [2/2] COPY test_file test_file\n#6 ERROR: failed to calculate checksum of ref 40880b12-160a-424d-a82b-d59b9594f64c::7cmhtk0ygxakortpvzlpd8pwp: \"/test_file\": not found\n------\n &gt; [2/2] COPY test_file test_file:\n------\ndockerfile1:2\n--------------------\n   1 |     FROM ubuntu\n   2 | &gt;&gt;&gt; COPY test_file test_file\n--------------------\nERROR: failed to solve: failed to compute cache key: failed to calculate checksum of ref 40880b12-160a-424d-a82b-d59b9594f64c::7cmhtk0ygxakortpvzlpd8pwp: \"/test_file\": not found\n\n\nCalledProcessError: Command 'b'cd dockerignore\\ndocker build -t test_image -f dockerfile1 .\\n'' returned non-zero exit status 1.\n\n\nOn the other hand, if I copy an entire folder and only a few files are blocked in the folder, the folder will be copied without those files. The following example show such configuration:\n\n%%bash\ncd dockerignore\n\necho \"=====dockerfile=====\"\ncat dockerfile2\necho\necho \"=====.dockerignore=====\"\ncat .dockerignore\n\necho\necho \"=====test_folder in host=====\"\nls test_folder\n\ndocker build -t test_image -f dockerfile2 . &&gt; /dev/null\n\ndocker run --rm --name test_container -itd test_image &&gt; /dev/null\necho \"=====test_folder in container=====\"\ndocker exec test_container ls test_folder\n\ndocker stop test_container &&gt; /dev/null\ndocker rmi test_image &&gt; /dev/null\n\n=====dockerfile=====\nFROM ubuntu\nCOPY test_folder test_folder\n=====.dockerignore=====\ntest_file\ntest_folder/banned_file\n\n=====test_folder in host=====\naccepted_file\nbanned_file\n=====test_folder in container=====\naccepted_file\n\n\nHere I copy the whole folder, but the file banned_file was mentioned in .dockerignore. So when we ls temp_folder from container we see only accepted_file in folder contents.\n\n\nFile in container forever\nIf you copied a file into the container, but literally deleted it by the next instruciton - it will still affect the size of the container.\nFollowing exampe show that fature: - First I create an image - just copy Ubuntu; - Second, add the COPY instruction for a large file - so the size of the container will be much larger than in the first step; - Last image add RUN rm for the file copied in the previous step, the point is that the image size hasn’t changed.\n\n%%bash\n\ndd if=/dev/zero of=file.txt bs=1M count=1000 &&gt; /dev/null\n\necho \"=====just ubuntu copy=====\"\necho \"FROM ubuntu\" &gt; test_dockerfile\ndocker build -f test_dockerfile -t test_image . &&gt; /dev/null\ndocker images | grep test_image\ndocker rmi test_image &&gt; /dev/null\n\necho \"=====ubuntu with big copied file=====\"\necho \"COPY file.txt file.txt\" &gt;&gt; test_dockerfile\ndocker build -f test_dockerfile -t test_image . &&gt; /dev/null\ndocker images | grep test_image\ndocker rmi test_image &&gt; /dev/null\n\necho \"=====ubuntu with deleted file=====\"\necho \"RUN rm file.txt\" &gt;&gt; test_dockerfile\ndocker build -f test_dockerfile -t test_image . &&gt; /dev/null\ndocker images | grep test_image\ndocker rmi test_image &&gt; /dev/null\n\n\nrm file.txt\nrm test_dockerfile\n\n=====just ubuntu copy=====\ntest_image                 latest    8173c3801863   3 months ago    77.8MB\n=====ubuntu with big copied file=====\ntest_image                 latest    86892a85e309   2 minutes ago   1.13GB\n=====ubuntu with deleted file=====\ntest_image                 latest    97524578efc6   52 seconds ago   1.13GB\n\n\n\n\ncommit - save state of the container\nAllows you to save the current state of any container as a new image. So if you have created something new in a container, you can save it as a new image. You have to follow such sintaksis:\ndocker commit &lt;container name&gt; &lt;new image name&gt;\nSo in follwing example I: - Running the container in which create file with message; - Create file in this container; - Commit this container as a new image; - Run the container based on the new image; - Check the message in the container based on the new image.\n\n%%bash\ndocker run --rm --name test_container -itd ubuntu &&gt; /dev/null\ndocker exec test_container bash -c \"echo \\\"I'm a new file in container\\\" &gt; new_file\"\n\ndocker commit test_container new_test_image &&gt; /dev/null\n\necho \"=====check new image=====\"\ndocker images | grep new_test_image\necho \"=====message from commited image=====\"\ndocker run --rm --name new_test_container -itd new_test_image &&gt; /dev/null\ndocker exec new_test_container cat new_file\n\ndocker stop new_test_container &&gt; /dev/null\ndocker stop test_container &&gt; /dev/null\ndocker rmi new_test_image &&gt; /dev/null\n\n=====check new image=====\nnew_test_image             latest    56c5c624ed38   Less than a second ago   77.8MB\n=====message from commited image=====\nI'm a new file in container"
  },
  {
    "objectID": "Docker/docker_file_instructions.html",
    "href": "Docker/docker_file_instructions.html",
    "title": "Dockerfile instructions",
    "section": "",
    "text": "Here are the most basic options for the dockerfile."
  },
  {
    "objectID": "Docker/docker_file_instructions.html#entrypoint",
    "href": "Docker/docker_file_instructions.html#entrypoint",
    "title": "Dockerfile instructions",
    "section": "ENTRYPOINT",
    "text": "ENTRYPOINT\nAllow command to run when container based on image is running. The feature of this instruction is that you can add something at the end of the docker run command, and it will be added to command described in ENTRYPOINT.\nSuch dockerfile:\nFROM ubuntu:20.04\nENTRYPOINT [ \"echo\" ]\nCreates a container that will echo the line declared at the end of the docker run command. For exmaple:\n\n%%bash\ndocker build \\\n    -f basic_instructions/entrypoint_example \\\n    -t test_ubuntu \\\n    basic_instructions &&gt; /dev/null\n\ndocker run --rm test_ubuntu \"hello world\"\ndocker run --rm test_ubuntu ls\ndocker rmi test_ubuntu &&gt; /dev/null\n\nhello world\nls\n\n\nSo the lines I passed as arguments were just printed - just like echo does."
  },
  {
    "objectID": "Docker/docker_file_instructions.html#cmd",
    "href": "Docker/docker_file_instructions.html#cmd",
    "title": "Dockerfile instructions",
    "section": "CMD",
    "text": "CMD\nAllow command to run when container based on image is running. If using this instruction you set any command for docker run, the command described in CMD will be completely removed with new commad.\nConsider containers based on dockerfile:\nFROM ubuntu:20.04\nCMD [ \"echo\" ]\nThe same command docker run --rm test_ubuntu ls like it was for the dockerfile from ENTRYPOINT example, desn’t print “ls” but executes the ls command.\n\n%%bash\ndocker build \\\n    -f basic_instructions/cmd_example \\\n    -t test_ubuntu \\\n    basic_instructions &&gt; /dev/null\ndocker run --rm test_ubuntu ls \ndocker rmi test_ubuntu &&gt; /dev/null\n\nbin\nboot\ndev\netc\nhome\nlib\nlib32\nlib64\nlibx32\nmedia\nmnt\nopt\nproc\nroot\nrun\nsbin\nsrv\nsys\ntmp\nusr\nvar"
  },
  {
    "objectID": "Docker/docker_file_instructions.html#entrypoint-cmd",
    "href": "Docker/docker_file_instructions.html#entrypoint-cmd",
    "title": "Dockerfile instructions",
    "section": "ENTRYPOINT + CMD",
    "text": "ENTRYPOINT + CMD\nBy combining ENTRYPOINT and CMD you can do this: - in ENTRYPOIN set the necessary part of the command; - in CMD set the part of the command that can be changed.\ndocker file like:\nFROM ubuntu:20.04\nENTRYPOINT [\"echo\"]\nCMD [\"default message\"]\nBy default, “default message” is printed, but if you add a line to `docker run’ it will be printed instead. The following cell show how it works:\n\n%%bash\ndocker build \\\n    -f basic_instructions/entrypoint_cmd \\\n    -t test_ubuntu \\\n    basic_instructions &&gt; /dev/null\ndocker run --rm test_ubuntu\ndocker run --rm test_ubuntu \"other message\"\ndocker rmi test_ubuntu &&gt; /dev/null\n\ndefault message\nother message\n\n\nConsequence of instractions doesn’t matter. So docker file:\nFROM ubuntu:20.04\nCMD [\"default message\"]\nENTRYPOINT [\"echo\"]\nWill work the same way. The folowing cell show this scenario.\n\n%%bash\ndocker build \\\n    -f basic_instructions/entrypoint_cmd2 \\\n    -t test_ubuntu \\\n    basic_instructions &&gt; /dev/null\ndocker run --rm test_ubuntu\ndocker run --rm test_ubuntu \"other message\"\ndocker rmi test_ubuntu &&gt; /dev/null\n\ndefault message\nother message\n\n\n\nSeveral CMD/ENTRYPOIN\nLooks like, docker only takes the last mention of CMD/ENTRY POINT. Which makes sense in the case of ‘inheriting’ containers. So at the following example I’m using docker file:\nFROM ubuntu:20.04\nCMD [\"echo\", \"default message1\"]\nCMD [\"echo\", \"default message2\"]\n\n%%bash\ndocker build \\\n    -f basic_instructions/several_cmd \\\n    -t test_ubuntu \\\n    basic_instructions &&gt; /dev/null\ndocker run --rm test_ubuntu\ndocker rmi test_ubuntu &&gt; /dev/null\n\ndefault message2\n\n\nSo it looks like docker just ignored CMD [\"echo\", \"default message1\"]"
  },
  {
    "objectID": "Docker/network/local_network.html",
    "href": "Docker/network/local_network.html",
    "title": "Local network",
    "section": "",
    "text": "It’s very interesting that you can access the containers you’ve created from other devices on your local network. It may not be associated with Docker exactly, but with networks in general, but still I am only familiar with the Throw Docker feature.\nSo we start a container with nginx on port 80 on host.\n\n%%bash\ndocker run --rm -itd --name test_nginx -p 80:80 nginx\n\n4a4a152a0d163ff988b14cc27953c435cd3acdc1328d941d40acbc9b4a4f2122\n\n\nUsing the ifconfig Linux utility, I can check some information about the network. The most interesting part is the section starting with w. In the line inet &lt;ip&gt; you can find your ip address in the wifi network.\nNote in your run ip can be different.\n\n%%bash\nifconfig\n\ndocker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n        inet6 fe80::42:e8ff:fefa:8cee  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 02:42:e8:fa:8c:ee  txqueuelen 0  (Ethernet)\n        RX packets 29  bytes 5741 (5.7 KB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 87  bytes 12097 (12.0 KB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nlo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 31340  bytes 9448607 (9.4 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 31340  bytes 9448607 (9.4 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nvethd50493c: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet6 fe80::9c62:edff:fe27:8803  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 9e:62:ed:27:88:03  txqueuelen 0  (Ethernet)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 26  bytes 5168 (5.1 KB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nwlp0s20f3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet 192.168.100.10  netmask 255.255.255.0  broadcast 192.168.100.255\n        inet6 fe80::735b:b9a:6447:646d  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether dc:41:a9:2e:4c:6c  txqueuelen 1000  (Ethernet)\n        RX packets 283983  bytes 382835053 (382.8 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 46994  bytes 11436293 (11.4 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\nYou can connect any other device to this network and you’ll find that when you enter a higher ip you’ll get a nginx “welcome” page.\n\n\n%%bash\ndocker stop test_nginx &&gt; /dev/null"
  },
  {
    "objectID": "Docker/network/small_features.html",
    "href": "Docker/network/small_features.html",
    "title": "Small features",
    "section": "",
    "text": "In this page I store topics related to the Docker networks that are too small to have their own page."
  },
  {
    "objectID": "Docker/network/small_features.html#ls-list-networks",
    "href": "Docker/network/small_features.html#ls-list-networks",
    "title": "Small features",
    "section": "ls list networks",
    "text": "ls list networks\n\n!docker network ls\n\nNETWORK ID     NAME      DRIVER    SCOPE\n4b609bad1d6c   bridge    bridge    local\n80c3e6772c8c   host      host      local\n45bb103d970f   none      null      local"
  },
  {
    "objectID": "Docker/network/small_features.html#name-of-network",
    "href": "Docker/network/small_features.html#name-of-network",
    "title": "Small features",
    "section": "Name of network",
    "text": "Name of network\nIf you need for some container to get network this container connected to, you need you command like this:\ndocker inspect -f '{{range $key, $value := .NetworkSettings.Networks}}{{$key}} {{end}}' &lt;container name&gt;\nI don’t really understand how it works yet. But the following cell shows that it’s working - by default every container is connected to the bridge network, so for just created container this command returns bridge.\n\n%%bash\ndocker run --rm -itd --name just_net ubuntu &&gt; /dev/null\ndocker inspect \\\n    -f '{{range $key, $value := .NetworkSettings.Networks}}{{$key}} {{end}}' \\\n    just_net\ndocker stop just_net &&gt; /dev/null\n\nbridge"
  },
  {
    "objectID": "Docker/network/container_connection.html",
    "href": "Docker/network/container_connection.html",
    "title": "Container connection",
    "section": "",
    "text": "You need to use the --net=&lt;network id/name&gt; parameter for the docker run command. As in the following cell, --net host has been used, and the command that prints the name of the network container it is connected to shows host.\n\n%%bash\ndocker run --rm -itd --name just_net --net host ubuntu &&gt; /dev/null\ndocker inspect -f '{{range $key, $value := .NetworkSettings.Networks}}{{$key}} {{end}}' just_net\ndocker stop just_net &&gt; /dev/null\n\nhost"
  },
  {
    "objectID": "Docker/network/container_connection.html#during-container-creation",
    "href": "Docker/network/container_connection.html#during-container-creation",
    "title": "Container connection",
    "section": "",
    "text": "You need to use the --net=&lt;network id/name&gt; parameter for the docker run command. As in the following cell, --net host has been used, and the command that prints the name of the network container it is connected to shows host.\n\n%%bash\ndocker run --rm -itd --name just_net --net host ubuntu &&gt; /dev/null\ndocker inspect -f '{{range $key, $value := .NetworkSettings.Networks}}{{$key}} {{end}}' just_net\ndocker stop just_net &&gt; /dev/null\n\nhost"
  },
  {
    "objectID": "Docker/network/container_connection.html#existing-container",
    "href": "Docker/network/container_connection.html#existing-container",
    "title": "Container connection",
    "section": "Existing container",
    "text": "Existing container\nYou need to know commands:\n\ndocker network connect &lt;net name/id&gt; &lt;container name/id&gt; to connect any container to the selected network;\ndocker network disconnect &lt;net name/id&gt; &lt;container name/id&gt; to disconnect any container from the selected network.\n\nThe manoeuvre of disconnecting a container from the selected network in which it was created by default and reconnecting it to another is shown in the next cell.\n\n%%bash\ndocker run --rm -itd --name just_net ubuntu &&gt; /dev/null\necho \"=====Just created container=====\"\ndocker inspect -f '{{range $key, $value := .NetworkSettings.Networks}}{{$key}} {{end}}' just_net\n\ndocker network disconnect bridge just_net\necho \"=====Network disconnected=====\"\ndocker inspect -f '{{range $key, $value := .NetworkSettings.Networks}}{{$key}} {{end}}' just_net\n\ndocker network connect none just_net\necho \"=====Container connect to the host network=====\"\ndocker inspect -f '{{range $key, $value := .NetworkSettings.Networks}}{{$key}} {{end}}' just_net\n\ndocker stop just_net &&gt; /dev/null\n\n=====Just created container=====\nbridge \n=====Network disconnected=====\n\n=====Container connect to the host network=====\nnone \n\n\nNote you cannot connect the container to different networks at the same time. The following cell shows warning that docker prints if you’ll try.\n\n%%bash\ndocker run --rm -itd --name just_net ubuntu &&gt; /dev/null\ndocker network connect none just_net\ndocker stop just_net &&gt; /dev/null\n\nError response from daemon: container cannot be connected to multiple networks with one of the networks in private (none) mode"
  },
  {
    "objectID": "Docker/network/network_rus.html",
    "href": "Docker/network/network_rus.html",
    "title": "ls",
    "section": "",
    "text": "Работа с сетями в docker\nРеализуется через API network.\nВыведет список доступных сетей.\n\n%%bash\ndocker network ls\n\nNETWORK ID     NAME      DRIVER    SCOPE\ncac8977da21a   bridge    bridge    local\nf8b2503d0640   host      host      local\nb1d7e6bda275   none      null      local\n\n\n\nПодключение к сети\n\nПри создании контейнера\nПроизводится, через указывание опции --net=&lt;имя/id сети&gt;. Далее в примере демонстрирую, что как минимум ничего не сломалось.\n\n%%bash\ndocker run --rm -di --net=none --name just_net ubuntu_curl\ndocker stop just_net\n\nee6e4f29315a7fcf3a5ad2ee39cdb86bb178ebb296563fee73b432a30799a33c\njust_net\n\n\n\n\nПодключение/откллючение уже созданного контейнера\nПроизводится с помощью комманды - Для подключения используется docker network connect &lt;сеть&gt; &lt;контейнер&gt;; - Для отключения используется docker network disconnect &lt;сеть&gt; &lt;контейнер&gt;.\n\n%%bash\n# запускаю контейнер с nginx он по умолчанию\n# прикрепляется к bridge\ndocker run --rm --name test_nginx -itd nginx\n# создаю новую сетку и цепляю не нее этот nginx\ndocker network create test_network\nsleep 10\ndocker network connect test_network test_nginx\n\n# отцепляю nginx от bridge\ndocker network disconnect bridge test_nginx\n\ndocker stop test_nginx\ndocker network rm test_network\n\n1ced62443c8437cdc2e4e3910957b2632cded2d709634543a6a212d6f4d08d7a\na8f26f0c7bea903a0c61a2d553b2ace6b96a952f1e0120159e1042463208a6f3\ntest_nginx\ntest_network\n\n\n\n\n\nСети по умолчанию\nВ docker по умолчанию доступно 3 сети:\n\n%%bash\ndocker network ls\n\nNETWORK ID     NAME      DRIVER    SCOPE\ncac8977da21a   bridge    bridge    local\nf8b2503d0640   host      host      local\nb1d7e6bda275   none      null      local\n\n\n\nСеть none\nПроизводит полное блокирование контейнера от сети.\nТак попробуем запустить clickhouse на этой сети и сделать к нему запрос. curl: (7) Failed to connect to localhost port 8123 after 0 ms: Connection refused свидетельствует о том, что по заданному адресу ничего не отвечат.\n\n%%bash\ndocker run --rm -d --name none_example -p 8123:8123 --net=none yandex/clickhouse-server\n# нельзя забывать, что clickhouse долговато поднимается\nsleep 10\ncurl localhost:8123\ndocker stop none_example\n\n05db6909cc4de9e808ffe927ad06594fafce9ea6e0a54e6fadf38f04e266759b\nnone_example\n\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\ncurl: (7) Failed to connect to localhost port 8123 after 0 ms: Connection refused\n\n\nТак же из нутри контейнера, нельзя будет достучаться в интернет. Так в следующем примере я запускаю ubuntu с предустановленным curl и получаю, и не могу из него достучаться до google.com. curl: (6) Could not resolve host: google.com свидетельсвует о том, что из контейнера не получается достучаться до google.com.\n\n%%bash\ndocker run -itd --rm --net=none --name none_example ubuntu_curl\ndocker exec none_example curl google.com\ndocker stop none_example\n\n3dd6e8e5f072ff86380acf7f092093bb96a1a1d7a3b091aaaf32d6ee21763e3c\nnone_example\n\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: google.com\n\n\n\n\nСеть host\nПолностью убирает сетевую изоляцию контейнера, то есть контейнер делит с хостом сеть полностью.\nТак в примере я запускаю yandex/clickhouse-server без указания каких-либо портов. В результате, этот clickhouse всеравно будет отвечать (даже без указанных портов).\n\n%%bash\ndocker run --rm -d --name host_example --net=host yandex/clickhouse-server\n# нельзя забывать, что clickhouse долговато поднимается\nsleep 10\ncurl localhost:8123\ndocker stop host_example\n\n69120ad84831e74d88b6085e5b38ca8ba2a0f05ff9b66ac2748a01b7974707e6\nOk.\nhost_example\n\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100     4    0     4    0     0   4149      0 --:--:-- --:--:-- --:--:--  4000\n\n\n\n\nСеть bridge\nСеть в которой контейнеры создаются по умолчанию. Далее показано несколько трюков.\nВесь этот раздел воспроиводится особым образом\nЯ предварительно поднял контейнеры с yandex/clickhouse-server и ubuntu с предустановленным curl:\n\n%%bash\ndocker ps\n\nCONTAINER ID   IMAGE                      COMMAND            CREATED              STATUS              PORTS                          NAMES\n3c653442fea3   ubuntu_curl                \"/bin/bash\"        About a minute ago   Up About a minute                                  ubu\n3f047e11c417   yandex/clickhouse-server   \"/entrypoint.sh\"   2 minutes ago        Up 2 minutes        8123/tcp, 9000/tcp, 9009/tcp   click\n\n\nТеперь демонстрирую результат комманды insperct (позволяет получить низкоуровневую инофрмацию о любом объекте docker) для сети bridge.\n\n%%bash\ndocker inspect bridge\n\n[\n    {\n        \"Name\": \"bridge\",\n        \"Id\": \"243b737447851abe893a50fab43e6fd6304423b81f848e31ae974692bb2388a5\",\n        \"Created\": \"2023-03-22T16:23:03.478736367+03:00\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": null,\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.17.0.0/16\",\n                    \"Gateway\": \"172.17.0.1\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Attachable\": false,\n        \"Ingress\": false,\n        \"ConfigFrom\": {\n            \"Network\": \"\"\n        },\n        \"ConfigOnly\": false,\n        \"Containers\": {\n            \"3c653442fea36887a8ff860b337148053ba5583c74ad635eeaa0bce4f75c8432\": {\n                \"Name\": \"ubu\",\n                \"EndpointID\": \"f29acdda0cc093af06a9797386eed25d491bb67e9e09112bae235657c81f93c9\",\n                \"MacAddress\": \"02:42:ac:11:00:03\",\n                \"IPv4Address\": \"172.17.0.3/16\",\n                \"IPv6Address\": \"\"\n            },\n            \"3f047e11c417e87a9f4e6eda57f0eed13695e569baf40d0dc0ff7204f209c08b\": {\n                \"Name\": \"click\",\n                \"EndpointID\": \"c872977345db4fb11ba931f75228816c4082b6879575167bc647f5c11cf94439\",\n                \"MacAddress\": \"02:42:ac:11:00:02\",\n                \"IPv4Address\": \"172.17.0.2/16\",\n                \"IPv6Address\": \"\"\n            }\n        },\n        \"Options\": {\n            \"com.docker.network.bridge.default_bridge\": \"true\",\n            \"com.docker.network.bridge.enable_icc\": \"true\",\n            \"com.docker.network.bridge.enable_ip_masquerade\": \"true\",\n            \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\",\n            \"com.docker.network.bridge.name\": \"docker0\",\n            \"com.docker.network.driver.mtu\": \"1500\"\n        },\n        \"Labels\": {}\n    }\n]\n\n\nОбращаю внимание на поле “Containers” а в нем на поля “IPv4Address”. По этим адресам мы можем общаться между контейнерами. Так вот например и из ubuntu спрошу clikchouse. Ok свидетельсвует о том, что я дейвительно дотянулся.\n\n%%bash\ndocker exec ubu curl 172.17.0.2:8123\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100     4    0     4    0     0   4944      0 --:--:-- --:--:-- --:--:--  4000\n\n\nOk.\n\n\nБолее того, несмотря на то, что я не указывал портов при поднятии контейнера clickhouse, через этот ip я могу достучаться до clickhouse и из хоста. В следующем примере, я сравниваю результат запроса на localhost и на этот ip.\n\nВ первом случае никуда я не достучался и закономерно получил curl: (7) Failed to connect to localhost port 8123 after 0 ms: Connection refused;\nВо втором случа clickhouse мне отвечает как ни в чем не бывало Ok..\n\n\n%%bash\ncurl localhost:8123\ncurl 172.17.0.2:8123\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\ncurl: (7) Failed to connect to localhost port 8123 after 0 ms: Connection refused\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100     4    0     4    0     0   9302      0 --:--:-- --:--:-- --:--:--  4000\n\n\nOk.\n\n\n\n\n\nСетевые интерфейсы\nКаждый контейнер создает новый сетевой интерфейс. Сетевые интерфейсы в linux можно посмотреть с помощью утилиты ifconfig. Далее пример, как выболняется ifconfig по умолчанию (с установленным docker).\n\n%%bash\nifconfig\n\ndocker0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt;  mtu 1500\n        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n        inet6 fe80::42:1eff:fe03:26e4  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 02:42:1e:03:26:e4  txqueuelen 0  (Ethernet)\n        RX packets 32158  bytes 1793702 (1.7 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 39205  bytes 192903770 (192.9 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nlo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 27239  bytes 6082445 (6.0 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 27239  bytes 6082445 (6.0 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nwlp0s20f3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet 192.168.100.10  netmask 255.255.255.0  broadcast 192.168.100.255\n        inet6 fe80::735b:b9a:6447:646d  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether dc:41:a9:2e:4c:6c  txqueuelen 1000  (Ethernet)\n        RX packets 312466  bytes 417021190 (417.0 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 68174  bytes 16481710 (16.4 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\nА теперь запустим какой-нибудь контейнер и посмотрим результат ifconfig. Появляется veth..., который и представляет собой интерфейс этого контейнера.\n\n%%bash\ndocker run --rm -itd --name ubuntu_inter ubuntu\nifconfig\ndocker stop ubuntu_inter\n\n64034d23001182e6a73b5fc24ad5de41800b6fb7a043b72de0d17aa4cde44aa2\ndocker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n        inet6 fe80::42:1eff:fe03:26e4  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 02:42:1e:03:26:e4  txqueuelen 0  (Ethernet)\n        RX packets 32158  bytes 1793702 (1.7 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 39206  bytes 192903900 (192.9 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nlo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 29201  bytes 6753989 (6.7 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 29201  bytes 6753989 (6.7 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nveth29fa8ed: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet6 fe80::874:a8ff:febd:21d0  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 0a:74:a8:bd:21:d0  txqueuelen 0  (Ethernet)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 2  bytes 220 (220.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nwlp0s20f3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet 192.168.100.10  netmask 255.255.255.0  broadcast 192.168.100.255\n        inet6 fe80::735b:b9a:6447:646d  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether dc:41:a9:2e:4c:6c  txqueuelen 1000  (Ethernet)\n        RX packets 313325  bytes 417478943 (417.4 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 68966  bytes 17051363 (17.0 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nubuntu_inter\n\n\nПримечание интерфейсы можно слушать с помощью утилиты tcpdump.\n\n\nКастомные сети\nДля создания собсвенной сети в api network используется команда create. Она создается используя DRIVER bridge, соответсвенно обладает всеми свойсвами сети bridge.\nДля удаления сети используется команда rm, так в следующем примере будет создана сеть new_net и сразу же удалена.\n\n%%bash\ndocker network create new_net\ndocker network ls\ndocker network rm new_netb\n\n5222bef596010f96790439ddc3dd6a392850f90bb660c820e993c7329e653b89\nNETWORK ID     NAME      DRIVER    SCOPE\ne2df331917d9   bridge    bridge    local\nf8b2503d0640   host      host      local\n5222bef59601   new_net   bridge    local\nb1d7e6bda275   none      null      local\nnew_net\n\n\n\n\nПример изоляции\nПродемонстрируем, что контейнеры развернутые в одной сети типа “bridge” могут достучаться друг до друга. А в разных - нет.\nВ следующей ячейке я создаю три контейнера - два из них в сети “bridge” и последний в кастомной сети “new_net”.\n\n%%bash\ndocker run --rm -itd --name ubuntu_bridge1 ubuntu_curl\ndocker run --rm -itd --name ubuntu_bridge2 ubuntu_curl\n\ndocker network create new_net\ndocker run --rm -itd --name ubuntu_new_net --net=new_net ubuntu_curl\n\n268c559a31fa4de87f1f96e344429086ecaaf57bfced8d3872e464ed7393ac99\nf6f2903f851b129dc98a5526c7aa52c5b4a51572088e1571b8361bdf20b1212d\nb96ad8e7eaa1294d4debd7afc69ee180f76ee96df2eaea4ead6b66b318342736\nf13eaef8c1e69a14c8529ba3614422fef68b76640a2c9b9a2af31a1f47f5c186\n\n\nПолучаю информацию о сетях. Тут самое главное это ip контейнеров: - “ubuntu_bridge1” - 172.17.0.2; - “ubuntu_bridge2” - 172.17.0.3; - “ubuntu_new_net” - 172.21.0.2 (этот ip от запуска к запуску может меняться);\n\n%%bash\ndocker inspect bridge\ndocker inspect new_net\n\n[\n    {\n        \"Name\": \"bridge\",\n        \"Id\": \"f2435156fe9a8b2feb702177a4e2b67d89ab065fc643bdf8260e152c19342bfb\",\n        \"Created\": \"2023-03-26T20:14:42.936227946+03:00\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": null,\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.17.0.0/16\",\n                    \"Gateway\": \"172.17.0.1\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Attachable\": false,\n        \"Ingress\": false,\n        \"ConfigFrom\": {\n            \"Network\": \"\"\n        },\n        \"ConfigOnly\": false,\n        \"Containers\": {\n            \"268c559a31fa4de87f1f96e344429086ecaaf57bfced8d3872e464ed7393ac99\": {\n                \"Name\": \"ubuntu_bridge1\",\n                \"EndpointID\": \"d67e3d4fb30ebbdfb8f60edb65598bf3b2dd72f558847c65fdb4ccef8c043989\",\n                \"MacAddress\": \"02:42:ac:11:00:02\",\n                \"IPv4Address\": \"172.17.0.2/16\",\n                \"IPv6Address\": \"\"\n            },\n            \"f6f2903f851b129dc98a5526c7aa52c5b4a51572088e1571b8361bdf20b1212d\": {\n                \"Name\": \"ubuntu_bridge2\",\n                \"EndpointID\": \"d69d898e96b0838756a0415d5f49e02c34757dcf2a43c6ba44fae6ffe773e3d2\",\n                \"MacAddress\": \"02:42:ac:11:00:03\",\n                \"IPv4Address\": \"172.17.0.3/16\",\n                \"IPv6Address\": \"\"\n            }\n        },\n        \"Options\": {\n            \"com.docker.network.bridge.default_bridge\": \"true\",\n            \"com.docker.network.bridge.enable_icc\": \"true\",\n            \"com.docker.network.bridge.enable_ip_masquerade\": \"true\",\n            \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\",\n            \"com.docker.network.bridge.name\": \"docker0\",\n            \"com.docker.network.driver.mtu\": \"1500\"\n        },\n        \"Labels\": {}\n    }\n]\n[\n    {\n        \"Name\": \"new_net\",\n        \"Id\": \"b96ad8e7eaa1294d4debd7afc69ee180f76ee96df2eaea4ead6b66b318342736\",\n        \"Created\": \"2023-03-26T21:06:06.063558177+03:00\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": {},\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.21.0.0/16\",\n                    \"Gateway\": \"172.21.0.1\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Attachable\": false,\n        \"Ingress\": false,\n        \"ConfigFrom\": {\n            \"Network\": \"\"\n        },\n        \"ConfigOnly\": false,\n        \"Containers\": {\n            \"f13eaef8c1e69a14c8529ba3614422fef68b76640a2c9b9a2af31a1f47f5c186\": {\n                \"Name\": \"ubuntu_new_net\",\n                \"EndpointID\": \"de8440213aec37fbccb433e903cc3c0dd48d32daf7ca7024adfc82cd52f17723\",\n                \"MacAddress\": \"02:42:ac:15:00:02\",\n                \"IPv4Address\": \"172.21.0.2/16\",\n                \"IPv6Address\": \"\"\n            }\n        },\n        \"Options\": {},\n        \"Labels\": {}\n    }\n]\n\n\nИз контейнера “ubuntu_bridge1” стучусь в контейнер “ubuntu_bridge2” с которым они в одной подсети, и, конечно, получаю ответ.\n\n%%bash\ndocker exec ubuntu_bridge1 ping -c 4 172.17.0.3\n\nPING 172.17.0.3 (172.17.0.3) 56(84) bytes of data.\n64 bytes from 172.17.0.3: icmp_seq=1 ttl=64 time=0.086 ms\n64 bytes from 172.17.0.3: icmp_seq=2 ttl=64 time=0.109 ms\n64 bytes from 172.17.0.3: icmp_seq=3 ttl=64 time=0.110 ms\n64 bytes from 172.17.0.3: icmp_seq=4 ttl=64 time=0.083 ms\n\n--- 172.17.0.3 ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 3078ms\nrtt min/avg/max/mdev = 0.083/0.097/0.110/0.012 ms\n\n\nТеперь из контейнера “ubuntu_bridge1” стучусь в контейнер “ubuntu_new_net”. Они в разных подсетях потому и ответа я не получил.\n\n%%bash\n# echo в конце надо чтобы не выдавалась ошибка\n# которую генерит ping когда у него не получилось\n# достучаться до сервака\ndocker exec ubuntu_bridge1 ping -c 4 -q 172.21.0.2;  echo $?\n\nPING 172.21.0.2 (172.21.0.2) 56(84) bytes of data.\n\n--- 172.21.0.2 ping statistics ---\n4 packets transmitted, 0 received, 100% packet loss, time 3062ms\n\n1\n\n\nВ конце концов, все удаляю, чтобы не захломляться.\n\n%%bash\ndocker stop ubuntu_bridge1 ubuntu_bridge2 ubuntu_new_net\ndocker network rm new_net\n\nubuntu_bridge1\nubuntu_bridge2\nubuntu_new_net\nnew_net"
  },
  {
    "objectID": "Docker/network/ports.html",
    "href": "Docker/network/ports.html",
    "title": "Ports",
    "section": "",
    "text": "You can set port using the following syntax run ... -p &lt;port on host&gt;:&lt;port on container&gt; ....\nTo show how it works, I need some specific Python libraries defined in the following cell.\n\nimport requests\nfrom requests import ConnectionError\nfrom IPython.display import HTML\n\nTwo following cells almost the same:\n\nStart the nginx container;\nTry to connect to the http://localhost:80;\nCatch ConnectionError if it occurs;\nIf connection goes fine, then display anwer as HTML.\n\nBut in the first example the -p 80:80 option was not used and in the second example it was. It is a connection error in the first cell and a welcome message from nginx in the second.\n\n!docker run --rm -d \\\n    --name test_nginx \\\n    nginx &&gt; /dev/null\n\ntry:\n    req_res = requests.get(\"http://localhost:80\")\n    display(HTML(req_res.content.decode(\"utf-8\")))\nexcept ConnectionError:\n    print(\"Connection error!!!\")\n    \n\n!docker stop test_nginx &&gt; /dev/null\n\nConnection error!!!\n\n\n\n!docker run --rm -d \\\n    --name test_nginx \\\n    -p 80:80 \\\n    nginx &&gt; /dev/null\n\ntry:\n    req_res = requests.get(\"http://localhost:80\")\n    display(HTML(req_res.content.decode(\"utf-8\")))\nexcept ConnectionError:\n    print(\"Connection error!!!\")\n    \n\n!docker stop test_nginx &&gt; /dev/null\n\n\n\n\nWelcome to nginx!\n\n\n\n\nIf you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.\n\nFor online documentation and support please refer to\nnginx.org.\nCommercial support is available at\nnginx.com.\n\nThank you for using nginx."
  },
  {
    "objectID": "Docker/network/ports.html#set-port-for-container",
    "href": "Docker/network/ports.html#set-port-for-container",
    "title": "Ports",
    "section": "",
    "text": "You can set port using the following syntax run ... -p &lt;port on host&gt;:&lt;port on container&gt; ....\nTo show how it works, I need some specific Python libraries defined in the following cell.\n\nimport requests\nfrom requests import ConnectionError\nfrom IPython.display import HTML\n\nTwo following cells almost the same:\n\nStart the nginx container;\nTry to connect to the http://localhost:80;\nCatch ConnectionError if it occurs;\nIf connection goes fine, then display anwer as HTML.\n\nBut in the first example the -p 80:80 option was not used and in the second example it was. It is a connection error in the first cell and a welcome message from nginx in the second.\n\n!docker run --rm -d \\\n    --name test_nginx \\\n    nginx &&gt; /dev/null\n\ntry:\n    req_res = requests.get(\"http://localhost:80\")\n    display(HTML(req_res.content.decode(\"utf-8\")))\nexcept ConnectionError:\n    print(\"Connection error!!!\")\n    \n\n!docker stop test_nginx &&gt; /dev/null\n\nConnection error!!!\n\n\n\n!docker run --rm -d \\\n    --name test_nginx \\\n    -p 80:80 \\\n    nginx &&gt; /dev/null\n\ntry:\n    req_res = requests.get(\"http://localhost:80\")\n    display(HTML(req_res.content.decode(\"utf-8\")))\nexcept ConnectionError:\n    print(\"Connection error!!!\")\n    \n\n!docker stop test_nginx &&gt; /dev/null\n\n\n\n\nWelcome to nginx!\n\n\n\n\nIf you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.\n\nFor online documentation and support please refer to\nnginx.org.\nCommercial support is available at\nnginx.com.\n\nThank you for using nginx."
  },
  {
    "objectID": "Docker/network/ports.html#several-ports",
    "href": "Docker/network/ports.html#several-ports",
    "title": "Ports",
    "section": "Several ports",
    "text": "Several ports\nYou can use the -p option to the docker run command as many times as you need. The nginx container was started with two ports. So requests to both of the ports won’t throw any errors.\n\n!docker run --rm -d \\\n    --name test_nginx \\\n    -p 123:80 -p 987:80\\\n    nginx &&gt; /dev/null\n\ntry:\n    requests.get(\"http://localhost:123\")\n    requests.get(\"http://localhost:987\")\nexcept ConnectionError:\n    print(\"Connection error!!!\")\n\n!docker stop test_nginx &&gt; /dev/null"
  },
  {
    "objectID": "Docker/network/ports.html#expose",
    "href": "Docker/network/ports.html#expose",
    "title": "Ports",
    "section": "EXPOSE",
    "text": "EXPOSE\nIs a keyword for dockerfiles that allows you to specify the port to be used by the container based on the corresponding image.\n\nExample on other image\nLet’s take nginx. If we start the container with it and then check the PORTS field - it’ll display the ports that should be used by this container.\n\n%%bash\ndocker run --rm -d \\\n    --name test_nginx \\\n    nginx &&gt; /dev/null\ndocker ps\ndocker stop test_nginx &&gt; /dev/null\n\nCONTAINER ID   IMAGE     COMMAND                  CREATED                  STATUS                  PORTS     NAMES\nd8469eb982e6   nginx     \"/docker-entrypoint.…\"   Less than a second ago   Up Less than a second   80/tcp    test_nginx\n\n\nAnd even if you want to check the history of the images, you can find the EXPOSE &lt;port&gt; layer there.\n\n%%bash\ndocker history nginx | grep EXPOSE\n\n&lt;missing&gt;      7 months ago   /bin/sh -c #(nop)  EXPOSE 80                    0B        \n\n\n\n\nUsing EXPOSE\nHere I want to focus on using the EXPOSE command to create your own docker files. So in the following cell I have created a docker based on ununtu, but added EXPOSE 1050 to it.\n\n%%writefile ports_files/test_dockerfile\nFROM ubuntu\nEXPOSE 1050\n\nOverwriting ports_files/test_dockerfile\n\n\nNow let us try to run the container based on the image we just created. The main difference is that in docker ps' in thePORTS` column you can find information about the port you mentioned in the docker file.\n\n%%bash\ndocker build -f ports_files/test_dockerfile -t test_expose . &&gt; /dev/null\n\ndocker run -itd --name test_expose --rm test_expose &&gt; /dev/null\ndocker ps\n\ndocker stop test_expose &&gt; /dev/null\ndocker rmi test_expose &&gt; /dev/null\n\nCONTAINER ID   IMAGE         COMMAND       CREATED        STATUS                  PORTS      NAMES\n55ceb23fccea   test_expose   \"/bin/bash\"   1 second ago   Up Less than a second   1050/tcp   test_expose"
  },
  {
    "objectID": "Docker/docker_compose/docker_compose.html",
    "href": "Docker/docker_compose/docker_compose.html",
    "title": "YAML",
    "section": "",
    "text": "Разбор инстумента docker-compose\nПозиционируется как инстумент, который следующая ступень абстрации над docker - инстумент который позволяет организовать взаимодейсвие контейнеров между собой.\nЯзык разметки, с помощью которого задается поведение docker-compose.\nYAML позволяет описывать структуры данных которые состоят из списков и словарей: - каждый элемент списка начинается с символа -; - каждый новый ключ в словаре задатся так &lt;ключ&gt;:; - шаблоны (якоря) - возможность создать ссылку на некоторую сущность и потом использовать её в произвольном месте структуры; - вложенность структуры формируется отступами.\nДалее на примерах станет понятнее.\nВ python существует библиотека yaml, которая позволяет пребразовывать yaml разметку в соответсвующие структуры данных python.\n\nimport yaml\n\nВ следующем примере создается ключ словарь с ключами names, ages под которыми скрываются соответсвующие списки.\n\nyamls_str = \\\n\"\"\"\nnames:\n    - peter\n    - olga\nages:\n    - 22\n    - 18\n\"\"\"\n\nyaml.full_load(yamls_str)\n\n{'names': ['peter', 'olga'], 'ages': [22, 18]}\n\n\nЗаметим, что между &lt;ключ&gt;: и &lt;значение&gt; обязательно должен быть пробел. Вот, для сравнения, правильно созданный словарь под ключом postgres и ошибочно созданный под ключом clickhouse.\n\nyamls_str = \\\n\"\"\"\npostgres:\n    user: postgres_app_user\n    password: postgres_app_password\n    host: postgres_host\n    port: 5432\nclickhouse:\n    host:clickhouse_host\n    user:clickhouse_app_user\n    db:clickhouse_app_db\n    password:clickhouse_app_password\n\"\"\"\n\nyaml.full_load(yamls_str)\n\n{'postgres': {'user': 'postgres_app_user',\n  'password': 'postgres_app_password',\n  'host': 'postgres_host',\n  'port': 5432},\n 'clickhouse': 'host:clickhouse_host user:clickhouse_app_user db:clickhouse_app_db password:clickhouse_app_password'}\n\n\nИнетестно то, что для того, что по умолчанию yaml игнорирует все переносы на новую строку. Для того, чтобы справиться с этим исполюзуется: - | после имени ключа заставил yaml “видеть” перевод строки; - &gt; после имени ключа воткнет перенос строки в конец занчения.\nТак в примене ниже test1 и test2 с точки срения программы читающей yaml не отличаются. А вот test3 и test4 получают в некоторых местах служебный \\n.\n\nyamls_str = \\\n\"\"\"\ntest1: peter olga\ntest2:\n    peter\n    olga\ntest3: |\n    peter\n    olga\ntest4: &gt;\n    peter olga\n\"\"\"\n\nyaml.full_load(yamls_str)\n\n{'test1': 'peter olga',\n 'test2': 'peter olga',\n 'test3': 'peter\\nolga\\n',\n 'test4': 'peter olga\\n'}\n\n\nНу и для примера покажем как сформировать список словарей:\n\nyamls_str = \\\n\"\"\"\n- name: peter\n  age: 22\n- name: olga\n  age: 18\n\"\"\"\n\nyaml.full_load(yamls_str)\n\n[{'name': 'peter', 'age': 22}, {'name': 'olga', 'age': 18}]\n\n\nЯкоря создаются следующим образом: - В сущности на которую ссылаются задают &&lt;обозначение ссылки&gt;; - Когда эту сущность надо вставить куда-то используется синтаксис &lt;&lt;: *&lt;обозначение ссылки&gt;.\nВ примере далее были описаны свойства junior-a некоторой компании, а затем созданы две сушности которым были переданы свойсва этих junior-ов.\n\nyamls_str = \\\n\"\"\"\njunior:\n    &junior\n    position: junior\n    salary: 55000\n\nPeter:\n    &lt;&lt;: *junior\nOlga:\n    &lt;&lt;: *junior\n\"\"\"\n\nyaml.full_load(yamls_str)\n\n{'junior': {'position': 'junior', 'salary': 55000},\n 'Peter': {'position': 'junior', 'salary': 55000},\n 'Olga': {'position': 'junior', 'salary': 55000}}\n\n\n\nКоманды docker-compose\nТут будут рассмотрены самые полезные случаи для работы с коммандой docker-compose. Для примера используется docker-compose.yaml приложенный в той-же папке, что и этот notebook.\n\nup - поднять приложение\nКоманда up используется для того, чтобы поднять приложение спользующее docker-compose. Выполняется обязательно в той папке в которой лежит yaml описывающий приложение.\nОпции:\n\nd - запустит в фоновом режиме - терминал останеться под управлением пользователя.\n\nТак, следующий пример показывает, что до вызова docker-comporse up в docker нет не контейнеров ни вольюмов, а после, все это появляется.\n\n%%bash\necho '=======запущенные контейнеры========='\ndocker ps\necho '===========доступные volume=========='\ndocker volume ls\n\necho '==========запускаю приложение==========='\ndocker-compose up -d &&gt; /dev/null\n\necho '=======запущенные контейнеры========='\ndocker ps --format '{{.Names}}'\necho '===========доступные volume=========='\ndocker volume ls\n\ndocker-compose down -v &&gt; /dev/null\n\n=======запущенные контейнеры=========\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n===========доступные volume==========\nDRIVER    VOLUME NAME\n==========запускаю приложение===========\n=======запущенные контейнеры=========\ndocker_compose-db-1\n===========доступные volume==========\nDRIVER    VOLUME NAME\nlocal     docker_compose_ex_vol\n\n\n\n\ndown - положить приложение\nОпять же требуется вызывать из папки в которой лежит yaml описывающий приложение.\nОпции: - v - удалит все volume созданные при поднятии этого приложения.\n\n%%bash\ndocker-compose up -d &&gt; /dev/null\ndocker-compose down &&gt; /dev/null\n\necho '============без опции -v============'\ndocker volume ls\ndocker volume rm docker_compose_ex_vol &gt; /dev/null 2&gt;&1\n\n\ndocker-compose up -d &&gt; /dev/null\ndocker-compose down -v &&gt; /dev/null\necho '============опция -v============'\ndocker volume ls\n\n============без опции -v============\nDRIVER    VOLUME NAME\nlocal     docker_compose_ex_vol\n============опция -v============\nDRIVER    VOLUME NAME\n\n\n\n\n\nСоздание docker-compose файла\nЗдается с помощью описанного выше языка yaml. Далее будем обсуждать ключи которые могут быть использованы и для чего они могут быть использованы.\n\nКлюч services\nСкрывает под собой описание контейнеров, которые будут использоваться при развертывании приложения. Каждый ключ в словале под seriveces создает новый контенер, ключи задаются произвольно. То есть выглядеть это должно прмерно так:\nservices:\n  &lt;контейнер1&gt;:\n    &lt;инструкции&gt;\n  &lt;контейнер2&gt;:\n    &lt;инструкии&gt;\n  ...\nДалее рассмотрим различные интструкции которые может содржать каждый из контейнеров:\n\nБазовые интсрукции\nЕсть ряд интсрукции которые просто воспроизводят некторые комманды обычного docker. Не считаю, что они заслуживают отдельного разбора (пока не столкнулся с проблемами), потому просто покажу соответсвие с коммандами docker.\n\n\n\n\n\n\n\ndocker-compose.yaml\ndocker\n\n\n\n\nimage: &lt;образ&gt;\ndocker run &lt;образ&gt;\n\n\ncontainer_name: &lt;имя контейнера&gt;\ndocker run --name &lt;имя контейнера&gt;\n\n\nvolumes:  - &lt;volume/путь на хосте 1&gt;:&lt;путь в контейнере1&gt;  - &lt;volume/путь на хосте 2&gt;:&lt;путь в контейнере2&gt;  …\ndocker run \\-v &lt;путь на хосте/volume 1&gt;:&lt;путь в контейнере1&gt;\\  -v &lt;путь на хосте/volume 2&gt;:&lt;путь в контейнере2&gt;\\  …\n\n\nenvironment:&lt;имя переменной1&gt;: &lt;значение1&gt; &lt;имя переменной2&gt;: &lt;значение2&gt;  …\ndocker run \\  -e &lt;имя переменной1&gt;=&lt;значение переменной1&gt;  -e &lt;имя переменной2&gt;=&lt;значение переменной2&gt;  …\n\n\nnetworks:  - &lt;сеть 1&gt;  - &lt;сеть 2&gt;  …\ndocker run  --net &lt;сеть 1&gt;  --net &lt;сеть 2&gt;  …\n\n\nports:  &lt;порт на хосте1&gt;:&lt;порт в контейнере1&gt;  &lt;порт на хосте2&gt;:&lt;порт в контейнере2&gt;  …\ndocker run  -p &lt;порт на хосте1&gt;:&lt;порт в контейнере1&gt;  -p &lt;порт на хосте2&gt;:&lt;порт в контейнере2&gt;  …\n\n\n\n\n\nСборка образа - инструкция build\nСоответсвует комманде docker build. Соберет образ и запустит на его основе контейнер. заметим, что при опускании приложения, docker-compose остановит и удалит контейнер, но, не образ, поэтому удаление образа (в случае необходимости) ложится на админа.\n\n%%bash\ncd build_example\ndocker-compose up -d &&gt; /dev/null\necho '=====показываю что появился новый образ====='\ndocker images | grep build_example_my_small_ubuntu\necho '=====а на его основании контейнер====='\ndocker ps -a --format '{{.Names}}'\ndocker-compose down &&gt; /dev/null\necho '=====опустил приложение, но образ то остался====='\ndocker images | grep build_example_my_small_ubuntu\ndocker rmi build_example_my_small_ubuntu &&gt; /dev/null\n\n=====показываю что появился новый образ=====\nbuild_example_my_small_ubuntu   latest    098799dc601d   9 days ago      77.8MB\n=====а на его основании контейнер=====\nbuild_example-my_small_ubuntu-1\n=====опустил приложение, но образ то остался=====\nbuild_example_my_small_ubuntu   latest    098799dc601d   9 days ago      77.8MB\n\n\n\n\nИнтерактивный режим и подключение tty\nДелаются интрукциями:\ntty: true\nstdin_open: true\nДалее пример. Там поднимаются два контейнера на основе ubuntu один: - with_tty использует названные инструкции; - no_tty не использует названные инструкции.\nВ итоге при вызовер docker ps -a выявляюется обра образа, а при docker ps только образ with_tty, что говорит о том, что образ no_tty завершает свою работу.\n\n%%bash\n\ncd it_option\ndocker-compose up -d &&gt; /dev/null\nsleep 5\necho \"=====docker ps -a=====\"\ndocker ps -a --format '{{.Names}}'\necho \"=====docker ps=====\"\ndocker ps --format '{{.Names}}'\ndocker-compose down &&gt; /dev/null\n\n=====docker ps -a=====\nno_tty\nwith_tty\n=====docker ps=====\nwith_tty\n\n\n\n\nПерезапуск контейнера - интструкция restart\nВ случае, если некоторая программа при определенных обстоятельсвах будет вылетать с ошбкой её приходится перезапускать. В docker-compose для того предусмотренна инструация restart. Она, похоже, может принимать множество значений, но на сегоняшний день известна только always, которая приведет к тому, что контейнер будет перезапускаться пока не запустится.\nОбраз приведенный в папке restart сделан таким образом, чтобы программа останавливась всегда, когда файл check_file сорержит число меньшеее 5, но приращает число файле на 1. Если же программа видит число большее либо равное 5-ти в контейнере, то это приводит к тому, что она зависает в бесконечном цикле.\nЗапуская docker-compose.yaml с таким контейнером внутри и опцией restart: true получаем, что записанное в файле число дорастает ровно до 5.\n\n%%bash\n\ncd restart\necho \"1\" &gt; check_file\n\ndocker-compose up -d &&gt; /dev/null\nsleep 10\n\ndocker-compose down &&gt; /dev/null\ndocker rmi example_python &&gt; /dev/null\n\ncat check_file\n\n5\n\n\n\n\nПроверка работоспособности контейнера - инструкция healthcheck\nИногоа бывает так, что контейнер может провериться, по поводу того насколько правильно он запущен. Для того, чтобы вызвать команду проверки используется интсрукция healthy.\nhealthy имеет некоторые настройки, вот некоторые из них: - test - задает команду которая будет исопльзована для проверки контейнера; - interval; - timeout; - retries.\nВот, например, как инструкция может быть использована в postgresql:\n...\nhealthcheck: \n    test: [\"CMD-SHELL\", \"pg_isready\", \"-U\", \"docker_app\"]\n...\nТак в примере, представленном ниже, разворачивается два контейнера на основе postgresql (на остальные контейнеры в рамках этого примера можно не обращать внимания). Один с этой опицией, другой без. При отображении их через dokcer ps у одного в STATUS есть пририска (health: starting) у второго - нет.\n\n%%bash\ncd postgres_example\ndocker-compose up -d &&gt; /dev/null\ndocker ps --format '{{.Names}}'\ndocker-compose down -v &&gt; /dev/null\n\npostgres_example-ubuntu3-1\npostgres_example-ubuntu1-1\npostgres_example-db1-1\npostgres_example-db2-1\n\n\n\n\nЗависимость от других сревисов - depends_on\nЕсли требуется что-то делать в зависимости от другого сервиса в этом docker-compose.yaml то делается это так:\n...\ndepends_on:\n    &lt;имя обуславливающего сервиса&gt;:\n        &lt;инструкции&gt;\n...\nНапример, если требуется запускать контейнер, только в том случае, если другой сервис healthy, то это будет записано так:\n...\ndepends_on:\n    &lt;имя обуславливающего сервиса&gt;:\n        condition: service_healthy\n...\nНа данный момент известно о следующих возможностях этой инструкции:\n\ncondition: service_healthy - проверить проведена ли для обулавливающего контейнера проверка healthcheck;\ncondition: service_started - проверить поднят ли обуславливающий контейнер.\n\nДля примера представим “docker-compose.yaml” расположенный в папке “postgres_example”. В нем: - сервисы “ubuntu1” и “ubuntu2” поднимаются только в случае “здоровья” сервисов “db1” и “db2” соотсветсвенно - в результате поднимается только “ubuntu1” потому как проверка healthcheck предусмотрена только для “db1”; - сервисы “ubuntu3” и “ubuntu4” поднимаются только в тех случах если подняты “ubuntu1” и “ubuntu2” соотственно - так как на прошлом шаге “unbuntu2” не поднялся не поднимется и “ubuntu4”.\n\n%%bash\ncd postgres_example\ndocker-compose up -d &&gt; /dev/null\ndocker ps --format '{{.Names}}'\ndocker-compose down -v &&gt; /dev/null\n\npostgres_example-ubuntu3-1\npostgres_example-ubuntu1-1\npostgres_example-db2-1\npostgres_example-db1-1\n\n\n\n\nРеплики контейнера - интсрукция deploy-&gt;replicas\nДля интсрукции deploy, наверняка будет больше подинтсрукций. Но на сегдняшний день известно только об replicas.\ndeploy-&gt;replicas позволяет задать число копий поднимаемого контейнера.\nТак использование последовательности инструкций:\ndeploy:\n  replicas: 3\nПриводит к тому, что будет поднято три реплики сервиса для которого это записано.\nТак в примере ниже я одним махом поднимаю 3 контейнера ubuntu:\n\n%%bash\ncd replicas\ndocker-compose up -d &&gt; /dev/null\ndocker ps -a --format '{{.Names}}'\ndocker-compose down &&gt; /dev/null\n\nreplicas-my_ubuntu-1\nreplicas-my_ubuntu-3\nreplicas-my_ubuntu-2\n\n\n\n\nКоманды при запуске - инструкция command\nМожно указать команду, которая будет выполнена при запуске контейнера. Так “docker-file.yaml” в папке “command” содержить строку: command: bash -c \"echo \\\"hello world\\\" &gt; test_file; bash\"\nЭта строка в контейре создаёт файл “test_file” наличие и содержание, котого мы проверяем в примере ниже:\n\n%%bash\ncd command\ndocker-compose up -d &&gt; /dev/null\ndocker exec temp_ubuntu cat test_file\ndocker-compose down &&gt; /dev/null\n\nhello world\n\n\nИнтерестно, то что если написть command так:\ncommand echo \"hello world\" &gt; test_file\nКонтейнер завершает работу. Видимо это связано с тем, что последняя комманда должна бесконечно ожидать ввода, чтобы все работало - именно такую функцию выполняет комманда bash.\n\n\n\nКлюч volumes\nЗадает volumes.\nКаждый вложенный ключ создаст volume.\nvolumes:\n    &lt;volume1&gt;:\n        name: &lt;volume name&gt;\n    &lt;volume2&gt;:\n    ...\nУ каждого volume можно задать поле name (а можно и не задавать) которое укажет имя volume при поднятии приложения. Так, в примере ниже, из папки volume_example создается volume с именем example_name.\n\n%%bash\ncd volume_example\ndocker-compose up -d &&gt; /dev/null\n\necho \"=====список volume=====\"\ndocker volume ls\n\ndocker-compose down -v &&gt; /dev/null\n\n=====список volume=====\nDRIVER    VOLUME NAME\nlocal     example_name\n\n\n\n\nКлюч networks\nЗадает сети импользуемые в приложении.\nКаждый вложенный ключ создаст сеть.\nnetworks:\n    &lt;net1&gt;:\n        name: &lt;network name&gt;\n    &lt;net2&gt;:\n    ...\nКлюч name задает имя сети и не является обязательным. На в папке network-example лежит yaml файл, который описывает сеть с именем example_name.\n\n%%bash\ncd network_example\ndocker-compose up -d &&gt; /dev/null\ndocker network ls\ndocker-compose down -v &&gt; /dev/null\n\nNETWORK ID     NAME           DRIVER    SCOPE\n75034612bd8f   bridge         bridge    local\n14cb969f28d4   example_name   bridge    local\nf8b2503d0640   host           host      local\nb1d7e6bda275   none           null      local\n\n\n\n\n\nДетали\n\nСеть по умолчанию\nЛюбое приложение запущенное через docker-compose, в случае отсудсвия указанных сетей, создает себе сеть с названием по типу &lt;имя папки&gt;_default. Так в примере далее показано, что в списке, кроме базовых сетей, появляется docker_compose_default.\n\n%%bash\ndocker-compose up -d &&gt; /dev/null\necho \"=====созданные сети=====\"\ndocker network ls\ndocker-compose down -v &&gt; /dev/null\n\n=====созданные сети=====\nNETWORK ID     NAME                     DRIVER    SCOPE\n75034612bd8f   bridge                   bridge    local\n205bf876f99f   docker_compose_default   bridge    local\nf8b2503d0640   host                     host      local\nb1d7e6bda275   none                     null      local\n\n\n\n\nНазвание по умолчанию\nvolumes/сети, по умолчанию, получают некоторые названия по типу &lt;название папки&gt;_&lt;название ключа&gt;. Так, в следующем примере, в папке default_namimg указаны volume ex_vol и сеть ex_net, но для них не указано ключа name.\n\n%%bash\ncd default_naming\ndocker-compose up -d &&gt; /dev/null\necho '=====volumes====='\ndocker volume ls\necho '=====networks====='\ndocker network ls\ndocker-compose down -v &&gt; /dev/null\n\n=====volumes=====\nDRIVER    VOLUME NAME\nlocal     default_naming_ex_vol\n=====networks=====\nNETWORK ID     NAME                    DRIVER    SCOPE\n75034612bd8f   bridge                  bridge    local\n4599a4f61b14   default_naming_ex_net   bridge    local\nf8b2503d0640   host                    host      local\nb1d7e6bda275   none                    null      local\n\n\n\n\nvolume/сеть не создаются?\nУбедитесь, что они указаны под ключами volumes/networks в каком-либо из контейнеров. В противном случае они не создаются.\nВ следующем примере из папки vol_net_missed разворачивается приложение. И хотя в соответсвующем docker-compose.yaml заданы volume ex_vol и сеть ex_net, при запуске приложения создается только безимянный volume (видимо создаваемый postgres по умолчанию) и сеть которая всегда создается docker-compose по умолчанию vol_net_missed_default.\nПримеры удачного создания сетей/volumes представлены выше.\n\n%%bash\ncd vol_net_missed\ndocker-compose up -d &&gt; /dev/null\necho '====volumes====='\ndocker volume ls\necho '=====networks====='\ndocker network ls\ndocker-compose down -v &&gt; /dev/null\n\n====volumes=====\nDRIVER    VOLUME NAME\nlocal     48e548f659d0e05ba4a981e4b17e9b2b1835ca62aeb0cbfa08974d23d7772469\n=====networks=====\nNETWORK ID     NAME                     DRIVER    SCOPE\n75034612bd8f   bridge                   bridge    local\nf8b2503d0640   host                     host      local\nb1d7e6bda275   none                     null      local\nbcef30a7a541   vol_net_missed_default   bridge    local\n\n\n\n\nМонтирование директорий из директирии запуска\nИногда требуется сослатся на папку из которой производится запуск docker-compose. Для того можно использовать ${PWD}/&lt;дирректория&gt; или ./&lt;дирректория&gt;\nКогда мы, например, в docker монтировали файл/папку, через bind mount мы писали что-то вроде:\ndocker run --rm\\\n    -v $(pwd)/&lt;название файла/папки&gt;:&lt;путь в контейнере&gt;\nАналогичная запись в docker-compose.yaml:\nservices:\n  &lt;название сервиса&gt;:\n    volumes:\n      - ${PWD}/&lt;название файла/папки&gt;:&lt;путь в контейнере&gt;\nили\nservices:\n  &lt;название сервиса&gt;:\n    volumes:\n      - ./&lt;название файла/папки&gt;:&lt;путь в контейнере&gt;\nПример далее, заодно покажем как пользоваться bind mount в docker-compose.\ndocker-compose файл лежит в папке pwd_example. В этой же папке создается файл test_file, который потом указано монтировать в файле docker-compose.yaml, так - ${PWD}/test_file:/test_file1 и как - ./test_file:test_file2.\nЗатем в файлы в файловой системе контейнера вносятся изменения.\nПосле закрытия контейнера, все изменения в файле остаются в исходном файле на хосте.\n\n%%bash\n\ncd pwd_example\necho \"Сообщение с хоста\" &gt; test_file\necho \"=====Исходный файл=====\"\ncat test_file\n\ndocker-compose up -d &&gt; /dev/null\ndocker exec test_cont bash -c \"echo 'Сообщение из контейнера 1' &gt;&gt; test_file1\"\ndocker exec test_cont bash -c \"echo 'Сообщение из контейнера 2' &gt;&gt; test_file2\"\ndocker-compose down &&gt; /dev/null\n\necho \"=====Измененный файл=====\"\ncat test_file\n\n=====Исходный файл=====\nСообщение с хоста\n=====Измененный файл=====\nСообщение с хоста\nСообщение из контейнера 1\nСообщение из контейнера 2\n\n\n\n\nОбновление docker-compose приложения\nЕсли вдруг, в docker-compose.yaml были внесены некоторые изменения, то не обязательно опускать приложение - можно его просто запустить наново, docker-compose подхватит, что это то же самое приложение (видимо по папке запуска) и обновит его.\nВ следующем примере, я сначала запускаю docker-compose с приложением в котором единтсвенный контейнер имеет имя first_name, затем подменяю docker-compose.yaml на тот, который содержит контейнер названный second_name.\nЯ хочу показать то, что несмотря на то что запуска два и немного разных контейнер то остается один и меняет имя в соовтесвии с актуальным docker-compose.yaml\n\n%%bash\ncd refresh\ncat first.yaml &gt; docker-compose.yaml\ndocker-compose up -d &&gt; /dev/null\necho \"=====Первый запуск=====\"\ndocker ps -a --format '{{.Names}}'\ncat second.yaml &gt; docker-compose.yaml\ndocker-compose up -d &&gt; /dev/null\necho \"=====Второй запуск=====\"\ndocker ps -a --format '{{.Names}}'\ndocker-compose down &&gt; /dev/null\n\n=====Первый запуск=====\nfirst_name\n=====Второй запуск=====\nsecond_name"
  },
  {
    "objectID": "Docker/logs.html",
    "href": "Docker/logs.html",
    "title": "Logging in docker",
    "section": "",
    "text": "Logs can:\n\nWrite them using the standard output stream;\nWrite to a predefined file (there is nothing special here, you can just use volume or bind mount);\nA combination of the two previously mentioned methods.\n\n\nlogs command\nAllows to read, what happened in container terminal.\nIn following example I: - I create conteiner which generates either a message in stdout or an error in stderr every second; - Wait 10 seconds; - Use docker logs to see what events happen in container.\n\n%%bash\ncd logs_examples\ndocker build -t log_example . &&gt; /dev/null\n\ndocker run -d --rm --name log_example log_example stream.py &&gt; /dev/null\nsleep 10\n\necho \"=====generated log=====\"\ndocker logs log_example\n\ndocker stop log_example &&gt; /dev/null\ndocker rmi log_example &&gt; /dev/null\n\n=====generated log=====\nJust message\nJust message\nJust message\nJust message\nJust message\n\n\nSome error\nSome error\nSome error\nSome error\n\n\nNote for some reason Jupyter puts errors in the first place in its output - so you may always get errors first when trying to reproduce the results of the following example.\nActually, you can avoid this by redirecting the error stream to the normal stream, by using 2&gt;&1 bash construction:\n\n%%bash\ncd logs_examples\ndocker build -t log_example . &&gt; /dev/null\n\ndocker run -d --rm --name log_example log_example stream.py &&gt; /dev/null\nsleep 10\n\necho \"=====generated log=====\"\ndocker logs log_example 2&gt;&1\n\ndocker stop log_example &&gt; /dev/null\ndocker rmi log_example &&gt; /dev/null\n\n=====generated log=====\nJust message\nJust message\nJust message\nJust message\nSome error\nSome error\nSome error\nJust message\nJust message\n\n\n\n-f - read container output in runtime\n\n\n\n-t - get time of the message\n\n%%bash\ncd logs_examples\ndocker build -t log_example . &&gt; /dev/null\n\ndocker run -d --rm --name log_example log_example stream.py &&gt; /dev/null\nsleep 10\n\necho \"=====generated log=====\"\ndocker logs -t log_example\n\ndocker stop log_example &&gt; /dev/null\ndocker rmi log_example &&gt; /dev/null\n\n=====generated log=====\n2023-06-12T08:42:12.063382853Z Just message\n2023-06-12T08:42:13.064541066Z Just message\n2023-06-12T08:42:14.065711848Z Just message\n2023-06-12T08:42:17.069086047Z Just message\n2023-06-12T08:42:19.071241128Z Just message\n2023-06-12T08:42:20.072419403Z Just message\n\n\n2023-06-12T08:42:15.066916732Z Some error\n2023-06-12T08:42:16.068155506Z Some error\n2023-06-12T08:42:18.070257834Z Some error\n\n\n\n\n\nGet log path on the computer\nIf you need to get the path to the Docker container log on your computer, you should use the construction shown below.\n\n%%bash\ncd logs_examples\ndocker build -t log_example . &&gt; /dev/null\n\ndocker run -d --rm --name log_example log_example stream.py &&gt; /dev/null\necho \"=====path to the log=====\"\ndocker inspect --format \"{{.LogPath}}\" log_example\n\ndocker stop log_example &&gt; /dev/null\ndocker rmi log_example &&gt; /dev/null\n\n=====path to the log=====\n/var/lib/docker/containers/cb2fb4f9b5d8829c1afb6b78293cf9487c0266d4152bd2f9a3f9d9d766740216/cb2fb4f9b5d8829c1afb6b78293cf9487c0266d4152bd2f9a3f9d9d766740216-json.log\n\n\nI can’t get superuser access from jupyter, but the log file should look like this:\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:01.788547631Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:02.788842446Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:03.788818941Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:04.789226578Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:05.789279007Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:06.789563215Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:07.7895666Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:08.789954572Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:09.790014965Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:10.790300833Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:11.790511897Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:12.790821869Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:13.790939824Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:14.791204789Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:15.791283359Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:16.791536539Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:17.791786679Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:18.791807047Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:19.792075268Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:20.792325859Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:21.792410762Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:22.792794096Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:23.792780477Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:24.793194852Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:25.793462485Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:26.793712972Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:27.793920753Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:28.794071626Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:29.794379101Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:30.794698985Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:31.794924583Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:32.795122566Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:33.795242226Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:34.795374507Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:35.795542017Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:36.795638844Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:37.795888676Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:38.796024537Z\"}\nThe fields in this example should have the following meaning:\n\nlog - message that was logged;\nstream - stream that was used;\ntime - time when it was made.\n\n\n\nStandart/error streams\n\nFrom terminal\nBasic Linux utilities for processing terminal output that are specified for the standard stream and don’t care about the error stream.\nFor example, if you use the head utility to handle program output:\n\n%%bash\n\ncd logs_examples\necho \"=====head result=====\"\npython3 stream.py -n 10| head -n 5\necho \"=====grep result=====\"\npython3 stream.py -n 10| grep message\n\n=====head result=====\nJust message\nJust message\nJust message\nJust message\n=====grep result=====\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\n\n\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error\n\n\nDespite the fact that I asked for head -n 5, which means that 5 lines should be printed in the command output, I got many more lines. This happens because utilities such as head, tail, grep and so on only work with the standard stream and ignore the error. But the error stream has priority over the standard stream - so it will be printed anyway.\nAs a solution you can redirect error stream info to standart stream by using 2&gt;&1 construction after the command displaying result:\n\n%%bash\n\ncd logs_examples\necho \"=====head result=====\"\npython3 stream.py -n 10 2&gt;&1| head -n 5\necho \"=====grep result=====\"\npython3 stream.py -n 10 2&gt;&1|grep message\n\n=====head result=====\nSome error\nSome error\nSome error\nSome error\nSome error\n=====grep result=====\nJust message\nJust message\nJust message\n\n\nThis way the Linux commands will see no difference between error and standard streams, but the error stream will still be displayed first - which you can see in the head command result.\nBut in the context of Docker container logging, if you use 2&gt;&1 with docker logs, it will be sufficient to print standard and error streams in apparent order. This is probably because you are not extracting messages from the runtime, but from a file somewhere.\n\n%%bash\ncd logs_examples\ndocker build -t log_example . &&gt; /dev/null\n\ndocker run -d --rm --name log_example log_example stream.py &&gt; /dev/null\nsleep 10\n\necho \"=====generated log=====\"\ndocker logs log_example 2&gt;&1| head -n 5\n\ndocker stop log_example &&gt; /dev/null\ndocker rmi log_example &&gt; /dev/null\n\n=====generated log=====\nJust message\nSome error\nJust message\nSome error\nSome error\n\n\n\n\nTo file\nYou can save streams to files by using the following constructions:\n\n&gt; - rewrite file with the results of the standart stream;\n&gt;&gt; - complete file with the result of the standart stream;\n2&gt; - rewrite file with the result of the error stream;\n2&gt;&gt; - complete file with the result of the error stream.\n\nThe following example shows how divide standart and error streams into two files.\n\n%%bash\ncd logs_examples\npython3 stream.py -n 20 &gt; standart_stream 2&gt; error_stream\n\necho \"=====standart stream=====\"\ncat standart_stream\necho \"=====error stream=====\"\ncat error_stream\n\nrm standart_stream error_stream\n\n=====standart stream=====\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\n=====error stream=====\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error"
  },
  {
    "objectID": "Docker/sources.html",
    "href": "Docker/sources.html",
    "title": "Sources",
    "section": "",
    "text": "This is where I put useful information about Docker. If any sources are mentioned in later sections, you should find them here.\n\nDocker instalation USE ONLY COMMANDS PROVIDED BY DOCKER DOCUMENTATION;\n May be useful after installing;\n\nHow not to always put sudo before the docker command;\nSomething still incomprehensible..\n\n Start daemon  sudo systemctl start docker;\n Docker cource by karpovcources."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]