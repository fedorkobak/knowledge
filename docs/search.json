[
  {
    "objectID": "jupyter/nbconvert/example_notebook.html",
    "href": "jupyter/nbconvert/example_notebook.html",
    "title": "Latex",
    "section": "",
    "text": "Notebook - пример для того чтобы разобраться в особенностсях рабты с nbcnovert\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\n\\[f(x) = x_2+3x+22\\]\n\nMatplotlib график\n\nans = plt.plot([1,2,3], [3,4,5])\n\n\n\n\n\n\nПросто картинка\n\n\n\npandas таблица\n\npd.DataFrame(\n    np.random.rand(20, 30)\n)\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n\n\n0\n0.663143\n0.021464\n0.858000\n0.766506\n0.985039\n0.346647\n0.364177\n0.912234\n0.037032\n0.272790\n...\n0.327494\n0.880709\n0.041401\n0.369179\n0.451213\n0.611814\n0.560559\n0.523025\n0.205788\n0.422654\n\n\n1\n0.827827\n0.649757\n0.215769\n0.179621\n0.570741\n0.088579\n0.845170\n0.596793\n0.161002\n0.002342\n...\n0.034259\n0.278648\n0.882712\n0.355811\n0.766390\n0.151718\n0.863036\n0.730791\n0.114088\n0.379146\n\n\n2\n0.865272\n0.487274\n0.399290\n0.380105\n0.088102\n0.054062\n0.795389\n0.883104\n0.364047\n0.394248\n...\n0.415779\n0.853940\n0.773343\n0.865510\n0.672601\n0.770037\n0.088337\n0.236902\n0.437594\n0.369074\n\n\n3\n0.009670\n0.119128\n0.477052\n0.103209\n0.975513\n0.152730\n0.106975\n0.577861\n0.976428\n0.734008\n...\n0.431997\n0.990676\n0.972629\n0.698313\n0.197316\n0.172827\n0.365104\n0.543878\n0.373947\n0.177256\n\n\n4\n0.209034\n0.328370\n0.747825\n0.912026\n0.684328\n0.730339\n0.222565\n0.723777\n0.249022\n0.515858\n...\n0.344164\n0.825411\n0.107212\n0.722163\n0.064626\n0.557274\n0.979061\n0.617117\n0.129202\n0.828734\n\n\n5\n0.748535\n0.438338\n0.321346\n0.048413\n0.564367\n0.938365\n0.504495\n0.701783\n0.817506\n0.966032\n...\n0.833825\n0.877737\n0.827943\n0.433181\n0.188727\n0.847585\n0.873378\n0.414874\n0.385979\n0.283664\n\n\n6\n0.169217\n0.189379\n0.279181\n0.105524\n0.321006\n0.469294\n0.298573\n0.752147\n0.512748\n0.326833\n...\n0.978364\n0.807084\n0.742420\n0.718420\n0.715044\n0.568432\n0.673553\n0.608451\n0.242622\n0.858917\n\n\n7\n0.318894\n0.703588\n0.918537\n0.798998\n0.097702\n0.837357\n0.734335\n0.260800\n0.746494\n0.996407\n...\n0.895983\n0.674704\n0.269369\n0.561942\n0.527911\n0.219911\n0.668875\n0.098179\n0.040179\n0.268487\n\n\n8\n0.538815\n0.789962\n0.170698\n0.653034\n0.209657\n0.784521\n0.721873\n0.653080\n0.735756\n0.870527\n...\n0.816603\n0.700780\n0.589116\n0.054555\n0.269549\n0.292141\n0.051452\n0.064437\n0.029045\n0.033099\n\n\n9\n0.825010\n0.985221\n0.892499\n0.012812\n0.073686\n0.189973\n0.263994\n0.868104\n0.625486\n0.905932\n...\n0.810490\n0.282077\n0.346684\n0.959549\n0.245090\n0.283466\n0.027302\n0.097790\n0.422846\n0.071181\n\n\n10\n0.071752\n0.566090\n0.576133\n0.042006\n0.724374\n0.617664\n0.646433\n0.685819\n0.075983\n0.945756\n...\n0.379925\n0.579344\n0.854027\n0.674528\n0.111671\n0.101454\n0.556477\n0.319533\n0.891699\n0.777899\n\n\n11\n0.321099\n0.606897\n0.152936\n0.282932\n0.240571\n0.523979\n0.499664\n0.103284\n0.252159\n0.749216\n...\n0.756029\n0.388600\n0.771017\n0.406881\n0.670963\n0.328559\n0.055640\n0.058266\n0.255477\n0.231221\n\n\n12\n0.069434\n0.471599\n0.879479\n0.150907\n0.259604\n0.121494\n0.283101\n0.632702\n0.969049\n0.416081\n...\n0.228064\n0.802990\n0.601474\n0.595615\n0.171583\n0.885227\n0.570803\n0.629680\n0.481346\n0.823556\n\n\n13\n0.008207\n0.210180\n0.048300\n0.360097\n0.540163\n0.947513\n0.017571\n0.152821\n0.986996\n0.352458\n...\n0.460305\n0.102086\n0.617660\n0.219018\n0.832248\n0.308261\n0.002964\n0.548857\n0.822519\n0.257786\n\n\n14\n0.564729\n0.040055\n0.281084\n0.704265\n0.293981\n0.351052\n0.014585\n0.487037\n0.433179\n0.850257\n...\n0.708030\n0.932107\n0.591465\n0.046695\n0.475054\n0.762240\n0.329465\n0.752053\n0.205726\n0.453508\n\n\n15\n0.916010\n0.569487\n0.000574\n0.240208\n0.380580\n0.704447\n0.128708\n0.905343\n0.504579\n0.139354\n...\n0.489544\n0.711177\n0.540197\n0.433703\n0.889278\n0.716258\n0.368589\n0.243502\n0.430579\n0.207018\n\n\n16\n0.555162\n0.159681\n0.611847\n0.286136\n0.345460\n0.190651\n0.211620\n0.289052\n0.445264\n0.415703\n...\n0.782363\n0.835031\n0.996787\n0.903400\n0.236019\n0.176010\n0.306686\n0.103315\n0.948140\n0.046661\n\n\n17\n0.867713\n0.831490\n0.288641\n0.728252\n0.620024\n0.315909\n0.273223\n0.423136\n0.236910\n0.257647\n...\n0.016341\n0.977661\n0.601080\n0.977532\n0.088836\n0.754579\n0.807837\n0.050929\n0.439012\n0.721582\n\n\n18\n0.333013\n0.409006\n0.669115\n0.700568\n0.903307\n0.822934\n0.635862\n0.613437\n0.187538\n0.050552\n...\n0.724519\n0.016494\n0.550508\n0.223219\n0.444358\n0.734620\n0.902881\n0.728414\n0.595171\n0.161489\n\n\n19\n0.614472\n0.792331\n0.300568\n0.345817\n0.407511\n0.816590\n0.950677\n0.037251\n0.316392\n0.058362\n...\n0.296249\n0.254440\n0.963934\n0.222605\n0.509345\n0.495333\n0.685706\n0.500341\n0.956666\n0.333952\n\n\n\n\n20 rows × 30 columns\n\n\n\n\n\nТэги\nВ следующих ячейках записано какой тэг для каждой применен.\nТэг remove_cell для markdown ячейки.\n\nprint(\"remove_input\")\n\nremove_input\n\n\n\nprint(\"remove_output\")\n\nremove_output"
  },
  {
    "objectID": "jupyter/nbconvert/nbconvert_examples.html",
    "href": "jupyter/nbconvert/nbconvert_examples.html",
    "title": "Источники",
    "section": "",
    "text": "Как пользоваться nbconvert\nnbconvernt моежт быть использован как утилита командной строки или же python библиотека. Тут я буду рассматривать nbconvert как python библиотеку.\nimport io\n\nimport nbformat\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom traitlets.config import Config\n\nfrom nbconvert import HTMLExporter,\\\n                        RSTExporter"
  },
  {
    "objectID": "jupyter/nbconvert/nbconvert_examples.html#htmlexporter",
    "href": "jupyter/nbconvert/nbconvert_examples.html#htmlexporter",
    "title": "Источники",
    "section": "HTMLExporter",
    "text": "HTMLExporter\nПозволяет экспортировать файл в html.\n\nhtml_exporter = HTMLExporter(template_name='classic')\n(body, resources) = html_exporter.from_notebook_node(notebook)\n\nИ так возвращаяется два объекта\n\nbody\nПервый это тело html файла, его можно сразу сохранить и получается вполне себе html.\n\nfile = open(\"basic_html_exporter.html\", \"w+\")\nfile.write(body)\nfile.close()\n\nНо при спользовании такого подхода есть проблема - картинки, формируемые как часть markdown разметки не будут встроены в .html, а будут лишь ссылками на файлы.\n\n\nresources\nСписок ресурсов используемых для формирования jupyter.\n\nresources\n\nResourcesDict(None,\n              {'metadata': ResourcesDict(None, {'name': 'Notebook'}),\n               'output_extension': '.html',\n               'deprecated': &lt;function nbconvert.exporters.templateexporter.deprecated(msg)&gt;,\n               'theme': 'light',\n               'include_css': &lt;function nbconvert.exporters.html.HTMLExporter._init_resources.&lt;locals&gt;.resources_include_css(name)&gt;,\n               'include_lab_theme': &lt;function nbconvert.exporters.html.HTMLExporter._init_resources.&lt;locals&gt;.resources_include_lab_theme(name)&gt;,\n               'include_js': &lt;function nbconvert.exporters.html.HTMLExporter._init_resources.&lt;locals&gt;.resources_include_js(name)&gt;,\n               'include_url': &lt;function nbconvert.exporters.html.HTMLExporter._init_resources.&lt;locals&gt;.resources_include_url(name)&gt;,\n               'require_js_url': 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js',\n               'mathjax_url': 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe',\n               'jquery_url': 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js',\n               'jupyter_widgets_base_url': 'https://unpkg.com/',\n               'widget_renderer_url': '',\n               'html_manager_semver_range': '*',\n               'inlining': {'css': ['pre { line-height: 125%; }\\ntd.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\\nspan.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\\ntd.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\\nspan.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\\n.highlight .hll { background-color: #ffffcc }\\n.highlight { background: #f8f8f8; }\\n.highlight .c { color: #3D7B7B; font-style: italic } /* Comment */\\n.highlight .err { border: 1px solid #FF0000 } /* Error */\\n.highlight .k { color: #008000; font-weight: bold } /* Keyword */\\n.highlight .o { color: #666666 } /* Operator */\\n.highlight .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\\n.highlight .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\\n.highlight .cp { color: #9C6500 } /* Comment.Preproc */\\n.highlight .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\\n.highlight .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\\n.highlight .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\\n.highlight .gd { color: #A00000 } /* Generic.Deleted */\\n.highlight .ge { font-style: italic } /* Generic.Emph */\\n.highlight .gr { color: #E40000 } /* Generic.Error */\\n.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */\\n.highlight .gi { color: #008400 } /* Generic.Inserted */\\n.highlight .go { color: #717171 } /* Generic.Output */\\n.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\\n.highlight .gs { font-weight: bold } /* Generic.Strong */\\n.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\\n.highlight .gt { color: #0044DD } /* Generic.Traceback */\\n.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\\n.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\\n.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\\n.highlight .kp { color: #008000 } /* Keyword.Pseudo */\\n.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\\n.highlight .kt { color: #B00040 } /* Keyword.Type */\\n.highlight .m { color: #666666 } /* Literal.Number */\\n.highlight .s { color: #BA2121 } /* Literal.String */\\n.highlight .na { color: #687822 } /* Name.Attribute */\\n.highlight .nb { color: #008000 } /* Name.Builtin */\\n.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */\\n.highlight .no { color: #880000 } /* Name.Constant */\\n.highlight .nd { color: #AA22FF } /* Name.Decorator */\\n.highlight .ni { color: #717171; font-weight: bold } /* Name.Entity */\\n.highlight .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\\n.highlight .nf { color: #0000FF } /* Name.Function */\\n.highlight .nl { color: #767600 } /* Name.Label */\\n.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\\n.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */\\n.highlight .nv { color: #19177C } /* Name.Variable */\\n.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\\n.highlight .w { color: #bbbbbb } /* Text.Whitespace */\\n.highlight .mb { color: #666666 } /* Literal.Number.Bin */\\n.highlight .mf { color: #666666 } /* Literal.Number.Float */\\n.highlight .mh { color: #666666 } /* Literal.Number.Hex */\\n.highlight .mi { color: #666666 } /* Literal.Number.Integer */\\n.highlight .mo { color: #666666 } /* Literal.Number.Oct */\\n.highlight .sa { color: #BA2121 } /* Literal.String.Affix */\\n.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */\\n.highlight .sc { color: #BA2121 } /* Literal.String.Char */\\n.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */\\n.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\\n.highlight .s2 { color: #BA2121 } /* Literal.String.Double */\\n.highlight .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\\n.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */\\n.highlight .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\\n.highlight .sx { color: #008000 } /* Literal.String.Other */\\n.highlight .sr { color: #A45A77 } /* Literal.String.Regex */\\n.highlight .s1 { color: #BA2121 } /* Literal.String.Single */\\n.highlight .ss { color: #19177C } /* Literal.String.Symbol */\\n.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */\\n.highlight .fm { color: #0000FF } /* Name.Function.Magic */\\n.highlight .vc { color: #19177C } /* Name.Variable.Class */\\n.highlight .vg { color: #19177C } /* Name.Variable.Global */\\n.highlight .vi { color: #19177C } /* Name.Variable.Instance */\\n.highlight .vm { color: #19177C } /* Name.Variable.Magic */\\n.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */']},\n               'raw_mimetypes': ['text/html', ''],\n               'global_content_filter': {'include_code': True,\n                'include_markdown': True,\n                'include_raw': True,\n                'include_unknown': True,\n                'include_input': True,\n                'include_output': True,\n                'include_output_stdin': False,\n                'include_input_prompt': True,\n                'include_output_prompt': True,\n                'no_prompt': False}})"
  },
  {
    "objectID": "jupyter/nbconvert/nbconvert_examples.html#rstexporter",
    "href": "jupyter/nbconvert/nbconvert_examples.html#rstexporter",
    "title": "Источники",
    "section": "RSTExporter",
    "text": "RSTExporter\nПозволяет диаграммы на графике экспортировать не в .html файл а в ресурсы.\nСпособ использования ничем не отличатеся от рассмотренного выше HTMLExporter.\n\nrst_exporter = RSTExporter()\n(body, resources) = rst_exporter.from_notebook_node(notebook)\n\nНо полученный body содержит только текст.\n\nfile = open(\"rst_exporter.html\", \"w+\")\nfile.write(body)\nfile.close()\n\nНекоторые дополнительные элементы сохранены в resources. Так, например, картинки-результаты выполнения ячеек будут лежать resources[\"outputs\"]. Далее пример их извлечения:\n\noutputs = resources[\"outputs\"]\noutputs_len = len(outputs)\n\nplt.figure(figsize = [5,20])\nfor i, pic_name in enumerate(outputs.keys()):\n    plt.subplot(outputs_len, 1, i+1)\n    plt.xticks([]); plt.yticks([])\n    plt.imshow(\n        plt.imread(\n            io.BytesIO(outputs[pic_name]), format='jpeg'\n        )\n    )\n\n\n\n\nГде были сохранены стили, и почему слетают способы формирования ячеек не понятно."
  },
  {
    "objectID": "jupyter/voila_vs_nbconvert_saving_html/contains_html.html",
    "href": "jupyter/voila_vs_nbconvert_saving_html/contains_html.html",
    "title": "NBconvert",
    "section": "",
    "text": "В этом простом notebook содражться несколько latex выражений. Я намереваю сравнить два случая: - Конвернация в html используя nbconvert; - И используя voila с последующим сохраненнием в html.\nЦель - выяснить, как отличаются части html документов, полученных при использовании каждого из подходов, ответсвенные за latex.\n\\[x_2+3=3232\\]\nА это latex внутри markdown с использованием всего одного знака $ для выделения \\(\\sqrt{x_2}\\).\nКак результат в не слишком продвинух html движках (например базовый viewer jupyter lab) результат получается не очень.\n$$x_2+3=3232$$\nНу а html разметка для той ячейки где сидит latex, выглядит так.\n&lt;div class=\"jp-Cell jp-MarkdownCell jp-Notebook-cell\"&gt;\n&lt;div class=\"jp-Cell-inputWrapper\"&gt;\n&lt;div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"&gt;\n&lt;/div&gt;\n&lt;div class=\"jp-InputArea jp-Cell-inputArea\"&gt;&lt;div class=\"jp-InputPrompt jp-InputArea-prompt\"&gt;\n&lt;/div&gt;&lt;div class=\"jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput \" data-mime-type=\"text/markdown\"&gt;\n$$x_2+3=3232$$\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n\nСохранение страницы из voila\nНа любом из известных графических движков выглядит нормально… Соответсвующий html для ячейки.\n&lt;div class=\"jp-Cell jp-MarkdownCell jp-Notebook-cell\"&gt;\n&lt;div class=\"jp-Cell-inputWrapper\"&gt;\n&lt;div class=\"jp-Collapser jp-InputCollapser jp-Cell-inputCollapser\"&gt;\n&lt;/div&gt;\n&lt;div class=\"jp-InputArea jp-Cell-inputArea\"&gt;&lt;div class=\"jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput \" data-mime-type=\"text/markdown\"&gt;\n&lt;span class=\"MathJax_Preview\" style=\"color: inherit;\"&gt;&lt;/span&gt;&lt;span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"&gt;&lt;span id=\"MathJax-Element-1-Frame\" class=\"mjx-chtml MathJax_CHTML\" tabindex=\"0\" style=\"font-size: 116%; text-align: center; position: relative;\" data-mathml=\"&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;3232&lt;/mn&gt;&lt;/math&gt;\" role=\"presentation\"&gt;&lt;span id=\"MJXc-Node-1\" class=\"mjx-math\" aria-hidden=\"true\"&gt;&lt;span id=\"MJXc-Node-2\" class=\"mjx-mrow\"&gt;&lt;span id=\"MJXc-Node-3\" class=\"mjx-msubsup\"&gt;&lt;span class=\"mjx-base\"&gt;&lt;span id=\"MJXc-Node-4\" class=\"mjx-mi\"&gt;&lt;span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.249em; padding-bottom: 0.311em;\"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"&gt;&lt;span id=\"MJXc-Node-5\" class=\"mjx-mn\" style=\"\"&gt;&lt;span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.373em; padding-bottom: 0.373em;\"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span id=\"MJXc-Node-6\" class=\"mjx-mo MJXc-space2\"&gt;&lt;span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.311em; padding-bottom: 0.434em;\"&gt;+&lt;/span&gt;&lt;/span&gt;&lt;span id=\"MJXc-Node-7\" class=\"mjx-mn MJXc-space2\"&gt;&lt;span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.373em; padding-bottom: 0.373em;\"&gt;3&lt;/span&gt;&lt;/span&gt;&lt;span id=\"MJXc-Node-8\" class=\"mjx-mo MJXc-space3\"&gt;&lt;span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.065em; padding-bottom: 0.311em;\"&gt;=&lt;/span&gt;&lt;/span&gt;&lt;span id=\"MJXc-Node-9\" class=\"mjx-mn MJXc-space3\"&gt;&lt;span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.373em; padding-bottom: 0.373em;\"&gt;3232&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"&gt;&lt;math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;3232&lt;/mn&gt;&lt;/math&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;script type=\"math/tex; mode=display\" id=\"MathJax-Element-1\"&gt;x_2+3=3232&lt;/script&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\nПонятное дело html полученный из voila выглядит значительно солиднее."
  },
  {
    "objectID": "python/numpy/functions.html",
    "href": "python/numpy/functions.html",
    "title": "fromfunciton",
    "section": "",
    "text": "Тут я собираю сведения о функция numpy которымы должен пользоваться или постоянно забываю как\n\nimport numpy as np\n\nПозволяет создать numpy.array используя правило задаваемое через функцию.\n\nnp.fromfunction(lambda i, j: i*3 + j, (4,4))\n\narray([[ 0.,  1.,  2.,  3.],\n       [ 3.,  4.,  5.,  6.],\n       [ 6.,  7.,  8.,  9.],\n       [ 9., 10., 11., 12.]])\n\n\n\nnumpy всегда оперирует массивами\nСледует помнить, что numpy всегда оперирует массивами. Рассмотрим пример кода из следующей ячейки. Тут предполагается возвращать для четной суммы индексов строковое значение “четная” а для не четной суммы индексов “нечетная”.\n\nnp.fromfunction(\n    lambda i,j:\"Четая\" if i&gt;j else \"Не четная\",\n    (4,4)\n)\n\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n\n\nДля того, чтобы разобраться почему так происходит, выведем параметы, которые приходят в функцию-правило переданную fromfunction.\n\ndef test_func(i,j):\n    print(i)\n    print(j)\n    return 0\n\nnp.fromfunction(test_func, (4,4))\n\n[[0. 0. 0. 0.]\n [1. 1. 1. 1.]\n [2. 2. 2. 2.]\n [3. 3. 3. 3.]]\n[[0. 1. 2. 3.]\n [0. 1. 2. 3.]\n [0. 1. 2. 3.]\n [0. 1. 2. 3.]]\n\n\n0\n\n\nИтак, приходят матрицы с индексами по строчкам для аргумента i и по столбцам для аргумента j.\n\nnp.fromfunction(\n    lambda i,j: np.where((i+j)%2==0, \"четная\", \"нечетная\"),\n    (4,4)\n)\n\narray([['четная', 'нечетная', 'четная', 'нечетная'],\n       ['нечетная', 'четная', 'нечетная', 'четная'],\n       ['четная', 'нечетная', 'четная', 'нечетная'],\n       ['нечетная', 'четная', 'нечетная', 'четная']], dtype='&lt;U8')"
  },
  {
    "objectID": "python/numpy/set_printoptions.html",
    "href": "python/numpy/set_printoptions.html",
    "title": "Источники информации",
    "section": "",
    "text": "В numpy, как оказалось можно настроить вывод инофрмации на в консоль, делается это с помощью функции set_printoptions, которой и посвящена эта книжка, далее я постепенно разбираю аргументы функции, распространенные и интерестные случаи из моей практики связанные с этой функцией.\n\nimport numpy as np\n\nnp.random.seed(1)\n# эксперементальный набор данных, который будет исопльзоваться для описания большинства примеров\narr = np.random.uniform(-10, 10, 20)\n\n\nhttps://numpy.org/doc/stable/reference/generated/numpy.set_printoptions.html. \n\n\nДалее разоран каждый аргумент:\n\nprecision;\nthreshold;\nedgeitems;\nlinewidth;\nsuppress;\nnanstr;\ninfstr;\nsing;\nformatter;\nfloatmode;\nlegacy.\n\n\n\nprecision\nПозволяет настроить сколько знаков после запятой numpy будет отображать. По умолчанию 8.\n\nprint(\"precision = 3\")\nnp.set_printoptions(\n    precision = 3\n)\nprint(arr)\nprint(\"precision = 5\")\nnp.set_printoptions(\n    precision = 5\n)\nprint(arr)\n\nprecision = 3\n[-1.66   4.406 -9.998 -3.953 -7.065 -8.153 -6.275 -3.089 -2.065  0.776\n -1.616  3.704 -5.911  7.562 -9.452  3.409 -1.654  1.174 -7.192 -6.038]\nprecision = 5\n[-1.65956  4.40649 -9.99771 -3.95335 -7.06488 -8.15323 -6.2748  -3.08879\n -2.06465  0.77633 -1.61611  3.70439 -5.91096  7.56235 -9.45225  3.40935\n -1.6539   1.1738  -7.19226 -6.03797]\n\n\n\n\nthreshold\nПозволяет настроить насколько большие массивы будут выводиться без “сокращения”. (По умолчанию 1000)\n\nprint(\"threshold = 20; приведёт к полному отображению массива\")\nnp.set_printoptions(threshold = 20)\nprint(arr)\nprint(\"threshold = 19; приведёт к сокращенному отображению массива\")\nnp.set_printoptions(threshold = 19)\nprint(arr)\n\nthreshold = 20; приведёт к полному отображению массива\n[-1.65956  4.40649 -9.99771 -3.95335 -7.06488 -8.15323 -6.2748  -3.08879\n -2.06465  0.77633 -1.61611  3.70439 -5.91096  7.56235 -9.45225  3.40935\n -1.6539   1.1738  -7.19226 -6.03797]\nthreshold = 19; приведёт к сокращенному отображению массива\n[-1.65956  4.40649 -9.99771 ...  1.1738  -7.19226 -6.03797]\n\n\n\n\nedgeitems\nУкажет сколько в сокращенном отображении массива должно элементов отображаться с каждой стороны. По умолчанию 3.\n\nnp.set_printoptions(\n    edgeitems=3,\n    threshold=0 #для того, \n    # чтобы заставить любой массив\n    # отображаться в сокращенной форме\n)\nprint(\"edgeitems=3\")\nprint(arr)\nnp.set_printoptions(\n    edgeitems=5\n)\nprint(\"edgeitems=5\")\nprint(arr)\n\nedgeitems=3\n[-1.65956  4.40649 -9.99771 ...  1.1738  -7.19226 -6.03797]\nedgeitems=5\n[-1.65956  4.40649 -9.99771 -3.95335 -7.06488 ...  3.40935 -1.6539\n  1.1738  -7.19226 -6.03797]\n\n\n\n\nlinewidth\nСколько символов будет отображено в каждой строке, по умолчанию используется 75. [ и \\n тоже учитываются. Потому всегда получается на 3 символа из массива меньше. Похоже результат приблизительный, потому как указанное linewidth может быть не кратно числу символов матрицы. Более того, строки бывают разные - минусы, и значение аргумента precision будут влиять на длинну строк.\nВот пару примеров\nlinewidth = 40\n\nnp.set_printoptions(\n    linewidth = 40,\n    threshold=1000 # для того, чтобы вне зависимости\n    # от предыдущих дейсвий отображался полный массив\n)\nprint(arr)\n\nprint(\"Число символов по строкам (\\\\n был удален)\")\nmatr_strs = str(arr).split(\"\\n\")\n[len(s) for s in matr_strs]\n\n[-1.65956  4.40649 -9.99771 -3.95335\n -7.06488 -8.15323 -6.2748  -3.08879\n -2.06465  0.77633 -1.61611  3.70439\n -5.91096  7.56235 -9.45225  3.40935\n -1.6539   1.1738  -7.19226 -6.03797]\nЧисло символов по строкам (\\n был удален)\n\n\n[36, 36, 36, 36, 37]\n\n\nlinewidth = 20\n\nnp.set_printoptions(\n    linewidth = 20,\n    threshold=1000 # для того, чтобы вне зависимости\n    # от предыдущих дейсвий отображался полный массив\n)\nprint(arr)\n\nprint(\"Число символов по строкам (\\\\n был удален)\")\nmatr_strs = str(arr).split(\"\\n\")\n[len(s) for s in matr_strs]\n\n[-1.65956  4.40649\n -9.99771 -3.95335\n -7.06488 -8.15323\n -6.2748  -3.08879\n -2.06465  0.77633\n -1.61611  3.70439\n -5.91096  7.56235\n -9.45225  3.40935\n -1.6539   1.1738\n -7.19226 -6.03797]\nЧисло символов по строкам (\\n был удален)\n\n\n[18, 18, 18, 18, 18, 18, 18, 18, 17, 19]\n\n\n\n\nsuppress\nОпределяет, будет ли использована экспоненциальная форма записи числа. В случае True числа всегда будут печататьсяв привычном формате, будучи сокращенными в соответствии со значением аргумента precision. В случае False, если в массиве находится число менее 0.0001 или отношение максимального и модуля минимального элемента массива составляет более 1000, весь массив будет напечатан в экспоненциальной форме. По умолчанию всегда False.\n\nОдно маленькое число (&lt;0.0001)\n\nunavailible_number = np.array([0.000099])\navailible_number = np.array([0.0001])\n\nnp.set_printoptions(\n    suppress = True,\n    linewidth = 20, # это для того, чтобы числа\n    # помещались в вывод\n    precision = 8 # это чтобы числа, которые я указал\n    # не округлились автоматически\n)\n\nprint(\"=================suppress = True================\")\nprint(\"availible number\", availible_number)\nprint(\"unavailible number\", unavailible_number, end = \"\\n\\n\\n\")\n\nnp.set_printoptions(suppress = False)\n\nprint(\"=================suppress = False================\")\nprint(\"availible number\", availible_number)\nprint(\"unavailible number\", unavailible_number)\n\n=================suppress = True================\navailible number [0.0001]\nunavailible number [0.000099]\n\n\n=================suppress = False================\navailible number [0.0001]\nunavailible number [9.9e-05]\n\n\n\n\nОтношение максимального числа к минимальному составляет более 1000\n\navailible_arr = np.array([1.0, 1000])\nunavailible_arr = np.array([1.0, 1001])\n\nnp.set_printoptions(\n    suppress = True,\n    linewidth = 20, # это для того, чтобы числа\n    # помещались в вывод\n    precision = 8 # это чтобы числа, которые я указал\n    # не округлились автоматически\n)\n\nprint(\"=================suppress = True==================\")\nprint(\"unavailible arr\", unavailible_arr)\nprint(\"availible arr\", availible_arr, end=\"\\n\\n\\n\")\n\nnp.set_printoptions(suppress = False)\nprint(\"=================suppress = False==================\")\nprint(\"unavailible arr\", unavailible_arr)\nprint(\"availible arr\", availible_arr, end=\"\\n\\n\\n\")\n\n=================suppress = True==================\nunavailible arr [   1. 1001.]\navailible arr [   1. 1000.]\n\n\n=================suppress = False==================\nunavailible arr [1.000e+00\n 1.001e+03]\navailible arr [   1. 1000.]\n\n\n\n\n\n\nЗаметим, что это работет только для массивов типа float\n\nnp.set_printoptions(suppress = False)\n\nprint(\"int не меняются\")\nints_arr = np.array([1, 1001])\nprint(ints_arr, end = \"\\n\\n\\n\")\n\nfloats_arr = np.array([1.0, 1001])\nprint(\"float меняется\")\nprint(floats_arr)\n\nint не меняются\n[   1 1001]\n\n\nfloat меняется\n[1.000e+00\n 1.001e+03]\n\n\n\n\n\nnanstr\nПозволяет настроить как будет отображен np.NaN в коммандном окне. По умолчанию 'nan'.\n\nnp.set_printoptions(nanstr = \"Нет данных\")\n\nnan_arr = np.fromfunction(\n    lambda i, j: np.where(\n        (i+j)%2, 0, np.NaN\n    ),\n    (4,4)\n)\n\nnan_arr\n\narray([[Нет данных,\n                0.,\n        Нет данных,\n                0.],\n       [        0.,\n        Нет данных,\n                0.,\n        Нет данных],\n       [Нет данных,\n                0.,\n        Нет данных,\n                0.],\n       [        0.,\n        Нет данных,\n                0.,\n        Нет данных]])\n\n\n\n\ninfstr\nПозволяет настроить как будет отображент np.inf в коммандном окне. По умолчанию 'inf'\n\nnp.set_printoptions(infstr = \"Бесконечность\")\n\nnan_arr = np.fromfunction(\n    lambda i, j: np.where(\n        (i+j)%2, -np.inf, np.inf\n    ),\n    (4,4)\n)\n\nnan_arr\n\narray([[ Бесконечность,\n        -Бесконечность,\n         Бесконечность,\n        -Бесконечность],\n       [-Бесконечность,\n         Бесконечность,\n        -Бесконечность,\n         Бесконечность],\n       [ Бесконечность,\n        -Бесконечность,\n         Бесконечность,\n        -Бесконечность],\n       [-Бесконечность,\n         Бесконечность,\n        -Бесконечность,\n         Бесконечность]])\n\n\n\n\nsign\nПозволяет определить как будет при выводе записан символ + для положительных дробных чисел, может принимать значения:\n\n'-' будет обозначать, что знак + следует просто опускать;\n'+' будет обозначать, что знак + будет явно записан;\n' ' будет обозначать, что знак на месте каждого знака + будет помещен ' ' (пробел).\n\nПо умолчанию используется значение '-'.\n\nnp.set_printoptions(\n    sign = '-',\n    linewidth = 10\n)\nprint(np.array([1.0]))\n\nnp.set_printoptions(sign = '+')\nprint(np.array([1.0]))\n\nnp.set_printoptions(sign = ' ')\nprint(np.array([1.0]))\n\n[1.]\n[+1.]\n[ 1.]\n\n\n\nЗамети, что это работает только для типа данных float\n\nnp.set_printoptions(sign = ' ')\nnp.array([1])\n\narray([1])\n\n\n\n\nЭто не работает когда numpy подгоняет под отображение матрицей\nВ следующем примере, по идее, не отрицательные числа должны не иметь пробелов вместо минуса, но для того, чтобы матрица была “ровная”, подставляется побел.\n\nnp.set_printoptions(\n    sign = '-',\n    linewidth = 40\n)\narr\n\narray([-1.65955991,  4.40648987,\n       -9.9977125 , -3.95334855,\n       -7.06488218, -8.1532281 ,\n       -6.27479577, -3.08878546,\n       -2.06465052,  0.77633468,\n       -1.61610971,  3.70439001,\n       -5.91095501,  7.56234873,\n       -9.45224814,  3.4093502 ,\n       -1.65390395,  1.17379657,\n       -7.19226123, -6.03797022])\n\n\n\n\n\nformatter\nПозволяет для каждого типа определить функцию как элементы этого массива будут преобразованы в функции. Функция ожидает словарь, в котором для каждого типа массива numpy может быть указан способ превращения в строку. Более подробно о всех типах можно уздать из оффициальной документации. Мы же рассмотрим только случаи показавшиеся мне интерестными:\n\nБазовый случай рассмотрим с использованием типа данных bool\n\nbool_exprimental = np.array([True, False])\ndef bool_formatter(val):\n    return \"Истинна\" if val else \"Ложь\"\n\nnp.set_printoptions(\n    formatter={'bool':bool_formatter}\n)\nprint(\"bool dtype\")\nprint(bool_exprimental)\n\nprint(\"int dtype\")\nprint(arr)\n\nbool dtype\n[Истинна Ложь]\nint dtype\n[-1.65955991  4.40648987 -9.9977125\n -3.95334855 -7.06488218 -8.1532281\n -6.27479577 -3.08878546 -2.06465052\n  0.77633468 -1.61610971  3.70439001\n -5.91095501  7.56234873 -9.45224814\n  3.4093502  -1.65390395  1.17379657\n -7.19226123 -6.03797022]\n\n\nИспользование пустого словаря переданного formatter приведёт к отмене всех установлленых функций форматирования.\n\nnp.set_printoptions(formatter={})\nprint(bool_exprimental)\n\n[ True False]\n\n\n\n\nКлюч all позволит применить этот форматер ко всем типам данных\nВ следующем примере для ключа all применяется функция которая для чисел типа numpy.float64 вернет Дробное а для любого другого числа Что-то ещё.\n\nnp.set_printoptions(\n    formatter = {\n        'all' : lambda val: \n        \"Дробное\" if type(val) == np.float64 else \"Что-то ещё\"\n    }\n)\n\nprint(\"float64 примет вид\")\nprint(arr)\nprint(\"int64 примет вид\")\nprint(np.array([0, 1, 2, 3]))\n\nfloat64 примет вид\n[Дробное Дробное Дробное Дробное\n Дробное Дробное Дробное Дробное\n Дробное Дробное Дробное Дробное\n Дробное Дробное Дробное Дробное\n Дробное Дробное Дробное Дробное]\nint64 примет вид\n[Что-то ещё Что-то ещё Что-то ещё\n Что-то ещё]\n\n\nИнтерестно, какой из ключей будет приоритетнее all или для некоторого конкретного типа.\n\nnp.set_printoptions(\n    formatter = {\n        'bool' : lambda x: \"ключ для bool\",\n        'all' : lambda x: \"ключ для all\"\n    }\n)\n\nbool_array = np.random.choice([True, False], 20)\nbool_array\n\narray([ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool,\n       ключ для bool, ключ для bool])\n\n\nПохоже, ключ определнного типа имеет приоритет.\n\n\n\nfloatmode\nПозволяет уточникть повередение преобразования дробных чисел в случае, если precision имеет спорное знечение. Вообще все сводится к двум случаям: - Число не может быть однозначно определено используя столько знаков; - Для однозначного определения числа слишком много знаков.\nВ следующем массиве при precision = 3 представлены оба случая.\n\nnp.set_printoptions(precision = 3)\n\ntest_arr = np.array(\n    [0.4839, 0.7]\n)\n\nДалее рассмотрим значения, которые может принимать floatmode.\n\nfixed\nОзначат безприкословное исполнение числа символов указанное, в precision. То есть неоднозначно определяемые числа будут округлены а числа с излишним количесвом знаков для однозначного определния будут дополнены 0.\n\nnp.set_printoptions(\n    floatmode = 'fixed',\n    precision = 3\n)\n\ntest_arr\n\narray([0.484, 0.700])\n\n\n\n\nunique\nОзанчает, что будет использовано ровно столько знаков, сколько требуется для однозначного определения числа. По сути, это эквивалентно полному игнорированию аргумента precision.\n\nnp.set_printoptions(\n    floatmode = 'unique'\n)\n\ntest_arr\n\narray([0.4839, 0.7   ])\n\n\n\n\nmaxprec\nИспользуется не более чем precision цифр. То есть, несмотря на неоднозначно определяемые числа используется не более precision знаков, а для числа, содеражащего менее precision цифр не происходит автодополнения нулями.\n\nnp.set_printoptions(floatmode = \"maxprec\")\ntest_arr\n\narray([0.484, 0.7  ])\n\n\n\n\nmaxprec_equal\nБудет обозначать что используется всегда не более precision знаков. Но, в случае, если ни для однозначного определния любого из чисел требуется меньше знаков чем precision то будет использовано ровно столько занков сколько требуется. При этом все числа имеют одинаковое число выводимых знаков, т.е. вслучае если число (\\(a\\)) однозначно определяется меньшим числом знаков нежели число определившие число знаков, то число \\(a\\) при выводе будет дополнено нулями.\n\nnp.set_printoptions(floatmode = \"maxprec_equal\")\nprint('требуется 4 занка для определения первого числа')\nprint(test_arr)\nprint('требуется 2 знака для определения первого числа')\nprint(np.array([0.55, 0.5]))\n\nтребуется 4 занка для определения первого числа\n[0.484 0.700]\nтребуется 2 знака для определения первого числа\n[0.55 0.50]\n\n\n\n\n\nlegacy\nИспользуется для ограницазции поддержки старого когда. Может быть использован для возврата к версиям:\n\n1.13;\n1.21;\nFalse - гворит о том, что не надо использовать legacy.\n\n\n1.13\nИз документации удалось выяснить только что предыдущие версии отличаются заменой знака на пропуск для полижительного числа. В документации упоминаются и прочие особенности отображения для нульмерных массивов, которые до сих поа для меня остаются загадкой.\n\ntest_arr = np.array([1.123456789])\n\nnp.set_printoptions(legacy = False)\nprint(test_arr)\n\nnp.set_printoptions(legacy = '1.13')\nprint(test_arr)\n\n[1.123]\n[ 1.123]\n\n\n\n\n1.21\nУтвержается об сособенностях в отображении для сложных структурных типов. Но пока о об таких типах мне тоже не известно, потому, пока просто будем иметь эту возможность ввиду.\n\ntest_arr = np.array(\n    [('Rex', 9, 81.0), ('Fido', 3, 27.0)],\n    dtype=[('name', 'U10'), ('age', 'i4'), ('weight', 'f4')]\n)\n\nnp.set_printoptions(legacy = False)\nprint(test_arr)\n\nnp.set_printoptions(legacy = '1.21')\nprint(test_arr)\n\n[('Rex', 9, 81.) ('Fido', 3, 27.)]\n[('Rex', 9, 81.) ('Fido', 3, 27.)]"
  },
  {
    "objectID": "python/class_spesials/python_class_specials.html",
    "href": "python/class_spesials/python_class_specials.html",
    "title": "Источники информации",
    "section": "",
    "text": "Разбор спецальных меодов/полей в языке программирования python3"
  },
  {
    "objectID": "python/class_spesials/python_class_specials.html#методы-метаклассов",
    "href": "python/class_spesials/python_class_specials.html#методы-метаклассов",
    "title": "Источники информации",
    "section": "Методы метаклассов",
    "text": "Методы метаклассов\n\n__instancecheck__\nДоступен пример использования https://github.com/Dranikf/knowledge_bank/blob/main/python_class_interface/python_class_interface.ipynb (см. раздел “Использование метаклассов”)\nБудет вызван для класса при использовании встроенной функции isinstace(instance, class) - функции которая (при __instancecheck__ оставленного по умолчанию) вернет True если первый аргумент экземпляр класса указанного вторым.\n\nisinstance(Auto(\"Gelentvagen\"), TechThing)\n\n__isinstacecheck__ called\nGelentvagen удачно был удален\n\n\nTrue\n\n\nПритом, ход приведенный в следующей ячейке, не сработает.\n\nisinstance(Auto(\"Toyota\"), Auto)\n\nToyota удачно был удален\n\n\nTrue\n\n\nВидимо потому, что в класс Auto не указан метакласс Thing как это сделано для класса TechThing. Весьма обывательское объяснение, но возможно в будующем я буду знать об этой концепции больше.\n\n\n__subclasscheck__\nДоступен пример использования https://github.com/Dranikf/knowledge_bank/blob/main/python_class_interface/python_class_interface.ipynb (см. раздел “Использование метаклассов”)\nБудет вызван для класса при использовании встроенной функции issubclass(class1, class2) которая (при __subclasscheck__ оставленной по умолчанию), вернет True если class1 наследник class2.\n\nissubclass(Auto, TechThing)\n\n__issubclasscheck__ called\n\n\nTrue\n\n\nПритом, ход приведенный в следующей ячейке, сработает, в отличии от аналогичной ситуации для другого специального метода метаклассов __instancecheck__.\n\nissubclass(Auto, Machine)\n\n__issubclasscheck__ called\n\n\nTrue\n\n\nПочему так, на данном этапе погружения в pyhton, остается загадкой."
  },
  {
    "objectID": "python/class_spesials/python_class_specials.html#методы-приведения-к-типу",
    "href": "python/class_spesials/python_class_specials.html#методы-приведения-к-типу",
    "title": "Источники информации",
    "section": "Методы приведения к типу",
    "text": "Методы приведения к типу\n\n__bool__\nЭтот метод будет вызван для любого экземпляра переданного в базовую функцию bool\n\nprint(\"Gili result\", bool(Auto(\"Gili\")))\nprint(\"None result\", bool(Auto(None)))\n\nGili удачно был удален\nGili result True\nNone удачно был удален\nNone result False\n\n\n\n\n__complex__\nЭтот метод будет вызваться при передече экземпляра класса в функцию complex. complex производит преведение переданного объекта к типу complex. В данном случае я в преобразование заложил чтобы действительная и мнимая части числа были равны числу букв в марке автомобиля.\n\ncomplex(Auto(\"Lexus\"))\n\nLexus удачно был удален\n\n\n(5+5j)\n\n\n\n\n__float__\nЭтот метод будет вызваться при предаче экземпляра класса в функцию float. float произодит приведение переданного объекта к типу float. В данном случае я в преобразование заложил, чтобы возвращалось число символов в поле marka преобарзованное к типу float\n\nfloat(Auto(\"Hyundai\"))\n\nHyundai удачно был удален\n\n\n7.0\n\n\n\n\n__int__\nЭтот метод будет вызываться при передаче экземпляра класса в функцию int. int производит приведенение переданного объекта к типу int. В данном случае я в преобразование заложил, чтобы приведение означало подсчет числа символов в марке автомобиля.\n\nint(Auto(\"Mitsubishi\"))\n\nMitsubishi удачно был удален\n\n\n10\n\n\n\n\n__str__\nЭтот метод будет вызываться при передаче экземпляра класса в функцию str. str производит приведение переданного объекта к строковому типу. В данном случае я в преобразование заложил, чтобы приведение просто возвращало марку автомобиля.\n\nstr(Auto(\"Honda\"))\n\nHonda удачно был удален\n\n\n'Honda'"
  },
  {
    "objectID": "python/class_spesials/python_class_specials.html#методы-для-работы-с-индексами",
    "href": "python/class_spesials/python_class_specials.html#методы-для-работы-с-индексами",
    "title": "Источники информации",
    "section": "Методы для работы с индексами",
    "text": "Методы для работы с индексами\n\n__setitem__\nМетод, который будет вызваться при использовании оператора [] с присвоением. В метод __setitem__ должен содерать два аргумента: 1. индекс - объект указонный в скобках; 2. значение - присваимое заначение (после оператора =).\nБыл заложен смысл извлечения замены символа в марке автомобиля.\n\nmaz_car = Auto(\"Maserati\")\nmaz_car[3] = \"t\"\nprint(maz_car)\n\nMastrati удачно был удален\nMastrati\n\n\n\n\n__getitem__\nМетод, который будет вызваться при использовании оператора [], для извелечения значения. В данном случае, индекс используется как индекс марки автомобиля.\n\nbug_car = Auto(\"Bugatti\")\nbug_car[:3]\n\n'Bug'\n\n\n\n\n__delitem__\nМетод, который будет вызываться при использовании оператора [] вместе с оператором del. В данном случае, из марки автомобиля\n\nbmw_car = Auto(\"BMW\")\ndel bmw_car[1]\nbmw_car.marka\n\nBW удачно был удален\n\n\n'BW'\n\n\n\n\nМножественный индекс\nПри передаче множественного индекса, функции __setitem__, __getitem__ и __delitem__ в аргуметы соответвующие индексу получают картеж.\n\nind_exmpl = indexer_example()\n\nind_exmpl[3,4,5,\"str index\"]\n\nпришёл инедкс (3, 4, 5, 'str index')\n\n\n\n\nОпретор : внутри индекса\nПри использовании : внутри индекса в методы отвечающие за управление поведением класса придет slice\n\nind_exmpl = indexer_example()\n\nind_exmpl[:3]\n\nпришёл инедкс slice(None, 3, None)"
  },
  {
    "objectID": "python/class_spesials/python_class_specials.html#протокол-итерации",
    "href": "python/class_spesials/python_class_specials.html#протокол-итерации",
    "title": "Источники информации",
    "section": "Протокол итерации",
    "text": "Протокол итерации\nИли методы которые делают экземпляры класса iterable.\n\n__iter__\nВызывается для того, что-бы “предупредить” объект, что по нему будут итерироваться - можно провести некоторый процессинг, который будет готовить этот класс к итерированию по нему. Будет вызван при: - Передаче экземпляра в функцию iter(); - При использовании после оператора in в цикле for.\nОжидается возврат любого объекта у которого переопределен метод __next__. Чаще всего возврящают self но не всегда.\n\n\n__next__\nОпределяет что класс будет возвращать при каждой следующей итерации по нему. Будет вызван при: - Передаче экземпляра в фнукцию next(); - При каждой идерации цикла for по объекту.\nВозвращать следует, то что должно попасть в теририрующую переменную на этой итерации. В момент, когда требуется прeкратить процесс итерирования следует использовать raise StopIteration.\n\n\nБазовый пример\nЭти операторы лучше рассматривать в комбинации, потому общий пример для них:\n\nclass ar_progression_shower:\n    '''\n        Класс имплементирует расчет элементов\n        арифметической прогрессии до определенного\n        наблюдения в прогрессии\n    '''\n    def __init__(self, a0 = 0, n = 5, d = 3):\n        self.n = n\n        self.a0 = a0\n        self.d = d\n        \n    def __iter__(self):\n        print(\"был вызван __iter__\")\n        self.i = 0\n        self.curr_a = self.a0\n        return self\n    \n    def __next__(self):\n        print(\"был вызван __next__\")\n        if self.i &lt; self.n:\n            self.curr_a = self.a0 + self.d*self.i\n            self.i += 1\n            return \"{} : {}\".format(self.i-1, self.curr_a)\n        else:\n            print(\"вызван StopIteration\")\n            raise StopIteration\n        \n        \n        \nexample_iter = ar_progression_shower()\n\nМожно использовать методы iter() и next().\n\niter(example_iter)\n\nprint(next(example_iter))\nprint(next(example_iter))\nprint(next(example_iter))\nprint(next(example_iter))\nprint(next(example_iter))\n\nбыл вызван __iter__\nбыл вызван __next__\n0 : 0\nбыл вызван __next__\n1 : 3\nбыл вызван __next__\n2 : 6\nбыл вызван __next__\n3 : 9\nбыл вызван __next__\n4 : 12\n\n\nНо в случае, если вывалиться за допустииое число итераций. Вывод будет следующий.\n\niter(example_iter)\n\nprint(next(example_iter))\nprint(next(example_iter))\nprint(next(example_iter))\nprint(next(example_iter))\nprint(next(example_iter))\nprint(next(example_iter))\n\nбыл вызван __iter__\nбыл вызван __next__\n0 : 0\nбыл вызван __next__\n1 : 3\nбыл вызван __next__\n2 : 6\nбыл вызван __next__\n3 : 9\nбыл вызван __next__\n4 : 12\nбыл вызван __next__\nвызван StopIteration\n\n\nStopIteration: \n\n\nВсе те-же самые результаты при использовании цикла.\n\nfor val in example_iter:\n    print(val)\n\nбыл вызван __iter__\nбыл вызван __next__\n0 : 0\nбыл вызван __next__\n1 : 3\nбыл вызван __next__\n2 : 6\nбыл вызван __next__\n3 : 9\nбыл вызван __next__\n4 : 12\nбыл вызван __next__\nвызван StopIteration\n\n\n\ntype(iter(example_iter))\n\nбыл вызван __iter__\n\n\n__main__.ar_progression_shower\n\n\n\n\nФишки\n\nБез __next__\n\nclass test:\n    def __iter__(self):\n        return self\n    \niter(test())\n\nTypeError: iter() returned non-iterator of type 'test'\n\n\n\nclass test:\n    def __next__(self):\n        return 0\n    def __iter__(self):\n        return self\n    \niter(test())\n\n&lt;__main__.test at 0x7f081022c220&gt;\n\n\n\n\nlist/tuple/dict как результат __iter__\nСами по себе эти пипы не переопределяют __next__, как следвие, вернуть их как из __iter__ не получится.\n\nclass test():\n    def __iter__(self):\n        return [10, 20, 30, 40]\n    \niter(test())\n\nTypeError: iter() returned non-iterator of type 'list'\n\n\n\nclass test():\n    def __iter__(self):\n        return (10, 20, 30, 40)\n    \niter(test())\n\nTypeError: iter() returned non-iterator of type 'tuple'\n\n\n\nclass test():\n    def __iter__(self):\n        return {\"a\":10, \"b\":20, \"c\":30, \"d\":40}\n    \niter(test())\n\nTypeError: iter() returned non-iterator of type 'dict'\n\n\nНо можно вернуть результат передачи их функции iter(). Обращею отдельное внимание на типы данных результатов.\n\nclass test():\n    def __iter__(self):\n        return iter([10, 20, 30, 40])\n    \ntype(iter(test()))\n\nlist_iterator\n\n\n\nclass test():\n    def __iter__(self):\n        return iter((10, 20, 30, 40))\n    \ntype(iter(test()))\n\ntuple_iterator\n\n\n\nclass test():\n    def __iter__(self):\n        return iter({\"a\":10, \"b\":20, \"c\":30, \"d\":40})\n    \ntype(iter(test()))\n\ndict_keyiterator"
  },
  {
    "objectID": "python/class_spesials/python_class_specials.html#другие-методы",
    "href": "python/class_spesials/python_class_specials.html#другие-методы",
    "title": "Источники информации",
    "section": "Другие методы",
    "text": "Другие методы\n\n__init__\nБудет вызван при создании экземпляра класса\n\nAuto(\"mersedes\").marka\n\nmersedes удачно был удален\n\n\n'mersedes'\n\n\n\n\n__del__\nБудет вызван при удалении экземпляра класса\n\na = Auto(\"москвич\")\ndel a\n\nмосквич удачно был удален\n\n\n\n\n__call__\nВызывается при попытке “вызвать” экземпляр класса, то есть ипользование оператора () для экземплара класса.\n\nAuto(\"tesla\")()\n\ntesla удачно был удален\n\n\n'вы вызвали tesla'\n\n\n\n\n__len__\nВызывается при передаче экземпляра в функцию базовую функцию len. В данном случае я заложил возврат числа символов в марке.\n\nlen(Auto(\"Mazda\"))\n\nMazda удачно был удален\n\n\n5\n\n\n\n\n__index__\nВызывается при передаче экземпляра в одну из базовых функций bin, oct и hex. Вернуть из __index__ следует число, которое в зависимости от вызванной функции будет преобразовано соответсвенно к соответсвующей системе исчисления. В данном случае __index__ всегда возвращает число 17.\n\nmy_auto = Auto(\"Lambargini\")\n\nprint(\"Приведение к бинарному виду \", bin(my_auto))\nprint(\"Приведение к восьмеричному виду \", oct(my_auto))\nprint(\"Приведение к шестнадцатиричному виду \", hex(my_auto))\n\nLambargini удачно был удален\nПриведение к бинарному виду  0b10001\nПриведение к восьмеричному виду  0o21\nПриведение к шестнадцатиричному виду  0x11\n\n\n\n\n__round__\nВызвается при передаче экземпляра базовой функции round.\n\njeep_auto = Auto(\"Jeep\")\nround(jeep_auto).marka\n\nJeep rounded удачно был удален\n\n\n'Jeep rounded'"
  },
  {
    "objectID": "python/tkinter/basics.html",
    "href": "python/tkinter/basics.html",
    "title": "Источники",
    "section": "",
    "text": "Отсновы библиотеки tkinter\n\nфайл предоставленный на курсах от belhard по программированию на python (см. в тойже папке, в которой лежит этот .ipynb);"
  },
  {
    "objectID": "python/tkinter/list_box.html",
    "href": "python/tkinter/list_box.html",
    "title": "Источники",
    "section": "",
    "text": "Виджет Listbox из библиотеки tkinter\n\nфайл предоставленный на курсах от belhard по программированию на python (см. в тойже папке, в которой лежит этот .ipynb);\n\n\nСодержание\n\nМетоды;\n\ninsert вставка элементов в Listbox;\nget получение элементов из Listbox;\ndelete удаление элементо из Listbox;\ncurselection\n\nПоля.\n\n\n\nПодготовка\n\nfrom tkinter import *\n\ndef get_l_box():\n    '''\n        Для того, чтобы кратко создавать окно с `Listbox` внутри сделал функию.\n    '''\n    root = Tk()\n\n    lst_box = Listbox()\n    lst_box.pack()\n\n    return root, lst_box\n\ndef insert_123(lst_box):\n    '''\n        Для быстрой вставки\n        one\n        two \n        three\n        в переданный listbox\n    '''\n    for i in (\"one\", \"two\", \"three\"):\n        lst_box.insert(0, i)\n\n\n\nМетоды\n\ninsert\nПроизводит вставку элементов в Listbox\nАгрументы:\n\nИдекс вставки;\n\n\nroot, lst_box = get_l_box()\n\nfor i in (\"one\", \"two\", \"three\"):\n    lst_box.insert(0, i)\n    \nroot.mainloop()\n\n\n\n\nget\nПроизводит извлечение элементов из Listbox\nАргументы для извлечения одного элемента:\n\nиндекс или срез извлекаемых элементов;\n\n\nroot, lst_box = get_l_box()\ninsert_123(lst_box)\n    \nprint(\"Извлечение из индекса '1'\", lst_box.get(1))\n\nroot.mainloop()\n\nИзвлечение из индекса '1' two\n\n\nАргументы для извлечения слеза:\n\nпервый индекс среза;\nпоследний индекс среза.\n\n\nroot, lst_box = get_l_box()\ninsert_123(lst_box)\n    \nprint(\"Извлечение среза с от 0 до 1\", lst_box.get(0,1))\n\nroot.mainloop()\n\nИзвлечение среза с от 0 до 1 ('three', 'two')\n\n\n\n\ndelete\nПроизводит удаление по индексу или срезу.\nАргументы для удаления по индексу:\n\nИндекс удаляемого элемента.\n\n\nroot, lst_box = get_l_box()\ninsert_123(lst_box)\n    \nlst_box.delete(2)\n\nroot.mainloop()\n\n\nАргументы для удаления среза:\n\nпервый индекс среза;\nпоследний индекс среза.\n\n\nroot, lst_box = get_l_box()\ninsert_123(lst_box)\n    \nlst_box.delete(1,2)\n\nroot.mainloop()\n\n\n\n\ncurselection\nПолучение в виде картежа выделенных индексов.\n\nroot, lst_box = get_l_box()\ninsert_123(lst_box)\nlst_box[\"selectmode\"] = EXTENDED\n\ndef print_sel_ind():\n    sel_lab[\"text\"] = lst_box.curselection()\n\nButton(\n    text = \"Вывести индексы\",\n    command = print_sel_ind\n).pack()\n\nsel_lab = Label()\nsel_lab.pack()\n\nroot.mainloop()\n\n\n\n\n\nПоля\n\nselectmode\nОпределяет будет доступен ли множествнный выбор. В следующем примере создаются 2, ListBox в одном из которых доступен множественный выбор во втором нет.\n\nroot, lst_box1 = get_l_box()\nlst_box2 = Listbox(selectmode = EXTENDED)\nlst_box2.pack()\n\nfor i in (\"one\", \"two\", \"three\"):\n    lst_box1.insert(0, i)\n    lst_box2.insert(0,i)\n\nroot.mainloop()"
  },
  {
    "objectID": "python/regex/regex.html",
    "href": "python/regex/regex.html",
    "title": "Источники",
    "section": "",
    "text": "Регулярные выражения (regex)\nТут разберем реализацию регулярных выражений в python. Вообще, конечно, регулярные выражения используются во многих языках программирования и выходят за контекст python. Но никаким языком программирования я и близко так не владею, как владею python (на сегодняшний день). Потому тут будут разбораны и общие идеи лежащие в синтаксисе регулярных выражений. Разбор общих элементов регулярных выражений я надеюсь вынести на уровень выше.\n\nhttps://docs.python.org/3/howto/regex.html#regex-howto статья в официальной докумментации python в которой описаны принципы использования regex."
  },
  {
    "objectID": "python/class_interface/python_class_interface.html",
    "href": "python/class_interface/python_class_interface.html",
    "title": "Иточники",
    "section": "",
    "text": "Изучение того как в python работать с интерфесми (как концепцией)\n\nhttps://realpython.com/python-interface/\n\nИнтерфейс - некоторая абстакция, которая позволяет определить какими методы должны быть обязательно реализованы в наследниках.\n\nНе формальное определение интефейса\nРассмотрим пример - класс парсер. При том там надо реализовать парсеры для pdf документов и для документов из электронной почнты (eml)\n\nclass InformalParserInterface:\n    '''\n        Класс который определят все общее \n        принадлежащее парсерам\n    '''\n    def load_data_source(self, path: str, file_name : str) -&gt; str:\n        '''\n            Пусть пасерам надо доставать данные из различных\n            файлов по пути path\n        '''\n        pass\n    \n    def extrac_text(self, full_file_name: str):\n        '''\n            Пусть всем парсерам надо уметь доставать данные из\n            диррекстивно указанного пути\n        ''' \n        pass\n\nИтак, были описаны возможности которыми должен обладать любой парсер. Далее конктеретизация.\n\nclass PdfParser(InformalParserInterface):\n    '''\n        Конкредная реализация парсера для pdf документов\n    '''\n    def load_data_source(self, path: str, file_name:str) -&gt; str:\n        '''\n            Определяем как именно должен работать парсинг\n            для pdf документов\n        '''\n        pass\n    \n    def extract_text(self, full_file_path:str) -&gt; dict:\n        '''\n            Тут также определяем как именно должен работать \n            парсинг для pdf документов\n        '''\n        pass\n    \nclass EmlParser(InformalParserInterface):\n    '''\n        Конкретная реализация для документов электронной почты\n    '''\n    def load_data_source(self, path:str, file_name:str)-&gt;str:\n        '''\n            Определяем как именно должен работать парсинг для email документов\n        '''\n        pass\n    \n    def extract_text_from_email(self, full_file_path:str)-&gt;str:\n        '''\n            Метод определенный только для документов email,\n            но он по прежнему определяет как должен работать\n            парсинг для email документов\n        '''\n        pass\n\nУбедимся, что подклассы созданные реализации являются классами-наследниками для базового класса InformalParserInterface с использованием функции issubclass\n\nissubclass(PdfParser, InformalParserInterface)\n\nTrue\n\n\n\nissubclass(EmlParser, InformalParserInterface)\n\nTrue\n\n\nИдея, которую доносят в источнике 1, состоит в том, что хорошо чтобы issubclass(EmlParser, InformalParserInterface) возвращало False так как, мы не переопределили extract_text и EmlParser не может считаться полноценной реализацией интерфейса InformalParserInterface.\n\n\nИспользование Метаклассов\nИдея создания интерфейса через метакласс, сосотои в том, что интерфейс имеет метакласс, в котором переопределены. __instancecheck__ и __subclasscheck__ (подробнее об этих базовых методах можно узать тут https://github.com/Dranikf/knowledge_bank/blob/main/python_class_spesials/python_class_specials.ipynb в разделе “Методы-&gt;Методы метаклассов”). Приведенным ниже образом.\n\nclass ParserMeta(type):\n    '''\n        Мета-парсер который будет использоваться для\n        создания парсеров\n    '''\n    def __subclasscheck__(cls, subclass):\n        '''\n            Все классы наследующие этот класс \n            в качесве мета класса будут, будут своими \n            экземплярами (в смысле функции issubclass) \n            воспринимать лишь те классы, в которых объявлены \n            и определены методы load_data_source и extract_text.\n        '''\n        return (\n            hasattr(subclass, 'load_data_source') and\n            callable(subclass.load_data_source) and\n            hasattr(subclass, 'extract_text') and\n            callable(subclass.extract_text)\n        )\n    \n    \n    def __instancecheck__(cls, instance):\n        '''\n            Все классы наследующие это класс в качестве\n            мета класса, своими экземплярами будут воспринимпть\n            лишь те объекты, классы которых воспинимаются\n            наследниками\n        '''\n        return cls.__subclasscheck__(type(instance))\n    \n\n    \nclass UpdatedInformalParserInterface(metaclass = ParserMeta):\n    '''\n        Объявляем обновленный парсер-интерфейс\n    '''\n    pass\n\nРассмотрим, тот-же пример.\n\nclass PdfParserNew():\n    '''\n        Новая конкредная реализация парсера для pdf документов\n    '''\n    def load_data_source(self, path: str, file_name:str) -&gt; str:\n        '''\n            Определяем как именно должен работать парсинг\n            для pdf документов\n        '''\n        pass\n    \n    def extract_text(self, full_file_path:str) -&gt; dict:\n        '''\n            Тут также определяем как именно должен работать \n            парсинг для pdf документов\n        '''\n        pass\n    \nclass EmlParserNew:\n    '''\n        Конкретная реализация для документов электронной почты\n    '''\n    def load_data_source(self, path:str, file_name:str)-&gt;str:\n        '''\n            Определяем как именно должен работать парсинг для email документов\n        '''\n        pass\n    \n    def extract_text_from_email(self, full_file_path:str)-&gt;str:\n        '''\n            Метод определенный только для документов email,\n            но он по прежнему определяет как должен работать\n            парсинг для email документов\n        '''\n        pass\n\nПроверяем результат выполнения функции issubclass для новосозданных классов.\n\nissubclass(PdfParserNew, UpdatedInformalParserInterface)\n\nTrue\n\n\n\nissubclass(EmlParserNew, UpdatedInformalParserInterface)\n\nFalse\n\n\nТак формально UpdatedInformalParserInterface не является реализацией интерфейса EmlParserNew.\nНо такая реализация по прежнему не являтся правильной Рассмотрим результат метода __mro__ для PdfParserNew (__mro__ - одно из специальных полей).\n\nPdfParserNew.__mro__\n\n(__main__.PdfParserNew, __main__.UpdatedInformalParserInterface, object)\n\n\nТак в __mro__ для класса PdfParserNew, не видно, что он как-либо связан с UpdatedInformalParserInterface. Такую ситуалию еще описывают, что UpdatedInformalParserInterface является виртуальным базовым классом для класса PdfParserNew.\nВпрочем, новерное, это можно преодолеть следующей реализацией pdf парсера.\n\nclass PdfParserNew2(UpdatedInformalParserInterface):\n    '''\n        Новая конкредная реализация парсера для pdf документов\n    '''\n    def load_data_source(self, path: str, file_name:str) -&gt; str:\n        '''\n            Определяем как именно должен работать парсинг\n            для pdf документов\n        '''\n        pass\n    \n    def extract_text(self, full_file_path:str) -&gt; dict:\n        '''\n            Тут также определяем как именно должен работать \n            парсинг для pdf документов\n        '''\n        pass\n\n\nissubclass(PdfParserNew2, UpdatedInformalParserInterface)\n\nTrue\n\n\n\nPdfParserNew2.__mro__\n\n(__main__.PdfParserNew2, __main__.UpdatedInformalParserInterface, object)\n\n\n\n\nФормальная реализация интерфейса\nДля формальной реализации интерфейсов используется модуль abc\n\nimport abc"
  },
  {
    "objectID": "machine_learning/var_vs_bias/quadratic.html",
    "href": "machine_learning/var_vs_bias/quadratic.html",
    "title": "Knowledge bank",
    "section": "",
    "text": "import numpy as np\nimport scipy.interpolate as inter\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\nnp.random.seed(4)\n\n# data generation\nx_p = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ny_p = np.array([2, 4, 3, 5, 4, 6, 5, 7, 6, 8, 10])\npoly = inter.lagrange(x_p, y_p)\ndef f(x):\n    X = np.concatenate(\n        [(x**a)[:, np.newaxis] for a in range(len(poly.coef))],\n        axis = 1\n    )\n    return np.dot(X, poly.coef[::-1][:, np.newaxis]).ravel()\n\ny = lambda x: f(x) + np.random.normal(0, 1, x.shape)\n\nX_sample = np.sort(np.random.uniform(0, 10, 200)).astype(np.longdouble)\nY_sample = y(X_sample)\n\n\n# models\ndef get_poly_matrix(X, p = 2):\n    return np.concatenate(\n        [np.array(X)[:, np.newaxis]**(i) for i in range(p+1)],\n        axis = 1\n    )\ndef get_poly_predict(X, y, p = 2):\n    \n    X_matr = get_poly_matrix(X, p)\n    return LinearRegression(\n        fit_intercept=False\n    ).fit(X_matr, y).predict(X_matr)\n\n\nCHANGE_ME = 17\nplt.scatter(X_sample, Y_sample, color = \"black\")\nplt.title(\"polynomial degree \" + str(CHANGE_ME))\nplt.plot(\n    X_sample,\n    get_poly_predict(X_sample, Y_sample, CHANGE_ME),\n    linewidth = 4\n)\nplt.savefig(\"poly16.png\")"
  },
  {
    "objectID": "machine_learning/var_vs_bias/var_vs_bias.html",
    "href": "machine_learning/var_vs_bias/var_vs_bias.html",
    "title": "Введение",
    "section": "",
    "text": "Компромисс дисперсии и смещения\nВ этом notebook я надеюсь подробно разобрать вопрос компромиса между смещением (bias) и дисперсией (variance) в машинном обучении.\nВдохновлено соотсветсвующим разделом в ISLR.\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\n\nimport scipy.interpolate as inter\n\nn = 1000\n\nУтверждается что средне квадратическую ошибку модели (Mean Square Error, MSE) можно разложить на три составляющие: - Дисперсию; - Квардрат смещения; - Неустранимую ошибку.\nИли записывая серез формулу:\n\\[\\mathbb{E}(y_0 - \\hat{f}(x_0))^2 = Var(\\hat{f}(x_0)) + [Bias(\\hat{f}(x_0))]^2 + Var(\\varepsilon). \\tag{1}\\]\nГде: - \\(\\hat{f}(x)\\) - некоторая модель описывающая данные; - \\(x_0\\) - некоторое произвольное контрольное значение предикторов; - \\(y_0\\) - некоторое произвольное контрольное значение оклика; - \\(\\varepsilon\\) - неустранимая ошибка модели (irreducible error); в нее вкладывается та информация о описываемом процессе, которой нет в полученной выборке; - \\(Var(\\hat{f}(x_0))\\) - дисперсия полученной модели; эта величина должна быть тем больше, чем сильнее предстказания модели будут меняться от измениния выбоки; - \\(Bias(\\hat{f}(x_0))\\) - смещение модели эта величина тем меньше, чем точнее модель подогнанна к описываемому просцессу; - \\(Var(\\varepsilon)\\) - дисперсия неустранимой ошибки; чем полнее и точнее наши данные, тем меньше эта величина; - \\(\\mathbb{E}(y_0 - \\hat{f}(x_0))^2\\) - математическое ожидание ошибки полученной модели.\nВ различных источниках к этой теме очень часто прикладывают график подобный этому:\n\nx_plot_range = np.arange(0,0.8, 0.05)\nvariance = 3*(x_plot_range)**2 + x_plot_range\nbias = 3*(x_plot_range)**2 - 4.8*x_plot_range + 2\nirrecible_error = 1\nmodel_error = variance + bias + irrecible_error\n\nplt.figure(figsize = [10, 6])\nplt.plot(x_plot_range, variance)\nplt.plot(x_plot_range, bias)\nplt.axhline(irrecible_error, color = \"gray\", linestyle = \"dashed\")\nplt.plot(x_plot_range, model_error)\n\nplt.xticks([])\nplt.yticks([])\n\nplt.xlabel(\"Сложность модели\", fontsize = 15)\nplt.ylabel(\"Ошибка\", fontsize = 15)\n\nans = plt.legend([\n    \"$Var(\\hat{f}(x_0))$\",\n    \"$Bias(\\hat{f}(x_0))$\",\n    \"$Var(\\\\varepsilon)$\",\n    \"$\\mathbb{E}(y_0 - \\hat{f}(x_0))^2$\"\n])\n\n\n\n\nДалее я на примере простой задачи регрессии попытаюсь провести такой вычислитеньный эксперимент, который приведет именно к такому графику.\n\nИдея эксперимента\nПусть имеется некоторе уравнение которое обисывает некоторых достаточно сложный полином. В следующей ячейке происходит его генерация.\n\nx_p = np.array([0, 1, 2, 3, 4])\ny_p = np.array([2, 4, 3, 5, 4])\npoly = inter.lagrange(x_p, y_p)\n\nИтак, полученный полином записывается в форме:\n\n\\[f(x)=-0.0002+0.0105x^{1}-0.2263x^{2}+2.7223x^{3}-20.1388x^{4}+94.3996x^{5}-278.1615x^{6}+491.6866x^{7}-466.4732x^{8}+178.181x^{9}+2.0x^{10}\\]\n\ndef f(x):\n    X = np.concatenate(\n        [(x**a)[:, np.newaxis] for a in range(len(poly.coef))],\n        axis = 1\n    )\n    return np.dot(X, poly.coef[::-1][:, np.newaxis]).ravel()\n    \nx_range = np.arange(0, 4.01, 0.01)\nans = plt.plot(x_range, f(x_range))\n\n\n\n\nПусть зачение объясняемой переменной объясняется так:\n\\(y = f(x) + \\varepsilon\\)\nПусть для нашего примера \\(\\varepsilon \\sim N(0, 0.5)\\). То есть, по определениею нормального распределения \\(Var(\\varepsilon) = 0.5^2=0.25\\). Таким образом мы можем сгенерировать множество выборок подобных \\((x_i,y_i), i \\in \\overline{1,n}\\). Некторые из них предствлены на рисунке:\n\ny = lambda x: f(x) + np.random.normal(0, 0.5, x.shape)\n\n\nnp.random.seed(20)\nsample_size = 100\nexamples_count = 3\n\nX_samples = np.random.uniform(0, 4, [sample_size, examples_count])\nY_samples = np.concatenate(\n    [\n        y(X_samples[:, col_i])[:, np.newaxis] for col_i in range(examples_count)\n    ],\n    axis = 1\n)\n\nplt.figure(figsize = [5, 10])\nfor i in range(examples_count):\n    plt.subplot(examples_count, 1, i+1)\n    plt.scatter(\n        X_samples[:, i], Y_samples[:,i]\n    )\n    plt.xlabel(\"x\");ans = plt.ylabel(\"y\")\n\n\n\n\nОбычно об \\(f(x)\\) нам ничего, кроме выборки неизвестно. Потому задачу по формированию модели можно поставить следующим образом - найти такое \\(\\hat{f}(x)\\) что-бы оно максимально походило на дейсвительное \\(f(x)\\) располагая только выборкой. Методы подгонки моделей решают задачу оптимальным (или близким к оптимальному) образом при условии, что исследователь определился с идентификационной формой модели. Таким образом, задача, обычно, сводится именно к определению идентификационной формы модели.\n\ndef get_poly_matrix(X, p = 2):\n    return np.concatenate(\n        [np.array(X)[:, np.newaxis]**(i) for i in range(p+1)],\n        axis = 1\n    )\n\ndef get_poly_model(X, y, p = 2):\n    \n    X_matr = get_poly_matrix(X, p)\n    \n    return LinearRegression(\n        fit_intercept=False\n    ).fit(X_matr, y)\n\ndef get_poly_predict(X, y, p = 2):\n    \n    X_matr = get_poly_matrix(X, p)\n    return LinearRegression(\n        fit_intercept=False\n    ).fit(X_matr, y).predict(X_matr)\n\nnp.random.seed(21)\nsample_size = 100\npoly_max = 5\n\nX_sample = np.sort(np.random.uniform(0, 4, sample_size))\nY_sample = y(X_sample)\n\nplt.figure(figsize = [10, 8])\n\nlegend_line = \"\"\nlegend_list = []\n\nfor i in range(poly_max):\n    \n    X_matr = get_poly_matrix(X_sample, p = i)\n    model = LinearRegression(\n        fit_intercept=False\n    ).fit(X_matr, Y_sample)\n    pred = model.predict(X_matr)\n    plt.plot(X_sample, pred, linewidth = 5)\n    \n    eq = \"$f(x)=\"\n    for i, c in enumerate(model.coef_.round(3)):\n        if c != 0:\n            eq += \\\n                (\"+\" if c &gt; 0 and i != 0 else \"\") + \\\n                str(c) + \\\n                (\"x^{{{}}}\".format(i) if i != 0 else \"\")\n    eq += \"$\"\n    legend_list += [eq]\n\n    \nans = plt.scatter(X_sample, Y_sample, color = \"black\")\nplt.legend(legend_list)\n\nplt.xlabel(\"x\", fontsize = 13);ans = plt.ylabel(\"y\", fontsize = 13)\n\n\n\n\n\nplt.figure(figsize = [15, 7])\n\nsample_size = 30\n\nfor i in range(3):\n    for j, p in enumerate([0,4, 10]):\n        \n        plt.subplot(3,3,i+1+3*j)\n        X_sample = np.sort(np.random.uniform(0, 4, sample_size))\n        Y_sample = y(X_sample)\n        X_matrix = np.zeros([sample_size, poly_max])\n\n        plt.scatter(X_sample, Y_sample)\n        plt.plot(\n            X_sample,\n            get_poly_predict(X_sample, Y_sample, p),\n            color = \"black\"\n        )\n\n\n\n\n\nnp.random.seed(30)\nexp_count = 2000\nsample_size = 30\npoly_max = 14\n\nX_matrix = np.zeros([sample_size, poly_max])\n# x_ij - результат i-го эксперимента для j-го полинома\nprediction = np.zeros([exp_count, poly_max])\nresidual = np.zeros([exp_count, poly_max])\n\nfor i in range(exp_count):\n    # генерирую выборку актуальную на этой итерации\n    X_sample = np.random.uniform(0, 4, sample_size)\n    Y_sample = y(X_sample)\n    X_matrix = np.zeros([sample_size, poly_max])\n    \n    # индекс того наблюдения которое будет использоваться для проверки\n    i_0 = 0\n    \n    # пробегаюсь по возможным коэффициентам полинома\n    # подгонаяю соответсвующие модели\n    for j in range(poly_max):\n        pred = get_poly_predict(X_sample, Y_sample, j)\n        prediction[i,j] = pred[i_0]\n        residual[i,j] = (pred[i_0] - Y_sample[i_0])\n\n\nplt.plot(np.var(prediction, axis = 0))\nplt.plot(np.mean(residual**2, axis = 0))\nplt.plot(np.var(prediction, axis = 0) + np.mean(residual**2, axis = 0))\n\n\n\n\n\nnp.argsort(\n    (np.var(prediction, axis = 0) + np.mean(residual**2, axis = 0))\n)\n\narray([ 0,  1, 12, 13, 11,  9, 10,  8,  3,  4,  2,  6,  7,  5])\n\n\nnp.random.seed(30) exp_count = 2000 sample_size = 100 poly_max = 14\nX_matrix = np.zeros([sample_size, poly_max]) # x_ij - результат i-го эксперимента для j-го полинома prediction = np.zeros([exp_count, poly_max]) residual = np.zeros([exp_count, poly_max])"
  },
  {
    "objectID": "machine_learning/metrix/chisquare.html",
    "href": "machine_learning/metrix/chisquare.html",
    "title": "Knowledge bank",
    "section": "",
    "text": "Разбор статистики \\(\\chi^2\\)\nИсточники: - расстояние Пирсона от Анатолия Карпова; - анализ таблиц сопряженности от Анатолия Карпова."
  },
  {
    "objectID": "machine_learning/models_selection_methods/l2_regularisaiton/l2_regularisation.html",
    "href": "machine_learning/models_selection_methods/l2_regularisaiton/l2_regularisation.html",
    "title": "Источники",
    "section": "",
    "text": "Разбор способа отбора модлеи - L2-регуляризация\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom IPython.display import clear_output"
  },
  {
    "objectID": "machine_learning/models_selection_methods/l2_regularisaiton/l2_regularisation.html#описание-1",
    "href": "machine_learning/models_selection_methods/l2_regularisaiton/l2_regularisation.html#описание-1",
    "title": "Источники",
    "section": "Описание",
    "text": "Описание\nL2-регулялизация в сочетании с регрессионной моделью, называются гребеньковой регрессией (ridge regression). Т.е. целевая функция в задаче оптимизации принимает вид:\n\\[\\sum_{i=1}^n\\left(y_i - x_i\\beta\\right)^2 + \\lambda\\sum_{j=1}^p\\beta_j \\rightarrow min\\]\nГде: - \\(n\\) - объемы выборки; - \\(p\\) - размерность данных; - \\(x_i = (x_{i1}, x_{i2}, ..., x_{ip})\\) - вектор описывающий \\(i\\)-е наблюдение; - \\(\\beta = (\\beta_1, \\beta_2, ..., \\beta_p)\\) - вектор оценок коэффициентов."
  },
  {
    "objectID": "machine_learning/models_selection_methods/l2_regularisaiton/l2_regularisation.html#рекомендуется-стандартизация-данных",
    "href": "machine_learning/models_selection_methods/l2_regularisaiton/l2_regularisation.html#рекомендуется-стандартизация-данных",
    "title": "Источники",
    "section": "Рекомендуется стандартизация данных",
    "text": "Рекомендуется стандартизация данных\nПеред применением Гребеньковой регрессии данные рекомендуется стандартизовать по формуле.\n\\[\\tilde{x}_{ij} = \\frac{x_{ij}}{\\sqrt{\\frac{1}{n}\\sum_{i=1}^n (x_{ij} - \\bar{x}_{j})^2}}.\\]\nГде: - \\(\\bar{x}_{j}\\) - среднее значенте по \\(j\\)-му показателю.\nПодробнее о стандартизации можно узнать тут."
  },
  {
    "objectID": "machine_learning/classification_task/metrics/GINI/GINI.html",
    "href": "machine_learning/classification_task/metrics/GINI/GINI.html",
    "title": "Сдержание:",
    "section": "",
    "text": "Описание того, что мне известно о показателе GINI (в задаче классификации)\nGINI метрика используемая для определения качества классификационной модели.\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics import roc_curve, auc\n\nimport matplotlib.pyplot as plt\n\nfrom statsmodels.distributions.empirical_distribution import ECDF\nnp.random.seed(10)\n\n\nБазовое опеределение GINI;\nСвязь GINI c ROC.\n\n\nБазовое определение GINI\n Обычно GINI определяют через CAP кривую. GINI для некоторой модели, это отношение площадей между CAP кривой модели и случайной CAP кривой к площади между идеальной CAP и случайной CAP.\n\nПокажем на рисунке:\n\nplot_ss = 10000\n\nnp.random.seed(3)\nrandom_range = np.random.rand(plot_ss)\n\nplot_data = pd.DataFrame({\n    \"p_hat\" : random_range,\n    \"y\" : map(\n        lambda r_val: np.random.choice(\n            [0, 1], p = [1 - r_val, r_val]\n        ), \n        random_range\n    )\n})\n\nplot_data.sort_values(\"y\",inplace = True, ascending = False)\nplot_data[\"p_hat_ideal\"] = np.linspace(1,0, plot_data.shape[0])\n\n\nfpr, or_tpr, t = roc_curve(\n    plot_data[\"y\"], plot_data[\"p_hat\"],\n    drop_intermediate = False\n)\nfpr, id_tpr, t = roc_curve(\n    plot_data[\"y\"], plot_data[\"p_hat_ideal\"],\n    drop_intermediate = False\n)\n\nCAP_x = np.arange(len(or_tpr))/len(or_tpr)\n\n\nplt.figure(figsize = [10,7])\nplt.plot(CAP_x, or_tpr, linewidth = 5)\nplt.plot(CAP_x, id_tpr, linewidth = 5)\nplt.plot(\n    [0,1], [0,1], color = \"red\", \n    linestyle = \"dashed\",\n    linewidth = 5\n)\n\nplt.fill_between(\n    np.arange(len(or_tpr))/len(or_tpr),\n    or_tpr,\n    np.arange(len(or_tpr))/len(or_tpr),\n    hatch = \"//\",\n    alpha = 0\n)\nplt.fill_between(\n    np.arange(len(or_tpr))/len(or_tpr),\n    id_tpr,\n    np.arange(len(or_tpr))/len(or_tpr),\n    hatch = \"\\\\\\\\\",\n    alpha = 0\n)\n\nplt.xlabel(\"Доля наблюдений\", fontsize = 15)\nplt.ylabel(\"$TPR$\", fontsize = 15)\n\nplt.xlim([0,1])\nplt.ylim([-0.005,1.005])\n\nplt.legend(\n    [\n        \"CAP модели\", \"Идеальная CAP\", \n        \"Случайная CAP\", \"A\", \"B\"\n    ],\n    fontsize = 14\n)\n\n&lt;matplotlib.legend.Legend at 0x7ff53d4a7fa0&gt;\n\n\n\n\n\nСледуя обозначениям площадей на рисунке, получаем:\n\\[GINI = \\frac{A}{B}\\]\nИли испозуя альтернативное обозначение площадей (по, пока, незвенстной причине особенно популярное)\n\nplt.figure(figsize = [10,7])\nplt.plot(CAP_x, or_tpr, linewidth = 5)\nplt.plot(CAP_x, id_tpr, linewidth = 5)\nplt.plot(\n    [0,1], [0,1], color = \"red\", \n    linestyle = \"dashed\",\n    linewidth = 5\n)\n\nplt.fill_between(\n    np.arange(len(or_tpr))/len(or_tpr),\n    or_tpr,\n    np.arange(len(or_tpr))/len(or_tpr),\n    hatch = \"//\",\n    alpha = 0\n)\nplt.fill_between(\n    np.arange(len(or_tpr))/len(or_tpr),\n    id_tpr,\n    or_tpr,\n    hatch = \"\\\\\\\\\",\n    alpha = 0\n)\n\nplt.xlabel(\"Доля наблюдений\", fontsize = 15)\nplt.ylabel(\"$TPR$\", fontsize = 15)\n\nplt.xlim([0,1])\nplt.ylim([-0.005,1.005])\n\nans = plt.legend(\n    [\n        \"CAP модели\", \"Идеальная CAP\", \n        \"Случайная CAP\", \"A\", \"B\"\n    ],\n    fontsize = 14\n)\n\n\n\n\n\\[GINI = \\frac{A}{B+A}\\]\n\n\n\nСвязь GINI c ROC\n Есть альтернативный способ подсчитать \\(GINI\\) - через ROC кривую.\n\nАналитическое доказательсво\nВ качесве примера возьмем таблицу которую использовали при рассмотрении CAP кирвой. Каждое полученное тождество буду сверять с этим примером, для того, что-бы быть уверенным, в том, что в процессе не допущено ошибок.\n\n\n\n\\(i\\)\n\\(\\hat{p}_i\\)\n\\[y_i\\]\n\\[i/n\\]\n\\[TPR_i\\]\n\\[FPR_i\\]\n\n\n\n\n1\n0.8\n1\n0.2\n1/3\n0\n\n\n2\n0.7\n1\n0.4\n2/3\n0\n\n\n3\n0.6\n0\n0.6\n2/3\n1/2\n\n\n4\n0.4\n0\n0.8\n2/3\n1\n\n\n5\n0.2\n1\n1\n1\n1\n\n\n\nСразу обозначим, что \\(FPR_0=TPR_0=0\\).\nВсе массивы примера, что на м понадобиться, загоняем в память компьютера.\n\nn = 5\nTPR = np.array([0, 1/3, 2/3, 2/3, 2/3, 1])\nFPR = np.array([0, 0, 0, 1/2, 1, 1])\ni = np.arange(6)\ny = np.array([1,1,0,0,1])\n\nЗапишем площадь под ROC кривой, что и будет показателем \\(AUC_{roc}\\):\n\\[AUC_{roc} = \\sum_{i=0}^{n-1} (FPR_{i+1} - FPR_i)(TPR_{i+1} + TPR_i)/2. \\tag{1}\\]\n\\(GINI\\) от сюда выражается:\n\\[GINI = 2AUC_{roc}-1. \\tag{2}\\]\n\nauc_roc = np.sum((FPR[1:] - FPR[:-1])*(TPR[1:] + TPR[:-1])/2)\n2*auc_roc - 1\n\n0.33333333333333326\n\n\nЗапишем площадь под дейсвтительной CAP кривой:\n\\[AUC_{cap} = \\sum_{i=0}^{n-1}([i+1]/n - i/n)(TPR_{i+1} + TPR_i)/2 = \\sum_{i=0}^{n-1}(TPR_{i+1} + TPR_i)/2n.\\]\nТогда площадь между случайной CAP кривой и действительной CAP кривой будет выражаться так:\n\\[AUC_{cap}' = \\sum_{i=0}^{n-1}(TPR_{i+1} + TPR_i)/2n - 0.5.\\tag{3}\\]\nПодсчитаем эту величину, для нашего примера:\n\nAUC_cap = sum((i[1:]/n - i[:-1]/n)*(TPR[1:] + TPR[:-1])/2) - 0.5\nAUC_cap\n\n0.06666666666666654\n\n\nК записи площади под идеальной CAP кривой лучше подойти с геометрической точки зрения:\n\ny_rel_ideal = [0, 1/3, 2/3, 1, 1, 1]\nx_rel = [i/5 for i in range(6)]\n\nplt.figure(figsize = [10, 7])\n\nplt.plot(x_rel, y_rel_ideal)\nplt.fill_between(\n    [0, 0.6], [0, 1], [0,0],\n    alpha = 0, hatch = \"//\"\n)\nplt.fill_between(\n    [0.6, 1], [0, 0], [1,1],\n    alpha = 0, hatch = \"\\\\\\\\\"\n)\n\nplt.yticks([0, 1])\nplt.xticks(\n    [0, 0.6, 1],\n    [\"0\", \"$\\gamma$\", \"1\"],\n    fontsize = 14\n)\n\nplt.title(\n    \"Идеальная CAP кривая\",\n    fontsize = 15\n)\n\nplt.grid()\nplt.xlabel(\"Доля наблюдений\", fontsize = 15)\n\nText(0.5, 0, 'Доля наблюдений')\n\n\n\n\n\nГде \\(\\gamma\\) - доля наблюдений с проявлением признака:\n\\[\\gamma = \\frac{\\sum_{i=1}^ny_i}{n}.\\]\nЭта площадь раскладывается на 2 фигуры: - Треугольник, выделенный штриховкой наклоненной влево; - Прямоугольник, выделейнный штрифовной наклоненной вправо.\nОчевидно такую площадь можно записать:\n\\[AUC^I = \\gamma/2 + (1-\\gamma) = 1 - \\gamma/2.\\]\nТогда площадь можду идеальной CAP кривой и случайной CAP кривой составит:\n\\[AUC'^I = 1 + \\gamma/2 - 0.5=0.5 - \\gamma/2.\\]\nИли подставляя \\(\\gamma\\):\n\\[AUC'^I = 0.5 - \\frac{\\sum_{i=1}^{n}y_i}{2n}.\\tag{4}\\]\nПодсчитаем значение, принимаемое данной величиной, для нашего примера:\n\nAUC_I = 0.5-sum(y)/(2*n)\nAUC_I\n\n0.2\n\n\nТогда \\(GINI\\) через CAP кривую:\n\\[GINI = \\frac{AUC_{cap}'}{AUC'^I}. \\tag{5}\\]\nУбедимся, что он совпадает с числом полученным через ROC:\n\nAUC_cap/AUC_I\n\n0.3333333333333327\n\n\nИ так, для доказательства нам следуем показать равенство выражений \\((2),(5)\\), подставив туда \\((1),(3),(4)\\) или:\n\\[2AUC_{roc}-1 = \\frac{AUC_{cap}'}{AUC'^I} \\Leftrightarrow\\] \\[\\Leftrightarrow 2\\left[\\sum_{i=0}^{n-1} (FPR_{i+1} - FPR_i)(TPR_{i+1} + TPR_i)/2\\right] -1 =\n\\frac{\n    \\sum_{i=0}^{n-1}(TPR_{i+1} + TPR_i)/2n - \\frac{1}{2}\n}{\n    \\frac{1}{2} - \\frac{\\sum_{i=1}^{n}y_i}{2n}\n} \\Leftrightarrow \\tag{6}\\]\n\\[\\Leftrightarrow \\left[\\sum_{i=0}^{n-1} (FPR_{i+1} - FPR_i)(TPR_{i+1} + TPR_i)\\right] -1 =\n\\frac{\n    \\sum_{i=0}^{n-1}(TPR_{i+1} + TPR_i)/2n - \\frac{1}{2}\n}{\n    \\frac{1}{2} - \\frac{\\sum_{i=1}^{n}y_i}{2n}\n}\\]\nБудем работать с правой частью тождества:\n\\[\\frac{\n    \\sum_{i=0}^{n-1}(TPR_{i+1} + TPR_i)/2n - \\frac{1}{2}\n}{\n    \\frac{1}{2} - \\frac{\\sum_{i=1}^{n}y_i}{2n}\n}=\\]\n\\[=\\frac{\n    \\sum_{i=0}^{n-1}(TPR_{i+1} + TPR_i)/2n - \\frac{1}{2}\n}{\n    \\frac{n - \\sum_{i=1}^{n}y_i}{2n}\n}=\\]\n\\[=\\frac{\n    \\left[\\sum_{i=0}^{n-1}(TPR_{i+1} + TPR_i)\\right] - n\n}{\n    n - \\sum_{i=1}^{n}y_i\n}=\\]\n\\[\n=\\left[\\sum^{n-1}_{i=0}\n    \\frac{1}{n - \\sum_{i=1}^{n}y_i}(TPR_{i+1}+TPR_i)\n    \\right] - \\frac{n}{n - \\sum_{i=1}^{n}y_i}\n\\tag{7}\n\\]\nУбедимся на числах, что проделанные пребразования корректны.\n\n(sum(TPR[1:] + TPR[:-1])-n)/(n-sum(y))\n\n0.33333333333333304\n\n\nБудем работать с левой частью тождества:\n\\[\n\\left[\\sum_{i=0}^{n-1} (FPR_{i+1} - FPR_i)(TPR_{i+1} + TPR_i)\\right] -1 \\tag{8}\n\\]\nОбсудим свойсва выражения:\n\\[\n(FPR_{i+1} - FPR_i)\n\\]\n\\(FPR\\) (доля ложно положительных предсказаний) прирастает только для предсказаний без проявления признака. А, для наблюдения без проявления признака, прирастает на долю, которую занимает одно набллюдение без проявления признка:\n\\[\n(FPR_{i+1} - FPR_i)=\\begin{cases}\n    0, y_i=1;\\\\\n    \\frac{1}{n-\\sum_i^n y_i}, y_i=0.\n\\end{cases}\n\\]\nГде \\(n-\\sum_i^n y_i\\) - число наблюдений без проявления признака, тогда:\n\\[\\frac{1}{n-\\sum_i^n y_i}\\]\nдоля в одного наблюдения в наблюдениях с проявлением признака.\nТогда выражение \\((8)\\) может быть переписано следующим образом:\n\\[\n\\left[\\sum_{i|y_{i+1}=0} \\frac{1}{\\sum_{i=1}^n n-y_i}(TPR_{i+1} + TPR_i)\\right] -1\n\\tag{9}\n\\]\nТо есть суммирование можно произвести только для членов, для которых \\(y_{i+1}=0\\), все остальные будут равняться нулю. При том в не нулевых членнах один из множителей - константа относительно оператора суммирования.\nУбедимся, что проделанные преобразования корректны:\n\nnp.sum(\n    (1/(n - sum(y)))*\\\n    (TPR[1:][y==0] + TPR[:-1][y==0])\n) - 1\n\n0.33333333333333326\n\n\nТеперь допустим, что тождество \\((6)\\) верно. Тогда, учитвая во внимание, последние результаты \\((7), (9)\\):\n\\[\n\\left[\\sum^{n-1}_{i=0}\n    \\frac{1}{n - \\sum_{i=1}^{n}y_i}(TPR_{i+1}+TPR_i)\n    \\right] - \\frac{n}{n - \\sum_{i=1}^{n}y_i}\n=\n\\left[\\sum_{i|y_{i+1}=0} \\frac{1}{n-\\sum_{i=1}^n y_i}(TPR_{i+1} + TPR_i)\\right] -1\n\\Leftrightarrow \\tag{10}\\]\n\\[\n\\Leftrightarrow\n\\left[\\sum^{n-1}_{i=0}\n    \\frac{1}{n - \\sum_{i=1}^{n}y_i}(TPR_{i+1}+TPR_i)\n    \\right] -\n    \\left[\\sum_{i|y_{i+1}=0} \\frac{1}{n-\\sum_{i=1}^n y_i}(TPR_{i+1} + TPR_i)\\right] -\n    \\frac{n}{n - \\sum_{i=1}^{n}y_i} + 1\n= 0\n\\]\nОбратите внимание на выражения в квадратных скобках - они полностью совпадают, отличается лишь число компонент суммирования, т.е. после вычитания остануться только те компоненты которых нет в вычитаемом:\n\\[\n\\left[\n    \\sum_{i|y_{i+1}=1} \\frac{1}{n-\\sum_{i=1}^n y_i}(TPR_{i+1} + TPR_i)\n\\right] -\n    \\frac{n}{n - \\sum_{i=1}^{n}y_i} + 1\n= 0\n\\]\nУбедисмя, что представленное равенстно верно:\n\nsum(\n   (1/(n-sum(y)))*(TPR[1:][y==1] + TPR[:-1][y==1])\n) -\\\nn/(n-sum(y)) + 1\n\n0.0\n\n\nДалее можно провести рад преобразований над полученным выражением:\n\\[\n\\left[\n    \\sum_{i|y_{i+1}=1} \\frac{1}{n-\\sum_{i=1}^n y_i}(TPR_{i+1} + TPR_i)\n\\right] -\n    \\frac{n}{n - \\sum_{i=1}^{n}y_i} + 1\n= 0 \\Leftrightarrow\n\\]\n\\[\n\\Leftrightarrow\n\\left[\n    \\sum_{i|y_{i+1}=1} \\frac{1}{n-\\sum_{i=1}^n y_i}(TPR_{i+1} + TPR_i)\n\\right] -\n    \\frac{\\sum_{i=1}^{n}y_i}{n - \\sum_{i=1}^{n}y_i}\n= 0\n\\Leftrightarrow\n\\]\n\\[\n\\Leftrightarrow\n\\frac{1}{n-\\sum_{i=1}^n y_i}\n\\left\\{\n    \\left[\n        \\sum_{i|y_{i+1}=1} (TPR_{i+1} + TPR_i)\n    \\right] -\n       \\sum_{i=1}^{n}y_i\n\\right\\}\n= 0\n\\]\nУчитывая, что выражение \\(\\frac{1}{n-\\sum_{i=1}^n y_i}\\) не отрицательное. То для выполнения последнего тождества необходимо, чтобы:\n\\[\n\\left[\n    \\sum_{i|y_{i+1}=1} (TPR_{i+1} + TPR_i)\n\\right] -\n   \\sum_{i=1}^{n}y_i\n=0 \\tag{11}\\]\nРассмотрим сумму в квадратных скобрах:\n\\[\\sum_{i|y_{i+1}=1} (TPR_{i+1} + TPR_i)\\]\nПерепишем её проще, но держа в памяти, что суммирование проводится только по наблюдениям с проявлением признака:\n\\[\\sum_{i=0}^{m-1} (TPR_{i+1} + TPR_i)\\]\nГде \\(m=\\sum_{i=1}^{n}y_i\\).\nТеперь вспомним, что \\(TPR\\) это доля клиентов, с проявлением, признака для которых было предсказано проявление признака. Получается, что для каждого клиента с проявлением признака \\(TPR\\) возрастает на \\(\\frac{1}{m}\\). Тогда в данной сумме. можно записать, что:\n\\[\n\\sum_{i=0}^{m-1} \\left(\\frac{i+1}{m} + \\frac{i}{m}\\right)=\n\\sum_{i=0}^{m-1} \\left(\\frac{2i+1}{m}\\right)\n\\]\nВозвращаясь к тождеству \\((10)\\) и используя нововведенные обозначения:\n\\[\n\\sum_{i=0}^{m-1} \\left(\\frac{2i+1}{m}\\right)=m\\Leftrightarrow\n\\sum_{i=0}^{m-1} 2i+1 = m^2\n\\tag{12}\n\\]\nДоказав это пождество мы докажем, что выполняется вся цепочка тождеств выше. Есть уже очень похожее доказательсво, представленное тут. Но мы его приведдем для нашего примера:\nРаспишем выражение:\n\\[\\sum_{i=0}^{m-1} 2i+1 = 1 + 3 + 5 + ... + 2(m-1)+1.\\]\nТут не хватает четных чисел в суммации добавим и отнимем их:\n\\[\\sum_{i=0}^{m-1} 2i+1 = \\{1 + 3 + 5 + ... + [2(m-1)+1]\\} + \\{2 + 4 + 6 + ... + 2(m-1)\\} - \\{2 + 4 + 6 + ... + 2(m-1)\\}.\\]\nОбъединим и упрядочим компоненты первых и вторых фигурных скобок и вынесем 2 из вторых:\n\\[\\sum_{i=0}^{m-1} 2i+1 = \\{1 + 2 + 3 + 4 + ... + 2(m-1) + [2(m-1)+1]\\} - 2\\{1 + 2 + 3 + ... + (m-1)\\}.\\]\nВозвращаясь к оператом суммирования получаем:\n\\[\\sum_{i=0}^{m-1} 2i+1 = \\left[\\sum_{i=1}^{2(m-1)+1}i\\right] - 2\\left[\\sum_{i=1}^{m-1}i\\right]. \\tag{13}\\]\nДалее надо выразить:\n\\[\\sum_{i=1}^\\nu i.\\]\nТут можно найти, что:\n\\[2\\sum_{i=1}^\\nu i = \\sum_{i=1}^\\nu i + \\sum_{i=1}^\\nu i = [1 + 2 + ... + (\\nu-1) + \\nu] + [\\nu + (\\nu-1) + ... + 2 + 1]=\\] \\[=(\\nu+1) + (\\nu-1+2) + ... + (2 + \\nu - 1) + (\\nu+1)=\\] \\[=(\\nu+1) + (\\nu+1) + ... + (\\nu+1)=\\] \\[=\\sum_{i=1}^n (\\nu+1) = \\nu(\\nu+1)\\]\nИ так:\n\\[2\\sum_{i=1}^\\nu i = \\nu(\\nu+1) \\Leftrightarrow \\sum_{i=1}^\\nu i = \\frac{\\nu(\\nu +1)}{2}\\]\nТогда, возвращаясь к \\((13)\\) получаем: \\[\n\\sum_{i=0}^{m-1} 2i+1 =\n\\] \\[\n=\\frac{[2(m-1)+1]([2(m-1)+1] + 1)}{2} - 2\\frac{[m-1]([m-1]+1)}{2}=.\n\\] \\[\n=\\frac{2m[2m+1]}{2} - [m-1]([m-1]+1)=\n\\] \\[\n=m[2m+1] - m[m-1] =\n\\] \\[\n= 2m^2+m-m^2-m=\n\\] \\[\n= m^2\n\\]\nИ так получается, что:\n\\[\\sum_{i=0}^{m-1} 2i+1 = m^2\\]\nТаким образом, выполняется тождество \\((12)\\), получается справедливым \\((11)\\), за ним \\((10)\\) и окончательно \\((6)\\boxtimes\\).\n\n\nВычислительный экперимент\nПредполагается сэмитировать результаты не которого классификатора и подсчитать для него \\(GINI\\) обоими методами, для того, чтобы убедиться, что результат одинаковый.\nЭмитация результата модели\n\nplot_ss = 10000\n\nnp.random.seed(3)\nrandom_range = np.random.rand(plot_ss)\n\nplot_data = pd.DataFrame({\n    \"p_hat\" : random_range,\n    \"y\" : map(\n        lambda r_val: np.random.choice(\n            [0, 1], p = [1 - r_val, r_val]\n        ), \n        random_range\n    )\n})\n\nplot_data.head()\n\n\n\n\n\n\n\n\np_hat\ny\n\n\n\n\n0\n0.550798\n0\n\n\n1\n0.708148\n1\n\n\n2\n0.290905\n1\n\n\n3\n0.510828\n0\n\n\n4\n0.892947\n1\n\n\n\n\n\n\n\nВычисление через ROC\n\n# вычисление точек ROC-кривой\nfpr, tpr, t = roc_curve(\n    plot_data[\"y\"], plot_data[\"p_hat\"],\n    drop_intermediate = False\n)\n# вычисление GINI через площадь точек под\n# ROC кривой\n2*auc(fpr, tpr) - 1\n\n0.6599391056843444\n\n\nВычисление через CAP\n\nplot_data.sort_values(\"y\",inplace = True, ascending = False)\nplot_data[\"p_hat_ideal\"] = np.linspace(1,0, plot_data.shape[0])\n\n\n# вычисление ординат наблюдаемой CAP кривой\n_, tpr_real, _= roc_curve(\n    plot_data[\"y\"], plot_data[\"p_hat\"],\n    drop_intermediate = False\n)\n# вычисление площади под CAP\nideal_CAP_auc = plot_data[\"y\"].sum()/plot_data.shape[0]/2 + \\\n(plot_data[\"y\"] == 0).sum()/plot_data.shape[0]\n# вычисление ординат случайной CAP\ntpr_random = np.linspace(0,1, len(tpr_real))\n\nB = ideal_CAP_auc - 0.5\nA = auc(tpr_random, tpr_real) - 0.5\nA/B\n\n0.6599391056843441\n\n\nОтличие только в последнем знаке и, скорее всего, обусловлено округлением.\n(sum(tpr_real[1:] + tpr_real[:-1]) - plot_data.shape[0])/\n(plot_data.shape[0] - plot_data[“y”].sum())"
  },
  {
    "objectID": "machine_learning/classification_task/metrics/CAP/CAP.html",
    "href": "machine_learning/classification_task/metrics/CAP/CAP.html",
    "title": "Содержание:",
    "section": "",
    "text": "Как работает CAP кривая\nИсточники:\n\nhttps://en.wikipedia.org/wiki/Cumulative_accuracy_profile - статься на википедии посвященная CAP кривой;\nhttps://medium.com/geekculture/classification-model-performance-evaluation-using-auc-roc-and-cap-curves-66a1b3fc0480 - простенькая статейка но с примерами кода на python3.\n\nБибилиотеки\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import accuracy_score, auc\n\nfrom statsmodels.distributions.empirical_distribution import ECDF\n\n\nОпределение CAP кривой;\nИдеальная CAP кривая;\nСлучайная CAP кривая;\n\\(TPR\\) на оси ординат у CAP.\n\n # Определение CAP кривой\nCAP кривая представляет собой кумулятивное число положительных исходов по оси ординат по отношению к соответствующему кумулятивному числу классифицирующего параметра по оси абсцысс.\n\nБазовое понимае CAP кривой на примере\nНапример, пусть некоторая модель предсказывает вероятности \\(\\hat{p}_i\\) того, что \\(y_i=1\\) (у \\(i\\)-го клиента положительный исход, проявление признака). Допустим в тестовой выборке у нас 5 наблюдений имеются предсказания для них и настоящий класс:\n\n\n\n\\(\\hat{p}_i\\)\n\\[y_i\\]\n\n\n\n\n0.2\n1\n\n\n0.6\n0\n\n\n0.8\n1\n\n\n0.7\n1\n\n\n0.4\n0\n\n\n\nДля того чтобы построить CAP кривую надо: 1. Отсортировать наблюдения по убыванию \\(\\hat{p}_i\\);\n\n\n\n\\(\\hat{p}_i\\)\n\\[y_i\\]\n\n\n\n\n0.8\n1\n\n\n0.7\n1\n\n\n0.6\n0\n\n\n0.4\n0\n\n\n0.2\n1\n\n\n\n2. Пронумеровать каждое наблюедение начиная от 1;\n\n\n\n\\(i\\)\n\\(\\hat{p}_i\\)\n\\[y_i\\]\n\n\n\n\n1\n0.8\n1\n\n\n2\n0.7\n1\n\n\n3\n0.6\n0\n\n\n4\n0.4\n0\n\n\n5\n0.2\n1\n\n\n\n3. Вычислить кумулятивную сумму \\(y_i\\) (\\(\\hat{S}_{\\hat{y}}\\));\n\n\n\n\\(i\\)\n\\(\\hat{p}_i\\)\n\\[y_i\\]\n\\[\\hat{S}_{\\hat{y}}\\]\n\n\n\n\n1\n0.8\n1\n1\n\n\n2\n0.7\n1\n2\n\n\n3\n0.6\n0\n2\n\n\n4\n0.4\n0\n2\n\n\n5\n0.2\n1\n3\n\n\n\nНачиная с точки (0,0) и продолжая пременными \\(i\\) и \\(\\hat{S}_{\\hat{y}}\\) на график наносят CAP кривую.\n\nplt.figure(figsize = [10,7])\n\nx = list(range(6))\ny = [0,1,2,2,2,3]\n\nplt.plot(x, y, marker = \".\")\n\nplt.xlabel(\"Число наблюдений\", fontsize = 15)\nplt.ylabel(\"$\\hat{S}_{\\hat{y}}$\", fontsize = 15)\n\nfor x_val, y_val in zip(x, y):\n    plt.text(x_val, y_val + 0.05, x_val, fontsize = 14)\n\nplt.yticks(y)\nplt.grid()\n\n\n\n\nИнтерпритация у \\(i\\)-й точки следующая: в \\(i\\) худших, по мнению модели, наблюдениях лежит \\(\\hat{S}_{\\hat{y}_i}\\) проявлений признака. Или для каждой точки:\n\nВ 1 худших, по менинию модели, наблюдениях лежит 1 проявлений признака;\nВ 2 худших, по менинию модели, наблюдениях лежит 2 проявлений признака;\nВ 3 худших, по менинию модели, наблюдениях лежит 2 проявлений признака;\nВ 4 худших, по менинию модели, наблюдениях лежит 2 проявлений признака;\nВ 5 худших, по менинию модели, наблюдениях лежит 3 проявлений признака.\n\n\n\nОтносительная CAP кривая\nЕсли по оси абсцысс откладывать не номер наблюдения \\(i\\) а \\(i/n\\) (где \\(n\\) - число наблюдений на которых вычисляется CUP кривая) и по оси ординат откладывать не кумулятивную сумму, но кумулятивный процент (величина, совпадающся с \\(TPR\\), подробнее), то получиться, так мной названная, относительная CAP кривая, такая же по форме, но ограниченная в единичном квадрате: \n\n\n\n\\(i\\)\n\\(\\hat{p}_i\\)\n\\[y_i\\]\n\\[\\hat{S}_{\\hat{y}}\\]\n\\[i/n\\]\n\\[TPR_i\\]\n\n\n\n\n1\n0.8\n1\n1\n0.2\n1/3\n\n\n2\n0.7\n1\n2\n0.4\n2/3\n\n\n3\n0.6\n0\n2\n0.6\n2/3\n\n\n4\n0.4\n0\n2\n0.8\n2/3\n\n\n5\n0.2\n1\n3\n1\n1\n\n\n\n\nplt.figure(figsize = [10,7])\n\ny_rel = [0, 1/3, 2/3, 2/3, 2/3, 1]\nx_rel = [i/5 for i in range(6)]\n\nplt.plot(\n    x_rel, y_rel, marker = \".\"\n)\n\nplt.xlabel(\"Доля наблюдений\", fontsize = 15)\n\nplt.ylabel(\"$TPR$\", fontsize = 15)\n\nfor i, (x_val, y_val) in enumerate(zip(x_rel, y_rel)):\n    plt.text(x_val, y_val + 0.02, i, fontsize = 14)\n    \nplt.yticks(y_rel)\nplt.grid()\n\n\n\n\nИнтерпритация \\(i\\)-й точки будет следующая: в \\(i/n*100\\%\\) худших, по мнению модели, наблюдениях лежит \\(\\hat{F}_{\\hat{y}i}*100\\%\\) проявлений признака. Или для каждой точки в рассматриваемом примере:\n\nВ 0% худших, по мнению модели, наблюдениях лежит 0% проявлений признака;\nВ 20% худших, по мнению модели, наблюдениях лежит 33% проявлений признака;\nВ 40% худших, по мнению модели, наблюдениях лежит 67% проявлений признака;\nВ 60% худших, по мнению модели, наблюдениях лежит 67% проявлений признака;\nВ 80% худших, по мнению модели, наблюдениях лежит 67% проявлений признака;\nВ 100% худших, по мнению модели, наблюдениях лежит 100% проявлений признака.\n\nДалее, по умолчанию, будет обсуждаться именно относительная CAP кривая, потому как она мне видится более применимой.\n # Идеальная CAP кривая\nИграет важную роль в понимании механизма CAP кривой.\n\n\nОписание\nИдеальный классификатор обладает следующим совойсвом - он из входной комбинации переменных, отписывающих наблюдение, \\(X_i\\) может сделать такую дискриминирующую переменную \\(p_i\\), чтобы:\n\\[y_i=1,y_j=0 \\Rightarrow p_i&gt;p_j; \\forall i,j; i\\neq j\\]\nТо есть для любых двух наблюдений (\\(i\\)-го и \\(j\\)-го) если одно имеет проявление признака а другое нет, то предсказание для перовго должно быть больше.\nВ таких условиях, после сортировки по убыванию, все наблюдения с проявлением признака окажуться выше чем все наблюдения без проялвения признака. Следовательно CAP кривая будет расти только в начале, пока идут только наблюдения с проявлением признака. Так пока она не достигнет 1 - в точке соответсвующей самому низкому предсказанию для наблюдения с проявлением признака. Затем будет неизменна для всех наблюдений без проявления признака.\n\n\nДемонстрация на примере\nВозвращаясь к примеру из прошлого раздела, последняя рассмотренная таблица, в случае идеального классификатора должна была бы быть отсортирована так:\n\n\n\n\\(i\\)\n\\(\\hat{p}_i\\)\n\\[y_i\\]\n\\[\\hat{S}_{\\hat{y}}\\]\n\\[i/n\\]\n\\[TPR\\]\n\n\n\n\n1\n0.8\n1\n1\n0.2\n1/3\n\n\n2\n0.7\n1\n2\n0.4\n2/3\n\n\n3\n0.2\n1\n2\n0.6\n1\n\n\n4\n0.6\n0\n2\n0.8\n1\n\n\n5\n0.4\n0\n3\n1\n1\n\n\n\nВсе наблюдения с \\(y_i=1\\) выше нежели наблюдения для которых \\(y_i=0\\). Добавим идеальную CAP кривую к прошлому графику.\n\nplt.figure(figsize = [10,7])\n\ny_rel = [0, 1/3, 2/3, 2/3, 2/3, 1]\ny_rel_ideal = [0, 1/3, 2/3, 1, 1, 1]\nx_rel = [i/5 for i in range(6)]\n\nplt.plot(x_rel, y_rel, marker = \".\")\nplt.plot(x_rel, y_rel_ideal, marker = \".\", color = \"green\")\n\nplt.xlabel(\"Доля наблюдений\", fontsize = 15)\nplt.ylabel(\"$TPR$\", fontsize = 15)\n\nplt.legend(\n    [\"Действительная CAP\", \"Идеальная CAP\"],\n    fontsize = 15\n)\n\nplt.yticks(y_rel)\nplt.grid()\n\n\n\n\n # Случайная CAP кривая\nВместе с идеальной исползуется для понимания насколько хороша или плоха та или иная модель.\n\n\nОписание\nИз рассуждений, предложенных выше, становиться понятно, что чем быстрее CUP кривая растет в начале, тем лучше оциниваемый классификатор. Понятно, что случайный классификатор будет образовывать CAP которая приростает равномерно на любой области доли рассмотренных наблюдений. Потому, в случае генеральной совокупности, это будет просто прямая протянутая от точки (0,0) до точки (1,1). В случае выборки это будет кривая с очень близкими (или, в некоторых случаях, совпадающими) характеристиками.\n\n\nВычислительный эксперимент\nРассмотрим вычислительный эксперимент: сэмитируем случайный классификатор и постоим для него CAP.\n\ndef plot_random_CAP(sample_size):\n    experimental_sample = pd.DataFrame({\n        \"p_hat\" : np.random.rand(sample_size),\n        \"y\" : np.random.choice([0,1], sample_size)\n    })\n\n    experimental_sample.sort_values(\n        \"p_hat\", ascending = False,\n        inplace = True\n    )\n\n    experimental_sample[\"$$\\hat{F}_{\\hat{y}}$$\"] = ECDF(\n        1 - experimental_sample.query(\"y == 1\")[\"p_hat\"]\n    )(1 - experimental_sample[\"p_hat\"])\n    experimental_sample.head()\n\n    experimental_sample[\"$i$\"] = range(1, sample_size + 1)\n    experimental_sample[\"$i/n$\"] = experimental_sample[\"$i$\"]/sample_size\n\n    plt.plot(\n        experimental_sample[\"$i/n$\"], \n        experimental_sample[\"$$\\hat{F}_{\\hat{y}}$$\"],\n        color = \"red\"\n    )\n    plt.xlim([0,1])\n    plt.ylim([0,1])\n    plt.xlabel(\"Доля наблюдений\")\n    plt.ylabel(\"$FPR$\")\n    \n    \nsample_sizes = [500, 1000, 5000, 10000]\nplt.figure(figsize = [15, 10])\nfor i in range(4):\n    plt.subplot(2, 2, i+1)\n    plt.title(\"Размер выборки \" + str(sample_sizes[i]))\n    plot_random_CAP(sample_sizes[i])\n\n\n\n\nВидно, что такая кривая дейсвительно стремиться к диагональной прямой с увеличением объема выборки. Потому, в прикладных исследованиях, ее принимают равной диагональной прямой.\n\n\nДополняя пример прошлого раздела\nТогда полный CAP график, для рассмотренного примера, примет вид:\n\nplt.figure(figsize = [10,7])\n\ny_rel = [0, 1/3, 2/3, 2/3, 2/3, 1]\ny_rel_ideal = [0, 1/3, 2/3, 1, 1, 1]\nx_rel = [i/5 for i in range(6)]\n\nplt.plot(x_rel, y_rel, marker = \".\")\nplt.plot(\n    x_rel, y_rel_ideal, \n    marker = \".\", color = \"green\"\n)\nplt.plot(\n    [0,1], [0,1],\n    color = \"red\", marker = \".\"\n)\n\nplt.xlabel(\"Доля наблюдений\", fontsize = 15)\nplt.ylabel(\"$TPR$\", fontsize = 15)\n\nplt.legend(\n    [\n        \"Действительная CAP\", \n        \"Идеальная CAP\",\n        \"Случайная CAP\"\n    ],\n    fontsize = 15\n)\n\nplt.yticks(y_rel)\nplt.grid()\n\n\n\n\n # \\(TPR\\) на оси ординат у CAP\n\\(TPR\\) это доля правильно предсказнных наблюдений проявлений признака при точке отсчения \\(p'\\):\n\\[TPR_i(p')=\\sum_{i=1}^n\\frac{I(\\hat{p}_i \\geq p')}{n};\\]\n\\[I(\\hat{p}_i \\geq p')=\\begin{cases}\n    1, \\hat{p}_i \\geq p';\\\\\n    0, \\text{в противном случае}.\n\\end{cases}\\]\nЭта величина и будет на оси ординат CAP-кривой.\n\n\nПроверка на примере\nВесьма условноая вроверка, но все же, рассчитаем \\(TPR\\) как мы считали для CAP кривой и получим его используя sklearn.metrics.roc_curve и сравнить.\n\nfrom sklearn.metrics import roc_curve\n\nnp.random.seed(10)\n\nsample_size = 200\n\n\ntest_df = pd.DataFrame({\n    \"p_hat\" : np.random.rand(sample_size),\n    \"y\" : np.random.choice([0,1], sample_size)\n})\n\n# подсчет подобно тому как мы слитали для CAP\nCAT_TPR = np.concatenate([\n    [0],# для нулевой точки отсечния нужно добачить 0\n    np.sort(\n        ECDF(1 - test_df.query('y == 1')[\"p_hat\"])\\\n        (1 - test_df[\"p_hat\"])\n    )\n])\n\n# вычисление используя, которвый инструмент\nfpr, tpr, t = roc_curve(\n    test_df[\"y\"],\n    test_df[\"p_hat\"],\n    drop_intermediate = False\n)\n\n# сравнение - c точностью до 4-ех знаков после запятой\nall(np.round(CAT_TPR,4) == np.round(tpr,4))\n\nTrue\n\n\nВсе верно - величины совпадают."
  },
  {
    "objectID": "machine_learning/data_transformations/PCA.html",
    "href": "machine_learning/data_transformations/PCA.html",
    "title": "Первая главная компонента",
    "section": "",
    "text": "Метод главных компонент\nВсе особенности и тонкоссти исползования метода главных компонент.\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.decomposition import PCA"
  },
  {
    "objectID": "machine_learning/data_transformations/PCA.html#определение",
    "href": "machine_learning/data_transformations/PCA.html#определение",
    "title": "Первая главная компонента",
    "section": "Определение",
    "text": "Определение\nПусть имеюстся \\(n\\) наблюдений за \\(m\\) переменными - \\(x_{ij}, i\\in \\overline{1,n}, j \\in \\overline{1,m}\\). Тогда первой главной компонентой назвается функция:\n\\[Z_1(x_1, x_2, ... , x_m) = \\sum_{j=1}^m\\phi_{j}(x_j - \\bar{x}_j);\\]\nГде: - \\(\\bar{x}_j\\) - среднее выборочное \\(j\\)-й переменной \\(\\forall j\\).\nПри том \\(\\phi_j\\) подбираются так, чтобы:\n\\[(\\phi_1, \\phi_2, ... \\phi_m) = argmax_{\\varphi_1, \\varphi_2, ..., \\varphi_{m}}\\left\\{Var\\left[\\sum_{j=1}^m\\varphi_{j}(x_j - \\bar{x}_j)\\right]\\right\\};\\]\n\\[\\sum_{j=1}^m \\varphi_j^2 = 1.\\]’"
  },
  {
    "objectID": "machine_learning/data_transformations/PCA.html#пример",
    "href": "machine_learning/data_transformations/PCA.html#пример",
    "title": "Первая главная компонента",
    "section": "Пример",
    "text": "Пример\nДопустим имеются \\(5\\) наблюдений за 2-мя переменными.\n“\\(\\phi_{j}(x_{{i}, {j}} - \\\\bar{x}_{j})\\)”.format(i = 2,j = 3)\n\nfor i in range(1, len(x1) + 1):\n    formula = \"\"\n    for j in range(1,3):\n        formula += \"$\\phi_1(x_{\" + str(i) + str(j) + \"} - \\\\bar{x}_\" + str(j) + \")$\"\n    print(\"- \" + formula + \";\")\n\n- $\\phi_1(x_{11} - \\bar{x}_1)$$\\phi_1(x_{12} - \\bar{x}_2)$;\n- $\\phi_1(x_{21} - \\bar{x}_1)$$\\phi_1(x_{22} - \\bar{x}_2)$;\n- $\\phi_1(x_{31} - \\bar{x}_1)$$\\phi_1(x_{32} - \\bar{x}_2)$;\n- $\\phi_1(x_{41} - \\bar{x}_1)$$\\phi_1(x_{42} - \\bar{x}_2)$;\n\n\n\n\\(\\phi_1(x_{1,1} - \\bar{x}_1)\\)\\(\\phi_1(x_{1,2} - \\bar{x}_2)\\);\n\\(\\phi_1(x_{2,1} - \\bar{x}_1)\\)\\(\\phi_1(x_{2,2} - \\bar{x}_2)\\);\n\\(\\phi_1(x_{3,1} - \\bar{x}_1)\\)\\(\\phi_1(x_{3,2} - \\bar{x}_2)\\);\n\\(\\phi_1(x_{4,1} - \\bar{x}_1)\\)\\(\\phi_1(x_{4,2} - \\bar{x}_2)\\);\n\n\nx1 = np.array([2, 3, 5, 6])\nx2 = np.array([3, 2, 6, 5])\n\nplt.figure(figsize = [10, 7])\nplt.scatter(x1, x2, s = 100)\n\n\nfor i in range(len(x1)):\n    plt.annotate(\n        str(i+1), (x1[i], x2[i]), fontsize = 20\n    )\n\nplt.axhline(\n    np.mean(x2), color = 'red', linestyle = \"dashed\"\n)\nplt.axvline(\n    np.mean(x1), color = \"red\",linestyle = \"dashed\"\n)\n\ndef create_tiks(values, sub_index):\n    \n    ticks_vals = np.unique(np.concatenate(\n        [values, [np.mean(values)]]\n    ))\n    tick_labels = \\\n    [\n        str(tick_val) \n        if tick_val != np.mean(x1) \n        else \"$\\\\bar{x}_ \" + sub_index + \" = $\" + str(tick_val) \n        \\\n        for tick_val in ticks_vals\n    ]\n    \n    return [ticks_vals, tick_labels]\nplt.xticks(*create_tiks(x1, \"1\"), fontsize = 14)\nplt.yticks(*create_tiks(x2, \"2\"), fontsize = 14)\n\nplt.grid()\n\n\n\n\n\nx1 - np.mean(x1)\nx2 - np.mean(x2)\n\narray([-2.,  0., -1.,  2.,  1.])"
  },
  {
    "objectID": "machine_learning/data_transformations/standartisation.html",
    "href": "machine_learning/data_transformations/standartisation.html",
    "title": "1. Определение",
    "section": "",
    "text": "Процедура стандартизации данных\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom statsmodels.tools.tools import add_constant\nПусть имеется множество измерений определенного признака \\(x_i, i=\\overline{1,n}\\). Тогда стандартизацией такого ряда называется преобразование по формуле:\n\\[\\tilde{x}_{i} = \\frac{x_{i} - \\bar{x}}{\\sigma_x}. \\tag{1.1}\\]\nГде: - \\(\\bar{x}\\) - среднее арифметческое рассматртваемого ряда; - \\(\\sigma_x\\) - стандартное отклонение.\nПолучется, что выражение \\((1.1)\\) может быть переписано следующим образом:\n\\[\\tilde{x}_{i} = \\frac{x_{i} - \\bar{x}}{\\sqrt{\\frac{1}{n} \\sum_{i=1}^n(x_i - \\bar{x})^2}}.\\]\nИногда предпочитают не отнимать среднее арифметическое в числителе, тогда формула \\((1.1)\\) принимает вид:\n\\[\\tilde{x}_i  = \\frac{x_i}{\\sigma}.\\]"
  },
  {
    "objectID": "machine_learning/data_transformations/standartisation.html#линейная-регрессия",
    "href": "machine_learning/data_transformations/standartisation.html#линейная-регрессия",
    "title": "1. Определение",
    "section": "Линейная регрессия",
    "text": "Линейная регрессия\n\nВведение\nМодель на исходнынх данных в матричных обозначениях примет вид:\n\\[\\hat{y} = b X. \\tag{3.1}\\]\nГде: - \\(X\\) - факторная матрица; - \\(\\hat{y}\\) - вектор столбец предсказаний модели; - \\(b\\) - вектор строка оценк коэффициентов модели.\nТогда модель на стандартизированных данных примет вид:\n\\[\\hat{y} = \\tilde{b} \\tilde{X}. \\tag{3.2}\\]\nГде: - \\(\\tilde{X}\\) - стандартизированная матрица предикоторов; - \\(\\tilde{b}\\) - оценки коэффициентов полученные при использовании стантатицованной фактороной матрицы.\nУточним, что факторную матрицу можно переписать: \\[\\tilde{X} = \\left(\\begin{array}\\\\\n    x_{11}/\\sigma_{x_1}&x_{12}/\\sigma_{x_2} & \\cdots & x_{1p}/\\sigma_{x_p}\\\\\n    x_{21}/\\sigma_{x_1}&x_{22}/\\sigma_{x_2} & \\cdots & x_{2p}/\\sigma_{x_p}\\\\\n    \\vdots & \\vdots & \\ddots & \\vdots\\\\\n    x_{n1}/\\sigma_{x_1}&x_{n2}/\\sigma_{x_2} & \\cdots & x_{np}/\\sigma_{x_p}\\\\\n\\end{array}\\right)\\]\nГде: - \\(p\\) - число переменных модели; - \\(\\sigma_{x_j}\\) - стандартное отклоненение \\(j\\)-й переменной.\nТакая матрица раскладывается:\n\\[\\tilde{X} = X*\\Sigma'. \\tag{3.3}\\]\nГде: - \\(\\Sigma' = diag(1/\\sigma_{x_1}, 1/\\sigma_{x_2}, \\cdots, 1/\\sigma_{x_p})\\).\n\n\nВлияние стандартизации на коэффициенты\n\nТеория\nТеоритически можно доказать, что предсказания линейной регрессии на исходных данных и на стандартизированных данных не отличаются. Далее представлено доказательсво.\nПредсзакания модели \\((3.1)\\) для \\(i\\)-го наблюдения формируются так:\n\\[\\hat{y}_i = \\sum_{j=1}^p b_jx_{ij}\\]\nА модели \\((3.2)\\):\n\\[\\hat{y}_i = \\sum_{j=1}^p \\tilde{b}_j\\tilde{x}_{ij}\\]\nГлавный вопрос этого раздела, дают ли эти две модели одинаковое предсказание? Поработаем с последним выражением:\n\\[\\hat{y}_i = \\sum_{j=1}^p \\tilde{b}_j \\frac{x_{ij}}{\\sigma_j}.\\]\nТаким образом, если \\(b_j = \\tilde{b}_j/\\sigma_j, \\forall j\\) - то получается, что предсказания моделей одинаковые. Покажем это.\nДля нахождения коэффициентов в \\((2.1)\\) можно воспользоваться матричной формулой:\n\\[b=\\left[X^TX\\right]^{-1}X^TY\\tag{3.4}\\]\nДля нахождения коэффициентов в \\((2.2)\\) можно воспользоваться формулой:\n\\[\\tilde{b}=\\left[\\tilde{X}^T\\tilde{X}\\right]^{-1}\\tilde{X}^TY\\]\nИспользуя \\((3.3)\\):\n\\[\\tilde{b} =\n\\left[\\left(X\\Sigma'\\right)^T\\left(X\\Sigma'\\right)\\right]^{-1}\\left(X\\Sigma'\\right)^TY\n=\\left[\\Sigma^TX^TX\\Sigma'\\right]^{-1}\\Sigma'^TX^TY\\]\nДалее используя свойсва обращения произведения \\((AB)^{-1} = B^{-1}A^{-1}\\):\n\\[\\tilde{b} = \\left[X^TX\\Sigma'\\right]^{-1}\\left[\\Sigma^T\\right]^{-1}\\Sigma'^TX^TY\\]\n\\[\\tilde{b}=\\Sigma'^{-1}\\left[X^TX\\right]^{-1}X^TY\\]\nТогда:\n\\[\\Sigma'\\tilde{b} = \\left[X^TX\\right]^{-1}X^TY\\]\nПодставляя \\((3.4)\\) получим, что:\n\\[\\Sigma'^{-1}\\tilde{b}=b.\\]\nРасписывая выражение подробнее:\n\\[\\left(\\begin{array}\\\\\n    1/\\sigma_1 & 0 & \\cdots & 0 \\\\\n    0 & 1/\\sigma_2 & \\cdots & 0 \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    0 & 0 & \\cdots & 1/\\sigma_p\n\\end{array}\\right)\n\\left(\\begin{array}\\\\\n    \\tilde{b}_1 \\\\\n    \\tilde{b}_2 \\\\\n    \\vdots \\\\\n    \\tilde{b}_p\n\\end{array}\\right) =\n\\left(\\begin{array}\\\\\n    b_1 \\\\\n    b_2 \\\\\n    \\vdots \\\\\n    b_p\n\\end{array}\\right)\n\\]\nОт куда следует, что:\n\\[\n\\left(\\begin{array}\\\\\n    \\tilde{b}_1/\\sigma_1 \\\\\n    \\tilde{b}_2/\\sigma_2 \\\\\n    \\vdots \\\\\n    \\tilde{b}_p/\\sigma_p\n\\end{array}\\right) =\n\\left(\\begin{array}\\\\\n    b_1 \\\\\n    b_2 \\\\\n    \\vdots \\\\\n    b_p\n\\end{array}\\right)\n\\]\nТогда \\(b_j = \\tilde{b}_j/\\sigma_j, \\forall j\\), что и требовалось доказать \\(\\boxtimes\\).\n\n\nЧисленный эксперимент\nОднако, на числах, рассуждения, представленные выше, не выполняются. Далее представлен эксперимент это подтверждающий.\nФормирование данных.\n\nn = 200\nnp.random.seed(15)\n\nx = pd.DataFrame({\n    \"x1\":np.random.normal(0, 0.3, n),\n    \"x2\":np.random.normal(0, 3, n)\n})\n\ny = x[\"x1\"]*3 + x[\"x2\"]*2 + (np.random.rand(n)-0.5) + 3\n\nКоэффициенты на исходных данных примут вид:\n\nbasic_model = LinearRegression(fit_intercept = False).fit(\n    add_constant(x), y)\nbasic_model.coef_\n\narray([2.95566332, 3.13373587, 2.00359775])\n\n\nКоэффициент при использованнии стандатризированных данных примет вид:\n\n# стандартизованная модель\nx_stand = (x-x.mean())/np.std(x)\n\nstand_model = LinearRegression(fit_intercept = False).fit(\n    add_constant(x_stand), y\n)\n\nstand_model.coef_\n\narray([2.60710742, 0.95731566, 5.8421477 ])\n\n\nИли, приводя коэффициент к использованию на исходных данных.\n\nstand_model.coef_/np.concatenate([[1], x.std().to_numpy()])\n\narray([2.60710742, 3.12589172, 1.99858248])\n\n\nКак видно, коэффициенты на стандартизорованных данных достаточно заметно отличаются от коэффициентов на исходных данных. Следовательно и предсказания должны отличаться в чем мы удостоверимся.\n\npd.set_option(\"display.precision\", 50)\npred_df = pd.DataFrame({\n    \"basic predict\" : basic_model.predict(add_constant(x)),\n    \"stand predict\" : stand_model.predict(add_constant(x_stand))\n})\n\npred_df\n\n\n\n\n\n\n\n\nbasic predict\nstand predict\n\n\n\n\n0\n3.53475496739942940394030301831662654876708984...\n3.53475496739942940394030301831662654876708984...\n\n\n1\n-0.47040250288071661088906694203615188598632812...\n-0.47040250288071527862143739184830337762832641...\n\n\n2\n1.19065003861016061037503277475479990243911743...\n1.19065003861016149855345247488003224134445190...\n\n\n3\n-5.00032926914154529640654800459742546081542968...\n-5.00032926914154263187128890422172844409942626...\n\n\n4\n7.54930929882019441379270574543625116348266601...\n7.54930929882019441379270574543625116348266601...\n\n\n...\n...\n...\n\n\n195\n5.73269150865232113289948756573721766471862792...\n5.73269150865232024472106786561198532581329345...\n\n\n196\n-2.20031285504599605218345459434203803539276123...\n-2.20031285504599383173740534402895718812942504...\n\n\n197\n-4.44552414243254645498382160440087318420410156...\n-4.44552414243254467862698220415040850639343261...\n\n\n198\n2.16478039072416539312371241976507008075714111...\n2.16478039072416583721292226982768625020980834...\n\n\n199\n-0.80340280563815458236831545946188271045684814...\n-0.80340280563815325010068590927403420209884643...\n\n\n\n\n200 rows × 2 columns\n\n\n\nНо оказалось, предсказания почити отличаются - различие в рамках погрежности!!!\nПоявлялась мысль, что данное различие обусровлено особенностями sklearn. Но при использовании формул привычной матричной алгебры, результат тот-же самый.\nОбычные данные\n\nnp_y = y.to_numpy().reshape([n,1])\nnp_x = add_constant(x).to_numpy()\nnp.dot(\n    np.linalg.inv(\n        np.dot(np.transpose(np_x), np_x)\n    ),\n    np.dot(np.transpose(np_x), np_y)\n).ravel()\n\narray([2.95566332, 3.13373587, 2.00359775])\n\n\nСтандартизированные данные\n\nnp_x_stand = add_constant(x_stand).to_numpy()\nnp.dot(\n    np.linalg.inv(\n        np.dot(np.transpose(np_x_stand), np_x_stand)\n    ),\n    np.dot(np.transpose(np_x_stand), np_y)\n).ravel()\n\narray([2.60710742, 0.95731566, 5.8421477 ])"
  },
  {
    "objectID": "machine_learning/tree_based_methods/tree.html",
    "href": "machine_learning/tree_based_methods/tree.html",
    "title": "Источники",
    "section": "",
    "text": "Изучение алгоритма “Решающее дерево”\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport seaborn as sns\n\nimport sklearn.tree as tree\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.model_selection import cross_val_score,\\\n                                    train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.datasets import load_breast_cancer\n\nimport graphviz\n\n\nISLR страница 336;\nUser guide от sklearn;\nАлгоритм обрезки с учётом сложности затрат в sklearn;\nПример использования алгоритма обрезки с учётом сложности затрат от sklearn;\n\n\nИдея группы методов\nРешающим деревом можно решать как задачи регрессии так и классификации. Идея в том, что исходное пространтсво предикторов разбивается на обаласти (\\(R_1, R_2, ... , R_m\\)) и на каждой области \\(R_i\\) предсказывается значение зависящее от наблюдений в ней.\nНапример для задачи регрессии можно предсказывать среднее значение отклика для выбранной области. Так в следующем примере представлено как может быть сформировано решеющее дерево для данных соответсвующий параболоиду.\nГраф сверху описывает принцип принятия решений, рисунки снизу указывают как формировались предсказания.\n\nзвенья графа в которых происходит решение называются внутренние узлы (internal nodes);\nзвенья графа которые формирут конечный результат и соответсвуют \\(R_i\\) называеются конечные узлы или листики (terminal nodes).\n\n\nЗадача регрессии\n\n# подготовка обучающей выборки\nsample_size = 500\nnp.random.seed(30)\n\nx1_lim = [-5, 5]\nx2_lim = [-5, 5]\n\nsample_df = pd.DataFrame({\n    \"$x_1$\" : np.random.uniform(*x1_lim, sample_size),\n    \"$x_2$\" : np.random.uniform(*x2_lim, sample_size),\n})\n\nsample_df[\"$y$\"] = sample_df[\"$x_1$\"]**2 + sample_df[\"$x_2$\"]**2\n\n# формирование модели\nmy_first_tree = tree.DecisionTreeRegressor(\\\n    max_depth = 3\n).fit(\n    sample_df[[\"$x_1$\", \"$x_2$\"]],\n    sample_df[\"$y$\"]\n)\n\n# сетка предстказаний\nx1_range = np.arange(*x1_lim, 0.1)\nx2_range = np.arange(*x2_lim, 0.1)\nx1_mesh, x2_mesh = np.meshgrid(x1_range, x2_range)\n\nmesh_df = pd.DataFrame({\n    \"$x_1$\" : x1_mesh.ravel(),\n    \"$x_2$\" : x2_mesh.ravel()\n})\np_mesh = np.reshape(\n    my_first_tree.predict(mesh_df),\n    x1_mesh.shape\n)\n\n# визуализация\ndot_data = tree.export_graphviz(\n    my_first_tree, out_file=None,\n    feature_names = [\"x_1\", \"x_2\"],\n    filled=True, rounded=True,  \n    special_characters=True\n)\ngraph = graphviz.Source(dot_data)\ndisplay(graph)\n\nfig = plt.figure(figsize = [20, 10])\n\nax1 = fig.add_subplot(121)\nDecisionBoundaryDisplay.from_estimator(\n    my_first_tree,\n    mesh_df,\n    cmap=cm.coolwarm,\n    response_method=\"predict\",\n    ax = ax1,\n)\nsns.scatterplot(\n    data = sample_df,\n    x = \"$x_1$\", y = \"$x_2$\",\n    size = \"$y$\",\n    ax=ax1,\n    color = \"green\"\n)\nplt.xlabel(\"$x_1$\", fontsize = 14)\nplt.ylabel(\"$x_2$\", fontsize = 14)\n\nax2 = fig.add_subplot(122, projection='3d')\nax2.scatter(\n    sample_df[\"$x_1$\"],\n    sample_df[\"$x_2$\"],\n    sample_df[\"$y$\"],\n    color = \"green\"\n)\nsurf = ax2.plot_surface(\n    x1_mesh, x2_mesh, p_mesh,\n    cmap=cm.coolwarm\n)\n\nfig.colorbar(surf, shrink=0.5, aspect=5)\n\nplt.xlabel(\"$x_1$\"); plt.ylabel(\"$x_2$\");\n\n\n\n\n\n\n\n\n\nЗадача классификации\nИдея та же - бинарное деление пространтсва предикоторов максимизируя некоторую статистику. Отдельного внимания заслуживают эти статистики:\n\nИндекс GINI:\n\n\\[G = \\sum_{k =1}^K \\hat{p}_{mk}(1-\\hat{p}_{mk});\\]\nгде \\(\\hat{p}_{mk}\\) - доля наблюдений \\(k\\) класса принадлежащих региону \\(m\\);\nИнтерестно, что в данном случае получается что чем ближе доли \\(\\hat{p}_{mk}\\) к нулю или единице (что в данном случае хорошо), тем меньше будет индекс GINI. Пока не до конца понятно как именно происходит минимизация - похоже подбирается такое отсечение, чтобы GINI был миниматен в любой из получаемых после отсечения областей.\n\nЭнтропия\n\n\\[D = -\\sum_{k=1}^{K}\\hat{p}_{mk}log(\\hat{p}_{mk})\\]\nОбладает очень похожими свойствами с индексом GINI.\n\n\n\nОбрезка дерева\nОчевидно, что слишком глубокие деревья ведут к переобучению а недостаточно глубокие к низкой гибкости модели. В результате требуется подобрать такую глибину дерева, чтобы подобрать опитимальный компромисс между дисперсией и смещением. Для того можно пробовать:\n\nИдеальном случае следовало бы провести кроссвалидацию для дерева любой длинны и выбрать ту, что на кроссвалидации выдает наилучшие результаты;\nВ [1] предлагают использовать алгоритм “обрезки с учетом сложности затрат” (cost complexity pruning).\n\n\nАлгоритм “обрезки с учетом сложности затрат”\nАлгоритм предполагает использование целевой функции:\n\\[\\sum_{m=1}^{|T|}\\sum_{x_i \\in R_m}(y_i-\\hat{y}_{R_m})^2+\\alpha|T|\\rightarrow min\\]\nМодель кроссвалидируется при разных \\(\\alpha\\). Соответсвенно подбирается оптимальный параметр \\(\\alpha\\). По сути это эквивалентно регуляризации модели.\n\nSKLearn\nПример представленный в докумментации sklearn. Основная фишка в том, что sklearn может найти эффективные \\(\\alpha\\) для каждого звена. То есть такие \\(\\alpha\\), при которых отбрасывается следущее звено за ненадобностью (то есть эффект от \\(\\alpha|T|\\) выше чем влияние узла на результат на тренировочной выборке).\nВ sklearn предзожен метод tree.DecisionTreeClassifier.cost_complexity_pruning_path. Она возвращаяет те после которых отбрасывается листик. Кроме того, можно получить соответствующую суммарную примесь листьев на каждом этапе процесса обрезки (total impurity of leaves). Так далее представлен гарфик, на котором показано, как с ростом \\(\\alpha\\) все больше и больше лисьев оказываются отброщенными.\n\nX, y = load_breast_cancer(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\nclf = tree.DecisionTreeClassifier(random_state=0)\npath = clf.cost_complexity_pruning_path(X_train, y_train)\nccp_alphas, impurities = path.ccp_alphas, path.impurities\n\nfig, ax = plt.subplots()\nax.plot(ccp_alphas[:-1], impurities[:-1], marker=\"o\", drawstyle=\"steps-post\")\nax.set_xlabel(\"эффективные $\\\\alpha$\")\nax.set_ylabel(\"суммарная примесь листьев\")\nans = ax.set_title(\"Суммарная примесь листьев и эффективные $\\\\alpha$\")\n\n\n\n\nСледующий пример учит модели на эффективных \\(\\alpha\\) и представляет как с увеличением \\(\\alpha\\) уменьшаяется гибкость модели - мельше листьев и глубины. Вплоть до одного узла.\nЭтот пример я вставил больше потому, что полезно знать как извлекать длинну глубину и число узлов полученного дерева: - tree.DecisionTreeClassifier.tree_.max_depth; - tree.DecisionTreeClassifier.tree_.node_count.\n\nclfs = []\nfor ccp_alpha in ccp_alphas:\n    clf = tree.DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n    clf.fit(X_train, y_train)\n    clfs.append(clf)\nprint(\n    \"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n        clfs[-1].tree_.node_count, ccp_alphas[-1]\n    )\n)\n\nclfs = clfs[:-1]\nccp_alphas = ccp_alphas[:-1]\n\nnode_counts = [clf.tree_.node_count for clf in clfs]\ndepthes = [clf.tree_.max_depth for clf in clfs]\nfig, ax = plt.subplots(2, 1, figsize = [14, 10])\nax[0].plot(ccp_alphas, node_counts, marker=\"o\", drawstyle=\"steps-pre\")\nax[0].set_xlabel(\"$\\\\alpha$\", fontsize = 14)\nax[0].set_ylabel(\"Число узлов\")\nax[0].set_title(\"Число узлов и $\\\\alpha$\")\nax[1].plot(ccp_alphas, depthes, marker=\"o\", drawstyle=\"steps-pre\")\nax[1].set_xlabel(\"$\\\\alpha$\", fontsize = 14)\nax[1].set_ylabel(\"Глупина дерева\")\nax[1].set_title(\"Глубина и $\\\\alpha$\")\nfig.tight_layout()\n\nfor i, (alpha, node_count, depth) in enumerate(zip(\n    ccp_alphas, node_counts, depthes\n)):\n    ax[0].text(alpha, node_count, i, fontsize = 14)\n    ax[0].axhline(node_count, color = \"gray\", linestyle = \"dashed\",alpha = 0.1)\n    ax[1].text(alpha, depth, i, fontsize = 14)\n    ax[1].axhline(depth, color = \"gray\", linestyle = \"dashed\",alpha = 0.1)\n\nax[0].set_yticks(node_counts)\nans = ax[1].set_yticks(depthes)\n\nNumber of nodes in the last tree is: 1 with ccp_alpha: 0.3272984419327777\n\n\n\n\n\nДля того, что-бы убедиться во всем описанно я решил нарисовать графы для деревьев соответсвующие 7-й и 8-й точкам. Чтобы проследить как исчезает лишний уровень глубины дерева.\n\n# визуализация\ndef plot_my_tree(clf):\n\n    dot_data = tree.export_graphviz(\n        clf, out_file=None,\n        filled=True, rounded=True,\n        special_characters=True\n    )\n    graph = graphviz.Source(dot_data)\n    display(graph)\n\nprint(\"Alpha =\", ccp_alphas[7])\nplot_my_tree(clfs[7])\nprint(\"Alpha =\", ccp_alphas[8])\nplot_my_tree(clfs[8])\n\nAlpha = 0.009114019793328328\nAlpha = 0.011443661971830986\n\n\n\n\n\n\n\n\nДалее продолжается исследование баланса между дисперсией и смещением. В следующем примере показано как растёт точность предсказаний на тестовой выборке с увеличением параметра \\(\\alpha\\).\n\ntrain_scores = [clf.score(X_train, y_train) for clf in clfs]\ntest_scores = [clf.score(X_test, y_test) for clf in clfs]\n\nfig, ax = plt.subplots()\nax.set_xlabel(\"$\\\\alpha$\")\nax.set_ylabel(\"Точность\")\nax.set_title(\"Точность и $\\\\alpha$ для терениовочной и тестовой выборки\")\nax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"Тренировачная\", drawstyle=\"steps-post\")\nax.plot(ccp_alphas, test_scores, marker=\"o\", label=\"Тестовая\", drawstyle=\"steps-post\")\nax.legend()\nplt.show()\n\n\n\n\n\n\nISLR\nПроведем на python эксперимент аналогичный представленному в [1]. В источнике не указано подробно как эксперимент проводился, потому проведу его как чуствую:\n\nВсе следующие шаги формируются в множество прогонов:\n\nФормируем train/test;\nВычиляем эффективные \\(\\alpha\\) для выбранного train;\nДля всех эффективных \\(\\alpha\\):\n\nОциниваем на train/test;\nКроссвалидируем на test.\n\n\n\nПо идее кроссвалидация тут не нужна, потому как прогоны разбиения train/test сами по себе эквиванентны кроссвалидации.\nfrom tqdm import tqdm\nnp.random.seed(25) fold_count = 6 Hitters = pd.read_csv(“Hitters.csv”).dropna()\ndef get_fit_data(f): return ( pd.get_dummies( f[[ “Years”, “RBI”, “Hits”, “PutOuts”, “Walks”, “Runs” ]] ), np.log(f[“Salary”]) )\ntree_regressor = tree.DecisionTreeRegressor()\nresults_frame = pd.DataFrame( columns = [ “alpha”, “Прогон экперимента”, “MSE тренировочное”, “MSE тестовое”, “Кроссвалидация”, “Глубина дерева”, “Число листов” ], )\nindexator = 0\n\n\n\n\nпрогоняем эксперимент\nfor i in tqdm(range(50)):\ntrain = Hitters.sample(132)\ntest = Hitters.loc[~Hitters.index.isin(train.index)]\n\ncpp_alphas = tree_regressor.cost_complexity_pruning_path(\n    *get_fit_data(train)\n)[\"ccp_alphas\"]\n\nfor alpha in cpp_alphas:\n\n    # подготовка\n    tree_regressor.set_params(ccp_alpha = alpha)\n    train_model = tree_regressor.fit(*get_fit_data(train))\n    train_X, train_y = get_fit_data(train)\n    test_X, test_y = get_fit_data(test)\n    train_model.fit(train_X, train_y)\n\n    train_pred = train_model.predict(train_X)\n    test_pred = train_model.predict(test_X)\n    cv_result = (\n        cross_val_score(\n            tree_regressor,\n            *get_fit_data(train),\n            cv = fold_count,\n            scoring=\"neg_mean_squared_error\"\n        )[:, np.newaxis]\n    )\n\n    results_frame.loc[indexator] = {\n        \"alpha\" : alpha,\n        \"Прогон экперимента\" : i,\n        \"MSE тренировочное\" : mean_squared_error(train_y, train_pred),\n        \"MSE тестовое\" : mean_squared_error(test_y, test_pred),\n        \"Кроссвалидация\" : -np.mean(cv_result),\n        \"Глубина дерева\" : train_model.tree_.max_depth,\n        \"Число листов\" : train_model.get_n_leaves()\n    }\n\n    indexator += 1\nresults_frame.to_csv(“ISLR_exeriment.csv”)\nДалее графичеки представим результаты. На следующем графике показана связь точности модели с числом листов. Палочками представлено стандарное отлоенние по различным прогонам.\n\nresults_frame = pd.read_csv(\"ISLR_exeriment.csv\")\n\ntree_depth_gb = results_frame.groupby(\"Число листов\")\n\nMSE_plots = (\n    tree_depth_gb[\"MSE тренировочное\"],\n    tree_depth_gb[\"MSE тестовое\"],\n    tree_depth_gb[\"Кроссвалидация\"]\n)\n\nfor MSE in MSE_plots:\n    plt.errorbar(tree_depth_gb.groups.keys(), MSE.mean(), MSE.std())\n\nans = plt.legend([\n    \"MSE тренировочное\",\n    \"MSE тестовое\",\n    \"Кроссвалидация\"\n])\nplt.xlabel(\"Число листов\", fontsize = 14)\nplt.ylabel(\"Точность модели\", fontsize = 14)\n\nans = plt.xlim([0,20])\n\n\n\n\nНе получается в точности воспроизвести эксперимент из ISLR. И в нашем случае лучшая модель исопльзует 4 листа. Но идея о бесконечном увеличении метрики качества на обучающей выборке понятна.\n\n\nДерево и пропуски\nВроде сказано, что дерево может по прежнему обучаться на тех наборах данных в которых присудствуют пропуски. Рассмотрим подробнее как это работатет.\nВ следующей ячейке создан набор данных на задачу классификации , в котром пропущено 100 значений для одной из переменных.\n\nnp.random.seed(20)\n\nd = pd.DataFrame({\n    \"x1\" : np.random.uniform(0, 10, 500),\n    \"x2\" : np.random.uniform(0, 10, 500)\n})\n\nr = d[\"x1\"] + d[\"x2\"]\n\nd[\"c\"] = ((r - r.min())/(r.max() - r.min())).apply(\n    lambda prob: np.random.choice([1,0], p = [prob**2, 1-(prob**2)])\n)\n\nd[\"x1 nans\"] = d[\"x1\"]\nd.loc[d.sample(100).index, \"x1 nans\"] = np.NaN\n\nans = sns.scatterplot(data=d, x=\"x1\", y=\"x2\", hue=\"c\", style=d[\"x1 nans\"].isna())\n\n\n\n\nПопробуем, такой набор данных скормить дереву и посмотрим, какое решение оно предложит:\nclf = tree.DecisionTreeClassifier(max_depth=3,random_state=0) clf.fit(d[[“x1 nans”, “x2”]], d[“c”])\ndot_data = tree.export_graphviz( clf, out_file=None, filled=True, rounded=True, special_characters=True, feature_names=[“x1”, “x2”] ) graph = graphviz.Source(dot_data) display(graph)\nВ общем, это не сработало - выдает ошибку оценщик."
  },
  {
    "objectID": "machine_learning/tree_based_methods/ensemble copy.html",
    "href": "machine_learning/tree_based_methods/ensemble copy.html",
    "title": "Баггинг",
    "section": "",
    "text": "Изучение ансамблей решающих деревьев\nИспользьвание алгоритма - решающее дерево может приводить к высокой дисперисии предсказаний. Для того, чтобы это избежать исползуются методы, которые обощают под названием ансамбли решающих деревьев. Выделяют следующие методы:\n\nBagging;\nRandom Forests;\nBoosting;\nBayesian Additive Regression Trees.\n\nИсточники\n\nISLR;\nСобрание возможностей sklearn посвященных ансамблям;\n\n\nfrom copy import copy\nimport warnings\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.ensemble import BaggingRegressor, BaggingClassifier\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n\nfrom sklearn.model_selection import cross_val_score\n\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\n\nПредполагает бутстрапирование обучающей выборки и подгонку множестава деревьев. Для получания предсказаний результаты каждого дерева аггрегируют (обычно усредняют). Вообще говоря, баггинг можно ложить не только на деревья но и на KNN модели.\n\nСравнение с единичным деревом\nСоздам выборку и на ней попробую оценить обычное дерево и баггинг на дереве. Результаты сравним.\n\nsample_size = 500\nnp.random.seed(10)\n\ndata = pd.DataFrame({\n    \"x\" : np.random.rand(sample_size)\n})\n\nf_x = lambda x: 15*x**3 - 15*x**2 + x \n\ndata[\"y\"] = f_x(data[\"x\"]) + np.random.uniform(0, 1, sample_size)\n\nДля контроля глубины дерева будет использоватся алгоритм обрезки с учетом сложности затрат. Для того, надо подобрать его парамерт \\(\\alpha\\).\n\nccp_alphas = DecisionTreeRegressor().\\\ncost_complexity_pruning_path(\n    data[[\"x\"]], data[\"y\"]\n)[\"ccp_alphas\"]\n\nclf = DecisionTreeRegressor()\nMSEs = {}\n\nfor alpha in tqdm(ccp_alphas):\n    clf.set_params(ccp_alpha = alpha)\n    MSE = cross_val_score(\n        clf, data[[\"x\"]], \n        data[\"y\"], \n        cv = 20,\n        scoring = \"neg_mean_squared_error\"\n    )\n    MSEs[alpha] = MSE\n\nMSEs = pd.DataFrame(MSEs)\n\n100%|██████████| 345/345 [00:21&lt;00:00, 15.69it/s]\n\n\n\nplt.figure(figsize = [15, 5])\n\ndef set_params():\n    plt.xlabel(\"$\\\\alpha$\")\n    plt.ylabel(\"$MSE$\")\n\nbordres = [-0.0001, 0.0035]\n\nplt.subplot(121)\nplt.plot(MSEs.columns, MSEs.mean())\nset_params()\nfor b in bordres:\n    plt.axvline(b, color = \"gray\", linestyle = \"dashed\")\nplt.title(\"Общий график\", fontsize = 14)\n\n\ncond = (MSEs.columns &gt; bordres[0]) & (MSEs.columns &lt; bordres[1])\n\nplt.subplot(122)\nplt.errorbar(MSEs.columns[cond], MSEs.mean()[cond], MSEs.std()[cond])\nplt.axvline(\n    MSEs.mean().idxmax(), \n    color = \"gray\", \n    linestyle = \"dashed\"\n)\nplt.xlim(bordres)\nset_params()\nplt.title(\"Максимум - подробно\", fontsize = 14)\nplt.xticks([MSEs.mean().idxmax()])\n\ndel set_params\n\n\n\n\nТеперь подгоням которые будем сравнивать.\n\nx_range = np.arange(0, 1, 0.005)\n\nclf = DecisionTreeRegressor(ccp_alpha=0.0076)\nclf.fit(data[[\"x\"]].to_numpy(), data[\"y\"])\ntree_predict = clf.predict(x_range[:, np.newaxis])\n\nbclf = BaggingRegressor(clf, n_estimators=200).fit(\n    data[[\"x\"]].to_numpy(), data[\"y\"]\n)\nbagging_predict = bclf.predict(x_range[:, np.newaxis])\n\nplt.figure(figsize = [15, 5])\n\nplt.subplot(121)\nplt.scatter(data[\"x\"], data[\"y\"])\nfor pred, col in zip(\n    [tree_predict, bagging_predict],\n    [\"red\", \"green\"]\n):\n    plt.plot(\n        x_range, pred,\n        color = col, linewidth = 3\n    )\n\nplt.legend([\"Наблюдения\", \"Дерево\", \"Баггинг\"])\nplt.title(\"Предсказания моделей\")\nplt.xlabel(\"x\")\n\nplt.subplot(122)\nplt.boxplot((\n    (f_x(x_range) - tree_predict)**2, \n    (f_x(x_range) - bagging_predict)**2)\n)\n\nplt.title(\"Отклонениние модели от реального закона распределения\")\nplt.ylabel(\"$RS$\")\nans = plt.xticks([1,2], [\"Дерево\", \"Баггинг\"])\n\n\n\n\nВсе складывается так, что баггированная модель “сглаживает” неготорые скачки, которые проявляются в одиночном дереве. В результате квадраты остатков (которые описывает правый график) более тучные для баггинга - меньше болших оклонений вверх но и нижняя граница выше.\n\n\nСлучайный лес (Random Forest)\nИдея как у баггинга, но, кроме того, что каждая подвыборка содержит только \\(m\\) из \\(p\\) случайных показателей. Обычно берут \\(m = \\sqrt{p}\\). А в остальном особой разницы нет.\nЕсли в выборке есть очень сильные показатели, то первое деление дерева производится часто именно по нему. В результате простой баггинг от подвыборки к подвыборке имеет очень похожие результаты. Случайное дерево справляется с этой ситуацией лучше.\n\n\nOOB\nOOB - out of bag. Способ оценки качества ансамблей моделей, при котором, оценка метрики качества модели производится на том “кусочке” выборке который не был задейсвован при обучении конкретной модели. Затем полученные величины, собранные со всей выборки агрегируют - полученное число и становится результатом.\n\nПример на котором будем экспериментировать\n\n# делаю пример классификационной задачи\nnp.random.seed(50)\n\n# vector of coefs of the discriminating curve (as a polynom)\ncoefs = np.array([0.40740741, -4.44444444, 13.88888889, -9.25925926])\n\ndef compute_poly_for_np_array(array, coefs):\n    '''\n        Calculation of the polynomial for an numpy array.\n        Inputs:\n            array - an array of any dimension to be used as an argument of the polynom;\n            coefs - polynomial coefficients (i-th for i degree);\n        Output numpy.array with gived same dimentions as array.\n    '''\n    \n    poly_degree = len(coefs)\n    return np.sum(\n        [coefs[i]*(array**i) for i in range(poly_degree)], \n        axis = 0\n    )\n\n# transition speed from one class to another\ntrans_speed = 4\ndef prob_for_bayes(x1, x2):\n    '''\n        This function describes a Bayesian \n        law that is used to divide into classes.\n        Inputs:\n            x1 - coordinate of first variable;\n            x2 - coordiante of second variable;\n        Output:\n            p - probability that observation takes class 1 \n                for given coordinates.\n    '''\n    return 1/(1 + np.exp(trans_speed*(compute_poly_for_np_array(x1, coefs) - x2)))\n\n\n\ndef create_sample():\n    '''\n        Создать случайную выборку, в соответсвии с\n        заданным законом распределения\n    '''\n\n    df = pd.DataFrame(\n        np.random.rand(1000, 2),\n        columns = [\"x1\", \"x2\"]\n    )\n    df[\"prob\"] = prob_for_bayes(df[\"x1\"], df[\"x2\"])\n    df[\"class\"] = df[\"prob\"].apply(\n        lambda p: np.random.choice([0, 1], p = [1-p, p])\n    )\n\n    return df\n\n\n# создание выборки - примера\nnp.random.seed(50)\ndf = create_sample()\n\n# создание сетки\nx1_range = np.linspace(0, 1, 500)\nx2_range = np.linspace(0, 1, 500)\n\nx1_mesh, x2_mesh = np.meshgrid(x1_range, x2_range)\nmesh_df = pd.DataFrame({\n    \"x1\" : x1_mesh.ravel(), \"x2\" : x2_mesh.ravel()\n})\n\nreal_prob = prob_for_bayes(mesh_df[\"x1\"], mesh_df[\"x2\"]).to_numpy()\nreal_prob = real_prob.reshape(x1_mesh.shape)\n\n\nplt.figure(figsize = [15, 7])\n\nplt.subplot(121)\nplt.imshow(real_prob, origin = \"lower\", extent = [0, 1, 0, 1])\nplt.title(\"Дейсвительное распредлеление\")\nplt.xlabel(\"$x_1$\"); plt.ylabel(\"$x_2$\");\n\nplt.subplot(122)\nplt.scatter(df[\"x1\"], df[\"x2\"], c=df[\"class\"])\nplt.xlabel(\"$x_1$\"); plt.ylabel(\"$x_2$\");\nans = plt.title(\"Реализация распределения\")\n\n\n\n\n\n\nРеализация в sklearn\nsklearn умеет OOB, но из метрик доступна только accuracy (доля правильно предсказанных), это тупо захардкожено тут. Например, можно провести oob для баггинга используя параметр oob_score = True констуктора класса BaggingClassifier. Ну а после обучения получить поле oob_score_ полученного объекта.\n\nclf = BaggingClassifier(\n    DecisionTreeClassifier(ccp_alpha = 0.01),\n    n_estimators=30,\n    oob_score=True,\n    random_state=50,\n).fit(df[[\"x1\", \"x2\"]], df[\"class\"])\n\nclf.oob_score_\n\n0.747\n\n\nИнтересное поле - oob_decision_function_. В исходние получается, что это среднее предсказание для каждого наблюдения, из всех его попаданий вне обучающей выборки. На нем при желании можно оценивать AUC.\n\nclf.oob_decision_function_\n\narray([[0.47801078, 0.52198922],\n       [0.35901744, 0.64098256],\n       [0.12722208, 0.87277792],\n       ...,\n       [0.15777634, 0.84222366],\n       [0.89753659, 0.10246341],\n       [0.86331456, 0.13668544]])\n\n\nИнтерестно, что если для каждого наблюдения сформировать предсказание и сравнить среднюю точность с oob_score_, то всегда будет получаться одно и тоже число. Хотя в коде sklearn oob_score_ вычисляется подругому. Если будет совсем нечего делать, можно попробовать разобраться почему так происходит.\n\n# частный случай пример \n(df[\"class\"].to_numpy() == np.argmax(clf.oob_decision_function_, axis=1)).mean()\n\n0.747\n\n\n\n# 20 других частных случаев\nlst = []\n\nfor i in range(20):\n    temp_df = create_sample()\n\n    temp_clf = BaggingClassifier(\n        DecisionTreeClassifier(ccp_alpha = 0.01),\n        n_estimators=30,\n        oob_score=True,\n        random_state=50,\n    ).fit(temp_df[[\"x1\", \"x2\"]], temp_df[\"class\"])\n\n    comp = (\n        temp_df[\"class\"].to_numpy() == \\\n        np.argmax(temp_clf.oob_decision_function_, axis=1)\n    ).mean()\n\n    lst.append(comp == temp_clf.oob_score_)\n\nall(lst)\n\nTrue\n\n\n\n\nСравнение cv и oob\n\ndef fit_estimate(X, y, ccp, n_estimators):\n\n    # приходится отключить warnings потому, что bagging\n    # ругается в случае малого числа оценщиков\n    warnings.filterwarnings(\"ignore\", category=UserWarning)\n    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n    clf = BaggingClassifier(\n        DecisionTreeClassifier(ccp_alpha = ccp),\n        n_estimators=n_estimators,\n        oob_score=True,\n        random_state=50,\n    )\n\n    cv_score = cross_val_score(\n        clf, X, y, scoring=\"accuracy\", cv = 20\n    )\n    res = cv_score.mean(), clf.fit(X,y).oob_score_\n    warnings.filterwarnings(\"ignore\", category=UserWarning)\n    warnings.filterwarnings(\"ignore\", category=RuntimeWarning\n\n    return res\n\ndef get_best_model(scores):\n    '''\n        Получить лучшую модель.\n        Под лучшей понимается модель, с самым высоким \n        значением целевой метрики, но при этом с \n        минимальными возможными числом оценщиков \n        и глубиной дерева.\n\n        Input:\n            scores - pandas.Series который содержит занчения целевой\n                     метрики, а в колонках у него:\n                        \"n_estimators\" - число оценщиков соответсвующей модели;\n                        \"ccp\" - параметр обрезки дерева.\n        Output - та строка из scores в которой заданы параметры\n                 наилучшей модели.\n    '''\n\n    main_val = scores.name\n    return scores.reset_index().sort_values(\n        [main_val, \"n_estimators\", \"ccp\"], \n        ascending=[False, True, False]\n    ).iloc[0]\n\n# создание тех комбинаций\n# параметров модели которое нужно\n# осчитать\nccp_alphas = DecisionTreeRegressor().\\\ncost_complexity_pruning_path(\n    df[[\"x1\", \"x2\"]], df[\"class\"]\n)[\"ccp_alphas\"]\n\nccp_alphas = np.linspace(ccp_alphas.min(), ccp_alphas.max(), 10)\nestimator_counts = range(30, 70)\n\ncombinations = pd.DataFrame(\n    [col.ravel() for col in np.meshgrid(ccp_alphas, estimator_counts)],\n    index=[\"ccp\", \"n_estimators\"]\n).T\n\nSyntaxError: '(' was never closed (1082649026.py, line 19)\n\n\nval_ress = combinations.apply( lambda x: fit_estimate( df[[“x1”, “x2”]], df[“class”], x[“ccp”], int(x[“n_estimators”]) ), axis = 1 )\nval_ress = val_ress.apply( lambda row: pd.Series( row, index = [“cross validation”, “OOB”] ) ) val_ress.index = pd.MultiIndex.from_frame(combinations)\nval_ress.to_csv(“cv_vs_oob.csv”)\n\nval_ress = pd.read_csv(\"cv_vs_oob.csv\", index_col=[0, 1])\n\n\nplt.scatter(val_ress[\"cross validation\"], val_ress[\"OOB\"])\nplt.xlabel(\"CV accuracy\")\nplt.title(\"OOB против CV\")\nans = plt.ylabel(\"OOB accuracy\")\n\n\n\n\n\npd.concat(\n    [\n        get_best_model(val_ress[\"cross validation\"]),\n        get_best_model(val_ress[\"OOB\"])\n    ],\n    axis=1\n)\n\n\n\n\n\n\n\n\n281\n201\n\n\n\n\nccp\n0.006929\n0.006929\n\n\nn_estimators\n58.000000\n50.000000\n\n\ncross validation\n0.763000\nNaN\n\n\nOOB\nNaN\n0.756000\n\n\n\n\n\n\n\n\n\n\nООб\n\nheart = pd.read_csv(\"Heart.csv\", index_col=0)\n\ny = (heart[\"AHD\"] == \"Yes\").astype(\"int32\")\nX = pd.get_dummies(heart.drop(\"AHD\", axis=1))\n\nX_train = X.iloc[:152]\nX_test = X.loc[~X.index.isin(X_train.index)]\ny_train = y.loc[X_train.index]\ny_test = y.loc[X_test.index]\n\nclf = RandomForestClassifier()\nfor tree_count in range(1,301):\n    clf.set_params()\n\n\n\n\n\n\n\n\nAge\nSex\nRestBP\nChol\nFbs\nRestECG\nMaxHR\nExAng\nOldpeak\nSlope\nCa\nChestPain_asymptomatic\nChestPain_nonanginal\nChestPain_nontypical\nChestPain_typical\nThal_fixed\nThal_normal\nThal_reversable\n\n\n\n\n153\n67\n0\n115\n564\n0\n2\n160\n0\n1.6\n2\n0.0\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n154\n55\n1\n160\n289\n0\n2\n145\n1\n0.8\n2\n1.0\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n155\n64\n1\n120\n246\n0\n2\n96\n1\n2.2\n3\n1.0\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n156\n70\n1\n130\n322\n0\n2\n109\n0\n2.4\n2\n3.0\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n157\n51\n1\n140\n299\n0\n0\n173\n1\n1.6\n1\n0.0\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n299\n45\n1\n110\n264\n0\n0\n132\n0\n1.2\n2\n0.0\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nTrue\n\n\n300\n68\n1\n144\n193\n1\n0\n141\n0\n3.4\n2\n2.0\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n301\n57\n1\n130\n131\n0\n0\n115\n1\n1.2\n2\n1.0\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n302\n57\n0\n130\n236\n0\n2\n174\n0\n0.0\n2\n1.0\nFalse\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\n\n\n303\n38\n1\n138\n175\n0\n0\n173\n0\n0.0\n1\nNaN\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n\n\n151 rows × 18 columns"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Knowledge bank",
    "section": "",
    "text": "Website provided by Fedor Kobak, with various studies in data science, computer science and related fields."
  },
  {
    "objectID": "other/basic_apache2.html",
    "href": "other/basic_apache2.html",
    "title": "Basic work with apache2 web server",
    "section": "",
    "text": "Sources\n\nInstalation https://httpd.apache.org/docs/2.4/install.html;\n\n\n\nRun/stop server\nTo start the Apache web server you can use service apache2 start. After successful execution of this command you should get response from localhost:80 - in browser it would be Apache2 Default Page. service apache2 stop therefore stops the server.\nIn fllowing example: - Before the server starts, I access the web server via curl - but get no response; - I start the server with service apache2 start, after starting curl return apache start page; - I stop the server with service apache2 stop - this stops the apache welcome page from appearing.\n\n%%bash\necho \"=====Curl before server start=====\"\ncurl -s localhost:80 | head -n 50\n\nservice apache2 start\necho \"=====Curl after server start=====\"\ncurl -s localhost:80 | head -n 50\n\nservice apache2 stop\necho \"=====Curl after server stop=====\"\ncurl -s localhost:80 | head -n 50\n\n=====Curl before server start=====\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\"&gt;\n  &lt;!--\n    Modified from the Debian original for Ubuntu\n    Last updated: 2022-03-22\n    See: https://launchpad.net/bugs/1966004\n  --&gt;\n  &lt;head&gt;\n    &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /&gt;\n    &lt;title&gt;Apache2 Ubuntu Default Page: It works&lt;/title&gt;\n    &lt;style type=\"text/css\" media=\"screen\"&gt;\n  * {\n    margin: 0px 0px 0px 0px;\n    padding: 0px 0px 0px 0px;\n  }\n\n  body, html {\n    padding: 3px 3px 3px 3px;\n\n    background-color: #D8DBE2;\n\n    font-family: Ubuntu, Verdana, sans-serif;\n    font-size: 11pt;\n    text-align: center;\n  }\n\n  div.main_page {\n    position: relative;\n    display: table;\n\n    width: 800px;\n\n    margin-bottom: 3px;\n    margin-left: auto;\n    margin-right: auto;\n    padding: 0px 0px 0px 0px;\n\n    border-width: 2px;\n    border-color: #212738;\n    border-style: solid;\n\n    background-color: #FFFFFF;\n\n    text-align: center;\n  }\n\n  div.page_header {\n    height: 180px;\n    width: 100%;\n\n=====Curl after server start=====\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\"&gt;\n  &lt;!--\n    Modified from the Debian original for Ubuntu\n    Last updated: 2022-03-22\n    See: https://launchpad.net/bugs/1966004\n  --&gt;\n  &lt;head&gt;\n    &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /&gt;\n    &lt;title&gt;Apache2 Ubuntu Default Page: It works&lt;/title&gt;\n    &lt;style type=\"text/css\" media=\"screen\"&gt;\n  * {\n    margin: 0px 0px 0px 0px;\n    padding: 0px 0px 0px 0px;\n  }\n\n  body, html {\n    padding: 3px 3px 3px 3px;\n\n    background-color: #D8DBE2;\n\n    font-family: Ubuntu, Verdana, sans-serif;\n    font-size: 11pt;\n    text-align: center;\n  }\n\n  div.main_page {\n    position: relative;\n    display: table;\n\n    width: 800px;\n\n    margin-bottom: 3px;\n    margin-left: auto;\n    margin-right: auto;\n    padding: 0px 0px 0px 0px;\n\n    border-width: 2px;\n    border-color: #212738;\n    border-style: solid;\n\n    background-color: #FFFFFF;\n\n    text-align: center;\n  }\n\n  div.page_header {\n    height: 180px;\n    width: 100%;\n\n=====Curl after server stop====="
  },
  {
    "objectID": "other/linux_backup.html",
    "href": "other/linux_backup.html",
    "title": "How to linux backup",
    "section": "",
    "text": "rsync usage example;\nrsync documentation;\n backup with rsync;\n official ubuntu backup instructions;\noffical ubutntu backup instructions - section about tar.\n\n\ntar\nIn the following cell I just try to follow the instructions from official ubutntu backup instructions - section about tar, to make a backup - and test how it works in different cases.\nI want to try: - step 1 - backup creating: - run docker container with ubuntu; - install curl, abache2; - run the apache2 service; - check apache2 with curl; - use tar to make a backup of the current system; - stop the container; - step2 - recovery from back up: - run a new empty ubuntu container; - copy the backup archive from the previous container; - restore the backup in empty ubuntu system; - check curl and apache2.\nstep 1 - backup creating\n\n%%bash\nmkdir backups\ndocker run --rm --name ubun_cont -i -v $(pwd)/backups:/backups ubuntu\n\necho \"=====install=====\"\napt-get update &&gt; /dev/null\napt-get install curl apache2 -y &&gt; /dev/null\nservice apache2 start &&gt; /dev/null\n\n\necho\necho \"=====check=====\"\ncurl -s localhost:80 | head -n 20\n\necho\necho \"=====make backup=====\"\ntar \\\n    -cvpzf \\\n    /backups/backup.tar.gz \\\n    --exclude=/backups/backup.tar.gz \\\n    --one-file-system / &&gt; /dev/null\nexit\n\n=====install=====\n\n=====check=====\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\"&gt;\n  &lt;!--\n    Modified from the Debian original for Ubuntu\n    Last updated: 2022-03-22\n    See: https://launchpad.net/bugs/1966004\n  --&gt;\n  &lt;head&gt;\n    &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /&gt;\n    &lt;title&gt;Apache2 Ubuntu Default Page: It works&lt;/title&gt;\n    &lt;style type=\"text/css\" media=\"screen\"&gt;\n  * {\n    margin: 0px 0px 0px 0px;\n    padding: 0px 0px 0px 0px;\n  }\n\n  body, html {\n    padding: 3px 3px 3px 3px;\n\n    background-color: #D8DBE2;\n\n=====make backup=====\n\n\nThere is not much to say - it saves the backup in the “backups” folder.\nstep2 - recovery from backup\n\n%%bash\ndocker run --rm --name ubun_cont -i -v $(pwd)/backups:/backups ubuntu\ntar -xvpzf /backups/backup.tar.gz -C / --numeric-owner &&gt; /dev/null\n\necho \"=====culr --help=====\"\ncurl --help\necho \"=====curl localhost:80=====\"\nculr -s localhost:80\n\necho\necho \"=====curl localhost:80 after apache=====\"\nservice apache2 start\ncurl -s localhost:80 | head -n 20\n\nexit\n\n=====culr --help=====\nUsage: curl [options...] &lt;url&gt;\n -d, --data &lt;data&gt;          HTTP POST data\n -f, --fail                 Fail silently (no output at all) on HTTP errors\n -h, --help &lt;category&gt;      Get help for commands\n -i, --include              Include protocol response headers in the output\n -o, --output &lt;file&gt;        Write to file instead of stdout\n -O, --remote-name          Write output to a file named as the remote file\n -s, --silent               Silent mode\n -T, --upload-file &lt;file&gt;   Transfer local FILE to destination\n -u, --user &lt;user:password&gt; Server user and password\n -A, --user-agent &lt;name&gt;    Send User-Agent &lt;name&gt; to server\n -v, --verbose              Make the operation more talkative\n -V, --version              Show version number and quit\n\nThis is not the full help, this menu is stripped into categories.\nUse \"--help category\" to get an overview of all categories.\nFor all options use the manual or \"--help all\".\n=====curl localhost:80=====\n\n=====curl localhost:80 after apache=====\n * Starting Apache httpd web server apache2\n * \n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\"&gt;\n  &lt;!--\n    Modified from the Debian original for Ubuntu\n    Last updated: 2022-03-22\n    See: https://launchpad.net/bugs/1966004\n  --&gt;\n  &lt;head&gt;\n    &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /&gt;\n    &lt;title&gt;Apache2 Ubuntu Default Page: It works&lt;/title&gt;\n    &lt;style type=\"text/css\" media=\"screen\"&gt;\n  * {\n    margin: 0px 0px 0px 0px;\n    padding: 0px 0px 0px 0px;\n  }\n\n  body, html {\n    padding: 3px 3px 3px 3px;\n\n    background-color: #D8DBE2;\n\n\n/bin/bash: line 6: culr: command not found\nAH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 172.17.0.2. Set the 'ServerName' directive globally to suppress this message\n\n\nNote Even without downloading curl and apache2 I can use it after unpacking. To use apache2 you had to start the corresponding service - but it was still really easy.\n\n\nrsync basics\nActually rsync is just a copy tool, but if you compare it with cp it has much more options and features.\n\nBasic syntax\nrsync &lt;copied file&gt; &lt;destination of copying&gt;\nExample follows\n\n%%bash\n# creating to directories\nmkdir dir1 dir2\n# creating file in dir1\necho \"hello new file\" &gt; dir1/test_file\n# rsynk file from dir1 to dir2\nrsync dir1/test_file dir2/test_file\n# check the message\ncat dir2/test_file\n\nrm -r dir1 dir2\n\nhello new file\n\n\n\n\nr - copy recursive\nAllow to copy a folder with all its contents.\nIn the following example I’m trying to copy contents from dir1 to dir2, as you can see I couldn’t do it without the r option.\n\n%%bash\n\nmkdir dir1 dir2\ntouch dir1/file{1..5}.txt\n\necho \"=====content of dir1=====\"\nls dir1\n\necho \"=====no r option=====\"\nrsync dir1/ dir2\nls dir2\n\necho \"=====r option=====\"\nrsync -r dir1/ dir2\nls dir2\n\nrm -r dir1 dir2\n\n=====content of dir1=====\nfile1.txt\nfile2.txt\nfile3.txt\nfile4.txt\nfile5.txt\n=====no r option=====\nskipping directory .\n=====r option=====\nfile1.txt\nfile2.txt\nfile3.txt\nfile4.txt\nfile5.txt\n\n\n\n\n-a - attributes\nIt works just like r, but also deals with file attributes (like creation time, user and so on). So in the following example:\n\nFew files was created in dir1;\nThe user for these files has been changed from root to user1;\nThen I use rsync twice:\n\nFirst with the r option, which puts the user back in root;\nSecond, with the a option, which saves the user attribute as user1 from source.\n\n\n\n%%bash\n# docker container for usperuser access\ndocker run --rm --name test_container -i ubuntu\napt-get update &&gt; /dev/null\napt-get install -y rsync &&gt; /dev/null\n# creating file with some specific user\nuseradd user1\nmkdir dir1 dir2\ntouch dir1/file{1..5}.txt\nchown user1 dir1/file*\n\necho \"=====dir1=====\"\nls -l dir1\n\necho\necho \"=====dir2 after rsync -r=====\"\nrsync -r dir1/ dir2\nls -l dir2\n\necho\necho \"=====dir2 after rsync -a=====\"\nrsync -a dir1/ dir2\nls -l dir2\n\nexit\n\n=====dir1=====\ntotal 0\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file1.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file2.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file3.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file4.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file5.txt\n\n=====dir2 after rsync -r=====\ntotal 0\n-rw-r--r-- 1 root root 0 Jun 17 15:31 file1.txt\n-rw-r--r-- 1 root root 0 Jun 17 15:31 file2.txt\n-rw-r--r-- 1 root root 0 Jun 17 15:31 file3.txt\n-rw-r--r-- 1 root root 0 Jun 17 15:31 file4.txt\n-rw-r--r-- 1 root root 0 Jun 17 15:31 file5.txt\n\n=====dir2 after rsync -a=====\ntotal 0\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file1.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file2.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file3.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file4.txt\n-rw-r--r-- 1 user1 root 0 Jun 17 15:31 file5.txt\n\n\n\n\n--delete - delete extraneous\nIf you don’t use this option rsync will save files wich are in destination directory. Оtherwise all files that are not in the source will be deleted in the destination folder. The following exampe show: - In dir2 I created file test.txt; - First I rsync files from dir1 to dir2 without the --delete option - test.txt is still in dir2; - Second I rsync files from dir1 to dir2 using the --delete option - test.txt disappears from dir2.\n\n%%bash\nmkdir dir1 dir2\ntouch dir1/file{1..5}.txt\ntouch dir2/test.txt\n\necho \"====initial dir2=====\"\nls dir2\n\necho \"=====dir2 after rsync no --delete=====\"\nrsync -r dir1/ dir2\nls dir2\n\necho \"=====dir2 after rsync with --delete=====\"\nrsync -r --delete dir1/ dir2\nls dir2\n\nrm -r dir1 dir2\n\n====initial dir2=====\ntest.txt\n=====dir2 after rsync no --delete=====\nfile1.txt\nfile2.txt\nfile3.txt\nfile4.txt\nfile5.txt\ntest.txt\n=====dir2 after rsync with --delete=====\nfile1.txt\nfile2.txt\nfile3.txt\nfile4.txt\nfile5.txt"
  },
  {
    "objectID": "other/pltly_dash.html",
    "href": "other/pltly_dash.html",
    "title": "Experiments with plotly dash",
    "section": "",
    "text": "Sources\n\nUsing dash inside jupyter;\nCheck list component in dash;\nDash basic callbacks;\nCallback without output - github discussion.\n\n\n\nCallbacks\nIt is a mechanism that allows you to create a function that will be called when you perform an action. It realised. This is implemented via the dash.callback decorator. More details in the documentation. I will focus on some practical features.\n\nInput/output format\nInput/Output, implemented by dash.Input/dash.Output, which should be passed as arguments to the callback decorator. Constructors of the classes require the following syntax (\"&lt;object-id&gt;\", \"&lt;property&gt;\"), so you can choose which property to pass to the callback and which to change.\nIn the following example, I simply take dcc.Checklist.values and link it to ddc.Slider.marks - the markers on the dcc.slider will exactly match the selected checkboxes on the dcc.checklist.\n\nfrom dash import dcc, html, Input, Output, callback\nfrom IPython.display import clear_output\n\napp = JupyterDash(__name__)\noptions = list(range(0,20))\nvalue = [1,5]\n\nlst_val_to_slider_marks = lambda value: {val:str(val) for val in value}\n\napp.layout = html.Div(\n    [\n        dcc.Checklist(\n            options,\n            value = value,\n            id = \"check-lst\",\n            inline = True\n        ),\n        dcc.Slider(\n            min(options), max(options),\n            step = None,\n            marks = lst_val_to_slider_marks(value),\n            id = \"slider\"\n        )\n    ],\n    style={'display': 'flex', 'flex-direction': 'column'}\n)\n\n@callback(\n    Output(\"slider\", \"marks\"),\n    Input(\"check-lst\", \"value\")\n)\ndef my_callback(val):\n    return lst_val_to_slider_marks(val)\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\nclear_output()\n\nIn site it will looks like:  Any check box you click - it will add one more marker on slider.\n\n\nCallback without output\nIt turns out that dash has no callback mechanism without output. So the only tricky way is to create a dummy object and set it as the output object. In the following example, I use html.Div(id='dummy'), or rather its children property. I also print out some messages with changes to dcc.Checklist to prove that everything is working.\n\nfrom dash import dcc, html, Input, Output, callback\nfrom jupyter_dash import JupyterDash\nfrom IPython.display import clear_output\n\n\napp = JupyterDash(__name__)\n\ncheck_values = [\"value1\", \"value2\", \"value3\"]\n\napp.layout = html.Div([\n    html.Div(id='dummy'),\n    dcc.Checklist(\n        check_values,\n        id = \"check-lst\"\n    )\n])\n\nclicks_counter = 0\n\n@callback(\n    Output(\"dummy\", \"children\"),\n    Input(\"check-lst\", \"value\")\n)\ndef test_callback(checklist_value):\n    global clicks_counter\n    clicks_counter += 1\n\n    print(\"==========================\")\n    print(f\"    CLICK {clicks_counter}     \")\n    print(\"==========================\")\n    \n    print(\"-------value-------\")\n    print(checklist_value)\n    return None\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n\nclear_output()\n\n==========================\n    CLICK 1     \n==========================\n-------value-------\nNone\n==========================\n    CLICK 2     \n==========================\n-------value-------\n['value2']\n==========================\n    CLICK 3     \n==========================\n-------value-------\n['value2', 'value3']\n==========================\n    CLICK 4     \n==========================\n-------value-------\n['value2', 'value3', 'value1']\n==========================\n    CLICK 5     \n==========================\n-------value-------\n['value2', 'value3']\n==========================\n    CLICK 6     \n==========================\n-------value-------\n['value3']"
  },
  {
    "objectID": "latex/latex.html",
    "href": "latex/latex.html",
    "title": "Символы",
    "section": "",
    "text": "Тут разбраны самые часто забываемые мной возможности latex\nВсевозможнейшие символы и конструкции latex. Источниками полсужили: - http://tex.imm.uran.ru/tex/2e/lshort2e/node52.html; - https://ido.tsuab.ru/mod/book/view.php?id=62&chapterid=23; - https://ru.overleaf.com/learn/latex/List_of_Greek_letters_and_math_symbols.\nЗдесь для бысторого доступа я приведу лишь те сиволы, которые мне пригождались."
  },
  {
    "objectID": "latex/latex.html#буквы-с-пустым-пространством",
    "href": "latex/latex.html#буквы-с-пустым-пространством",
    "title": "Символы",
    "section": "Буквы с пустым пространством",
    "text": "Буквы с пустым пространством\nОбычно используются для обозначения можеств. Для того, чтобы букву написать таким образом используется команда \\mathbb{...}.\n\\[\\mathbb{ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz}\\]"
  },
  {
    "objectID": "Docker/docker_commands.html",
    "href": "Docker/docker_commands.html",
    "title": "Docker commands",
    "section": "",
    "text": "Working with containers\n\ndocker ps - show containers\n\n%%bash\ndocker run -itd --rm --name test_container python:3.10 &&gt; /dev/null\ndocker ps\ndocker stop test_container &&gt; /dev/null\n\nCONTAINER ID   IMAGE         COMMAND     CREATED        STATUS                  PORTS     NAMES\nb17984f2b882   python:3.10   \"python3\"   1 second ago   Up Less than a second             test_container\n\n\n\n-a show all containers\nBy default, inactive containers are hidden.\n\n%%bash\ndocker run --name temp_container ubuntu &&gt; /dev/null\necho \"========no option -a==============\"\ndocker ps\necho \"=========with option -a=============\"\ndocker ps -a\ndocker rm temp_container &&gt; /dev/null\n\n========no option -a==============\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n=========with option -a=============\nCONTAINER ID   IMAGE     COMMAND       CREATED                  STATUS                              PORTS     NAMES\nad0439c23847   ubuntu    \"/bin/bash\"   Less than a second ago   Exited (0) Less than a second ago             temp_container\n\n\n\n\n\ndocker history - show layers of the image\n\n\ndocker start - activate exited container\nIn the next cell, I build a ubuntu container that prints “hello world” when it starts. Like all standard ubuntu containers it quits, which we can see in the STATUS of the ps command. Then by docker start the container is reactivated.\nFor some reason it only works when I use the -i option for docker start.\n\n%%bash\ncd containers_files\ndocker build -t test_ubuntu . &&gt; /dev/null\necho \"=====First start=====\"\ndocker run --name u1 test_ubuntu\necho \"=====List of all containers=====\"\ndocker ps -a\necho \"=====Restart=====\"\ndocker start -i u1\ndocker rm u1 &&gt; /dev/null\ndocker rmi test_ubuntu &&gt; /dev/null\n\n=====First start=====\nhello world\n=====List of all containers=====\nCONTAINER ID   IMAGE         COMMAND                CREATED        STATUS                              PORTS     NAMES\naf533b577c94   test_ubuntu   \"echo 'hello world'\"   1 second ago   Exited (0) Less than a second ago             u1\n=====Restart=====\nhello world\n\n\n\n\ndocker stop - stop some container\nIn the following example, I start a container with Ubuntu in such a way that it stays running, which was proven by using docker ps. But after using docker stop the same container is in the state “Exited”.\n\n%%bash\ndocker run -itd --name test_ubuntu ubuntu &&gt; /dev/null\necho \"=====Just started container=====\"\ndocker ps -a\ndocker stop test_ubuntu &&gt; /dev/null\necho \"=====Stoped container (STATUS \\\"Exited\\\")=====\"\ndocker ps -a\ndocker rm test_ubuntu &&gt; /dev/null\n\n=====Just started container=====\nCONTAINER ID   IMAGE     COMMAND       CREATED                  STATUS                  PORTS     NAMES\ne175ae336dcb   ubuntu    \"/bin/bash\"   Less than a second ago   Up Less than a second             test_ubuntu\n=====Stoped container (STATUS \"Exited\")=====\nCONTAINER ID   IMAGE     COMMAND       CREATED          STATUS                                PORTS     NAMES\ne175ae336dcb   ubuntu    \"/bin/bash\"   10 seconds ago   Exited (137) Less than a second ago             test_ubuntu\n\n\n\n\ndocker exec - run a command in the container\nIn the next command I start ubuntu conteiner. Then using docker exec' I run thels’ command in the container and get a typical Linux result for that command.\n\n%%bash\ndocker run -itd --rm --name test_ubuntu ubuntu &&gt; /dev/null\ndocker exec test_ubuntu ls\ndocker stop test_ubuntu &&gt; /dev/null\n\nbin\nboot\ndev\netc\nhome\nlib\nlib32\nlib64\nlibx32\nmedia\nmnt\nopt\nproc\nroot\nrun\nsbin\nsrv\nsys\ntmp\nusr\nvar\n\n\n\n-it - take control of the container\nIt looks like the options individually have the same properties as in the docker run command. But the important thing is that you can take control of the detached container with this command. The following example shows how I can get control in detached ubuntu by running the bash command with named options.\n\n\n\n\ndocker logs - get container console\nDesrtiption of the command you can find here.\n\n\n\ndocker run - container from image\nThis command is related to the “Working with containers” section, but it is big enough and important enough to have its own section.\n\n%%bash\necho \"================before start=====================\"\ndocker ps -a\necho \"===============after start======================\"\ndocker run --name temp_container ubuntu &&gt; /dev/null\ndocker ps -a\ndocker rm temp_container\n\n================before start=====================\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n===============after start======================\nCONTAINER ID   IMAGE     COMMAND       CREATED        STATUS                              PORTS     NAMES\ncd0f144063c5   ubuntu    \"/bin/bash\"   1 second ago   Exited (0) Less than a second ago             temp_container\ntemp_container\n\n\n\n-rm - automatic container removal\nAfter stopping, the container is removed. In the following example there are two containers of ubuntu, one with the --rm option and the other without. Both containers stops by default - but only one stays with STATUS == Exited.\n\n%%bash\ndocker run --name no_rm_ubuntu ubuntu\ndocker run --rm --name ubuntu_with_rm ubuntu\ndocker ps -a\ndocker rm no_rm_ubuntu &&gt; /dev/null\n\nCONTAINER ID   IMAGE     COMMAND       CREATED        STATUS                              PORTS     NAMES\n7acc3cc0c61c   ubuntu    \"/bin/bash\"   1 second ago   Exited (0) Less than a second ago             no_rm_ubuntu\n\n\n\n\n--name - set name for the container\n\n%%bash\ndocker run --rm --name unbuntu_container -d ubuntu\ndocker ps\ndocker stop unbuntu_container\n\n7116dcdaa0a131a8507f9cbe149719498456fe356a23f1ddfc48f65080cfe660\nCONTAINER ID   IMAGE     COMMAND       CREATED        STATUS                  PORTS     NAMES\n7116dcdaa0a1   ubuntu    \"/bin/bash\"   1 second ago   Up Less than a second             unbuntu_container\nunbuntu_container\n\n\n\n\n-d - make container not to lock CLI\n\n%%bash\ndocker run --rm -d --name temp_nginx nginx &&gt; /dev/null\ndocker ps\ndocker stop temp_nginx &&gt; /dev/null\n\nCONTAINER ID   IMAGE     COMMAND                  CREATED                  STATUS                  PORTS     NAMES\n09175cb8c6d9   nginx     \"/docker-entrypoint.…\"   Less than a second ago   Up Less than a second   80/tcp    temp_nginx\n\n\n\n\n-i - interactive mode\nMode that allows to interapt with container.\nUnfortunately it is not possible to show how this mode will work in jupyter. So here is a gif of me experimenting with the following command:\ndocker run -i --rm --name test_ubuntu ubuntu\n\nIn the example, the ubuntu container has been started and is stopped by default. The -i option causes it to lock the terminal. Extremely interesting that you will be able to send messages to the container and get results (as I showed with ls and exit commands), but you won’t get the description of the user common for Linux terminal.\n\n\n-t turn on TTY\nTTY is something on backend language. The point here is that in combination with the -i option you can make will show you the “description” of the user which was mentioned in the previous section. And the terminal will be blocked waiting for input. But this option don’t allow you to send anything to the container.\nThe following .gif show what you will get in case using command docker run -t --rm --name temp_ubuntu ubuntu.\n\n\n\n-it - combination\nBoth options were discovered above, but they are really often used in combination. So Ubuntu provides full CLI interface with this options.\n\n\n\ncommands from jupyter\nUsing only the i option (without t), you can send commands to the container from the Jupyter cell.\nSo in the following example, I can easily run the ls program from the newly created ubuntu container.\n\n%%bash\ndocker run --rm -i --name test_container ubuntu\nls\nexit\n\nbin\nboot\ndev\netc\nhome\nlib\nlib32\nlib64\nlibx32\nmedia\nmnt\nopt\nproc\nroot\nrun\nsbin\nsrv\nsys\ntmp\nusr\nvar\n\n\nIt’s a pity I didn’t understand this before I wrote most of the Docker description. So don’t be surprised if you see something like this:\ndocker exec ...\ndocker exec ...\ndocker exec ...\nIn some section of docker description.\n\n\n-e - environment variables\nYou can also pass the values of the variables of the system you are calling from.\n\n%%bash\ndocker run --rm -i --name e_example -e FEDOR_TEST_VAR=$HOME ubuntu\necho $FEDOR_TEST_VAR\nexit\n\n/home/fedor\n\n\n\n\nCommand on container start\nIn the docker run command, after the name of the base image, you can specify a command that will be executed when the container starts. So in the next example I will show you how to run echo \"hello world\" in a new ubuntu container.\n\n%%bash\ndocker run --rm ubuntu echo \"hello world\"\n\nhello world\n\n\n\nIf you want to run several commands you have to use bash -c \"&lt;command&gt;\", like in following example:\n\n\n%%bash\ndocker run --rm ubuntu bash -c \"\n    echo \\\"hello world\\\"; \n    echo \\\"hello world2\\\"\n\"\n\nhello world\nhello world2\n\n\n\nNote that when containers are in interactive mode, the command executed should take input, otherwise it will just leave container anyway, the follwing gif describe how it looks like: \n\nIn the example, I ran the echo command with container starts and showed that there were no containers created - because the container was stopped and removed just after it was started. But immediately I created a new container, but now with the command bash -c \"echo \\\"hello world\\\"; bash - in this case the last command is bash which waits for input, so I’m comming back into the container.\n\n\n-v - map folder on container to folder on host\nThis is wide topic detailed in this section;\n\n\n-u - set user\nBy default, all docker containers have root privileges, but it can be useful to set user. For a more detailed description in the context of filesystem access, see here.\n\n\n\nWorking with images\n\ndocker pull - download image from dockerhub.com\nIt is obligatory to pass on one of the:\n\n&lt;image name&gt;:&lt;tag&gt; (&lt;tag&gt; - by default is latest);\nIMAGE ID - image id.\n\n\n%%bash\ndocker images | grep hello-world\necho \"===============beforre pull======================\"\ndocker pull hello-world:latest &&gt; /dev/null\necho \"===============after pull======================\"\ndocker images | grep hello-world\ndocker rmi hello-world &&gt; /dev/null\n\n===============beforre pull======================\n===============after pull======================\nhello-world                latest    9c7a54a9a43c   2 weeks ago     13.3kB\n\n\n\n\ndocker images - show list of available images;\n\n%%bash\ndocker images\n\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\nhello-world   latest    feb5d9fea6a5   16 months ago   13.3kB\n\n\n\n--a,--all - show all images\nBy default, so called “intermediate”, images are hiden. Nowadays I don’t know what “intermediate” images are.\n\n%%bash\ndocker images --all\n\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\nhello-world   latest    feb5d9fea6a5   16 months ago   13.3kB\n\n\n\n\n--digests - show digests\n\n%%bash\ndocker images --digests\n\nREPOSITORY    TAG       DIGEST                                                                    IMAGE ID       CREATED         SIZE\nhello-world   latest    sha256:aa0cc8055b82dc2509bed2e19b275c8f463506616377219d9642221ab53cf9fe   feb5d9fea6a5   16 months ago   13.3kB\n\n\n\n\n--format - format output\nAllows output to be formatted using GO templates.\n\n%%bash\ndocker images --format '{{.Repository}}:{{.Tag}}'\n\nhello-world:latest\n\n\n\n\n--no-trunc - full output\n\n%%bash\ndocker images --no-trunc\n\nREPOSITORY    TAG       IMAGE ID                                                                  CREATED         SIZE\nhello-world   latest    sha256:feb5d9fea6a5e9606aa995e879d862b825965ba48de054caab5ef356dc6b3412   16 months ago   13.3kB\n\n\n\n\n-q, --quiet - print only images ids\n\n%%bash\ndocker images -q\n\nfeb5d9fea6a5\n\n\n\n\n\ndocker rmi - delete images;\nIt is obligatory to pass on one of the:\n\n&lt;image name&gt;:&lt;tag&gt; (&lt;tag&gt; - by default is latest);\nIMAGE ID - image id.\n\n\n%%bash\ndocker images\necho \"===========================\"\ndocker rmi hello-world:latest\necho \"===========================\"\ndocker images\n\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\nhello-world   latest    feb5d9fea6a5   16 months ago   13.3kB\n===========================\nUntagged: hello-world:latest\nUntagged: hello-world@sha256:aa0cc8055b82dc2509bed2e19b275c8f463506616377219d9642221ab53cf9fe\nDeleted: sha256:feb5d9fea6a5e9606aa995e879d862b825965ba48de054caab5ef356dc6b3412\nDeleted: sha256:e07ee1baac5fae6a26f30cabfe54a36d3402f96afda318fe0a96cec4ca393359\n===========================\nREPOSITORY   TAG       IMAGE ID   CREATED   SIZE\n\n\n\n\ndocker build - build image from dockerfile\nThis command has description here\n\n\ndocker commit - save container state\nThis command has description here.\n\n\n\ndocker cp - copy files from/to container\nAllows files to be swapped between the host file system and the running container.\n\nhost -&gt; container\nThere is the following syntax:\ndocker cp &lt;host path&gt; &lt;cantainer name&gt;:&lt;container path&gt;\nThe following example shows how to copy a file into a container.\n\n\ncontainer -&gt; host\nThere is syntax for m\n\n%%bash\ncd filesystem_example\ndocker run --rm --name test_ubuntu -itd ubuntu &&gt; /dev/null\n\ndocker cp copied_message.txt test_ubuntu:copied_message.txt\n\necho \"=====copied to container=====\"\ndocker exec test_ubuntu cat copied_message.txt\necho \"\"\n\ndocker cp test_ubuntu:copied_message.txt new_message.txt\necho \"=====copied from container=====\"\ncat new_message.txt\n\nrm new_message.txt\ndocker stop test_ubuntu &&gt; /dev/null\n\n=====copied to container=====\nThis message is for checking the copy functions.\n=====copied from container=====\nThis message is for checking the copy functions.\n\n\n\n\n\ndocker instpect - docker object info\n\nBasic examples\nThis command provide information about docker ojects in json format such as:\n\nimages:\n\n\n%%bash\ndocker inspect ubuntu\n\n[\n    {\n        \"Id\": \"sha256:74f2314a03de34a0a2d552b805411fc9553a02ea71c1291b815b2f645f565683\",\n        \"RepoTags\": [\n            \"ubuntu:latest\"\n        ],\n        \"RepoDigests\": [\n            \"ubuntu@sha256:2adf22367284330af9f832ffefb717c78239f6251d9d0f58de50b86229ed1427\"\n        ],\n        \"Parent\": \"\",\n        \"Comment\": \"\",\n        \"Created\": \"2023-03-01T04:38:49.239257335Z\",\n        \"Container\": \"298f60554671ae2f5bf43b9892526aaa221e8093c9cee1ca68ef65fc3ac67600\",\n        \"ContainerConfig\": {\n            \"Hostname\": \"298f60554671\",\n            \"Domainname\": \"\",\n            \"User\": \"\",\n            \"AttachStdin\": false,\n            \"AttachStdout\": false,\n            \"AttachStderr\": false,\n            \"Tty\": false,\n            \"OpenStdin\": false,\n            \"StdinOnce\": false,\n            \"Env\": [\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n            ],\n            \"Cmd\": [\n                \"/bin/sh\",\n                \"-c\",\n                \"#(nop) \",\n                \"CMD [\\\"/bin/bash\\\"]\"\n            ],\n            \"Image\": \"sha256:6088cf91777e3b0190e579c7c7cab9c65626f5ff625373bcdb02ae877a9118d8\",\n            \"Volumes\": null,\n            \"WorkingDir\": \"\",\n            \"Entrypoint\": null,\n            \"OnBuild\": null,\n            \"Labels\": {\n                \"org.opencontainers.image.ref.name\": \"ubuntu\",\n                \"org.opencontainers.image.version\": \"22.04\"\n            }\n        },\n        \"DockerVersion\": \"20.10.12\",\n        \"Author\": \"\",\n        \"Config\": {\n            \"Hostname\": \"\",\n            \"Domainname\": \"\",\n            \"User\": \"\",\n            \"AttachStdin\": false,\n            \"AttachStdout\": false,\n            \"AttachStderr\": false,\n            \"Tty\": false,\n            \"OpenStdin\": false,\n            \"StdinOnce\": false,\n            \"Env\": [\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n            ],\n            \"Cmd\": [\n                \"/bin/bash\"\n            ],\n            \"Image\": \"sha256:6088cf91777e3b0190e579c7c7cab9c65626f5ff625373bcdb02ae877a9118d8\",\n            \"Volumes\": null,\n            \"WorkingDir\": \"\",\n            \"Entrypoint\": null,\n            \"OnBuild\": null,\n            \"Labels\": {\n                \"org.opencontainers.image.ref.name\": \"ubuntu\",\n                \"org.opencontainers.image.version\": \"22.04\"\n            }\n        },\n        \"Architecture\": \"amd64\",\n        \"Os\": \"linux\",\n        \"Size\": 77810712,\n        \"VirtualSize\": 77810712,\n        \"GraphDriver\": {\n            \"Data\": {\n                \"MergedDir\": \"/var/lib/docker/overlay2/dfcfb531746a088aaf673a8bc04602c8c8e19b1114680ff8164a95abfef8a0e6/merged\",\n                \"UpperDir\": \"/var/lib/docker/overlay2/dfcfb531746a088aaf673a8bc04602c8c8e19b1114680ff8164a95abfef8a0e6/diff\",\n                \"WorkDir\": \"/var/lib/docker/overlay2/dfcfb531746a088aaf673a8bc04602c8c8e19b1114680ff8164a95abfef8a0e6/work\"\n            },\n            \"Name\": \"overlay2\"\n        },\n        \"RootFS\": {\n            \"Type\": \"layers\",\n            \"Layers\": [\n                \"sha256:202fe64c3ce39b94d8beda7d7506ccdfcf7a59f02f17c915078e4c62b5c2ed11\"\n            ]\n        },\n        \"Metadata\": {\n            \"LastTagTime\": \"0001-01-01T00:00:00Z\"\n        }\n    }\n]\n\n\n\ncontainers:\n\n\n%%bash\ndocker run --rm --name test -itd ubuntu &&gt; /dev/null\ndocker inspect test\ndocker stop test &&gt; /dev/null\n\n[\n    {\n        \"Id\": \"020c99a8fbdca844a78956c0f7b2aba4fcd53e4f299112894dd0c0b7aca246c5\",\n        \"Created\": \"2023-06-12T13:37:52.23307605Z\",\n        \"Path\": \"/bin/bash\",\n        \"Args\": [],\n        \"State\": {\n            \"Status\": \"running\",\n            \"Running\": true,\n            \"Paused\": false,\n            \"Restarting\": false,\n            \"OOMKilled\": false,\n            \"Dead\": false,\n            \"Pid\": 32562,\n            \"ExitCode\": 0,\n            \"Error\": \"\",\n            \"StartedAt\": \"2023-06-12T13:37:52.471660971Z\",\n            \"FinishedAt\": \"0001-01-01T00:00:00Z\"\n        },\n        \"Image\": \"sha256:74f2314a03de34a0a2d552b805411fc9553a02ea71c1291b815b2f645f565683\",\n        \"ResolvConfPath\": \"/var/lib/docker/containers/020c99a8fbdca844a78956c0f7b2aba4fcd53e4f299112894dd0c0b7aca246c5/resolv.conf\",\n        \"HostnamePath\": \"/var/lib/docker/containers/020c99a8fbdca844a78956c0f7b2aba4fcd53e4f299112894dd0c0b7aca246c5/hostname\",\n        \"HostsPath\": \"/var/lib/docker/containers/020c99a8fbdca844a78956c0f7b2aba4fcd53e4f299112894dd0c0b7aca246c5/hosts\",\n        \"LogPath\": \"/var/lib/docker/containers/020c99a8fbdca844a78956c0f7b2aba4fcd53e4f299112894dd0c0b7aca246c5/020c99a8fbdca844a78956c0f7b2aba4fcd53e4f299112894dd0c0b7aca246c5-json.log\",\n        \"Name\": \"/test\",\n        \"RestartCount\": 0,\n        \"Driver\": \"overlay2\",\n        \"Platform\": \"linux\",\n        \"MountLabel\": \"\",\n        \"ProcessLabel\": \"\",\n        \"AppArmorProfile\": \"docker-default\",\n        \"ExecIDs\": null,\n        \"HostConfig\": {\n            \"Binds\": null,\n            \"ContainerIDFile\": \"\",\n            \"LogConfig\": {\n                \"Type\": \"json-file\",\n                \"Config\": {}\n            },\n            \"NetworkMode\": \"default\",\n            \"PortBindings\": {},\n            \"RestartPolicy\": {\n                \"Name\": \"no\",\n                \"MaximumRetryCount\": 0\n            },\n            \"AutoRemove\": true,\n            \"VolumeDriver\": \"\",\n            \"VolumesFrom\": null,\n            \"ConsoleSize\": [\n                0,\n                0\n            ],\n            \"CapAdd\": null,\n            \"CapDrop\": null,\n            \"CgroupnsMode\": \"private\",\n            \"Dns\": [],\n            \"DnsOptions\": [],\n            \"DnsSearch\": [],\n            \"ExtraHosts\": null,\n            \"GroupAdd\": null,\n            \"IpcMode\": \"private\",\n            \"Cgroup\": \"\",\n            \"Links\": null,\n            \"OomScoreAdj\": 0,\n            \"PidMode\": \"\",\n            \"Privileged\": false,\n            \"PublishAllPorts\": false,\n            \"ReadonlyRootfs\": false,\n            \"SecurityOpt\": null,\n            \"UTSMode\": \"\",\n            \"UsernsMode\": \"\",\n            \"ShmSize\": 67108864,\n            \"Runtime\": \"runc\",\n            \"Isolation\": \"\",\n            \"CpuShares\": 0,\n            \"Memory\": 0,\n            \"NanoCpus\": 0,\n            \"CgroupParent\": \"\",\n            \"BlkioWeight\": 0,\n            \"BlkioWeightDevice\": [],\n            \"BlkioDeviceReadBps\": [],\n            \"BlkioDeviceWriteBps\": [],\n            \"BlkioDeviceReadIOps\": [],\n            \"BlkioDeviceWriteIOps\": [],\n            \"CpuPeriod\": 0,\n            \"CpuQuota\": 0,\n            \"CpuRealtimePeriod\": 0,\n            \"CpuRealtimeRuntime\": 0,\n            \"CpusetCpus\": \"\",\n            \"CpusetMems\": \"\",\n            \"Devices\": [],\n            \"DeviceCgroupRules\": null,\n            \"DeviceRequests\": null,\n            \"MemoryReservation\": 0,\n            \"MemorySwap\": 0,\n            \"MemorySwappiness\": null,\n            \"OomKillDisable\": null,\n            \"PidsLimit\": null,\n            \"Ulimits\": null,\n            \"CpuCount\": 0,\n            \"CpuPercent\": 0,\n            \"IOMaximumIOps\": 0,\n            \"IOMaximumBandwidth\": 0,\n            \"MaskedPaths\": [\n                \"/proc/asound\",\n                \"/proc/acpi\",\n                \"/proc/kcore\",\n                \"/proc/keys\",\n                \"/proc/latency_stats\",\n                \"/proc/timer_list\",\n                \"/proc/timer_stats\",\n                \"/proc/sched_debug\",\n                \"/proc/scsi\",\n                \"/sys/firmware\"\n            ],\n            \"ReadonlyPaths\": [\n                \"/proc/bus\",\n                \"/proc/fs\",\n                \"/proc/irq\",\n                \"/proc/sys\",\n                \"/proc/sysrq-trigger\"\n            ]\n        },\n        \"GraphDriver\": {\n            \"Data\": {\n                \"LowerDir\": \"/var/lib/docker/overlay2/06b3ab167c3c359841177a3bc998d8bc5c32c1c8893d7518e2df4193a1dc98ee-init/diff:/var/lib/docker/overlay2/dfcfb531746a088aaf673a8bc04602c8c8e19b1114680ff8164a95abfef8a0e6/diff\",\n                \"MergedDir\": \"/var/lib/docker/overlay2/06b3ab167c3c359841177a3bc998d8bc5c32c1c8893d7518e2df4193a1dc98ee/merged\",\n                \"UpperDir\": \"/var/lib/docker/overlay2/06b3ab167c3c359841177a3bc998d8bc5c32c1c8893d7518e2df4193a1dc98ee/diff\",\n                \"WorkDir\": \"/var/lib/docker/overlay2/06b3ab167c3c359841177a3bc998d8bc5c32c1c8893d7518e2df4193a1dc98ee/work\"\n            },\n            \"Name\": \"overlay2\"\n        },\n        \"Mounts\": [],\n        \"Config\": {\n            \"Hostname\": \"020c99a8fbdc\",\n            \"Domainname\": \"\",\n            \"User\": \"\",\n            \"AttachStdin\": false,\n            \"AttachStdout\": false,\n            \"AttachStderr\": false,\n            \"Tty\": true,\n            \"OpenStdin\": true,\n            \"StdinOnce\": false,\n            \"Env\": [\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n            ],\n            \"Cmd\": [\n                \"/bin/bash\"\n            ],\n            \"Image\": \"ubuntu\",\n            \"Volumes\": null,\n            \"WorkingDir\": \"\",\n            \"Entrypoint\": null,\n            \"OnBuild\": null,\n            \"Labels\": {\n                \"org.opencontainers.image.ref.name\": \"ubuntu\",\n                \"org.opencontainers.image.version\": \"22.04\"\n            }\n        },\n        \"NetworkSettings\": {\n            \"Bridge\": \"\",\n            \"SandboxID\": \"422100341f6b603db62a0c616fa614091b66ac5a06796fa577503fd469b4ce56\",\n            \"HairpinMode\": false,\n            \"LinkLocalIPv6Address\": \"\",\n            \"LinkLocalIPv6PrefixLen\": 0,\n            \"Ports\": {},\n            \"SandboxKey\": \"/var/run/docker/netns/422100341f6b\",\n            \"SecondaryIPAddresses\": null,\n            \"SecondaryIPv6Addresses\": null,\n            \"EndpointID\": \"b2440d2f1d13674c667458fd051354ec32d2e11475db2308e20cd057e3b16037\",\n            \"Gateway\": \"172.17.0.1\",\n            \"GlobalIPv6Address\": \"\",\n            \"GlobalIPv6PrefixLen\": 0,\n            \"IPAddress\": \"172.17.0.2\",\n            \"IPPrefixLen\": 16,\n            \"IPv6Gateway\": \"\",\n            \"MacAddress\": \"02:42:ac:11:00:02\",\n            \"Networks\": {\n                \"bridge\": {\n                    \"IPAMConfig\": null,\n                    \"Links\": null,\n                    \"Aliases\": null,\n                    \"NetworkID\": \"cf037e1d3aeb308ae603f8028da3343134d92e79462fdcb5390b196a9e49c87d\",\n                    \"EndpointID\": \"b2440d2f1d13674c667458fd051354ec32d2e11475db2308e20cd057e3b16037\",\n                    \"Gateway\": \"172.17.0.1\",\n                    \"IPAddress\": \"172.17.0.2\",\n                    \"IPPrefixLen\": 16,\n                    \"IPv6Gateway\": \"\",\n                    \"GlobalIPv6Address\": \"\",\n                    \"GlobalIPv6PrefixLen\": 0,\n                    \"MacAddress\": \"02:42:ac:11:00:02\",\n                    \"DriverOpts\": null\n                }\n            }\n        }\n    }\n]\n\n\n\nnetworks:\n\n\n%%bash\ndocker inspect bridge\n\n[\n    {\n        \"Name\": \"bridge\",\n        \"Id\": \"cf037e1d3aeb308ae603f8028da3343134d92e79462fdcb5390b196a9e49c87d\",\n        \"Created\": \"2023-06-12T08:14:24.801403507+03:00\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": null,\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.17.0.0/16\",\n                    \"Gateway\": \"172.17.0.1\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Attachable\": false,\n        \"Ingress\": false,\n        \"ConfigFrom\": {\n            \"Network\": \"\"\n        },\n        \"ConfigOnly\": false,\n        \"Containers\": {},\n        \"Options\": {\n            \"com.docker.network.bridge.default_bridge\": \"true\",\n            \"com.docker.network.bridge.enable_icc\": \"true\",\n            \"com.docker.network.bridge.enable_ip_masquerade\": \"true\",\n            \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\",\n            \"com.docker.network.bridge.name\": \"docker0\",\n            \"com.docker.network.driver.mtu\": \"1500\"\n        },\n        \"Labels\": {}\n    }\n]\n\n\n\n\nSpecial cases\n\nFor more information about the path to container logs, you can look here."
  },
  {
    "objectID": "Docker/postgres_start/postgres_start.html",
    "href": "Docker/postgres_start/postgres_start.html",
    "title": "Разные контейнеры",
    "section": "",
    "text": "Пример развертывания с помощью docker базы данных postgres взаимодейсвующей с программой на python\nПрограма в одном контейнере, база в другом. В теории так и должно быть, так что это самый правильный вариант.\nЗапуск контейнеров\n\n%%bash\n\n# сеть\ndocker network create test_project_net\n# postgres\ndocker run --rm -d\\\n    --name database\\\n    -e POSTGRES_USER=docker_app\\\n    -e POSTGRES_PASSWORD=docker_app\\\n    -e POSTGRES_DB=docker_app_db\\\n    --net=test_project_net\\\n    custom_postgres\n# python\ndocker run --rm -itd\\\n    --name python_psql\\\n    --net=test_project_net\\\n    python_psql\n\n34a398d3020100bfba5156db3a78aef6f35d6c56051710a8178075f65b0e73cd\nfb428a7b940e7ebf4c6eadd4d8e6c55e8c0f0125ca551bcbd350df65e0c212fb\n8f717a2ad9f6998a2eb7db3ea0ac03cc96522b8a361db671c42bbdc8e9991a04\n\n\nНадо создать таблицу с которой наша программа на python будет работать.\n\n%%bash\n# надо дождаться пока база данных\n# развернется (но вообще это не обязательный шаг)\nsleep 1\ndocker exec database \\\n    psql --username docker_app --dbname docker_app_db -f create_table.sql\n\nCREATE TABLE\n\n\n\n%%bash\ndocker exec python_psql python3 script.py\n\nПроверим, чтобы записи сидели в базе.\n\n%%bash \ndocker exec database psql \\\n    --username docker_app \\\n    --dbname docker_app_db \\\n    -f create_table.sql\\\n    -c 'SELECT * FROM main_table;'\n\npsql:create_table.sql:4: ERROR:  relation \"main_table\" already exists\n\n\n id |         text         \n----+----------------------\n 0  | vymszdacizasoskeynrz\n 1  | zeedscxslqsviocgulpv\n 2  | pgaddokdpeaetjcjbgxn\n 3  | saofcamywgifngsrvghz\n 4  | anjfbasvwncfsybackza\n 5  | iuqjpjfxqzkcyjhxwixk\n 6  | uxsfbomwzpjmoldpepvx\n 7  | wkqqpzplzjbbuvyxnrxe\n 8  | jrbmbnnpxmexjtiyuici\n 9  | kllkgouehckewkmxsprv\n 10 | gszezoecjruwnfrgtczc\n 11 | mbudorfpbhmcklxhlyra\n 12 | xbkhupkusdsswbqcxjkh\n 13 | lsjyaooxxbouhoqfupzz\n 14 | vymzfuuaaiwsqlfnpiuw\n 15 | rqhcxlgefvhxgwsuyobn\n 16 | canvcvnttbctysiczkmf\n 17 | pbrlbrurbudorrcggsga\n 18 | qvpslycpamqdwrxwpkpu\n 19 | psiallsnotlotxeizopq\n(20 rows)\n\n\n\nУдаление всего того, что насоздавали.\n\n%%bash\ndocker stop database\ndocker stop python_psql\ndocker network rm test_project_net\n\ndatabase\npython_psql\ntest_project_net\n\n\n\nПрограмма на хосте\nВ целях отладки программы бывает полезно поднять контейнер с базой а программу отлаживать на localhost. В данном разделе представлено именно такой случай.\nСтарт контейнера с базой и создание табилцы.\n\n%%bash\n# особое внимане порту - тут от принципиально важен\ndocker run --rm -d\\\n    --name database\\\n    -e POSTGRES_USER=docker_app\\\n    -e POSTGRES_PASSWORD=docker_app\\\n    -e POSTGRES_DB=docker_app_db\\\n    -p 5431:5432\\\n    custom_postgres\n\n# надо дождаться пока база данных\n# развернется (но вообще это не обязательный шаг)\nsleep 1\ndocker exec database \\\n    psql --username docker_app --dbname docker_app_db -f create_table.sql\n\n7b2c720f625cfe5edcbb933c177b3100e37804f546c67d154bdeaa8199909546\nCREATE TABLE\n\n\nВ python надо открыть connection с базой.\n\nimport psycopg2\nimport random\nimport string\n\nconn = psycopg2.connect(\n    port = \"5431\",# указываем порт\n    dbname = \"docker_app_db\",\n    user = \"docker_app\",\n    password = \"docker_app\",\n    host= \"localhost\"\n)\n\nВставляем в новосозданную табличку 20 новый записей.\n\ncur = conn.cursor()\nfor i in range(20):\n    text = ''.join(random.choices(string.ascii_lowercase, k=20))\n    query = f\"INSERT INTO main_table (id, text) VALUES ('{i}', '{text}');\"\n    cur.execute(query)\ncur.close()\n\nИ посмотрим, что это за записи.\n\ncur = conn.cursor()\ncur.execute(\"SELECT * FROM main_table;\")\nfor i in cur:\n    print(i)\ncur.close()\n\n('0', 'jvzxfsnhqdqwzlcydplk')\n('1', 'dkikwyqonxbpuntctwbh')\n('2', 'hezacpzkyunfveeryric')\n('3', 'tiyiamkwkpldwwcssybh')\n('4', 'mlubzprlazklkwhfkjes')\n('5', 'cljklgwdqrdixouxmwvx')\n('6', 'qjwaaacfxtfgddfuuwcm')\n('7', 'edchlgwxfleemxiygppw')\n('8', 'jlhoegxnoufwwkmuqmbt')\n('9', 'inghkupkzzbqwwsorbty')\n('10', 'aarzufaztxozfknqnkry')\n('11', 'rseoefecuwmukfsctvvc')\n('12', 'jcndoogfkkfxrmhcynpn')\n('13', 'noyhhyphzwyxbmggethp')\n('14', 'klfzmuwbdikladtclngb')\n('15', 'yqqrnsmrpzmmwxmhyulr')\n('16', 'zfopjuwfzktsasfzwrbd')\n('17', 'zdawvtlfpffdukteteys')\n('18', 'zkculqcoqakiojcenslf')\n('19', 'jzdhhvqmoghjjattawqj')\n\n\nОтправляем изменения на базу и закрываем соединение.\n\nconn.commit()\nconn.close()\n\nДля того, чтобы убедится, что все сработало, спрошу эту табличку напрямую из базы.\n\n%%bash\ndocker exec database \\\n    psql --username docker_app --dbname docker_app_db -c 'SELECT * FROM main_table;'\n\n id |         text         \n----+----------------------\n 0  | jvzxfsnhqdqwzlcydplk\n 1  | dkikwyqonxbpuntctwbh\n 2  | hezacpzkyunfveeryric\n 3  | tiyiamkwkpldwwcssybh\n 4  | mlubzprlazklkwhfkjes\n 5  | cljklgwdqrdixouxmwvx\n 6  | qjwaaacfxtfgddfuuwcm\n 7  | edchlgwxfleemxiygppw\n 8  | jlhoegxnoufwwkmuqmbt\n 9  | inghkupkzzbqwwsorbty\n 10 | aarzufaztxozfknqnkry\n 11 | rseoefecuwmukfsctvvc\n 12 | jcndoogfkkfxrmhcynpn\n 13 | noyhhyphzwyxbmggethp\n 14 | klfzmuwbdikladtclngb\n 15 | yqqrnsmrpzmmwxmhyulr\n 16 | zfopjuwfzktsasfzwrbd\n 17 | zdawvtlfpffdukteteys\n 18 | zkculqcoqakiojcenslf\n 19 | jzdhhvqmoghjjattawqj\n(20 rows)\n\n\n\nОстанавливаю созданный для этого примера контейнер.\n\n%%bash\ndocker stop database\n\ndatabase"
  },
  {
    "objectID": "Docker/multistage_build/multistage_build.html",
    "href": "Docker/multistage_build/multistage_build.html",
    "title": "База",
    "section": "",
    "text": "Многоэтапная сборка в docker\nВ docker есть особый тип сборки, который позволяет оставить в финальном образе только те элементы, что нам нужны. Это, в некоторых случаях, позволит сэкономить размер docker образа.\nФормально это делается следующим образом:\nFROM &lt;название образа&gt; AS &lt;название сборки1&gt;\n\nFROM &lt;название образа&gt;\nCOPY --from=&lt;название сборки1&gt; &lt;файл из перовой сборки&gt; &lt;файл из второй сборки&gt;\n\nПример\nТак допуским ситуацию, где нам в финальной сборке надо иметь результаты обработки некоторого большого файла example.csv проводимой программой generation.py (в данном случае это просто взятие средних).\nЕсли делать это по простому, то мы сделаем dockerfile вида (simple_dockerfile):\n# простой dockerfile\nFROM python:3.10 AS BUILD\n\nWORKDIR some_dir\nCOPY example.csv example.csv\nCOPY requirements.txt requirements.txt\nCOPY generation.py generation.py\n\nRUN python -m pip install --upgrade pip && pip install -r requirements.txt\nRUN python generation.py\n\nCMD [\"cat\", \"means.csv\"]\nДалее: - Собираю образ; - Поднимаю контейнер на его основе, чтобы показать, что все работает номрмально; - Показываю размер образа.\n\n%%bash\ndocker build -q -t simple -f simple_dockerfile .\necho ==============================\ndocker run --rm simple\necho ==============================\ndocker images simple\necho ==============================\ndocker rmi simple\n\nsha256:daea387ec3b5bb08725927e3cf8a8274d8c535fbdebd7905760ebeeb6aec0156\n==============================\n,0\n0,0.49801512771615053\n1,0.5005384992657755\n2,0.5016440913126519\n3,0.49893742832936905\n4,0.5006416292879786\n5,0.500604403582076\n6,0.5024090926131595\n7,0.500360289940759\n8,0.4995687156844078\n9,0.4993301862968266\n10,0.4996320601371099\n11,0.49936364688453744\n12,0.4996892437983095\n13,0.5003040557416716\n14,0.5008896760787612\n15,0.49834042413261304\n16,0.5002565939707307\n17,0.499441058229968\n18,0.4994494362971878\n19,0.5000038702075555\n==============================\nREPOSITORY   TAG       IMAGE ID       CREATED          SIZE\nsimple       latest    daea387ec3b5   43 minutes ago   1.11GB\n==============================\nUntagged: simple:latest\nDeleted: sha256:daea387ec3b5bb08725927e3cf8a8274d8c535fbdebd7905760ebeeb6aec0156\n\n\nВ итоге мы вывели результат расчета. Ну и размер образа составляет титанические 1.11GB.\nА теперь сделаем тоже самое, только правильно. dockerfile в случае использоваиня многоэтапной сборке примет вид (multistage_dockerfile):\nFROM python:3.10 AS BUILDER\n\nWORKDIR some_dir\nCOPY example.csv example.csv\nCOPY requirements.txt requirements.txt\nCOPY generation.py generation.py\n\nRUN python -m pip install --upgrade pip && pip install -r requirements.txt\nRUN python generation.py\n\nFROM ubuntu:22.04\nWORKDIR some_dir\nCOPY --from=BUILDER /some_dir/means.csv /some_dir/means.csv\nCMD [\"cat\", \"means.csv\"]\nБуквально повторяю процедуры, которые проделал для предыдущего образа.\n\n%%bash\ndocker build -q -t multistage -f multistage_dockerfile .\necho ==============================\ndocker run --rm multistage\necho ==============================\ndocker images multistage\necho ==============================\ndocker rmi multistage\n\nsha256:15096f1d81baa6c46dadf24558dfa0c39ffcebb248495c779f1334b4b75a2eca\n==============================\n,0\n0,0.49801512771615053\n1,0.5005384992657755\n2,0.5016440913126519\n3,0.49893742832936905\n4,0.5006416292879786\n5,0.500604403582076\n6,0.5024090926131595\n7,0.500360289940759\n8,0.4995687156844078\n9,0.4993301862968266\n10,0.4996320601371099\n11,0.49936364688453744\n12,0.4996892437983095\n13,0.5003040557416716\n14,0.5008896760787612\n15,0.49834042413261304\n16,0.5002565939707307\n17,0.499441058229968\n18,0.4994494362971878\n19,0.5000038702075555\n==============================\nREPOSITORY   TAG       IMAGE ID       CREATED             SIZE\nmultistage   latest    15096f1d81ba   About an hour ago   77.8MB\n==============================\nUntagged: multistage:latest\nDeleted: sha256:15096f1d81baa6c46dadf24558dfa0c39ffcebb248495c779f1334b4b75a2eca\n\n\nИ так, в результате, все тоже самое но размером в 77.8MB.\n\n\nОстановка на нужном этапе\nПри многоэтапной сборке, например, для отладки, может понадобиться отсновится в сборке образа. Это делается с помощью опции --target &lt;название этапа&gt;. Так, в примере далее, я останавливаю сборку описанного выше образа multistage на этапе BUILDER и убеждаюсь, что это именно тот этап (файлы то его).\n\n%%bash\ndocker build -q -t multistage -f multistage_dockerfile --target BUILDER .\ndocker run --rm --name multistage -itd multistage\necho ==============================\ndocker exec multistage ls\necho ==============================\ndocker stop multistage\ndocker rmi multistage\n\nsha256:19ec4683d03994e2f466696a18fbd3db8deda7f1f251185feddb1d568b116a02\n0e9309e419e5c47647beb7005ecd0bb2d6c8c771eb96c216fcb24294781c4ff1\n==============================\nexample.csv\ngeneration.py\nmeans.csv\nrequirements.txt\n==============================\nmultistage\nUntagged: multistage:latest\nDeleted: sha256:19ec4683d03994e2f466696a18fbd3db8deda7f1f251185feddb1d568b116a02"
  },
  {
    "objectID": "Docker/docker_volumes.html",
    "href": "Docker/docker_volumes.html",
    "title": "Volumes",
    "section": "",
    "text": "In order to connect a folder on the host to the container, use the -v option of the docker run command. The full syntax is as follows:\ndocker run \\\n    -v &lt;older on host1&gt;:&lt;folder in container1&gt; \\\n    -v &lt;older on host2&gt;:&lt;folder in container2&gt; \\\n    ...\nBy &lt;folder on hosti&gt; it can be understood as:\n\nA path to some folder on the host, this is commonly referred to as bind mount, and is used more commonly to pass something specific to that host into the container;\nA volume, this is the preferred mount method, and is used to store information that is “created” by the container; it is essentially the same as a folder on the host but controlled by a docker.\n\n\nBind mount\nIn the following example I create folder temp_folder, put it into container named temp_folder_inc_count. From container create file there, exited from container and even deleted it, I can get file from host folder.\n\n%%bash\ncd filesystem_example\nmkdir temp_folder\n\ndocker run \\\n    -v $(pwd)/temp_folder:/temp_folder_in_cont \\\n    --rm -itd --name temp_example \\\n    ubuntu &&gt; /dev/null\ndocker exec temp_example bash -c \"echo \\'hello from container\\' &gt;&gt; temp_folder_in_cont/hello\"\ndocker stop temp_example &&gt; /dev/null\n\ncat temp_folder/hello\nrm -r temp_folder\n\n'hello from container'\n\n\n\n\nVolume\nIs a file that resides on the host and doesn’t depend on an image, but depends on Docker. Its primary purpose is to store data.\n\ndocker volume service\ndocker volume is a separate service for managing volumes.\n\nls - show volumes;\ncreate - create volume;\nrm - remove volume;\nprune - remove volumes not used in any container;\nisnpect - allows you to retrieve information about volume (including where it lies on the host).\n\nThe following example shows how to use volumes. Step-by-step description: - temp_volume is created; - ubuntu container named example_container running, and volume created earlier attached to container as temp_volume_cont folder; - file writes to the temp_volume_cont from container; - example_container stops and removes automatically (because the --rm' option was setted); - next,inspectshows where you can find the volume on the host (Mountpointdirectory), but I can't get access from Jupyter - you should have root privileges for this folder; -example_container` was started in the same way as before; - and in the folder associated with the container, you can still find the file created in the previous steps.\n\n%%bash\ndocker volume create temp_volume &&gt; /dev/null\n\ndocker run \\\n    -v temp_volume:/temp_volume_cont\\\n    --rm --name example_container -itd\\\n    ubuntu &&gt; /dev/null\ndocker exec example_container bash -c \"echo \\'hello from volume\\' &gt;&gt; temp_volume_cont/hello\"\ndocker stop example_container &&gt; /dev/null\n\ndocker volume inspect temp_volume\n\ndocker run \\\n    -v temp_volume:/temp_volume_cont\\\n    --rm --name example_container -itd\\\n    ubuntu &&gt; /dev/null\ndocker exec example_container cat temp_volume_cont/hello\ndocker stop example_container &&gt; /dev/null\n\ndocker volume rm temp_volume &&gt; /dev/null\n\n[\n    {\n        \"CreatedAt\": \"2023-06-03T19:15:02+03:00\",\n        \"Driver\": \"local\",\n        \"Labels\": null,\n        \"Mountpoint\": \"/var/lib/docker/volumes/temp_volume/_data\",\n        \"Name\": \"temp_volume\",\n        \"Options\": null,\n        \"Scope\": \"local\"\n    }\n]\n'hello from volume'\n\n\n\n\n\nAccess\n\nContainers always have root\nEven if host has root access to some folder/file, container always works under root. So if you mount a folder/file in this way, it may lead to unauthorised changes. The following cell contains the example.\n\n%%bash\ncd filesystem_example\n\n# creating fodler and file with super secret message\nmkdir secret_dir\ntouch secret_dir/secret_file\necho \"super secret info\" &gt; secret_dir/secret_file\n# Close access to the folder\nchmod 000 secret_dir\n\n\n# make sure we can't access or delte the file\necho \"=====From host=====\"\ncat secret_dir/secret_file\nrm secret_dir/secret_file\n\n\n# run container and mount created folder\ndocker run --rm -itd --name perm_ex\\\n    -v $(pwd)/secret_dir:/experimental/secret_dir \\\n    ubuntu &&gt; /dev/null\n# and voila ealily extract secret info\necho \"=====From docker====\"\ndocker exec perm_ex cat experimental/secret_dir/secret_file\n# or even can delete secret file\ndocker exec perm_ex rm experimental/secret_dir/secret_file\ndocker exec perm_ex ls experimental/secret_dir\n\ndocker stop perm_ex &&gt; /dev/null\n\n=====From host=====\n=====From docker====\nsuper secret info\n\n\ncat: secret_dir/secret_file: Permission denied\nrm: cannot remove 'secret_dir/secret_file': Permission denied\n\n\n\n\nro (read only) option\nContinuing from the previous section, note that when you move the folder to the container, you can set the ro option, which will prevent the container from modifying the file.\n\n%%bash\necho \"some data\" &gt; ro_ex\n# running container with ro option\ndocker run --rm -idt --name ro_ex\\\n    -v $(pwd)/ro_ex:/experimental/ro_ex:ro\\\n    ubuntu &&gt; /dev/null\n# change the file\ndocker exec ro_ex bash -c \"echo \\\"new some data\\\" &gt; ro_ex\"\n# print new file\ncat ro_ex\n\ndocker stop ro_ex &&gt; /dev/null\nrm -r ro_ex\n\nsome data\n\n\nSo I tried to change file from container, but even after operation file sill have initial message.\n\n\nRunnig with setting user -u{sec-run_u_option}\nThe problem with access can be solved by setting the user when starting the container (-u option). Using the example from the section “Containers always have root”, you can do this.\n\n%%bash\ncd filesystem_example\n# создаем папку и в ней файл и даже в него записываем\n# сверхсекретное сообщение\nmkdir secret_dir\ntouch secret_dir/secret_file\necho \"super secret info\" &gt; secret_dir/secret_file\n# закрываю доступ в папку\nchmod 000 secret_dir\n\n# поднимаем контейнер и монтируем в него данную папку\ndocker run --rm -itd --name perm_ex -u=1000\\\n    -v $(pwd)/secret_dir:/experimental/secret_dir \\\n    ubuntu &&gt; /dev/null\necho \"=====Trying to access from a container=====\"\ndocker exec perm_ex cat secret_dir/secret_file\n\ndocker stop perm_ex &&gt; /dev/null\n\nmkdir: cannot create directory ‘secret_dir’: File exists\ntouch: cannot touch 'secret_dir/secret_file': Permission denied\nbash: line 6: secret_dir/secret_file: Permission denied\ncat: secret_dir/secret_file: No such file or directory\n\n\n=====Trying to access from a container=====\n\n\n\n\nMounting .dockerignore files\nEven if you mount the file described in .dockerignore, we will still have it in the container.\nIn the following example, I create app/ignore_file.txt and mention it in dockerignore. Build image using this .dockerignore, but in container based on this image I mount app folder. And as a result I can see contents of ignore_file.txt regardless of what I specified in the .dockerignore.\n\n%%bash\ncd filesystem_example\nmkdir app\necho \"message in ignore_file.txt\" &gt; app/ignore_file.txt\necho \"=====.dockerignore=====\"\necho \"app/ignore_file.txt\" &gt; .dockerignore\ncat .dockerignore\necho \"=====dockerfile=====\"\necho \"FROM ubuntu\" &gt; dockerfile\ncat dockerfile\n\n# build image with setted .dockerignore\ndocker build -t test_image &&gt; /dev/null\n\n# start container mountig file mentioned in .dockerignore\ndocker run --rm -itd --name ignore_ex\\\n    -v $(pwd)/app:/app\\\n    ubuntu &&gt; /dev/null\n\necho \"=====ignore-file from container=====\"\n# make sure that this secret file is in the container\ndocker exec ignore_ex cat app/ignore_file.txt\n\ndocker stop ignore_ex &&gt; /dev/null\ndocker rmi test_image &&gt; /dev/null\nrm -r app\nrm .dockerignore\nrm dockerfile\n\n=====.dockerignore=====\napp/ignore_file.txt\n=====dockerfile=====\nFROM ubuntu\n=====ignore-file from container=====\nmessage in ignore_file.txt\n\n\n\n\n\nVolume by default\nSome containers create their own volumes by default when they run, so you may find that your entire hard drive is flooded.\nFor example yandex/clickhouse-server. In the following cell I have some containers yandex/clickhouse-server running and show that each container has created a volume.\n\n%%bash\n\necho \"=====docker volume ls before=====\"\ndocker volume ls\n\n# run clickhouse\ndocker run -d --name db_1 --rm yandex/clickhouse-server &&gt; /dev/null\ndocker run -d --name db_2 --rm yandex/clickhouse-server &&gt; /dev/null\ndocker run -d --name db_3 --rm yandex/clickhouse-server &&gt; /dev/null\n\n# list volumes\necho \"=====docker volume ls after=====\"\ndocker volume ls\ndocker stop db_1 db_2 db_3 &&gt; /dev/null\n\n=====docker volume ls before=====\nDRIVER    VOLUME NAME\n=====docker volume ls after=====\nDRIVER    VOLUME NAME\nlocal     66e881449c54eb455e1a0e16b6b1cfff0aac6fbe31739ea59d307d5631c04fa2\nlocal     b6d2ba76cf901665684319a3197166a61d8da5d75b8804945a8f0368de0c89ec\nlocal     d3ba9de2668e8e3f68d43ccfb02db72738f2c2b7048ed2bfc94b3134d00f53f1\n\n\n\n\nSeveral volumes in one command\nYou can repeat -v option in docker run many times as you need.\nBasic example.\n\n%%bash\ncd filesystem_example\n\nmkdir test1 test2\necho \"message in test1\" &gt; test1/my_file\necho \"message in test2\" &gt; test2/my_file\n\ndocker run --rm --name example_cont -itd\\\n    -v $(pwd)/test1:/test1\\\n    -v $(pwd)/test2:/test2\\\n    ubuntu &&gt; /dev/null\n\necho \"=====files from container=====\"\ndocker exec example_cont cat test1/my_file\ndocker exec example_cont cat test2/my_file\n\ndocker stop example_cont &&gt; /dev/null\nrm -r test1 test2\n\n=====files from container=====\nmessage in test1\nmessage in test2\n\n\nBut you can’t mount a directory on the container twice.\n\n%%bash\ncd filesystem_example\n\nmkdir test1 test2\necho \"message in test1\" &gt; test1/my_file\necho \"message in test2\" &gt; test2/my_file\n\ndocker run --rm --name example_cont -itd\\\n    -v $(pwd)/test1:/test\\\n    -v $(pwd)/test2:/test\\\n    ubuntu\n\nrm -r test1 test2\n\ndocker: Error response from daemon: Duplicate mount point: /test.\nSee 'docker run --help'.\n\n\nA directory from host to different folders in container is available. But you need to know that they are actually the same directory with different names - any change in one will happen in the other.\nIn the following example, we mount test in host to test1 and test2 in container. Then we add the file new_file to test1, but it will appear not only in test1 but also in test2 and test.\n\n%%bash\ncd filesystem_example\n\nmkdir test\n\ndocker run --rm --name example_cont -itd\\\n    -v $(pwd)/test:/test1\\\n    -v $(pwd)/test:/test2\\\n    ubuntu &&gt; /dev/null\n\ndocker exec example_cont bash -c \"echo \\\"hello from container\\\" &gt; test1/new_file\"\necho \"=====ls test1 from container=====\"\ndocker exec example_cont ls test1\necho \"=====ls test2 from container=====\"\ndocker exec example_cont ls test2\n\ndocker stop example_cont &&gt; /dev/null\n\n\necho \"=====ls test=====\"\nls test\nrm -r test\n\n=====ls test1 from container=====\nnew_file\n=====ls test2 from container=====\nnew_file\n=====ls test=====\nnew_file"
  },
  {
    "objectID": "Docker/image_creation.html",
    "href": "Docker/image_creation.html",
    "title": "Image creation",
    "section": "",
    "text": "docker build - build image\nThis is the command used to create a new docker image.\nBasic arguments:\n\nthe last mandatory argument sets the build directory - you should use . to set the current directory.\n-t - set the name and tag of the image.\n\n\n%%bash\ncd build_command_files\ndocker build -t custom_ubuntu:test .\ndocker images | grep custom_ubuntu\ndocker rmi custom_ubuntu:test\n\n#1 [internal] load .dockerignore\n#1 transferring context: 2B done\n#1 DONE 0.0s\n\n#2 [internal] load build definition from dockerfile\n#2 transferring dockerfile: 55B done\n#2 DONE 0.0s\n\n#3 [internal] load metadata for docker.io/library/ubuntu:latest\n#3 DONE 0.0s\n\n#4 [1/1] FROM docker.io/library/ubuntu:latest\n#4 CACHED\n\n#5 exporting to image\n#5 exporting layers done\n#5 writing image sha256:8173c380186319e1e49d54260624b8b78635789ab603389d63c65e828e150c8f done\n#5 naming to docker.io/library/custom_ubuntu:test done\n#5 DONE 0.0s\n\n\ncustom_ubuntu              test      8173c3801863   3 months ago    77.8MB\nUntagged: custom_ubuntu:test\nDeleted: sha256:8173c380186319e1e49d54260624b8b78635789ab603389d63c65e828e150c8f\n\n\n\n-f - allow to chose the dockerfile\nYou should see a difference between building directory and dockerfile. The dockerfile is only taken from the building directory if it is not specified in the -f option. But the files used for the build will in any case come from the build directory.\nSo let’s try some experiments with these details. I have prepared some folders for experiments with these options, in the following cell I show tree and file contents.\n\n%%bash\ncd build_command_files/f_option_examples\ntree\n\necho\necho\necho\n\nfor file in $(find -type f | grep -v \"\\/\\.\"); do\n    echo \"\"\n    echo \"=====File: $file=====\"\n    cat $file\n    echo \"\"\ndone\n\n.\n├── dockerfile\n├── script.sh\n├── specialdockerfile\n└── test_folder\n    ├── dockerfile\n    └── script.sh\n\n1 directory, 5 files\n\n\n\n\n=====File: ./dockerfile=====\nFROM ubuntu:latest\nCOPY script.sh script.sh\nRUN echo \"\\necho message from basic dockerfile\" &gt;&gt; script.sh\n\n=====File: ./script.sh=====\necho \"It's a script.sh from the run folder\"\n\n=====File: ./specialdockerfile=====\nFROM ubuntu:latest\nCOPY script.sh script.sh\nRUN echo \"\\necho message from specialdockerfile\" &gt;&gt; script.sh\n\n=====File: ./test_folder/dockerfile=====\nFROM ubuntu:latest\nCOPY script.sh script.sh\nRUN echo \"\\necho message from test_folder/dockerfile\" &gt;&gt; script.sh\n\n=====File: ./test_folder/script.sh=====\necho \"It's a script from test_folder\"\n\n\nWe have:\n\nscripts:\n\nfrom run folder - prints \"It's a script.sh from the run folder\";\nfrom test_folder - prints \"It's a script from test_folder\";\n\ndockerfiles:\n\nbasic dockerfile from run directory - adds to printing script line \"message from basic dockerfile\";\nspecisaldocker file from run dicrecotry but with special name - adds to printing script line \"message from specialdockerfile\";\ndockerfile from test_folder directory - adds to printing script line \"message from test_folder/dockerfile\";\nspecialdockerfile from test_folder directory - adds to printing script line \"message from test_folder/specialdockerfile\";\n\n\nThis way we can always tell from the output of script.sh from the container in which folder and from which dockerfile the image was built. Let’s try different options:\n\nThe most basic case no -f option and . as build directory - will lead to using docker file from run directory and script.sh was copiet from run dicrecory as well;\n\n\n%%bash\ncd build_command_files/f_option_examples\ndocker build -t test_ubuntu . &&gt; /dev/null\ndocker run --rm -itd \\\n    --name test_ubuntu \\\n    test_ubuntu &&gt; /dev/null\necho \"=====message from container=====\"\ndocker exec test_ubuntu bash script.sh\n\ndocker stop test_ubuntu &&gt; /dev/null\ndocker rmi test_ubuntu &&gt; /dev/null\n\n=====message from container=====\nIt's a script.sh from the run folder\nmessage from basic dockerfile\n\n\n\nIf you do not set the -f option but specify the build folder as test_folder everythig will be taken from test_folder;\n\n\n%%bash\ncd build_command_files/f_option_examples\ndocker build -t test_ubuntu test_folder &&gt; /dev/null\ndocker run --rm -itd \\\n    --name test_ubuntu \\\n    test_ubuntu &&gt; /dev/null\necho \"=====message from container=====\"\ndocker exec test_ubuntu bash script.sh\n\ndocker stop test_ubuntu &&gt; /dev/null\ndocker rmi test_ubuntu &&gt; /dev/null\n\n=====message from container=====\nIt's a script from test_folder\nmessage from test_folder/dockerfile\n\n\n\nIf you set -f specialdockerfile and specify the build folder as test_folder - everything is obvious;\n\n\n%%bash\ncd build_command_files/f_option_examples\ndocker build \\\n    -t test_ubuntu \\\n    -f specialdockerfile \\\n    test_folder &&gt; /dev/null\ndocker run --rm -itd \\\n    --name test_ubuntu \\\n    test_ubuntu &&gt; /dev/null\necho \"=====message from container=====\"\ndocker exec test_ubuntu bash script.sh\n\ndocker stop test_ubuntu &&gt; /dev/null\ndocker rmi test_ubuntu &&gt; /dev/null\n\n=====message from container=====\nIt's a script from test_folder\nmessage from specialdockerfile\n\n\n\nBit exotic case - dockerfile from test_folder, but build directory is run directory;\n\n\n%%bash\ncd build_command_files/f_option_examples\ndocker build \\\n    -t test_ubuntu \\\n    -f test_folder/dockerfile \\\n    . &&gt; /dev/null\ndocker run --rm -itd \\\n    --name test_ubuntu \\\n    test_ubuntu &&gt; /dev/null\necho \"=====message from container=====\"\ndocker exec test_ubuntu bash script.sh\n\ndocker stop test_ubuntu &&gt; /dev/null\ndocker rmi test_ubuntu &&gt; /dev/null\n\n=====message from container=====\nIt's a script.sh from the run folder\nmessage from test_folder/dockerfile\n\n\nNote even if you have specified a folder as some assembly folder, you must still pass in the -f parameter the path relative to the run folder.\nThe next two points show the difference:\n\nHere I set building directory as test_folder but -f specialdockerfile - specialdockerfile from run folder will be used;\n\n\n%%bash\ncd build_command_files/f_option_examples\ndocker build \\\n    -t test_ubuntu \\\n    -f specialdockerfile \\\n    test_folder &&gt; /dev/null\ndocker run --rm -itd \\\n    --name test_ubuntu \\\n    test_ubuntu &&gt; /dev/null\necho \"=====message from container=====\"\ndocker exec test_ubuntu bash script.sh\n\ndocker stop test_ubuntu &&gt; /dev/null\ndocker rmi test_ubuntu &&gt; /dev/null\n\n=====message from container=====\nIt's a script from test_folder\nmessage from specialdockerfile\n\n\n\nHere I set building directory as test_folder but -f test_folder/specialdockerfile - specialdockerfile from test_folder will be used;\n\n\n%%bash\ncd build_command_files/f_option_examples\ndocker build \\\n    -t test_ubuntu \\\n    -f test_folder/specialdockerfile \\\n    test_folder &&gt; /dev/null\ndocker run --rm -itd \\\n    --name test_ubuntu \\\n    test_ubuntu &&gt; /dev/null\necho \"=====message from container=====\"\ndocker exec test_ubuntu bash script.sh\n\ndocker stop test_ubuntu &&gt; /dev/null\ndocker rmi test_ubuntu &&gt; /dev/null\n\n=====message from container=====\nIt's a script from test_folder\nmessage from test_folder/specialdockerfile\n\n\n\n\n\n.dockerignore - select files ignored during image building\nIn docker ignore, you should specify files to be ignored when building the image.\nFor example lets try to build image with followig paremeters:\n\n%%bash\ncd dockerignore\necho \"=====dockerfile=====\"\ncat dockerfile1\necho\necho \"=====.dockerignore=====\"\ncat .dockerignore\n\n=====dockerfile=====\nFROM ubuntu\nCOPY test_file test_file\n=====.dockerignore=====\ntest_file\ntest_folder/banned_file\n\n\nSo in dockerfile I try to copy test_file into image, but in docker ignore I bun this file. At the next cell, I’m trying to build such image - and getting error.\n\n%%bash\ncd dockerignore\ndocker build -t test_image -f dockerfile1 .\n\n#1 [internal] load build definition from dockerfile1\n#1 transferring dockerfile: 74B done\n#1 DONE 0.0s\n\n#2 [internal] load .dockerignore\n#2 transferring context: 50B done\n#2 DONE 0.0s\n\n#3 [internal] load metadata for docker.io/library/ubuntu:latest\n#3 DONE 0.0s\n\n#4 [1/2] FROM docker.io/library/ubuntu\n#4 DONE 0.0s\n\n#5 [internal] load build context\n#5 transferring context: 2B done\n#5 DONE 0.0s\n\n#6 [2/2] COPY test_file test_file\n#6 ERROR: failed to calculate checksum of ref 40880b12-160a-424d-a82b-d59b9594f64c::7cmhtk0ygxakortpvzlpd8pwp: \"/test_file\": not found\n------\n &gt; [2/2] COPY test_file test_file:\n------\ndockerfile1:2\n--------------------\n   1 |     FROM ubuntu\n   2 | &gt;&gt;&gt; COPY test_file test_file\n--------------------\nERROR: failed to solve: failed to compute cache key: failed to calculate checksum of ref 40880b12-160a-424d-a82b-d59b9594f64c::7cmhtk0ygxakortpvzlpd8pwp: \"/test_file\": not found\n\n\nCalledProcessError: Command 'b'cd dockerignore\\ndocker build -t test_image -f dockerfile1 .\\n'' returned non-zero exit status 1.\n\n\nOn the other hand, if I copy an entire folder and only a few files are blocked in the folder, the folder will be copied without those files. The following example show such configuration:\n\n%%bash\ncd dockerignore\n\necho \"=====dockerfile=====\"\ncat dockerfile2\necho\necho \"=====.dockerignore=====\"\ncat .dockerignore\n\necho\necho \"=====test_folder in host=====\"\nls test_folder\n\ndocker build -t test_image -f dockerfile2 . &&gt; /dev/null\n\ndocker run --rm --name test_container -itd test_image &&gt; /dev/null\necho \"=====test_folder in container=====\"\ndocker exec test_container ls test_folder\n\ndocker stop test_container &&gt; /dev/null\ndocker rmi test_image &&gt; /dev/null\n\n=====dockerfile=====\nFROM ubuntu\nCOPY test_folder test_folder\n=====.dockerignore=====\ntest_file\ntest_folder/banned_file\n\n=====test_folder in host=====\naccepted_file\nbanned_file\n=====test_folder in container=====\naccepted_file\n\n\nHere I copy the whole folder, but the file banned_file was mentioned in .dockerignore. So when we ls temp_folder from container we see only accepted_file in folder contents.\n\n\nFile in container forever\nIf you copied a file into the container, but literally deleted it by the next instruciton - it will still affect the size of the container.\nFollowing exampe show that fature: - First I create an image - just copy Ubuntu; - Second, add the COPY instruction for a large file - so the size of the container will be much larger than in the first step; - Last image add RUN rm for the file copied in the previous step, the point is that the image size hasn’t changed.\n\n%%bash\n\ndd if=/dev/zero of=file.txt bs=1M count=1000 &&gt; /dev/null\n\necho \"=====just ubuntu copy=====\"\necho \"FROM ubuntu\" &gt; test_dockerfile\ndocker build -f test_dockerfile -t test_image . &&gt; /dev/null\ndocker images | grep test_image\ndocker rmi test_image &&gt; /dev/null\n\necho \"=====ubuntu with big copied file=====\"\necho \"COPY file.txt file.txt\" &gt;&gt; test_dockerfile\ndocker build -f test_dockerfile -t test_image . &&gt; /dev/null\ndocker images | grep test_image\ndocker rmi test_image &&gt; /dev/null\n\necho \"=====ubuntu with deleted file=====\"\necho \"RUN rm file.txt\" &gt;&gt; test_dockerfile\ndocker build -f test_dockerfile -t test_image . &&gt; /dev/null\ndocker images | grep test_image\ndocker rmi test_image &&gt; /dev/null\n\n\nrm file.txt\nrm test_dockerfile\n\n=====just ubuntu copy=====\ntest_image                 latest    8173c3801863   3 months ago    77.8MB\n=====ubuntu with big copied file=====\ntest_image                 latest    86892a85e309   2 minutes ago   1.13GB\n=====ubuntu with deleted file=====\ntest_image                 latest    97524578efc6   52 seconds ago   1.13GB\n\n\n\n\ndocker commit - save state of the container\nAllows you to save the current state of any container as a new image. So if you have created something new in a container, you can save it as a new image. You have to follow such sintaksis:\ndocker commit &lt;container name&gt; &lt;new image name&gt;\nSo in follwing example I: - Running the container in which create file with message; - Create file in this container; - Commit this container as a new image; - Run the container based on the new image; - Check the message in the container based on the new image.\n\n%%bash\ndocker run --rm --name test_container -itd ubuntu &&gt; /dev/null\ndocker exec test_container bash -c \"echo \\\"I'm a new file in container\\\" &gt; new_file\"\n\ndocker commit test_container new_test_image &&gt; /dev/null\n\necho \"=====check new image=====\"\ndocker images | grep new_test_image\necho \"=====message from commited image=====\"\ndocker run --rm --name new_test_container -itd new_test_image &&gt; /dev/null\ndocker exec new_test_container cat new_file\n\ndocker stop new_test_container &&gt; /dev/null\ndocker stop test_container &&gt; /dev/null\ndocker rmi new_test_image &&gt; /dev/null\n\n=====check new image=====\nnew_test_image             latest    56c5c624ed38   Less than a second ago   77.8MB\n=====message from commited image=====\nI'm a new file in container"
  },
  {
    "objectID": "Docker/ports/ports.html",
    "href": "Docker/ports/ports.html",
    "title": "“Прокинуть” порт",
    "section": "",
    "text": "Работа с портом в docker\nПорт это “окно” которое позволяет программе запущенной на компьютере связыватся с интернетом.\nПри выполнении docker run нужно укзать опцию -p и затем передать &lt;порт на хосте&gt;:&lt;порт в контейнере&gt;.\n\nБазовый пример\nДля примера рассмотрим clickhouse, сначала просто его запустим:\n\n%%bash\ndocker run --rm -d --name db_port yandex/clickhouse-server\n# проверка того отвечает ли порт 8123 (видимо базовый для clickhouse)\ncurl localhost:8123\ndocker stop db_port\n\n9501fc87dee9210094e0b28076a4b194aad159c3490f76a7ed31498196ba8e68\ndb_port\n\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\ncurl: (7) Failed to connect to localhost port 8123 after 0 ms: Connection refused\n\n\nВ результате curl оветил Failed ....\nА теперь продемонстрируем тоже самое, но укажем опцию -p 8123:8123. Теперь то, спросив что-то с порта 8123 мы получили OK.\n\n%%bash\ndocker run --rm -d --name db_port -p 8123:8123 yandex/clickhouse-server\n# clickshouse нужно немнго времени для того, чтобы развернуться\nsleep 10\ncurl localhost:8123\ndocker stop db_port\n\n76e77328a72b90ca8b7ec8cddd79582b7498de70f6ec502a0cff1cd57e829568\nOk.\ndb_port\n\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100     4    0     4    0     0   2711      0 --:--:-- --:--:-- --:--:--  4000\n\n\n\n\nПрокидывание нескольких портов\nДля того, чтобы прокинуть несколько портов в контенер опцию -p следует использовать несколько раз. Так в следующем примере мы к одному и тому-же контейнеру подвязываем сразу два контейнера и, затем, спрашиваем их через curl.\n\n%%bash\ndocker run --rm -d --name db_port -p 8123:8123 -p 8124:8123 yandex/clickhouse-server\ncurl localhost:8123\ncurl localhost:8124\ndocker stop db_port\n\n004bdedc8fce6f5945aef97ff822813f67d7edb7036218e182d13f7bf3e6cf72\nOk.\nOk.\ndb_port\n\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100     4    0     4    0     0   2762      0 --:--:-- --:--:-- --:--:--  4000\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100     4    0     4    0     0   4040      0 --:--:-- --:--:-- --:--:--  4000\n\n\n\n\nEXPOSE\nЭто инструкция dockerfile, которая подскзывает пользователю какой порт будет слушать программа завернутая в контейнер. Рассмотрим поле “ports” команды ps от docker. Так, там перечислены, порты которые могут быть использованы clickhouse.\n\n%%bash\ndocker run --rm -d --name db_ports yandex/clickhouse-server\ndocker ps\ndocker stop db_ports\n\nd26dfc13efc2fd37560d46b4af5e196412e48b2cc3e22e3f8de2ce708989a436\nCONTAINER ID   IMAGE                      COMMAND            CREATED        STATUS                  PORTS                          NAMES\nd26dfc13efc2   yandex/clickhouse-server   \"/entrypoint.sh\"   1 second ago   Up Less than a second   8123/tcp, 9000/tcp, 9009/tcp   db_ports\ndb_ports\n\n\nА если среди слоев образа clickhouse искать ключевое слово EXPOSE, то получается, то получим:\n\n%%bash\ndocker history yandex/clickhouse-server | grep EXPOSE\n\n&lt;missing&gt;      13 months ago   /bin/sh -c #(nop)  EXPOSE 8123 9000 9009        0B        \n\n\nТак, получается есть слой с инструкцией EXPOSE для которого пречислены все те-же числа. Ну, попробуем собрать простой dockerfile в котором используем эту конструкцию. Так, dockerfile принял вид:\nFROM ubuntu\nEXPOSE 1050\n\n%%bash\ndocker run -itd --name expose_test --rm expose_test\ndocker ps\ndocker stop expose_test\n\n6112abb33b2e5c863cef3b40e59aa0b19ae8523c8d8dc41c3f476b4bdfb05fd3\nCONTAINER ID   IMAGE         COMMAND       CREATED        STATUS                  PORTS      NAMES\n6112abb33b2e   expose_test   \"/bin/bash\"   1 second ago   Up Less than a second   1050/tcp   expose_test\nexpose_test\n\n\nТак в порте видим заветные 1050.\n\n\nДетали\n\nПорт в контейнере\nВ нутри самого контейнера порты будут открыты и без всяких опций. Так в примере ниже я поднимаю clickhouse и полсе дого спрашиваю wget (потому что curl по умолчанию не завезли).\n\n%%bash\ndocker run -itd --name db_test --rm yandex/clickhouse-server\nsleep 10\ndocker exec db_test wget localhost:8123\ndocker stop db_test\n\nefee7438d3e4cae585b742cc1ab20d7051ce17004d1de0b88871dae31384496a\ndb_test\n\n\n--2023-03-10 18:37:10--  http://localhost:8123/\nResolving localhost (localhost)... 127.0.0.1, ::1\nConnecting to localhost (localhost)|127.0.0.1|:8123... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [text/html]\nSaving to: ‘index.html’\n\n     0K                                                         611K=0s\n\n2023-03-10 18:37:10 (611 KB/s) - ‘index.html’ saved [4]\n\n\n\n\n\nКонтейнеры с одним портом\nДумаю очевидно, что нельзя на один и тот-же порт повесить более двух контейнеров. Однако, есть способ обойти эту особенность, нужно к опции -p для порта хоста указать другой порт, в то время как в контейнере использовать все тот-же.\nТак для начала, пример с ошибкой - пытаеися повесить два контейнера на один и тот-же порт.\n\n%%bash\ndocker run -itd --name db_test1 --rm -p 8123:8123 yandex/clickhouse-server\ndocker run -itd --name db_test2 --rm -p 8123:8123 yandex/clickhouse-server \nsleep 10\ndocker stop db_test1\n\n6b56c296cfcc1aa9f46968767f9502de695f474df65d60aad2716eef8813daee\n07fdf42a22e2045f74785e3247a51b8c75883dc701da8427055a66190953a356\ndb_test1\n\n\ndocker: Error response from daemon: driver failed programming external connectivity on endpoint db_test2 (edaa15bb3cba3dc8dec4558bdc32ea5a9a9978560b7cc5678dd53216c6ba187b): Bind for 0.0.0.0:8123 failed: port is already allocated.\n\n\nПуть исправления, соотвественно. Второй контейнер при запуске использует порт 8124 контейнера.\n\n%%bash\ndocker run -itd --name db_test1 --rm -p 8123:8123 yandex/clickhouse-server\ndocker run -itd --name db_test2 --rm -p 8124:8123 yandex/clickhouse-server \nsleep 10\ndocker stop db_test1\ndocker stop db_test2\n\nc976a7e50840653c112b1107fa0d95abb5af4635737ff03ec408f7adb24b86ac\n30038fc56fbd0966363de0b886d4896cfb90f921a8385b7f30bc97c16ad232a4\ndb_test1\ndb_test2\n\n\n\n\nДоступ в локальной сети\nКрайне интерестно то, что если поднимать контейнер то он будет доступен во всей локальной сети. То есть вот например я поднимаю nginx прокинув в него порт 80.\n\n%%bash\ndocker run --rm -itd --name test_nginx -p 80:80 nginx\n\n008bd0e53c7eed5087c1d19b007f02b5b88400f97a52b366fbec9b0ae886d28e\n\n\nНа данный момент я подключен к некоторому wifi. И я могу посмотреть свой ip в этой сети используюя ifconfig. Там интересен раздел, название которого начинается на w это обычно касается wifi. Короче мой ip в данном случае будет 192.168.100.149.\n\n%%bash\nifconfig\n\ndocker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n        inet6 fe80::42:6fff:fe52:2c32  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 02:42:6f:52:2c:32  txqueuelen 0  (Ethernet)\n        RX packets 17  bytes 2818 (2.8 KB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 53  bytes 8417 (8.4 KB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nlo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 19226  bytes 2622646 (2.6 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 19226  bytes 2622646 (2.6 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nvethb598bee: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet6 fe80::7473:3ff:fea9:ca8c  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 76:73:03:a9:ca:8c  txqueuelen 0  (Ethernet)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 25  bytes 3808 (3.8 KB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nwlp0s20f3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet 192.168.100.149  netmask 255.255.255.0  broadcast 192.168.100.255\n        inet6 fe80::8bae:4ba5:fad1:e46e  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether dc:41:a9:2e:4c:6c  txqueuelen 1000  (Ethernet)\n        RX packets 196833  bytes 170924805 (170.9 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 96927  bytes 24734975 (24.7 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\nПодключив телефон к тойже-самой сети получаю кое-что интересное. Тупо вбив в браузере 192.168.100.149:80, получаю результат:\n\n\n%%bash\ndocker stop test_nginx\n\ntest_nginx"
  },
  {
    "objectID": "Docker/docker_file_instructions.html",
    "href": "Docker/docker_file_instructions.html",
    "title": "Dockerfile instructions",
    "section": "",
    "text": "Here are the most basic options for the dockerfile.\n\nFROM - sets the base image for the new image;\nWORKDIR - sets the working directory;\nCOPY &lt;host directory&gt; &lt;image directory&gt; - copy file from host to the image;\nRUN - allows to run command during container build.\n\n\nRun something with start of container\nThe instructions provided in this section allow you to set container behaviour with the command specified when starting the container in docker run. So here you can find some useful tips.\n\nENTRYPOINT\nAllow command to run when container based on image is running. The feature of this instruction is that you can add something at the end of the docker run command, and it will be added to command described in ENTRYPOINT.\nSuch dockerfile:\nFROM ubuntu:20.04\nENTRYPOINT [ \"echo\" ]\nCreates a container that will echo the line declared at the end of the docker run command. For exmaple:\n\n%%bash\ndocker build \\\n    -f basic_instructions/entrypoint_example \\\n    -t test_ubuntu \\\n    basic_instructions &&gt; /dev/null\n\ndocker run --rm test_ubuntu \"hello world\"\ndocker run --rm test_ubuntu ls\ndocker rmi test_ubuntu &&gt; /dev/null\n\nhello world\nls\n\n\nSo the lines I passed as arguments were just printed - just like echo does.\n\n\nCMD\nAllow command to run when container based on image is running. If using this instruction you set any command for docker run, the command described in CMD will be completely removed with new commad.\nConsider containers based on dockerfile:\nFROM ubuntu:20.04\nCMD [ \"echo\" ]\nThe same command docker run --rm test_ubuntu ls like it was for the dockerfile from ENTRYPOINT example, desn’t print “ls” but executes the ls command.\n\n%%bash\ndocker build \\\n    -f basic_instructions/cmd_example \\\n    -t test_ubuntu \\\n    basic_instructions &&gt; /dev/null\ndocker run --rm test_ubuntu ls \ndocker rmi test_ubuntu &&gt; /dev/null\n\nbin\nboot\ndev\netc\nhome\nlib\nlib32\nlib64\nlibx32\nmedia\nmnt\nopt\nproc\nroot\nrun\nsbin\nsrv\nsys\ntmp\nusr\nvar\n\n\n\n\nENTRYPOINT + CMD\nBy combining ENTRYPOINT and CMD you can do this: - in ENTRYPOIN set the necessary part of the command; - in CMD set the part of the command that can be changed.\ndocker file like:\nFROM ubuntu:20.04\nENTRYPOINT [\"echo\"]\nCMD [\"default message\"]\nBy default, “default message” is printed, but if you add a line to `docker run’ it will be printed instead. The following cell show how it works:\n\n%%bash\ndocker build \\\n    -f basic_instructions/entrypoint_cmd \\\n    -t test_ubuntu \\\n    basic_instructions &&gt; /dev/null\ndocker run --rm test_ubuntu\ndocker run --rm test_ubuntu \"other message\"\ndocker rmi test_ubuntu &&gt; /dev/null\n\ndefault message\nother message\n\n\nConsequence of instractions doesn’t matter. So docker file:\nFROM ubuntu:20.04\nCMD [\"default message\"]\nENTRYPOINT [\"echo\"]\nWill work the same way. The folowing cell show this scenario.\n\n%%bash\ndocker build \\\n    -f basic_instructions/entrypoint_cmd2 \\\n    -t test_ubuntu \\\n    basic_instructions &&gt; /dev/null\ndocker run --rm test_ubuntu\ndocker run --rm test_ubuntu \"other message\"\ndocker rmi test_ubuntu &&gt; /dev/null\n\ndefault message\nother message\n\n\n\n\nSeveral CMD/ENTRYPOIN\nLooks like, docker only takes the last mention of CMD/ENTRY POINT. Which makes sense in the case of ‘inheriting’ containers. So at the following example I’m using docker file:\nFROM ubuntu:20.04\nCMD [\"echo\", \"default message1\"]\nCMD [\"echo\", \"default message2\"]\n\n%%bash\ndocker build \\\n    -f basic_instructions/several_cmd \\\n    -t test_ubuntu \\\n    basic_instructions &&gt; /dev/null\ndocker run --rm test_ubuntu\ndocker rmi test_ubuntu &&gt; /dev/null\n\ndefault message2\n\n\nSo it looks like docker just ignored CMD [\"echo\", \"default message1\"]\n\n\n\nEnvironment variables\nFor creating environment variable you can use ENV dockerfile instruction.\nIn following example I create a dockefile vich use ENV to create TEST_VAR with value \"test variable value\". Then print it from container.\n\n%%bash\ncd basic_instructions\n\necho \"FROM ubuntu\" &gt; envdockerfile\necho \"ENV TEST_VAR=\\\"test variable value\\\"\" &gt;&gt; envdockerfile\n\ndocker build -t test_image -f envdockerfile . &&gt; /dev/null\ndocker run --rm -itd --name test_container test_image &&gt; /dev/null\ndocker exec test_container bash -c \"echo \\$TEST_VAR\"\n\n\ndocker stop test_container &&gt; /dev/null\ndocker rmi test_image &&gt; /dev/null\nrm envdockerfile\n\ntest variable value"
  },
  {
    "objectID": "Docker/network/network.html",
    "href": "Docker/network/network.html",
    "title": "ls",
    "section": "",
    "text": "Работа с сетями в docker\nРеализуется через API network.\nВыведет список доступных сетей.\n\n%%bash\ndocker network ls\n\nNETWORK ID     NAME      DRIVER    SCOPE\ncac8977da21a   bridge    bridge    local\nf8b2503d0640   host      host      local\nb1d7e6bda275   none      null      local\n\n\n\nПодключение к сети\n\nПри создании контейнера\nПроизводится, через указывание опции --net=&lt;имя/id сети&gt;. Далее в примере демонстрирую, что как минимум ничего не сломалось.\n\n%%bash\ndocker run --rm -di --net=none --name just_net ubuntu_curl\ndocker stop just_net\n\nee6e4f29315a7fcf3a5ad2ee39cdb86bb178ebb296563fee73b432a30799a33c\njust_net\n\n\n\n\nПодключение/откллючение уже созданного контейнера\nПроизводится с помощью комманды - Для подключения используется docker network connect &lt;сеть&gt; &lt;контейнер&gt;; - Для отключения используется docker network disconnect &lt;сеть&gt; &lt;контейнер&gt;.\n\n%%bash\n# запускаю контейнер с nginx он по умолчанию\n# прикрепляется к bridge\ndocker run --rm --name test_nginx -itd nginx\n# создаю новую сетку и цепляю не нее этот nginx\ndocker network create test_network\nsleep 10\ndocker network connect test_network test_nginx\n\n# отцепляю nginx от bridge\ndocker network disconnect bridge test_nginx\n\ndocker stop test_nginx\ndocker network rm test_network\n\n1ced62443c8437cdc2e4e3910957b2632cded2d709634543a6a212d6f4d08d7a\na8f26f0c7bea903a0c61a2d553b2ace6b96a952f1e0120159e1042463208a6f3\ntest_nginx\ntest_network\n\n\n\n\n\nСети по умолчанию\nВ docker по умолчанию доступно 3 сети:\n\n%%bash\ndocker network ls\n\nNETWORK ID     NAME      DRIVER    SCOPE\ncac8977da21a   bridge    bridge    local\nf8b2503d0640   host      host      local\nb1d7e6bda275   none      null      local\n\n\n\nСеть none\nПроизводит полное блокирование контейнера от сети.\nТак попробуем запустить clickhouse на этой сети и сделать к нему запрос. curl: (7) Failed to connect to localhost port 8123 after 0 ms: Connection refused свидетельствует о том, что по заданному адресу ничего не отвечат.\n\n%%bash\ndocker run --rm -d --name none_example -p 8123:8123 --net=none yandex/clickhouse-server\n# нельзя забывать, что clickhouse долговато поднимается\nsleep 10\ncurl localhost:8123\ndocker stop none_example\n\n05db6909cc4de9e808ffe927ad06594fafce9ea6e0a54e6fadf38f04e266759b\nnone_example\n\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\ncurl: (7) Failed to connect to localhost port 8123 after 0 ms: Connection refused\n\n\nТак же из нутри контейнера, нельзя будет достучаться в интернет. Так в следующем примере я запускаю ubuntu с предустановленным curl и получаю, и не могу из него достучаться до google.com. curl: (6) Could not resolve host: google.com свидетельсвует о том, что из контейнера не получается достучаться до google.com.\n\n%%bash\ndocker run -itd --rm --net=none --name none_example ubuntu_curl\ndocker exec none_example curl google.com\ndocker stop none_example\n\n3dd6e8e5f072ff86380acf7f092093bb96a1a1d7a3b091aaaf32d6ee21763e3c\nnone_example\n\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: google.com\n\n\n\n\nСеть host\nПолностью убирает сетевую изоляцию контейнера, то есть контейнер делит с хостом сеть полностью.\nТак в примере я запускаю yandex/clickhouse-server без указания каких-либо портов. В результате, этот clickhouse всеравно будет отвечать (даже без указанных портов).\n\n%%bash\ndocker run --rm -d --name host_example --net=host yandex/clickhouse-server\n# нельзя забывать, что clickhouse долговато поднимается\nsleep 10\ncurl localhost:8123\ndocker stop host_example\n\n69120ad84831e74d88b6085e5b38ca8ba2a0f05ff9b66ac2748a01b7974707e6\nOk.\nhost_example\n\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100     4    0     4    0     0   4149      0 --:--:-- --:--:-- --:--:--  4000\n\n\n\n\nСеть bridge\nСеть в которой контейнеры создаются по умолчанию. Далее показано несколько трюков.\nВесь этот раздел воспроиводится особым образом\nЯ предварительно поднял контейнеры с yandex/clickhouse-server и ubuntu с предустановленным curl:\n\n%%bash\ndocker ps\n\nCONTAINER ID   IMAGE                      COMMAND            CREATED              STATUS              PORTS                          NAMES\n3c653442fea3   ubuntu_curl                \"/bin/bash\"        About a minute ago   Up About a minute                                  ubu\n3f047e11c417   yandex/clickhouse-server   \"/entrypoint.sh\"   2 minutes ago        Up 2 minutes        8123/tcp, 9000/tcp, 9009/tcp   click\n\n\nТеперь демонстрирую результат комманды insperct (позволяет получить низкоуровневую инофрмацию о любом объекте docker) для сети bridge.\n\n%%bash\ndocker inspect bridge\n\n[\n    {\n        \"Name\": \"bridge\",\n        \"Id\": \"243b737447851abe893a50fab43e6fd6304423b81f848e31ae974692bb2388a5\",\n        \"Created\": \"2023-03-22T16:23:03.478736367+03:00\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": null,\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.17.0.0/16\",\n                    \"Gateway\": \"172.17.0.1\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Attachable\": false,\n        \"Ingress\": false,\n        \"ConfigFrom\": {\n            \"Network\": \"\"\n        },\n        \"ConfigOnly\": false,\n        \"Containers\": {\n            \"3c653442fea36887a8ff860b337148053ba5583c74ad635eeaa0bce4f75c8432\": {\n                \"Name\": \"ubu\",\n                \"EndpointID\": \"f29acdda0cc093af06a9797386eed25d491bb67e9e09112bae235657c81f93c9\",\n                \"MacAddress\": \"02:42:ac:11:00:03\",\n                \"IPv4Address\": \"172.17.0.3/16\",\n                \"IPv6Address\": \"\"\n            },\n            \"3f047e11c417e87a9f4e6eda57f0eed13695e569baf40d0dc0ff7204f209c08b\": {\n                \"Name\": \"click\",\n                \"EndpointID\": \"c872977345db4fb11ba931f75228816c4082b6879575167bc647f5c11cf94439\",\n                \"MacAddress\": \"02:42:ac:11:00:02\",\n                \"IPv4Address\": \"172.17.0.2/16\",\n                \"IPv6Address\": \"\"\n            }\n        },\n        \"Options\": {\n            \"com.docker.network.bridge.default_bridge\": \"true\",\n            \"com.docker.network.bridge.enable_icc\": \"true\",\n            \"com.docker.network.bridge.enable_ip_masquerade\": \"true\",\n            \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\",\n            \"com.docker.network.bridge.name\": \"docker0\",\n            \"com.docker.network.driver.mtu\": \"1500\"\n        },\n        \"Labels\": {}\n    }\n]\n\n\nОбращаю внимание на поле “Containers” а в нем на поля “IPv4Address”. По этим адресам мы можем общаться между контейнерами. Так вот например и из ubuntu спрошу clikchouse. Ok свидетельсвует о том, что я дейвительно дотянулся.\n\n%%bash\ndocker exec ubu curl 172.17.0.2:8123\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100     4    0     4    0     0   4944      0 --:--:-- --:--:-- --:--:--  4000\n\n\nOk.\n\n\nБолее того, несмотря на то, что я не указывал портов при поднятии контейнера clickhouse, через этот ip я могу достучаться до clickhouse и из хоста. В следующем примере, я сравниваю результат запроса на localhost и на этот ip.\n\nВ первом случае никуда я не достучался и закономерно получил curl: (7) Failed to connect to localhost port 8123 after 0 ms: Connection refused;\nВо втором случа clickhouse мне отвечает как ни в чем не бывало Ok..\n\n\n%%bash\ncurl localhost:8123\ncurl 172.17.0.2:8123\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\ncurl: (7) Failed to connect to localhost port 8123 after 0 ms: Connection refused\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100     4    0     4    0     0   9302      0 --:--:-- --:--:-- --:--:--  4000\n\n\nOk.\n\n\n\n\n\nСетевые интерфейсы\nКаждый контейнер создает новый сетевой интерфейс. Сетевые интерфейсы в linux можно посмотреть с помощью утилиты ifconfig. Далее пример, как выболняется ifconfig по умолчанию (с установленным docker).\n\n%%bash\nifconfig\n\ndocker0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt;  mtu 1500\n        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n        inet6 fe80::42:1eff:fe03:26e4  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 02:42:1e:03:26:e4  txqueuelen 0  (Ethernet)\n        RX packets 32158  bytes 1793702 (1.7 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 39205  bytes 192903770 (192.9 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nlo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 27239  bytes 6082445 (6.0 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 27239  bytes 6082445 (6.0 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nwlp0s20f3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet 192.168.100.10  netmask 255.255.255.0  broadcast 192.168.100.255\n        inet6 fe80::735b:b9a:6447:646d  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether dc:41:a9:2e:4c:6c  txqueuelen 1000  (Ethernet)\n        RX packets 312466  bytes 417021190 (417.0 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 68174  bytes 16481710 (16.4 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n\nА теперь запустим какой-нибудь контейнер и посмотрим результат ifconfig. Появляется veth..., который и представляет собой интерфейс этого контейнера.\n\n%%bash\ndocker run --rm -itd --name ubuntu_inter ubuntu\nifconfig\ndocker stop ubuntu_inter\n\n64034d23001182e6a73b5fc24ad5de41800b6fb7a043b72de0d17aa4cde44aa2\ndocker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n        inet6 fe80::42:1eff:fe03:26e4  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 02:42:1e:03:26:e4  txqueuelen 0  (Ethernet)\n        RX packets 32158  bytes 1793702 (1.7 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 39206  bytes 192903900 (192.9 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nlo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;\n        loop  txqueuelen 1000  (Local Loopback)\n        RX packets 29201  bytes 6753989 (6.7 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 29201  bytes 6753989 (6.7 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nveth29fa8ed: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet6 fe80::874:a8ff:febd:21d0  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 0a:74:a8:bd:21:d0  txqueuelen 0  (Ethernet)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 2  bytes 220 (220.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nwlp0s20f3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\n        inet 192.168.100.10  netmask 255.255.255.0  broadcast 192.168.100.255\n        inet6 fe80::735b:b9a:6447:646d  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether dc:41:a9:2e:4c:6c  txqueuelen 1000  (Ethernet)\n        RX packets 313325  bytes 417478943 (417.4 MB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 68966  bytes 17051363 (17.0 MB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nubuntu_inter\n\n\nПримечание интерфейсы можно слушать с помощью утилиты tcpdump.\n\n\nКастомные сети\nДля создания собсвенной сети в api network используется команда create. Она создается используя DRIVER bridge, соответсвенно обладает всеми свойсвами сети bridge.\nДля удаления сети используется команда rm, так в следующем примере будет создана сеть new_net и сразу же удалена.\n\n%%bash\ndocker network create new_net\ndocker network ls\ndocker network rm new_netb\n\n5222bef596010f96790439ddc3dd6a392850f90bb660c820e993c7329e653b89\nNETWORK ID     NAME      DRIVER    SCOPE\ne2df331917d9   bridge    bridge    local\nf8b2503d0640   host      host      local\n5222bef59601   new_net   bridge    local\nb1d7e6bda275   none      null      local\nnew_net\n\n\n\n\nПример изоляции\nПродемонстрируем, что контейнеры развернутые в одной сети типа “bridge” могут достучаться друг до друга. А в разных - нет.\nВ следующей ячейке я создаю три контейнера - два из них в сети “bridge” и последний в кастомной сети “new_net”.\n\n%%bash\ndocker run --rm -itd --name ubuntu_bridge1 ubuntu_curl\ndocker run --rm -itd --name ubuntu_bridge2 ubuntu_curl\n\ndocker network create new_net\ndocker run --rm -itd --name ubuntu_new_net --net=new_net ubuntu_curl\n\n268c559a31fa4de87f1f96e344429086ecaaf57bfced8d3872e464ed7393ac99\nf6f2903f851b129dc98a5526c7aa52c5b4a51572088e1571b8361bdf20b1212d\nb96ad8e7eaa1294d4debd7afc69ee180f76ee96df2eaea4ead6b66b318342736\nf13eaef8c1e69a14c8529ba3614422fef68b76640a2c9b9a2af31a1f47f5c186\n\n\nПолучаю информацию о сетях. Тут самое главное это ip контейнеров: - “ubuntu_bridge1” - 172.17.0.2; - “ubuntu_bridge2” - 172.17.0.3; - “ubuntu_new_net” - 172.21.0.2 (этот ip от запуска к запуску может меняться);\n\n%%bash\ndocker inspect bridge\ndocker inspect new_net\n\n[\n    {\n        \"Name\": \"bridge\",\n        \"Id\": \"f2435156fe9a8b2feb702177a4e2b67d89ab065fc643bdf8260e152c19342bfb\",\n        \"Created\": \"2023-03-26T20:14:42.936227946+03:00\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": null,\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.17.0.0/16\",\n                    \"Gateway\": \"172.17.0.1\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Attachable\": false,\n        \"Ingress\": false,\n        \"ConfigFrom\": {\n            \"Network\": \"\"\n        },\n        \"ConfigOnly\": false,\n        \"Containers\": {\n            \"268c559a31fa4de87f1f96e344429086ecaaf57bfced8d3872e464ed7393ac99\": {\n                \"Name\": \"ubuntu_bridge1\",\n                \"EndpointID\": \"d67e3d4fb30ebbdfb8f60edb65598bf3b2dd72f558847c65fdb4ccef8c043989\",\n                \"MacAddress\": \"02:42:ac:11:00:02\",\n                \"IPv4Address\": \"172.17.0.2/16\",\n                \"IPv6Address\": \"\"\n            },\n            \"f6f2903f851b129dc98a5526c7aa52c5b4a51572088e1571b8361bdf20b1212d\": {\n                \"Name\": \"ubuntu_bridge2\",\n                \"EndpointID\": \"d69d898e96b0838756a0415d5f49e02c34757dcf2a43c6ba44fae6ffe773e3d2\",\n                \"MacAddress\": \"02:42:ac:11:00:03\",\n                \"IPv4Address\": \"172.17.0.3/16\",\n                \"IPv6Address\": \"\"\n            }\n        },\n        \"Options\": {\n            \"com.docker.network.bridge.default_bridge\": \"true\",\n            \"com.docker.network.bridge.enable_icc\": \"true\",\n            \"com.docker.network.bridge.enable_ip_masquerade\": \"true\",\n            \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\",\n            \"com.docker.network.bridge.name\": \"docker0\",\n            \"com.docker.network.driver.mtu\": \"1500\"\n        },\n        \"Labels\": {}\n    }\n]\n[\n    {\n        \"Name\": \"new_net\",\n        \"Id\": \"b96ad8e7eaa1294d4debd7afc69ee180f76ee96df2eaea4ead6b66b318342736\",\n        \"Created\": \"2023-03-26T21:06:06.063558177+03:00\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": {},\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.21.0.0/16\",\n                    \"Gateway\": \"172.21.0.1\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Attachable\": false,\n        \"Ingress\": false,\n        \"ConfigFrom\": {\n            \"Network\": \"\"\n        },\n        \"ConfigOnly\": false,\n        \"Containers\": {\n            \"f13eaef8c1e69a14c8529ba3614422fef68b76640a2c9b9a2af31a1f47f5c186\": {\n                \"Name\": \"ubuntu_new_net\",\n                \"EndpointID\": \"de8440213aec37fbccb433e903cc3c0dd48d32daf7ca7024adfc82cd52f17723\",\n                \"MacAddress\": \"02:42:ac:15:00:02\",\n                \"IPv4Address\": \"172.21.0.2/16\",\n                \"IPv6Address\": \"\"\n            }\n        },\n        \"Options\": {},\n        \"Labels\": {}\n    }\n]\n\n\nИз контейнера “ubuntu_bridge1” стучусь в контейнер “ubuntu_bridge2” с которым они в одной подсети, и, конечно, получаю ответ.\n\n%%bash\ndocker exec ubuntu_bridge1 ping -c 4 172.17.0.3\n\nPING 172.17.0.3 (172.17.0.3) 56(84) bytes of data.\n64 bytes from 172.17.0.3: icmp_seq=1 ttl=64 time=0.086 ms\n64 bytes from 172.17.0.3: icmp_seq=2 ttl=64 time=0.109 ms\n64 bytes from 172.17.0.3: icmp_seq=3 ttl=64 time=0.110 ms\n64 bytes from 172.17.0.3: icmp_seq=4 ttl=64 time=0.083 ms\n\n--- 172.17.0.3 ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 3078ms\nrtt min/avg/max/mdev = 0.083/0.097/0.110/0.012 ms\n\n\nТеперь из контейнера “ubuntu_bridge1” стучусь в контейнер “ubuntu_new_net”. Они в разных подсетях потому и ответа я не получил.\n\n%%bash\n# echo в конце надо чтобы не выдавалась ошибка\n# которую генерит ping когда у него не получилось\n# достучаться до сервака\ndocker exec ubuntu_bridge1 ping -c 4 -q 172.21.0.2;  echo $?\n\nPING 172.21.0.2 (172.21.0.2) 56(84) bytes of data.\n\n--- 172.21.0.2 ping statistics ---\n4 packets transmitted, 0 received, 100% packet loss, time 3062ms\n\n1\n\n\nВ конце концов, все удаляю, чтобы не захломляться.\n\n%%bash\ndocker stop ubuntu_bridge1 ubuntu_bridge2 ubuntu_new_net\ndocker network rm new_net\n\nubuntu_bridge1\nubuntu_bridge2\nubuntu_new_net\nnew_net"
  },
  {
    "objectID": "Docker/docker_compose/docker_compose.html",
    "href": "Docker/docker_compose/docker_compose.html",
    "title": "YAML",
    "section": "",
    "text": "Разбор инстумента docker-compose\nПозиционируется как инстумент, который следующая ступень абстрации над docker - инстумент который позволяет организовать взаимодейсвие контейнеров между собой.\nЯзык разметки, с помощью которого задается поведение docker-compose.\nYAML позволяет описывать структуры данных которые состоят из списков и словарей: - каждый элемент списка начинается с символа -; - каждый новый ключ в словаре задатся так &lt;ключ&gt;:; - шаблоны (якоря) - возможность создать ссылку на некоторую сущность и потом использовать её в произвольном месте структуры; - вложенность структуры формируется отступами.\nДалее на примерах станет понятнее.\nВ python существует библиотека yaml, которая позволяет пребразовывать yaml разметку в соответсвующие структуры данных python.\n\nimport yaml\n\nВ следующем примере создается ключ словарь с ключами names, ages под которыми скрываются соответсвующие списки.\n\nyamls_str = \\\n\"\"\"\nnames:\n    - peter\n    - olga\nages:\n    - 22\n    - 18\n\"\"\"\n\nyaml.full_load(yamls_str)\n\n{'names': ['peter', 'olga'], 'ages': [22, 18]}\n\n\nЗаметим, что между &lt;ключ&gt;: и &lt;значение&gt; обязательно должен быть пробел. Вот, для сравнения, правильно созданный словарь под ключом postgres и ошибочно созданный под ключом clickhouse.\n\nyamls_str = \\\n\"\"\"\npostgres:\n    user: postgres_app_user\n    password: postgres_app_password\n    host: postgres_host\n    port: 5432\nclickhouse:\n    host:clickhouse_host\n    user:clickhouse_app_user\n    db:clickhouse_app_db\n    password:clickhouse_app_password\n\"\"\"\n\nyaml.full_load(yamls_str)\n\n{'postgres': {'user': 'postgres_app_user',\n  'password': 'postgres_app_password',\n  'host': 'postgres_host',\n  'port': 5432},\n 'clickhouse': 'host:clickhouse_host user:clickhouse_app_user db:clickhouse_app_db password:clickhouse_app_password'}\n\n\nИнетестно то, что для того, что по умолчанию yaml игнорирует все переносы на новую строку. Для того, чтобы справиться с этим исполюзуется: - | после имени ключа заставил yaml “видеть” перевод строки; - &gt; после имени ключа воткнет перенос строки в конец занчения.\nТак в примене ниже test1 и test2 с точки срения программы читающей yaml не отличаются. А вот test3 и test4 получают в некоторых местах служебный \\n.\n\nyamls_str = \\\n\"\"\"\ntest1: peter olga\ntest2:\n    peter\n    olga\ntest3: |\n    peter\n    olga\ntest4: &gt;\n    peter olga\n\"\"\"\n\nyaml.full_load(yamls_str)\n\n{'test1': 'peter olga',\n 'test2': 'peter olga',\n 'test3': 'peter\\nolga\\n',\n 'test4': 'peter olga\\n'}\n\n\nНу и для примера покажем как сформировать список словарей:\n\nyamls_str = \\\n\"\"\"\n- name: peter\n  age: 22\n- name: olga\n  age: 18\n\"\"\"\n\nyaml.full_load(yamls_str)\n\n[{'name': 'peter', 'age': 22}, {'name': 'olga', 'age': 18}]\n\n\nЯкоря создаются следующим образом: - В сущности на которую ссылаются задают &&lt;обозначение ссылки&gt;; - Когда эту сущность надо вставить куда-то используется синтаксис &lt;&lt;: *&lt;обозначение ссылки&gt;.\nВ примере далее были описаны свойства junior-a некоторой компании, а затем созданы две сушности которым были переданы свойсва этих junior-ов.\n\nyamls_str = \\\n\"\"\"\njunior:\n    &junior\n    position: junior\n    salary: 55000\n\nPeter:\n    &lt;&lt;: *junior\nOlga:\n    &lt;&lt;: *junior\n\"\"\"\n\nyaml.full_load(yamls_str)\n\n{'junior': {'position': 'junior', 'salary': 55000},\n 'Peter': {'position': 'junior', 'salary': 55000},\n 'Olga': {'position': 'junior', 'salary': 55000}}\n\n\n\nКоманды docker-compose\nТут будут рассмотрены самые полезные случаи для работы с коммандой docker-compose. Для примера используется docker-compose.yaml приложенный в той-же папке, что и этот notebook.\n\nup - поднять приложение\nКоманда up используется для того, чтобы поднять приложение спользующее docker-compose. Выполняется обязательно в той папке в которой лежит yaml описывающий приложение.\nОпции:\n\nd - запустит в фоновом режиме - терминал останеться под управлением пользователя.\n\nТак, следующий пример показывает, что до вызова docker-comporse up в docker нет не контейнеров ни вольюмов, а после, все это появляется.\n\n%%bash\necho '=======запущенные контейнеры========='\ndocker ps\necho '===========доступные volume=========='\ndocker volume ls\n\necho '==========запускаю приложение==========='\ndocker-compose up -d &&gt; /dev/null\n\necho '=======запущенные контейнеры========='\ndocker ps --format '{{.Names}}'\necho '===========доступные volume=========='\ndocker volume ls\n\ndocker-compose down -v &&gt; /dev/null\n\n=======запущенные контейнеры=========\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n===========доступные volume==========\nDRIVER    VOLUME NAME\n==========запускаю приложение===========\n=======запущенные контейнеры=========\ndocker_compose-db-1\n===========доступные volume==========\nDRIVER    VOLUME NAME\nlocal     docker_compose_ex_vol\n\n\n\n\ndown - положить приложение\nОпять же требуется вызывать из папки в которой лежит yaml описывающий приложение.\nОпции: - v - удалит все volume созданные при поднятии этого приложения.\n\n%%bash\ndocker-compose up -d &&gt; /dev/null\ndocker-compose down &&gt; /dev/null\n\necho '============без опции -v============'\ndocker volume ls\ndocker volume rm docker_compose_ex_vol &gt; /dev/null 2&gt;&1\n\n\ndocker-compose up -d &&gt; /dev/null\ndocker-compose down -v &&gt; /dev/null\necho '============опция -v============'\ndocker volume ls\n\n============без опции -v============\nDRIVER    VOLUME NAME\nlocal     docker_compose_ex_vol\n============опция -v============\nDRIVER    VOLUME NAME\n\n\n\n\n\nСоздание docker-compose файла\nЗдается с помощью описанного выше языка yaml. Далее будем обсуждать ключи которые могут быть использованы и для чего они могут быть использованы.\n\nКлюч services\nСкрывает под собой описание контейнеров, которые будут использоваться при развертывании приложения. Каждый ключ в словале под seriveces создает новый контенер, ключи задаются произвольно. То есть выглядеть это должно прмерно так:\nservices:\n  &lt;контейнер1&gt;:\n    &lt;инструкции&gt;\n  &lt;контейнер2&gt;:\n    &lt;инструкии&gt;\n  ...\nДалее рассмотрим различные интструкции которые может содржать каждый из контейнеров:\n\nБазовые интсрукции\nЕсть ряд интсрукции которые просто воспроизводят некторые комманды обычного docker. Не считаю, что они заслуживают отдельного разбора (пока не столкнулся с проблемами), потому просто покажу соответсвие с коммандами docker.\n\n\n\n\n\n\n\ndocker-compose.yaml\ndocker\n\n\n\n\nimage: &lt;образ&gt;\ndocker run &lt;образ&gt;\n\n\ncontainer_name: &lt;имя контейнера&gt;\ndocker run --name &lt;имя контейнера&gt;\n\n\nvolumes:  - &lt;volume/путь на хосте 1&gt;:&lt;путь в контейнере1&gt;  - &lt;volume/путь на хосте 2&gt;:&lt;путь в контейнере2&gt;  …\ndocker run \\-v &lt;путь на хосте/volume 1&gt;:&lt;путь в контейнере1&gt;\\  -v &lt;путь на хосте/volume 2&gt;:&lt;путь в контейнере2&gt;\\  …\n\n\nenvironment:&lt;имя переменной1&gt;: &lt;значение1&gt; &lt;имя переменной2&gt;: &lt;значение2&gt;  …\ndocker run \\  -e &lt;имя переменной1&gt;=&lt;значение переменной1&gt;  -e &lt;имя переменной2&gt;=&lt;значение переменной2&gt;  …\n\n\nnetworks:  - &lt;сеть 1&gt;  - &lt;сеть 2&gt;  …\ndocker run  --net &lt;сеть 1&gt;  --net &lt;сеть 2&gt;  …\n\n\nports:  &lt;порт на хосте1&gt;:&lt;порт в контейнере1&gt;  &lt;порт на хосте2&gt;:&lt;порт в контейнере2&gt;  …\ndocker run  -p &lt;порт на хосте1&gt;:&lt;порт в контейнере1&gt;  -p &lt;порт на хосте2&gt;:&lt;порт в контейнере2&gt;  …\n\n\n\n\n\nСборка образа - инструкция build\nСоответсвует комманде docker build. Соберет образ и запустит на его основе контейнер. заметим, что при опускании приложения, docker-compose остановит и удалит контейнер, но, не образ, поэтому удаление образа (в случае необходимости) ложится на админа.\n\n%%bash\ncd build_example\ndocker-compose up -d &&gt; /dev/null\necho '=====показываю что появился новый образ====='\ndocker images | grep build_example_my_small_ubuntu\necho '=====а на его основании контейнер====='\ndocker ps -a --format '{{.Names}}'\ndocker-compose down &&gt; /dev/null\necho '=====опустил приложение, но образ то остался====='\ndocker images | grep build_example_my_small_ubuntu\ndocker rmi build_example_my_small_ubuntu &&gt; /dev/null\n\n=====показываю что появился новый образ=====\nbuild_example_my_small_ubuntu   latest    098799dc601d   9 days ago      77.8MB\n=====а на его основании контейнер=====\nbuild_example-my_small_ubuntu-1\n=====опустил приложение, но образ то остался=====\nbuild_example_my_small_ubuntu   latest    098799dc601d   9 days ago      77.8MB\n\n\n\n\nИнтерактивный режим и подключение tty\nДелаются интрукциями:\ntty: true\nstdin_open: true\nДалее пример. Там поднимаются два контейнера на основе ubuntu один: - with_tty использует названные инструкции; - no_tty не использует названные инструкции.\nВ итоге при вызовер docker ps -a выявляюется обра образа, а при docker ps только образ with_tty, что говорит о том, что образ no_tty завершает свою работу.\n\n%%bash\n\ncd it_option\ndocker-compose up -d &&gt; /dev/null\nsleep 5\necho \"=====docker ps -a=====\"\ndocker ps -a --format '{{.Names}}'\necho \"=====docker ps=====\"\ndocker ps --format '{{.Names}}'\ndocker-compose down &&gt; /dev/null\n\n=====docker ps -a=====\nno_tty\nwith_tty\n=====docker ps=====\nwith_tty\n\n\n\n\nПерезапуск контейнера - интструкция restart\nВ случае, если некоторая программа при определенных обстоятельсвах будет вылетать с ошбкой её приходится перезапускать. В docker-compose для того предусмотренна инструация restart. Она, похоже, может принимать множество значений, но на сегоняшний день известна только always, которая приведет к тому, что контейнер будет перезапускаться пока не запустится.\nОбраз приведенный в папке restart сделан таким образом, чтобы программа останавливась всегда, когда файл check_file сорержит число меньшеее 5, но приращает число файле на 1. Если же программа видит число большее либо равное 5-ти в контейнере, то это приводит к тому, что она зависает в бесконечном цикле.\nЗапуская docker-compose.yaml с таким контейнером внутри и опцией restart: true получаем, что записанное в файле число дорастает ровно до 5.\n\n%%bash\n\ncd restart\necho \"1\" &gt; check_file\n\ndocker-compose up -d &&gt; /dev/null\nsleep 10\n\ndocker-compose down &&gt; /dev/null\ndocker rmi example_python &&gt; /dev/null\n\ncat check_file\n\n5\n\n\n\n\nПроверка работоспособности контейнера - инструкция healthcheck\nИногоа бывает так, что контейнер может провериться, по поводу того насколько правильно он запущен. Для того, чтобы вызвать команду проверки используется интсрукция healthy.\nhealthy имеет некоторые настройки, вот некоторые из них: - test - задает команду которая будет исопльзована для проверки контейнера; - interval; - timeout; - retries.\nВот, например, как инструкция может быть использована в postgresql:\n...\nhealthcheck: \n    test: [\"CMD-SHELL\", \"pg_isready\", \"-U\", \"docker_app\"]\n...\nТак в примере, представленном ниже, разворачивается два контейнера на основе postgresql (на остальные контейнеры в рамках этого примера можно не обращать внимания). Один с этой опицией, другой без. При отображении их через dokcer ps у одного в STATUS есть пририска (health: starting) у второго - нет.\n\n%%bash\ncd postgres_example\ndocker-compose up -d &&gt; /dev/null\ndocker ps --format '{{.Names}}'\ndocker-compose down -v &&gt; /dev/null\n\npostgres_example-ubuntu3-1\npostgres_example-ubuntu1-1\npostgres_example-db1-1\npostgres_example-db2-1\n\n\n\n\nЗависимость от других сревисов - depends_on\nЕсли требуется что-то делать в зависимости от другого сервиса в этом docker-compose.yaml то делается это так:\n...\ndepends_on:\n    &lt;имя обуславливающего сервиса&gt;:\n        &lt;инструкции&gt;\n...\nНапример, если требуется запускать контейнер, только в том случае, если другой сервис healthy, то это будет записано так:\n...\ndepends_on:\n    &lt;имя обуславливающего сервиса&gt;:\n        condition: service_healthy\n...\nНа данный момент известно о следующих возможностях этой инструкции:\n\ncondition: service_healthy - проверить проведена ли для обулавливающего контейнера проверка healthcheck;\ncondition: service_started - проверить поднят ли обуславливающий контейнер.\n\nДля примера представим “docker-compose.yaml” расположенный в папке “postgres_example”. В нем: - сервисы “ubuntu1” и “ubuntu2” поднимаются только в случае “здоровья” сервисов “db1” и “db2” соотсветсвенно - в результате поднимается только “ubuntu1” потому как проверка healthcheck предусмотрена только для “db1”; - сервисы “ubuntu3” и “ubuntu4” поднимаются только в тех случах если подняты “ubuntu1” и “ubuntu2” соотственно - так как на прошлом шаге “unbuntu2” не поднялся не поднимется и “ubuntu4”.\n\n%%bash\ncd postgres_example\ndocker-compose up -d &&gt; /dev/null\ndocker ps --format '{{.Names}}'\ndocker-compose down -v &&gt; /dev/null\n\npostgres_example-ubuntu3-1\npostgres_example-ubuntu1-1\npostgres_example-db2-1\npostgres_example-db1-1\n\n\n\n\nРеплики контейнера - интсрукция deploy-&gt;replicas\nДля интсрукции deploy, наверняка будет больше подинтсрукций. Но на сегдняшний день известно только об replicas.\ndeploy-&gt;replicas позволяет задать число копий поднимаемого контейнера.\nТак использование последовательности инструкций:\ndeploy:\n  replicas: 3\nПриводит к тому, что будет поднято три реплики сервиса для которого это записано.\nТак в примере ниже я одним махом поднимаю 3 контейнера ubuntu:\n\n%%bash\ncd replicas\ndocker-compose up -d &&gt; /dev/null\ndocker ps -a --format '{{.Names}}'\ndocker-compose down &&gt; /dev/null\n\nreplicas-my_ubuntu-1\nreplicas-my_ubuntu-3\nreplicas-my_ubuntu-2\n\n\n\n\nКоманды при запуске - инструкция command\nМожно указать команду, которая будет выполнена при запуске контейнера. Так “docker-file.yaml” в папке “command” содержить строку: command: bash -c \"echo \\\"hello world\\\" &gt; test_file; bash\"\nЭта строка в контейре создаёт файл “test_file” наличие и содержание, котого мы проверяем в примере ниже:\n\n%%bash\ncd command\ndocker-compose up -d &&gt; /dev/null\ndocker exec temp_ubuntu cat test_file\ndocker-compose down &&gt; /dev/null\n\nhello world\n\n\nИнтерестно, то что если написть command так:\ncommand echo \"hello world\" &gt; test_file\nКонтейнер завершает работу. Видимо это связано с тем, что последняя комманда должна бесконечно ожидать ввода, чтобы все работало - именно такую функцию выполняет комманда bash.\n\n\n\nКлюч volumes\nЗадает volumes.\nКаждый вложенный ключ создаст volume.\nvolumes:\n    &lt;volume1&gt;:\n        name: &lt;volume name&gt;\n    &lt;volume2&gt;:\n    ...\nУ каждого volume можно задать поле name (а можно и не задавать) которое укажет имя volume при поднятии приложения. Так, в примере ниже, из папки volume_example создается volume с именем example_name.\n\n%%bash\ncd volume_example\ndocker-compose up -d &&gt; /dev/null\n\necho \"=====список volume=====\"\ndocker volume ls\n\ndocker-compose down -v &&gt; /dev/null\n\n=====список volume=====\nDRIVER    VOLUME NAME\nlocal     example_name\n\n\n\n\nКлюч networks\nЗадает сети импользуемые в приложении.\nКаждый вложенный ключ создаст сеть.\nnetworks:\n    &lt;net1&gt;:\n        name: &lt;network name&gt;\n    &lt;net2&gt;:\n    ...\nКлюч name задает имя сети и не является обязательным. На в папке network-example лежит yaml файл, который описывает сеть с именем example_name.\n\n%%bash\ncd network_example\ndocker-compose up -d &&gt; /dev/null\ndocker network ls\ndocker-compose down -v &&gt; /dev/null\n\nNETWORK ID     NAME           DRIVER    SCOPE\n75034612bd8f   bridge         bridge    local\n14cb969f28d4   example_name   bridge    local\nf8b2503d0640   host           host      local\nb1d7e6bda275   none           null      local\n\n\n\n\n\nДетали\n\nСеть по умолчанию\nЛюбое приложение запущенное через docker-compose, в случае отсудсвия указанных сетей, создает себе сеть с названием по типу &lt;имя папки&gt;_default. Так в примере далее показано, что в списке, кроме базовых сетей, появляется docker_compose_default.\n\n%%bash\ndocker-compose up -d &&gt; /dev/null\necho \"=====созданные сети=====\"\ndocker network ls\ndocker-compose down -v &&gt; /dev/null\n\n=====созданные сети=====\nNETWORK ID     NAME                     DRIVER    SCOPE\n75034612bd8f   bridge                   bridge    local\n205bf876f99f   docker_compose_default   bridge    local\nf8b2503d0640   host                     host      local\nb1d7e6bda275   none                     null      local\n\n\n\n\nНазвание по умолчанию\nvolumes/сети, по умолчанию, получают некоторые названия по типу &lt;название папки&gt;_&lt;название ключа&gt;. Так, в следующем примере, в папке default_namimg указаны volume ex_vol и сеть ex_net, но для них не указано ключа name.\n\n%%bash\ncd default_naming\ndocker-compose up -d &&gt; /dev/null\necho '=====volumes====='\ndocker volume ls\necho '=====networks====='\ndocker network ls\ndocker-compose down -v &&gt; /dev/null\n\n=====volumes=====\nDRIVER    VOLUME NAME\nlocal     default_naming_ex_vol\n=====networks=====\nNETWORK ID     NAME                    DRIVER    SCOPE\n75034612bd8f   bridge                  bridge    local\n4599a4f61b14   default_naming_ex_net   bridge    local\nf8b2503d0640   host                    host      local\nb1d7e6bda275   none                    null      local\n\n\n\n\nvolume/сеть не создаются?\nУбедитесь, что они указаны под ключами volumes/networks в каком-либо из контейнеров. В противном случае они не создаются.\nВ следующем примере из папки vol_net_missed разворачивается приложение. И хотя в соответсвующем docker-compose.yaml заданы volume ex_vol и сеть ex_net, при запуске приложения создается только безимянный volume (видимо создаваемый postgres по умолчанию) и сеть которая всегда создается docker-compose по умолчанию vol_net_missed_default.\nПримеры удачного создания сетей/volumes представлены выше.\n\n%%bash\ncd vol_net_missed\ndocker-compose up -d &&gt; /dev/null\necho '====volumes====='\ndocker volume ls\necho '=====networks====='\ndocker network ls\ndocker-compose down -v &&gt; /dev/null\n\n====volumes=====\nDRIVER    VOLUME NAME\nlocal     48e548f659d0e05ba4a981e4b17e9b2b1835ca62aeb0cbfa08974d23d7772469\n=====networks=====\nNETWORK ID     NAME                     DRIVER    SCOPE\n75034612bd8f   bridge                   bridge    local\nf8b2503d0640   host                     host      local\nb1d7e6bda275   none                     null      local\nbcef30a7a541   vol_net_missed_default   bridge    local\n\n\n\n\nМонтирование директорий из директирии запуска\nИногда требуется сослатся на папку из которой производится запуск docker-compose. Для того можно использовать ${PWD}/&lt;дирректория&gt; или ./&lt;дирректория&gt;\nКогда мы, например, в docker монтировали файл/папку, через bind mount мы писали что-то вроде:\ndocker run --rm\\\n    -v $(pwd)/&lt;название файла/папки&gt;:&lt;путь в контейнере&gt;\nАналогичная запись в docker-compose.yaml:\nservices:\n  &lt;название сервиса&gt;:\n    volumes:\n      - ${PWD}/&lt;название файла/папки&gt;:&lt;путь в контейнере&gt;\nили\nservices:\n  &lt;название сервиса&gt;:\n    volumes:\n      - ./&lt;название файла/папки&gt;:&lt;путь в контейнере&gt;\nПример далее, заодно покажем как пользоваться bind mount в docker-compose.\ndocker-compose файл лежит в папке pwd_example. В этой же папке создается файл test_file, который потом указано монтировать в файле docker-compose.yaml, так - ${PWD}/test_file:/test_file1 и как - ./test_file:test_file2.\nЗатем в файлы в файловой системе контейнера вносятся изменения.\nПосле закрытия контейнера, все изменения в файле остаются в исходном файле на хосте.\n\n%%bash\n\ncd pwd_example\necho \"Сообщение с хоста\" &gt; test_file\necho \"=====Исходный файл=====\"\ncat test_file\n\ndocker-compose up -d &&gt; /dev/null\ndocker exec test_cont bash -c \"echo 'Сообщение из контейнера 1' &gt;&gt; test_file1\"\ndocker exec test_cont bash -c \"echo 'Сообщение из контейнера 2' &gt;&gt; test_file2\"\ndocker-compose down &&gt; /dev/null\n\necho \"=====Измененный файл=====\"\ncat test_file\n\n=====Исходный файл=====\nСообщение с хоста\n=====Измененный файл=====\nСообщение с хоста\nСообщение из контейнера 1\nСообщение из контейнера 2\n\n\n\n\nОбновление docker-compose приложения\nЕсли вдруг, в docker-compose.yaml были внесены некоторые изменения, то не обязательно опускать приложение - можно его просто запустить наново, docker-compose подхватит, что это то же самое приложение (видимо по папке запуска) и обновит его.\nВ следующем примере, я сначала запускаю docker-compose с приложением в котором единтсвенный контейнер имеет имя first_name, затем подменяю docker-compose.yaml на тот, который содержит контейнер названный second_name.\nЯ хочу показать то, что несмотря на то что запуска два и немного разных контейнер то остается один и меняет имя в соовтесвии с актуальным docker-compose.yaml\n\n%%bash\ncd refresh\ncat first.yaml &gt; docker-compose.yaml\ndocker-compose up -d &&gt; /dev/null\necho \"=====Первый запуск=====\"\ndocker ps -a --format '{{.Names}}'\ncat second.yaml &gt; docker-compose.yaml\ndocker-compose up -d &&gt; /dev/null\necho \"=====Второй запуск=====\"\ndocker ps -a --format '{{.Names}}'\ndocker-compose down &&gt; /dev/null\n\n=====Первый запуск=====\nfirst_name\n=====Второй запуск=====\nsecond_name"
  },
  {
    "objectID": "Docker/logs.html",
    "href": "Docker/logs.html",
    "title": "Logging in docker",
    "section": "",
    "text": "Logs can: - Write them using the standard output stream; - Write to a predefined file (there is nothing special here, you can just use volume or bind mount); - A combination of the two previously mentioned methods.\n\nlogs command\nAllows to read, what happened in container terminal.\nIn following example I: - I create conteiner which generates either a message in stdout or an error in stderr every second; - Wait 10 seconds; - Use docker logs to see what events happen in container.\n\n%%bash\ncd logs_examples\ndocker build -t log_example . &&gt; /dev/null\n\ndocker run -d --rm --name log_example log_example stream.py &&gt; /dev/null\nsleep 10\n\necho \"=====generated log=====\"\ndocker logs log_example\n\ndocker stop log_example &&gt; /dev/null\ndocker rmi log_example &&gt; /dev/null\n\n=====generated log=====\nJust message\nJust message\nJust message\nJust message\nJust message\n\n\nSome error\nSome error\nSome error\nSome error\n\n\nNote for some reason Jupyter puts errors in the first place in its output - so you may always get errors first when trying to reproduce the results of the following example.\nActually, you can avoid this by redirecting the error stream to the normal stream, by using 2&gt;&1 bash construction:\n\n%%bash\ncd logs_examples\ndocker build -t log_example . &&gt; /dev/null\n\ndocker run -d --rm --name log_example log_example stream.py &&gt; /dev/null\nsleep 10\n\necho \"=====generated log=====\"\ndocker logs log_example 2&gt;&1\n\ndocker stop log_example &&gt; /dev/null\ndocker rmi log_example &&gt; /dev/null\n\n=====generated log=====\nJust message\nJust message\nJust message\nJust message\nSome error\nSome error\nSome error\nJust message\nJust message\n\n\n\n-f - read container output in runtime\n\n\n\n-t - get time of the message\n\n%%bash\ncd logs_examples\ndocker build -t log_example . &&gt; /dev/null\n\ndocker run -d --rm --name log_example log_example stream.py &&gt; /dev/null\nsleep 10\n\necho \"=====generated log=====\"\ndocker logs -t log_example\n\ndocker stop log_example &&gt; /dev/null\ndocker rmi log_example &&gt; /dev/null\n\n=====generated log=====\n2023-06-12T08:42:12.063382853Z Just message\n2023-06-12T08:42:13.064541066Z Just message\n2023-06-12T08:42:14.065711848Z Just message\n2023-06-12T08:42:17.069086047Z Just message\n2023-06-12T08:42:19.071241128Z Just message\n2023-06-12T08:42:20.072419403Z Just message\n\n\n2023-06-12T08:42:15.066916732Z Some error\n2023-06-12T08:42:16.068155506Z Some error\n2023-06-12T08:42:18.070257834Z Some error\n\n\n\n\n\nGet log path on the computer\nIf you need to get the path to the Docker container log on your computer, you should use the construction shown below.\n\n%%bash\ncd logs_examples\ndocker build -t log_example . &&gt; /dev/null\n\ndocker run -d --rm --name log_example log_example stream.py &&gt; /dev/null\necho \"=====path to the log=====\"\ndocker inspect --format \"{{.LogPath}}\" log_example\n\ndocker stop log_example &&gt; /dev/null\ndocker rmi log_example &&gt; /dev/null\n\n=====path to the log=====\n/var/lib/docker/containers/cb2fb4f9b5d8829c1afb6b78293cf9487c0266d4152bd2f9a3f9d9d766740216/cb2fb4f9b5d8829c1afb6b78293cf9487c0266d4152bd2f9a3f9d9d766740216-json.log\n\n\nI can’t get superuser access from jupyter, but the log file should look like this:\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:01.788547631Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:02.788842446Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:03.788818941Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:04.789226578Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:05.789279007Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:06.789563215Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:07.7895666Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:08.789954572Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:09.790014965Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:10.790300833Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:11.790511897Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:12.790821869Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:13.790939824Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:14.791204789Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:15.791283359Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:16.791536539Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:17.791786679Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:18.791807047Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:19.792075268Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:20.792325859Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:21.792410762Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:22.792794096Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:23.792780477Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:24.793194852Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:25.793462485Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:26.793712972Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:27.793920753Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:28.794071626Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:29.794379101Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:30.794698985Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:31.794924583Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:32.795122566Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:33.795242226Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:34.795374507Z\"}\n    {\"log\":\"Some error\\n\",\"stream\":\"stderr\",\"time\":\"2023-03-10T15:25:35.795542017Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:36.795638844Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:37.795888676Z\"}\n    {\"log\":\"Just message\\n\",\"stream\":\"stdout\",\"time\":\"2023-03-10T15:25:38.796024537Z\"}\nThe fields in this example should have the following meaning:\n\nlog - message that was logged;\nstream - stream that was used;\ntime - time when it was made.\n\n\n\nStandart/error streams\n\nFrom terminal\nBasic Linux utilities for processing terminal output that are specified for the standard stream and don’t care about the error stream.\nFor example, if you use the head utility to handle program output:\n\n%%bash\n\ncd logs_examples\necho \"=====head result=====\"\npython3 stream.py -n 10| head -n 5\necho \"=====grep result=====\"\npython3 stream.py -n 10| grep message\n\n=====head result=====\nJust message\nJust message\nJust message\nJust message\n=====grep result=====\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\n\n\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error\n\n\nDespite the fact that I asked for head -n 5, which means that 5 lines should be printed in the command output, I got many more lines. This happens because utilities such as head, tail, grep and so on only work with the standard stream and ignore the error. But the error stream has priority over the standard stream - so it will be printed anyway.\nAs a solution you can redirect error stream info to standart stream by using 2&gt;&1 construction after the command displaying result:\n\n%%bash\n\ncd logs_examples\necho \"=====head result=====\"\npython3 stream.py -n 10 2&gt;&1| head -n 5\necho \"=====grep result=====\"\npython3 stream.py -n 10 2&gt;&1|grep message\n\n=====head result=====\nSome error\nSome error\nSome error\nSome error\nSome error\n=====grep result=====\nJust message\nJust message\nJust message\n\n\nThis way the Linux commands will see no difference between error and standard streams, but the error stream will still be displayed first - which you can see in the head command result.\nBut in the context of Docker container logging, if you use 2&gt;&1 with docker logs, it will be sufficient to print standard and error streams in apparent order. This is probably because you are not extracting messages from the runtime, but from a file somewhere.\n\n%%bash\ncd logs_examples\ndocker build -t log_example . &&gt; /dev/null\n\ndocker run -d --rm --name log_example log_example stream.py &&gt; /dev/null\nsleep 10\n\necho \"=====generated log=====\"\ndocker logs log_example 2&gt;&1| head -n 5\n\ndocker stop log_example &&gt; /dev/null\ndocker rmi log_example &&gt; /dev/null\n\n=====generated log=====\nJust message\nSome error\nJust message\nSome error\nSome error\n\n\n\n\nTo file\nYou can save streams to files by using the following constructions:\n\n&gt; - rewrite file with the results of the standart stream;\n&gt;&gt; - complete file with the result of the standart stream;\n2&gt; - rewrite file with the result of the error stream;\n2&gt;&gt; - complete file with the result of the error stream.\n\nThe following example shows how divide standart and error streams into two files.\n\n%%bash\ncd logs_examples\npython3 stream.py -n 20 &gt; standart_stream 2&gt; error_stream\n\necho \"=====standart stream=====\"\ncat standart_stream\necho \"=====error stream=====\"\ncat error_stream\n\nrm standart_stream error_stream\n\n=====standart stream=====\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\nJust message\n=====error stream=====\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error\nSome error"
  },
  {
    "objectID": "Docker/sources.html",
    "href": "Docker/sources.html",
    "title": "Sources",
    "section": "",
    "text": "This is where I put useful information about Docker. If any sources are mentioned in later sections, you should find them here.\n\nDocker instalation;\n May be useful after installing;\n\nHow not to always put sudo before the docker command;\nSomething still incomprehensible..\n\n Start daemon  sudo systemctl start docker;\n Docker cource by karpovcources."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]