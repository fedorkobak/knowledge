{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01d4f65-fdbe-4546-9168-891beba49c89",
   "metadata": {},
   "source": [
    "# Confusion matrix\n",
    "\n",
    "Inaccuracy matrix is a very important concept for evaluating classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b82584-9b9d-4554-8334-6154d4f99dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6db2d0-a4e0-44a3-95dc-584a393d9033",
   "metadata": {},
   "source": [
    "## Example task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2636ffa5-f1cf-41fe-9564-3b5e66223952",
   "metadata": {},
   "source": [
    "Consider a binary classification problem. We have two classes, Positive and Negative.\n",
    "\n",
    "Let be:\n",
    "\n",
    "- $P$ is the number of positive observations in the sample;\n",
    "- $N$ is the number of negative observations in the sample.\n",
    "\n",
    "The following code generates possible outputs of the classification task:\n",
    "\n",
    "- $y$ - real targets, 0 corresponds to negative 1 to positive;\n",
    "- $t_i$ - score that indicates the probability that a particular object belongs to the positive class;\n",
    "- $\\hat{y}=\\left[t_i>T\\right]$ - final predicts that depends which depend on the cut-off threshold - $T$. You can choose different $T$ and it will fill the confusion matrix - it's discussed in the following sections. For the example below, $T$ is the mean of $t_i=\\overline{1,n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f93e88b-c423-4a05-b4de-497db68f33c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$y$</th>\n",
       "      <th>$t_i$</th>\n",
       "      <th>$\\hat{y}$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.644251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.162201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.624533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.033877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.012203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   $y$     $t_i$  $\\hat{y}$\n",
       "0    0 -0.644251          0\n",
       "1    0 -1.162201          0\n",
       "2    1 -0.624533          0\n",
       "3    1  2.033877          1\n",
       "4    1 -1.012203          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = make_classification(\n",
    "    n_features=1,\n",
    "    n_informative=1,\n",
    "    n_redundant=0,\n",
    "    n_repeated=0,\n",
    "    n_clusters_per_class=1,\n",
    "    flip_y=0.3,\n",
    "    random_state=2\n",
    ")\n",
    "x = x.ravel()\n",
    "pd.DataFrame({\n",
    "    \"$y$\" : y, \n",
    "    \"$t_i$\" : x, \n",
    "    \"$\\hat{y}$\":(x>np.mean(x)).astype(\"int\")\n",
    "}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12396198-f3de-4139-b424-36b2e9debedb",
   "metadata": {},
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3fc5f-2b74-4f1c-ac0b-8f1e621b5dcb",
   "metadata": {},
   "source": [
    "Now, suppose we have formed some classifier. We have the following groups of observations.\n",
    "\n",
    "- True positive - observations that were positive in the sample and we correctly predicted them as positive. We will denote their number as $TP$;\n",
    "- True negative - observations that were negative in the sample and we correcrly predicted then as negative. We will denote their number as $TN$;\n",
    "- False positve - observations that were negative in the sample, but which we then mistakenly predicted to be positive. We will denote their number as $FP$;\n",
    "- False negative - observations that were positive in the sample, but wich we then mistakenly predicted to be negative. We will denote their number as $FN$.\n",
    "\n",
    "So, if you put the actual value on the rows and the predicted value on the columns, you will get a confusion matrix.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th></th>\n",
    "      <th>Predicted $N$</th>\n",
    "      <th>Predicted $P$</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Actual $N$</td>\n",
    "      <td>$TN$</td>\n",
    "      <td>$FP$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Actual $P$</td>\n",
    "      <td>$FN$</td>\n",
    "      <td>$TP$</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8cbeaf-36e1-446f-819a-2c81b344bda2",
   "metadata": {},
   "source": [
    "Also valuable is the representation of the confusion matrix using relative values.\n",
    "\n",
    "Let be:\n",
    "\n",
    "- $P^* = TP + FP$ - number of observations from the sample predicted as positive;\n",
    "- $N^* = TN + FN$ - number of observations from the sample predicted as negative;\n",
    "- $TNR = TN/N^*$ - true negative rate, the proportion of correct predictions among observations that are predicted negative;\n",
    "- $FNR = FN/N^*$ - false negative rate, the proportion of incorrect predictions among observations that are predicted to be negative;\n",
    "- $TPR = TP/P^*$ - true positive rate, the proportion of correct predictions among observations that are predicted to be positive;\n",
    "- $FPR = FP/P^*$ - false positve rate, the proportion of incorrect predicitons among observations that are predicted to be negative.\n",
    "\n",
    "\n",
    "So using these notations the confusion matrix can also be written:\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th></th>\n",
    "      <th>Predicted $N$</th>\n",
    "      <th>Predicted $P$</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Actual $N$</td>\n",
    "      <td>$TNR$</td>\n",
    "      <td>$FPR$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Actual $P$</td>\n",
    "      <td>$FNR$</td>\n",
    "      <td>$TPR$</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210887e-81b9-4832-a024-b49d981b6363",
   "metadata": {},
   "source": [
    "Here is an example of calculating the confusion matrix using `sklearn.metrics.confusion_matrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d475e43-c213-4c6f-b025-f2d098a023ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39,  7],\n",
       "       [17, 37]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "sklearn.metrics.confusion_matrix(y, x > np.mean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37552f-be87-4bce-b36e-1bb7d474f4d3",
   "metadata": {},
   "source": [
    "## Confusion table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c502da-4730-4218-a712-74df61d57499",
   "metadata": {},
   "source": [
    "### Idea\n",
    "\n",
    "Many classification models allow to return a score that indicates the probability that a particular object belongs to the positive class. You can select the threshold above which you consider the object under consideration to be positive. Different treshold values will consequently produce different confusion matrixes.\n",
    "\n",
    "The table that puts in correspondence to some selected threshold the table of contiguity will be called the confusion table.\n",
    "\n",
    "| $T$   | $TN$ | $FP$ | $FN$ | $TP$ |\n",
    "|:-----------|:-----:|:-----:|:-----:|:-----:|\n",
    "| $t_1$      | $TN_1$| $FP_1$| $FN_1$| $TP_1$|\n",
    "| $t_2$      | $TN_2$| $FP_2$| $FN_2$| $TP_2$|\n",
    "| ...        | ...    | ...    | ...    | ...    |\n",
    "| $t_i$      | $TN_i$| $FP_i$| $FN_i$| $TP_i$|\n",
    "| ...        | ...    | ...    | ...    | ...    |\n",
    "| $t_n$      | $TN_n$| $FP_n$| $FN_n$| $TP_n$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca36fa90-9159-4553-a18d-9997ee2ee8a0",
   "metadata": {},
   "source": [
    "### Realisation\n",
    "\n",
    "I didn't find ready realisation of the similar concept. So here is my own realisation.\n",
    "\n",
    "The first thing that comes to mind is to use `sklearn.metrix.confusion_matrix` for all needed $t_i$. But this solution is extremely slow - an estimate of the complexity of the algorithm is $O(nT')$, where $n$ number of samples $T'$ is the number of thresholds to check.\n",
    "\n",
    "The following is a description of the algorithm that will work with complexity $O(n)$ assuming that the observations are sorted in ascending order $s_i$ and all tresholds are sorted in asceding order:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ee652-2f46-4537-bb93-13bab3d880c1",
   "metadata": {},
   "source": [
    "As input we have three arrays:\n",
    "\n",
    "- $\\left\\{y_1,y_2, ... , y_n\\right\\}$ - real classes of the observations, where:\n",
    "$$y_i = \\begin{cases}\n",
    "    0, \\text{if i-th observation negative};\\\\\n",
    "    1, \\text{if i-th observation positive}.\n",
    "\\end{cases}$$\n",
    "- $\\left\\{s_1,s_2, ..., s_n\\right\\}$ - scores of the observations;\n",
    "- $\\left\\{t_1, t_2, ..., t_{T'}\\right\\}$ - the thresholds we're interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c186c5-b14d-4f85-984a-9104c1ecd6ce",
   "metadata": {},
   "source": [
    "Let's introduce cursors for the values we are interested in, and setup them values for the smallest rational threshold for a given problem:\n",
    "\n",
    "- $TP'=P=\\sum_{i=1}^n{y_i}$ - with the lowest threshold, all positive outcomes are truly classified as positive;\n",
    "- $FP'=N = n -\\sum_{i=1}^n{y_i}$ - with the lowest threshold, all negative outcomes are mistaken classified as positive;\n",
    "- $TN'=0, FN'=0$ - with the lowest threshold there are no values that classified as negative;\n",
    "- $i=1$ indexes $y_i$ and $s_i$;\n",
    "- $j=1$ indexes $t_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3024d9a6-4bc4-40eb-a6c7-9b1751f637b0",
   "metadata": {},
   "source": [
    "Now let's talk about the iterative procedure:\n",
    "\n",
    "At each step we compare $s_i$ and $t_j$:\n",
    "\n",
    "- If $s_i < t_j$:\n",
    "    - If $y_i=1$, then we add one to $FN'$ and subtract one from $TP'$;\n",
    "    - If $y_i=0$, then we add one to $TN'$ and subtract one from $FP'$;\n",
    "    - Come the the next observation - add one to $i$;\n",
    "- If $s_i \\geq t_j$:\n",
    "    - Add the current values of $TP', FP', TN', FN'$ to the confusion table row corresponding to $t_j$;\n",
    "    - Come to the next threshold, - add one to $j$;\n",
    "- The algorithm stops when we've circled all thresholds $j>T'$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c7b7a54-9b4e-4862-ab78-43311b40e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_table(\n",
    "    y_true,\n",
    "    y_score,\n",
    "    tresholds=None\n",
    "):\n",
    "    if tresholds is None:\n",
    "        tresholds = y_score\n",
    "\n",
    "    for t in tresholds:\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
