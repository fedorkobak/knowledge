{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f433428",
   "metadata": {},
   "source": [
    "# Assets bundles\n",
    "\n",
    "Asset bundles are a way to define the databricks project as a code. You can develop your project locally by following the typical Databricks project patterns, and deploy it to the platform using your CI/CD pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743dcdfd",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The bundle's configuration of the bundle is defined in the `databricks.yml` file. Consider the configuration options for the bundle. Check the official desriptions in the [Databricks Asset Bundle configuration](https://docs.databricks.com/aws/en/dev-tools/bundles/settings).\n",
    "\n",
    "- `bundle`: Specifies the Databricks environment and the bundle's basic proerpties.\n",
    "- `include`: allows to specify other configuration files. When configuration is relatively complex, it's convenient to keep some configurations in the other files.\n",
    "- [`scripts`](https://docs.databricks.com/aws/en/dev-tools/bundles/settings#scripts): Define a script to be run in the local environemt. But the configuration specific to the Databricks environemnt that corresponds to the bunlde will be applied. You can use a command like `databricks bundle run <name specified for the script>`. \n",
    "- [`sync`](https://docs.databricks.com/aws/en/dev-tools/bundles/settings#sync): Specifies which files will be pushed to the Databricks environemtn during `databricks bundle deploy`.\n",
    "- [`artifacts`](https://docs.databricks.com/aws/en/dev-tools/bundles/settings#artifacts): if your project is supposed to produce some output files during build (python whl, java jar, etc.) you have to specify this using `artifacts` attribute. The most important detail is that here is defined the script that generates the artifact; this script will be executed with the `databricks bundle build` command.\n",
    "- [`variables`](https://docs.databricks.com/aws/en/dev-tools/bundles/settings#variables): here, you can define variables that can be used in subtitutions.\n",
    "- [`resources`](https://docs.databricks.com/aws/en/dev-tools/bundles/settings#resources): specifies the Databricks [resources](https://docs.databricks.com/aws/en/dev-tools/bundles/resources#supported-resources). It is literaly the features of the Databricks used by the project lie: jobs, dashboards, clusters etc.\n",
    "- [`targets`](https://docs.databricks.com/aws/en/dev-tools/bundles/settings#targets): sometimes you need several setups for the same project. The most popular cases are `dev` and `production`. The `targets` allows to specify exactly this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235778b",
   "metadata": {},
   "source": [
    "### Artifacts\n",
    "\n",
    "Consider the simpliest possible `artifact` usage. The following code specifies the artifact as the `result` file.\n",
    "\n",
    "```yaml\n",
    "artifacts:\n",
    "  default:\n",
    "    build: echo \"this is new configuration\" > result\n",
    "```\n",
    "\n",
    "Running the command `databricks bundle build` will create the `result` file, which will then published in the Databricks environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5275087",
   "metadata": {},
   "source": [
    "## Substitutions\n",
    "\n",
    "With substitutions mechanisms you will be able to retrieve some values and substitute them to the config during `bundle build` or `bundle run`. As typcail you have to define your substitutions in the `${<variable name>}` format.\n",
    "\n",
    "For example the following pattern in the configuration:\n",
    "\n",
    "```yaml\n",
    "artifacts:\n",
    "  default:\n",
    "    build: echo \"This is ${bundle.name} bundle\" > ${bundle.target}\n",
    "```\n",
    "\n",
    "It will create a file with the same name as the bundle's target and save the string that containing the bundle name there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d3d13a",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Variables can be sepcified using following symtax:\n",
    "```yaml\n",
    "variables:\n",
    "  <var_name1>:\n",
    "    ...\n",
    "  <var_name2>:\n",
    "    ...\n",
    "```\n",
    "\n",
    "To pass a value to a variable, use the environment variable that follows the pattern `BUNDLE_VAR_<name of variable>`, databricks CLI commands executed from corresponding environement will automatically substitute this value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8638ca3b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "As exmaple consider the following configuration for variables:\n",
    "\n",
    "```yaml\n",
    "variables:\n",
    "  var1:\n",
    "    default: value1\n",
    "  var2:\n",
    "    default: value2\n",
    "\n",
    "artifacts:\n",
    "  default:\n",
    "    build: echo \"${var.var1} and ${var.var2}\" > result\n",
    "```\n",
    "\n",
    "The values `var1` and `var2` are defined in the bundle, and then used in the command that creates the file.\n",
    "\n",
    "After running the pipeline, the content of the `result` file content will contain the default values of the variables.\n",
    "\n",
    "```bash\n",
    "$ databricks bundle deploy\n",
    "\n",
    "Building default...\n",
    "Uploading bundle files to /Workspace/Users/fedor.kobak@innowise.com/.bundle/python_default/dev/files...\n",
    "Deploying resources...\n",
    "Updating deployment state...\n",
    "Deployment complete!\n",
    "\n",
    "$ cat result\n",
    "\n",
    "value1 and value2\n",
    "```\n",
    "\n",
    "You can specify the value by defining the environemnt variable `BUNDLE_VAR_<name of the variable>`:\n",
    "\n",
    "```bash\n",
    "$ BUNDLE_VAR_var1=\"hello\" databricks bundle deploy\n",
    "\n",
    "Building default...\n",
    "Uploading bundle files to /Workspace/Users/fedor.kobak@innowise.com/.bundle/python_default/dev/files...\n",
    "Deploying resources...\n",
    "Updating deployment state...\n",
    "Deployment complete!\n",
    "\n",
    "$ cat result\n",
    "\n",
    "hello and value2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab3429e",
   "metadata": {},
   "source": [
    "## Execute scripts\n",
    "\n",
    "To execute scripts with a bundle configuration cretedentials use `databricks bundle run [reference to the script]`. The script can be defined *inline* or specified in *databricks.yml*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aea9524",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For example if you try to access the `DATABRICKS_HOST` from the local raw python environment, you will receive an error:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafbd465",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "$python3 -c 'import os; print(os.environ[\"DATABRICKS_HOST\"])'\n",
    "Traceback (most recent call last):\n",
    "  File \"<string>\", line 1, in <module>\n",
    "    import os; print(os.environ[\"DATABRICKS_HOST\"])\n",
    "                     ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
    "  File \"<frozen os>\", line 717, in __getitem__\n",
    "KeyError: 'DATABRICKS_HOST'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ce6cc",
   "metadata": {},
   "source": [
    "But the same command wroks fine under the Databricks CLI.\n",
    "\n",
    "```bash\n",
    "$ databricks bundle run -- python3 -c 'import os; print(os.environ[\"DATABRICKS_HOST\"][:20])'\n",
    "https://dbc-da0651ae\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
