{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f433428",
   "metadata": {},
   "source": [
    "# Assets bundles\n",
    "\n",
    "Asset bundles are a way to define the databricks project as a code. You can develop your project locally by following the typical Databricks project patterns, and deploy it to the platform using your CI/CD pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743dcdfd",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The bundle's configuration of the bundle is defined in the `databricks.yml` file. Consider the configuration options for the bundle. Check the official desriptions in the [Databricks Asset Bundle configuration](https://docs.databricks.com/aws/en/dev-tools/bundles/settings).\n",
    "\n",
    "- `bundle`: Specifies the Databricks environment and the bundle's basic proerpties.\n",
    "- `include`: allows to specify other configuration files. When configuration is relatively complex, it's convenient to keep some configurations in the other files.\n",
    "- [`scripts`](https://docs.databricks.com/aws/en/dev-tools/bundles/settings#scripts): Define a script to be run in the local environemt. But the configuration specific to the Databricks environemnt that corresponds to the bunlde will be applied. You can use a command like `databricks bundle run <name specified for the script>`. \n",
    "- [`sync`](https://docs.databricks.com/aws/en/dev-tools/bundles/settings#sync): Specifies which files will be pushed to the Databricks environemtn during `databricks bundle deploy`.\n",
    "- [`artifacts`](https://docs.databricks.com/aws/en/dev-tools/bundles/settings#artifacts): if your project is supposed to produce some output files during build (python whl, java jar, etc.) you have to specify this using `artifacts` attribute. The most important detail is that here is defined the script that generates the artifact; this script will be executed with the `databricks bundle build` command.\n",
    "- [`variables`](https://docs.databricks.com/aws/en/dev-tools/bundles/settings#variables): here, you can define variables that can be used in subtitutions.\n",
    "- [`resources`](https://docs.databricks.com/aws/en/dev-tools/bundles/settings#resources): specifies the Databricks [resources](https://docs.databricks.com/aws/en/dev-tools/bundles/resources#supported-resources). It is literaly the features of the Databricks used by the project lie: jobs, dashboards, clusters etc.\n",
    "- [`targets`](https://docs.databricks.com/aws/en/dev-tools/bundles/settings#targets): sometimes you need several setups for the same project. The most popular cases are `dev` and `production`. The `targets` allows to specify exactly this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235778b",
   "metadata": {},
   "source": [
    "### Artifacts\n",
    "\n",
    "Consider the simpliest possible `artifact` usage. The following code specifies the artifact as the `result` file.\n",
    "\n",
    "```yaml\n",
    "artifacts:\n",
    "  default:\n",
    "    build: echo \"this is new configuration\" > result\n",
    "```\n",
    "\n",
    "Running the command `databricks bundle build` will create the `result` file, which will then published in the Databricks environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5275087",
   "metadata": {},
   "source": [
    "## Substitutions\n",
    "\n",
    "With substitutions mechanisms you will be able to retrieve some values and substitute them to the config during `bundle build` or `bundle run`. As typcail you have to define your substitutions in the `${<variable name>}` format. Check more about substitutions in the [Substitutions](https://docs.databricks.com/aws/en/dev-tools/bundles/variables) page of the official documentation.\n",
    "\n",
    "For example the following pattern in the configuration:\n",
    "\n",
    "```yaml\n",
    "artifacts:\n",
    "  default:\n",
    "    build: echo \"This is ${bundle.name} bundle\" > ${bundle.target}\n",
    "```\n",
    "\n",
    "It will create a file with the same name as the bundle's target and save the string that containing the bundle name there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d3d13a",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Variables can be sepcified using following symtax:\n",
    "```yaml\n",
    "variables:\n",
    "  <var_name1>:\n",
    "    ...\n",
    "  <var_name2>:\n",
    "    ...\n",
    "```\n",
    "\n",
    "To pass a value to a variable, use the environment variable that follows the pattern `BUNDLE_VAR_<name of variable>`, databricks CLI commands executed from corresponding environement will automatically substitute this value.\n",
    "\n",
    "For more check the [Custom variables](https://docs.databricks.com/aws/en/dev-tools/bundles/variables#custom-variables) section of the official documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8638ca3b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "As exmaple consider the following configuration for variables:\n",
    "\n",
    "```yaml\n",
    "variables:\n",
    "  var1:\n",
    "    default: value1\n",
    "  var2:\n",
    "    default: value2\n",
    "\n",
    "artifacts:\n",
    "  default:\n",
    "    build: echo \"${var.var1} and ${var.var2}\" > result\n",
    "```\n",
    "\n",
    "The values `var1` and `var2` are defined in the bundle, and then used in the command that creates the file.\n",
    "\n",
    "After running the pipeline, the content of the `result` file content will contain the default values of the variables.\n",
    "\n",
    "```bash\n",
    "$ databricks bundle deploy\n",
    "\n",
    "Building default...\n",
    "Uploading bundle files to /Workspace/Users/fedor.kobak@innowise.com/.bundle/python_default/dev/files...\n",
    "Deploying resources...\n",
    "Updating deployment state...\n",
    "Deployment complete!\n",
    "\n",
    "$ cat result\n",
    "\n",
    "value1 and value2\n",
    "```\n",
    "\n",
    "You can specify the value by defining the environemnt variable `BUNDLE_VAR_<name of the variable>`:\n",
    "\n",
    "```bash\n",
    "$ BUNDLE_VAR_var1=\"hello\" databricks bundle deploy\n",
    "\n",
    "Building default...\n",
    "Uploading bundle files to /Workspace/Users/fedor.kobak@innowise.com/.bundle/python_default/dev/files...\n",
    "Deploying resources...\n",
    "Updating deployment state...\n",
    "Deployment complete!\n",
    "\n",
    "$ cat result\n",
    "\n",
    "hello and value2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab3429e",
   "metadata": {},
   "source": [
    "## Execute scripts\n",
    "\n",
    "To execute scripts with a bundle configuration cretedentials use `databricks bundle run [reference to the script]`. The script can be defined *inline* or specified in *databricks.yml*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aea9524",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For example if you try to access the `DATABRICKS_HOST` from the local raw python environment, you will receive an error:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafbd465",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "$python3 -c 'import os; print(os.environ[\"DATABRICKS_HOST\"])'\n",
    "Traceback (most recent call last):\n",
    "  File \"<string>\", line 1, in <module>\n",
    "    import os; print(os.environ[\"DATABRICKS_HOST\"])\n",
    "                     ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
    "  File \"<frozen os>\", line 717, in __getitem__\n",
    "KeyError: 'DATABRICKS_HOST'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ce6cc",
   "metadata": {},
   "source": [
    "But the same command wroks fine under the Databricks CLI.\n",
    "\n",
    "```bash\n",
    "$ databricks bundle run -- python3 -c 'import os; print(os.environ[\"DATABRICKS_HOST\"][:20])'\n",
    "https://dbc-da0651ae\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5a25f",
   "metadata": {},
   "source": [
    "## Targets\n",
    "\n",
    "The `targets` allow you to define multiple behavior patterns for the bundle. For example, you may need to organize development and production environments.\n",
    "\n",
    "The target definition may have the following syntax:\n",
    "\n",
    "```yaml\n",
    "targets:\n",
    "  <tagtet1 name>:\n",
    "    <configuration>\n",
    "  <target2 name>:\n",
    "    <configuration>\n",
    "```\n",
    "\n",
    "The typical way to specify the target is to use `-t <target name>` option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929787de",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "As example consider the following configuration:\n",
    "\n",
    "```yaml\n",
    "artifacts:\n",
    "  default:\n",
    "    build: echo \"My target is ${bundle.target}\" > result\n",
    "\n",
    "targets:\n",
    "  dev:\n",
    "    mode: development\n",
    "    default: true\n",
    "  prod:\n",
    "    mode: development\n",
    "```\n",
    "\n",
    "The information about the used target was forwarded through the artifact. \n",
    "\n",
    "**Note.** Here, the `mode` for the `prod` target is set to the `development` value just to keep things simple, since the other options require additional configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd53b8b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "With the typical run system returns the `dev` as value for `bundle.target`.\n",
    "\n",
    "```bash\n",
    "$ databricks bundle deploy\n",
    "\n",
    "Building default...\n",
    "Uploading bundle files to /Workspace/Users/fedor.kobak@innowise.com/.bundle/python_default/dev/files...\n",
    "Deploying resources...\n",
    "Updating deployment state...\n",
    "Deployment complete!\n",
    "\n",
    "$ cat result\n",
    "\n",
    "My target is dev\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad9aa40",
   "metadata": {},
   "source": [
    "The following cell runs `databricks bundle deploy -t prod` which forces CLI to use `prod` target. \n",
    "\n",
    "```bash\n",
    "$ databricks bundle deploy -t prod\n",
    "\n",
    "Building default...\n",
    "Uploading bundle files to /Workspace/Users/fedor.kobak@innowise.com/.bundle/python_default/prod/files...\n",
    "Deploying resources...\n",
    "Updating deployment state...\n",
    "Deployment complete!\n",
    "\n",
    "$ cat result\n",
    "\n",
    "My target is prod\n",
    "```\n",
    "\n",
    "There is corresponding result in the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9231b51",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "In this section, we will discuss how to define resources in Databricks. A resource is a feature of Databricks that can be used by our application.\n",
    "\n",
    "They are defined using the following syntax:\n",
    "\n",
    "```yaml\n",
    "resources:\n",
    "    jobs:\n",
    "        <list of the jobs>\n",
    "    apps:\n",
    "        <list of the apps>\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1867f679",
   "metadata": {},
   "source": [
    "### Job\n",
    "\n",
    "Probably the most popular type of the resource in the Databricks. Job is an automated workflow defined in the Databricks.\n",
    "\n",
    "The most imporatant aspects of the job configuration are:\n",
    "\n",
    "- `name`: Defines the name of the job.\n",
    "- `tasks`: lists the tasks awailable for the job.\n",
    "- `shedule`: sets up the rules when task have to be executed.\n",
    "\n",
    "Check more in:\n",
    "\n",
    "- [Job](https://docs.databricks.com/aws/en/dev-tools/bundles/resources#job) description for keys of assests bundles.\n",
    "- [Job configuration](https://docs.databricks.com/aws/en/dev-tools/bundles/examples#job) in bundle configuration examples.\n",
    "- [Task settings](https://docs.databricks.com/aws/en/dev-tools/bundles/job-task-types#task-settings) lists different types of tasks and their configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56b6dee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The most minimalistic definition of the job may take form:\n",
    "\n",
    "```yaml\n",
    "resources:\n",
    "  jobs:\n",
    "    job1:\n",
    "      name: job1\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
