{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model\n",
    "\n",
    "Saving and loading PyTorch models is crucial because any model you build needs to be transferred and deployed in some way. Check the [official tutorial](https://pytorch.org/tutorials/beginner/saving_loading_models.html). Here, we'll experiment with the options from the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import itertools\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State dict\n",
    "\n",
    "The classical method to save and load a model's state dictionary follows these steps:\n",
    "\n",
    "- Retrieve the model's state dictionary with `nn.Module.state_dict()`.\n",
    "- Save the state dictionary with `torch.save`.\n",
    "- Load the state dictionary with `torch.load`.\n",
    "- Load the weights into the model using `nn.Module.load_state_dict()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In the following cell, we created a simple model and initialized it with a constant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[3., 3., 3.],\n",
       "                      [3., 3., 3.],\n",
       "                      [3., 3., 3.]])),\n",
       "             ('0.bias', tensor([3., 3., 3.])),\n",
       "             ('1.weight',\n",
       "              tensor([[3., 3., 3.],\n",
       "                      [3., 3., 3.],\n",
       "                      [3., 3., 3.]])),\n",
       "             ('1.bias', tensor([3., 3., 3.]))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 3),\n",
    "    nn.Linear(3, 3)\n",
    ")\n",
    "for p in model.parameters():\n",
    "    nn.init.constant_(p, 3)\n",
    "\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using `torch.save`, we save the state dictionary and discard the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(obj=model.state_dict(), f=Path(\"/tmp\")/\"my_model\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with `torch.load`, we load the state dictionaryâ€”since all values were constant during saving, they remain as 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[3., 3., 3.],\n",
       "                      [3., 3., 3.],\n",
       "                      [3., 3., 3.]])),\n",
       "             ('0.bias', tensor([3., 3., 3.])),\n",
       "             ('1.weight',\n",
       "              tensor([[3., 3., 3.],\n",
       "                      [3., 3., 3.],\n",
       "                      [3., 3., 3.]])),\n",
       "             ('1.bias', tensor([3., 3., 3.]))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_dict = torch.load(Path(\"/tmp\")/\"my_model\", weights_only=False)\n",
    "state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By recreating the exact same model and loading the previously saved state dictionary into it, you can fully recreate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 3),\n",
    "    nn.Linear(3, 3)\n",
    ")\n",
    "\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfully executed `nn.load_state_dict` returns a special string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save entire model\n",
    "\n",
    "By passing the entire model to the `torch.save` function, you'll save a serialized Torch model. Then, with just one line of code, you can restore the model using the `torch.load` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following cell demonstrates creating a model, initializing its weights with a constant, and saving this model to disk by passing it as `obj` to the `torch.save` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 3),\n",
    "    nn.Linear(3, 3)\n",
    ")\n",
    "for p in model.parameters():\n",
    "    nn.init.constant_(p, 3)\n",
    "\n",
    "torch.save(model, Path(\"/tmp\")/\"model.pht\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `torch.load`, the model can be restored. The following cell shows that the loaded model has weights identical to those initialized before saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[3., 3., 3.],\n",
       "                      [3., 3., 3.],\n",
       "                      [3., 3., 3.]])),\n",
       "             ('0.bias', tensor([3., 3., 3.])),\n",
       "             ('1.weight',\n",
       "              tensor([[3., 3., 3.],\n",
       "                      [3., 3., 3.],\n",
       "                      [3., 3., 3.]])),\n",
       "             ('1.bias', tensor([3., 3., 3.]))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(Path(\"/tmp\")/\"model.pht\", weights_only=False).state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving group\n",
    "\n",
    "A typical case where this approach requires two `torch` objects, such as a generator and discriminator in a GAN, is straightforward. It's not a problem to save a batch of models grouped in any Python collection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "As an example, consider two linear layers that we want to save as a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = nn.Linear(3, 3)\n",
    "val2 = nn.Linear(3, 3)\n",
    "\n",
    "for p in itertools.chain(val1.parameters(), val2.parameters()):\n",
    "    nn.init.constant_(p, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll save models as dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    obj={\"val1\": val1, \"val2\": val2},\n",
    "    f=Path(\"/tmp\")/\"model.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are no problems to load that dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val1': Linear(in_features=3, out_features=3, bias=True),\n",
       " 'val2': Linear(in_features=3, out_features=3, bias=True)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = torch.load(Path(\"/tmp\")/\"model.pth\", weights_only=False)\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be sure, let's check that the extracted model has weights just as we initialized them before saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[3., 3., 3.],\n",
       "                      [3., 3., 3.],\n",
       "                      [3., 3., 3.]])),\n",
       "             ('bias', tensor([3., 3., 3.]))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[\"val1\"].state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same trick will work with tuples as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Linear(in_features=3, out_features=3, bias=True),\n",
       " Linear(in_features=3, out_features=3, bias=True))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(obj=(val1, val2), f=Path(\"/tmp\")/\"model.pth\")\n",
    "torch.load(Path(\"/tmp\")/\"model.pth\", weights_only=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
