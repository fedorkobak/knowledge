{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd07a3cd-0d99-4461-b8ed-87b42d90f9e5",
   "metadata": {},
   "source": [
    "# Selfmade memory based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efcffa71-b2e6-443d-9b83-a1aea7b6108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from scipy.spatial.distance import (\n",
    "    correlation as orig_correlation,\n",
    "    cosine as orig_cosine\n",
    ")\n",
    "from surprise import KNNWithMeans, Dataset, Reader\n",
    "from ranx import Qrels, Run, evaluate\n",
    "\n",
    "from typing import Union, Callable\n",
    "\n",
    "from IPython.display import HTML\n",
    "header_pattern = \"<text style='font-size:20px'>{}</text>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9cc818-82b1-416e-8165-35464cb59575",
   "metadata": {},
   "source": [
    "## Task generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801a39a2-f654-448f-aa2d-d7a047f97d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  7,  0,  3,  7,  5,  5,  0,  3,  4,  3,  4,  5,  2,  0,  2,\n",
       "         1,  1,  8,  3,  2,  6,  1,  6,  4,  6,  1,  1,  5,  1,  1,  4,\n",
       "         2,  2,  8,  8,  4,  4,  0,  8,  4,  6,  4,  7,  5,  5,  1,  4,\n",
       "         5,  1],\n",
       "       [ 9, 10,  6, 10,  7,  5, 10,  9,  7,  8,  5, 10, 10,  6, 10,  5,\n",
       "         3,  3,  4,  4,  5, 10,  7,  4, 10,  6,  4,  9,  5,  9,  6,  9,\n",
       "        10,  7,  7,  3,  6,  6,  7, 10,  6,  6,  9,  6,  5,  9,  7,  4,\n",
       "        10,  5],\n",
       "       [ 4,  6,  0,  3,  5,  5,  4,  0,  1,  3,  1,  3,  4,  0,  0,  2,\n",
       "         0,  1,  7,  1,  0,  5,  0,  5,  3,  4,  0,  0,  4,  0,  1,  3,\n",
       "         0,  3,  6,  7,  4,  3,  0,  7,  3,  5,  3,  6,  4,  5,  1,  2,\n",
       "         4,  0],\n",
       "       [ 5,  6,  1,  3,  6,  7,  5,  1,  3,  4,  3,  4,  5,  1,  0,  2,\n",
       "         1,  1,  7,  3,  2,  6,  1,  6,  4,  5,  1,  1,  5,  1,  1,  5,\n",
       "         2,  3,  7,  7,  5,  4,  1,  7,  4,  5,  4,  7,  5,  5,  0,  4,\n",
       "         6,  1],\n",
       "       [ 8,  8,  5, 10,  5,  4,  8,  7,  6,  7,  4,  9, 10,  5,  9,  4,\n",
       "         3,  2,  3,  2,  4, 10,  6,  4,  8,  4,  3,  8,  4,  8,  5,  8,\n",
       "         9,  6,  6,  2,  5,  5,  6, 10,  5,  5,  8,  5,  4,  9,  7,  2,\n",
       "        10,  3],\n",
       "       [ 7,  4,  7, 10,  4,  9,  7,  8,  5,  6,  5,  3,  4,  7,  9,  8,\n",
       "         6,  5, 10,  8,  9, 10,  7,  9,  7,  3,  9,  5,  6,  7,  6, 10,\n",
       "         4,  3,  9,  9,  6,  7,  3,  6,  4,  9,  3,  5,  7,  6,  8, 10,\n",
       "         6,  3],\n",
       "       [ 4,  2,  4,  6,  1,  7,  4,  5,  1,  4,  2,  0,  0,  3,  5,  4,\n",
       "         3,  1,  6,  4,  6,  7,  5,  6,  5,  1,  6,  1,  4,  4,  3,  6,\n",
       "         2,  0,  6,  6,  4,  3,  0,  2,  1,  6,  1,  1,  5,  3,  6,  6,\n",
       "         3,  1],\n",
       "       [ 2,  0,  6,  0,  2,  7,  7,  3,  6,  1,  3,  7,  3,  4,  0,  2,\n",
       "         0,  1,  2,  6,  0,  2,  2,  4,  1,  0,  6,  5,  6,  2,  4,  3,\n",
       "         3,  1,  1,  0,  1,  1,  4,  4,  3,  1,  0,  6,  1,  2,  7,  3,\n",
       "         1,  3],\n",
       "       [ 7,  6,  3,  6,  3,  2,  6,  6,  4,  5,  2,  7,  8,  3,  7,  2,\n",
       "         0,  0,  2,  1,  2,  8,  3,  0,  7,  3,  0,  7,  2,  6,  3,  6,\n",
       "         6,  5,  5,  1,  3,  3,  4,  7,  3,  3,  6,  4,  1,  7,  5,  1,\n",
       "         9,  2],\n",
       "       [ 6,  8,  2,  5,  8,  7,  4,  2,  4,  6,  4,  5,  6,  3,  1,  5,\n",
       "         2,  2,  8,  4,  3,  7,  2,  7,  4,  5,  2,  3,  7,  1,  4,  6,\n",
       "         3,  4,  7,  8,  5,  5,  1,  9,  6,  7,  6,  8,  5,  7,  2,  4,\n",
       "         6,  2]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "r_width = 50\n",
    "r_height = 500\n",
    "\n",
    "R, group = make_blobs(\n",
    "    n_samples=r_height,\n",
    "    n_features=r_width,\n",
    "    centers=5,\n",
    "    random_state=10\n",
    ")\n",
    "R = np.round((R-R.min())*10/(R.max()-R.min())).astype(int)\n",
    "\n",
    "# add bias for each object\n",
    "bias = np.random.randint(-2,3, [R.shape[0], 1])\n",
    "R = R + bias\n",
    "# sometimes bias can lead to ratings\n",
    "R = np.where(R<0, 0, R)\n",
    "R = np.where(R>10, 10, R)\n",
    "R[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add750b8-71c9-4920-bf4b-4959fbb600b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>relevant</th>\n",
       "      <th>random_predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object</th>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.397484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.270233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.598170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.709187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <th>24</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.754604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rank  relevant  random_predict\n",
       "object item                                \n",
       "440    47       2         0        0.975159\n",
       "283    2        3         0        0.229527\n",
       "396    33       0         0        0.397484\n",
       "14     6        5         0        0.270233\n",
       "198    15       5         0        0.598170\n",
       "20     33       1         0        0.709187\n",
       "422    24       9         1        0.814357\n",
       "267    4        2         0        0.505066\n",
       "408    25       0         0        0.244018\n",
       "99     44       3         0        0.754604"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "R_frame = pd.Series(\n",
    "    R.ravel(),\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            (j,i)\n",
    "            for j in np.arange(R.shape[0]) \n",
    "            for i in np.arange(R.shape[1])\n",
    "        ],\n",
    "        names = [\"object\", \"item\"]\n",
    "    ),\n",
    "    name = \"rank\"\n",
    ").to_frame()\n",
    "\n",
    "R_frame[\"relevant\"] = (R_frame[\"rank\"] > 5).astype(\"int\")\n",
    "R_frame[\"random_predict\"] = np.random.rand(R_frame.shape[0])\n",
    "R_frame.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80746516-5d9d-4346-9e1d-70ed1f5bde68",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_fr_train, R_fr_test = train_test_split(\n",
    "    R_frame, \n",
    "    train_size=0.8, \n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "# preparing test/train samples representation as\n",
    "# as user/item matrix\n",
    "R_mat_train = pd.DataFrame(\n",
    "    R_fr_train[\"rank\"].unstack(),\n",
    "    columns = R_frame.index.get_level_values(1).unique()\n",
    ")\n",
    "R_mat_test = pd.DataFrame(\n",
    "    R_fr_test[\"rank\"].unstack(),\n",
    "    columns = R_frame.index.get_level_values(1).unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5025db-e22b-4460-adc2-e102238172f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision@3': 0.3713333333333333,\n",
       " 'recall@3': 0.3102086885336885,\n",
       " 'ndcg@3': 0.4036283432588485}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    \"precision@3\", \n",
    "    \"recall@3\", \n",
    "    \"ndcg@3\"\n",
    "]\n",
    "R_fr_test[[\"object_str\", \"item_str\"]] = \\\n",
    "    R_fr_test.index.to_frame()[[\"object\", \"item\"]].astype(\"str\")\n",
    "\n",
    "qrels = Qrels.from_df(\n",
    "    df=R_fr_test.reset_index(),\n",
    "    q_id_col=\"object_str\", \n",
    "    doc_id_col=\"item_str\",\n",
    "    score_col=\"relevant\"\n",
    ")\n",
    "\n",
    "random_run = Run.from_df(\n",
    "    df=R_fr_test.reset_index(),\n",
    "    q_id_col=\"object_str\",\n",
    "    doc_id_col=\"item_str\",\n",
    "    score_col=\"random_predict\"\n",
    ")\n",
    "\n",
    "evaluate(\n",
    "    qrels, \n",
    "    random_run, \n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0bab9b-e3d6-41e6-9b3a-5ae3d46f349e",
   "metadata": {},
   "source": [
    "## surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf75fe5-b408-45db-83dc-fcf84f73db4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(\n",
    "    rating_scale=(\n",
    "        R.min().min(), R.max().max()\n",
    "    )\n",
    ")\n",
    "train_set = Dataset.load_from_df(\n",
    "    df=R_fr_train[\"rank\"].reset_index(), \n",
    "    reader=reader\n",
    ").build_full_trainset()\n",
    "algo = KNNWithMeans().fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1885f73-f692-45c6-bbc0-11ece768b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_fr_test[\"surpr_predict\"] = [\n",
    "    algo.predict(uid=uid, iid=iid).est \n",
    "    for uid, iid in R_fr_test.index\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "377add8e-cc46-4dff-ad3e-2b9dda5cd967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.414035940075337"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(\n",
    "    R_fr_test[\"rank\"],\n",
    "    R_fr_test[\"surpr_predict\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4358d656-0f38-4d26-8155-4577beb2dc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision@3': 0.7666666666666667,\n",
       " 'recall@3': 0.7254612137862139,\n",
       " 'ndcg@3': 0.9273804112635808}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_run = Run.from_df(\n",
    "    df=R_fr_test.reset_index(),\n",
    "    q_id_col=\"object_str\",\n",
    "    doc_id_col=\"item_str\",\n",
    "    score_col=\"surpr_predict\"\n",
    ")\n",
    "evaluate(\n",
    "    qrels, \n",
    "    surprise_run, \n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd51255-db9c-4abd-aaf0-02205cff7a8c",
   "metadata": {},
   "source": [
    "## Selfmade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1407bce-c8fd-4e0c-b845-69724457fbf0",
   "metadata": {},
   "source": [
    "### Similarity measure\n",
    "\n",
    "**Note** Many sources use difference instead of similarity, but similarity is the inverse of difference, so you can search not for items that have the smallest difference, but for items that have the strongest similarity.\n",
    "\n",
    "We need a method to estimate how close the objects are to each other. The following cell defines such a function - it implements Pearson's correlation coefficient, which can solve some problems related to the RecSys domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75e15af4-4a22-4817-9958-f362c5a1d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(\n",
    "        a : np.ndarray,\n",
    "        b : np.ndarray\n",
    "        ) -> float:\n",
    "    '''\n",
    "    Pearson correlation coefficient modified\n",
    "    for our requirements. In particular, empty \n",
    "    handling\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : (N,) np.ndarray\n",
    "        input array;\n",
    "    b : (N, ) np.ndarray\n",
    "        input array;\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    out : float\n",
    "        The Pearson correlation coefficient is \n",
    "        computed using only the common items \n",
    "        for both arrays. If it's not possible \n",
    "        to compute the coefficient, it returns 0, \n",
    "        indicating neutral similarity.\n",
    "        The coefficient is a number ranging from -1 to 1.\n",
    "    '''\n",
    "    cond = ~(np.isnan(a) | np.isnan(b))\n",
    "    # in case if there are only two\n",
    "    # observations it's impossible\n",
    "    # to compute coorrelation coeficient\n",
    "    if sum(cond) <=1:\n",
    "        return 0.\n",
    "\n",
    "    sub_a = a[cond]\n",
    "    sub_b = b[cond]\n",
    "    \n",
    "    variation_a = (sub_a - sub_a.mean())\n",
    "    variation_b = (sub_b - sub_b.mean())\n",
    "\n",
    "    # to compute pirson correlation coefficient\n",
    "    # all variables should have some variation\n",
    "    if (variation_a==0).all() or (variation_b==0).all():\n",
    "        return 0.\n",
    "    \n",
    "    cov = (variation_a*variation_b).sum()\n",
    "    return cov/np.sqrt(\n",
    "        (variation_a**2).sum()*(variation_b**2).sum()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a5e32-0863-4434-a0e4-27ef78904183",
   "metadata": {},
   "source": [
    "Here are some cases where this function has been used and the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d0eab8f-2c6e-49ff-92aa-6f5b7801c71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correlation - 1.0\n",
      "Total correlation with empty - 1.0\n",
      "Constant variable - 0.0\n",
      "Not enough common elements - 0.0\n"
     ]
    }
   ],
   "source": [
    "result = correlation(\n",
    "    np.array([0,1,2,3,4]),\n",
    "    np.array([5,6,7,8,9])\n",
    ")\n",
    "print(\"Total correlation -\", result)\n",
    "result = correlation(\n",
    "    np.array([np.NaN, 1, 2, np.NaN]),\n",
    "    np.array([10, 10, 20, np.NaN])\n",
    ")\n",
    "print(\"Total correlation with empty -\", result)\n",
    "result = correlation(\n",
    "    np.array([1,1,1,1]),\n",
    "    np.array([3,2,1,2])\n",
    ")\n",
    "print(\"Constant variable -\", result)\n",
    "result = correlation(\n",
    "    np.array([np.NaN, 2, np.NaN, 3]),\n",
    "    np.array([1, np.NaN, 10, np.NaN])\n",
    ")\n",
    "print(\"Not enough common elements -\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed269af5-fe23-488c-97df-e76e4bc339c6",
   "metadata": {},
   "source": [
    "### Prediction function\n",
    "\n",
    "We need methods to create predictions based on results of the previous steps. The following cell realises the classical formula for generating predicsts based on collaboration:\n",
    "\n",
    "$$\\frac{(\\sum_{i}r_{ij}-\\overline{r_i})sim_i}{\\sum_i{|sim_i|}}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $r_{ij}$  - relevance of the $j$-th item for the $i$-th user of the collaboration.\n",
    "- $\\overline{r_i}$ - average relevance of the $i$-th user.\n",
    "- $sim_i$ similarity of the $i$-th object of the collaboration to the object for which we are making a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d79151fa-223e-4b92-bbf2-0f7f86bc6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_prediction(\n",
    "        collaboration : np.ndarray,\n",
    "        similarities : np.ndarray\n",
    "        ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Basic function for creating prediction.\n",
    "    Uses formula\n",
    "    \\frac{(\\sum_{i}x_{ij}-\\overline{x_i})sim_i}{\\sum_i{|sim_i|}}.\n",
    "    \n",
    "    items that have no observable preferences \n",
    "    for any user in the collation will simply \n",
    "    be omitted from the result;.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    collaboration : np.ndarray (\n",
    "        <users number>, \n",
    "        <games number>\n",
    "        )\n",
    "        relevances matrix for collaboration;\n",
    "    relevances : np.ndarray (<items number>)\n",
    "        relavences of the user under consdieration;\n",
    "    similarities : np.ndarray (<observations number>)\n",
    "        similarities of the users from \n",
    "        collaboration to user under consideration.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : np.ndarray(<items number>)\n",
    "        scores of the items under consideration.\n",
    "    \"\"\"\n",
    "    users_mean = np.nanmean(collaboration, axis=1, keepdims=1)\n",
    "    weighed_collab = (collaboration - users_mean)*similarities[:, np.newaxis]\n",
    "    res = np.nansum(weighed_collab, axis=0)/np.abs(similarities).sum()\n",
    "    \n",
    "    # items that have not been played by \n",
    "    # any of the users should have nan\n",
    "    is_empty = np.isnan(collaboration).all(axis=0)\n",
    "    res[is_empty] = np.NaN\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9379293-01ef-412e-bc38-327abf705158",
   "metadata": {},
   "source": [
    "Consider how it works.\n",
    "\n",
    "We will consider collaborations that have a matrix of relevance:\n",
    "\n",
    "$$P_u=\\left( \\begin{array} \\\\\n",
    "2,7,9,- \\\\\n",
    "0,-,3,-\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "And estimations of similarity:\n",
    "\n",
    "$$\n",
    "\\overline{sim} = \n",
    "\\left( \n",
    "\\begin{array}\\\\\n",
    "0.7, \\\\\n",
    "0.6\n",
    "\\end{array} \n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87af2e3-72b7-42c0-befd-01b911b54ad9",
   "metadata": {},
   "source": [
    "The average relevance of the users in the collaboration will take shape:\n",
    "\n",
    "$$\\overline{P_u}= \n",
    "\\left(\n",
    "\\begin{array}\\\\\n",
    "6\\\\\n",
    "1.5\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Sum of similarities:\n",
    "\n",
    "$$\\sum_i \\left|sim_i\\right|=0.7+0.6=1.3$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e999c5d1-3fbb-495a-bde6-3cb63015770b",
   "metadata": {},
   "source": [
    "So we finally can compute estimated relevances for user with this collaboration:\n",
    "\n",
    "$$\\left( \\frac{(2-6)0.7 + (0-1.5)0.6}{1.3}, \\frac{(7-6)0.7}{1.3}, \\frac{(9-6)0.7 + (3-1.5)0.6}{1.5}, - \\right)=$$\n",
    "$$=\\left(-2.8461,0.5384,-2.3077, - \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a4355a-2cee-466a-b9b6-185e44027e23",
   "metadata": {},
   "source": [
    "Now let's try to apply it to the same numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "413ba75c-cde2-4d7c-98e8-221ae9119dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.84615385,  0.53846154,  2.30769231,         nan])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collaboration = np.array([\n",
    "    [2,7,9, np.NaN],\n",
    "    [0,np.NaN,3, np.NaN]\n",
    "])\n",
    "similarities = np.array([0.7,0.6])\n",
    "\n",
    "basic_prediction(\n",
    "    collaboration=collaboration,\n",
    "    similarities=similarities\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa1dcf1-e48e-49e5-80a5-ab438075e17d",
   "metadata": {},
   "source": [
    "### Collaborative filter\n",
    "\n",
    "Finally, consider a class that implements such an algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9a73934-efc6-43fd-b113-702cdf6d50f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFilter:\n",
    "    \"\"\"\n",
    "    Сlass implements collaborative filtering based \n",
    "    on nearest neighbours.It uses information about \n",
    "    previous relevancies, we will call them \n",
    "    \"fit relevancies\", to estimate relevancies for \n",
    "    some new users, we will call them \"predict relevancies\".\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    similarity : Callable[[np.ndarray, np.ndarray], float]\n",
    "        Similarity calculation function\n",
    "        to find collaboration;\n",
    "    prediction : Callable[[np.ndarray, np.ndarray]\n",
    "        Function that predicts scores for all items\n",
    "        available in train sample based on passed\n",
    "        collaboration;\n",
    "    sim_threshold : float = -np.inf\n",
    "        Tresholld that will be used. Objects that have\n",
    "        distance value is higher are not allowed to pass;\n",
    "    n_nearest : int = 1000\n",
    "        Maximum number of rows that can be\n",
    "        included to the collaboration.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            similarity : Callable[[np.ndarray, np.ndarray], float] = correlation,\n",
    "            prediction : Callable[[np.ndarray, np.ndarray], float] = basic_prediction,\n",
    "            sim_threshold : float = -np.inf,\n",
    "            n_nearest : int = 1000\n",
    "            ):\n",
    "        self.similarity = similarity\n",
    "        self.prediction = prediction\n",
    "        self.sim_threshold = sim_threshold\n",
    "        self.n_nearest = n_nearest\n",
    "        \n",
    "    \n",
    "    def fit(self, X:Union[np.ndarray, pd.DataFrame]):\n",
    "        '''\n",
    "        Remember the train sample.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray(\n",
    "            <users number>,\n",
    "            <items number>\n",
    "        )\n",
    "            Relevances matrix;\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : CollaborativeFilter\n",
    "            Model instance.\n",
    "        '''\n",
    "        self.X=np.array(X)\n",
    "        return self\n",
    "\n",
    "    def get_similarities(self, X:np.ndarray):\n",
    "        '''\n",
    "        Get similarities to the object for the \n",
    "        selected set of rows. Here, we use \n",
    "        information about the relevances of \n",
    "        users from the training sample and users \n",
    "        for which we need to create predictions. \n",
    "        We will use the terms \"fit users\" and \"predict users\" \n",
    "        accordingly for these terms.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray (\n",
    "            <users numer>, \n",
    "            <number of items>)\n",
    "            Fit relevancies;\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : np.ndarray (\n",
    "            <users number in fit relevacies>, \n",
    "            <users number in predict relevacies>\n",
    "            )\n",
    "            array where each element is similarity\n",
    "            between i-th fit user and j-th predict\n",
    "            user.\n",
    "        '''\n",
    "        return np.apply_along_axis(\n",
    "            func1d=lambda history_row: np.apply_along_axis(\n",
    "                func1d=(\n",
    "                    lambda predict_row: \n",
    "                    self.similarity(history_row, predict_row)\n",
    "                ),\n",
    "                arr=X, axis=1\n",
    "            ), \n",
    "            arr=self.X, axis=1\n",
    "        )\n",
    "    \n",
    "\n",
    "    def get_collaborations(self, X:np.ndarray):\n",
    "        '''\n",
    "        Get collaboration for given set predict \n",
    "        relevancies.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array (<users number>, <items number>)\n",
    "            Predict relevancies.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        out : np.array\n",
    "        '''\n",
    "        similarities = self.get_similarities(X=X)\n",
    "        # перебираем столбики с похожестями пользователей\n",
    "        # для которых ведется предсказание и достаем нужные \n",
    "        # коллаборации\n",
    "        return np.apply_along_axis(\n",
    "            func1d=lambda user_sim: (\n",
    "                self.X[user_sim>self.sim_threshold,:][:self.n_nearest,:]\n",
    "            ),\n",
    "            axis=0, arr=similarities\n",
    "        )\n",
    "\n",
    "\n",
    "    def predict(self, X:np.ndarray)->np.ndarray:\n",
    "        '''\n",
    "        Получить предсказания для \n",
    "        пользователей с заданными предпочтениями\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray (<количетсво пользователей>, <количество игр>)\n",
    "            матрица, которая описывает предпочтения\n",
    "            пользователей для которых надо сформировать\n",
    "            предсказание;\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        out : np.ndarray\n",
    "            np.ndarray (<количество полльзователей>, <количество игр>)\n",
    "            предсказания для заданных пользователей.\n",
    "        '''\n",
    "        if X.shape[1] != self.X.shape[1]:\n",
    "            raise ValueError(\n",
    "                \"Количества игр в обучающем наборе данных \"\n",
    "                \"и наборе для предсказания не совпадают.\"\n",
    "                )\n",
    "        \n",
    "        similarities = self.get_similarities(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7561cdaa-e138-4a79-a006-b5450e9ad282",
   "metadata": {},
   "source": [
    "#### Get similarities\n",
    "\n",
    "Each row from the training must be compared with all prediction row via similarity fuinction passed to the constructor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a95dc1-2ebb-4d2c-8ef5-aa9fa63a7dcf",
   "metadata": {},
   "source": [
    "Here's an example that does only element-wise concatenation instead of similarity - so we can see that we'll have all combinations of raws in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a1c0fa1-efad-423b-bbd8-0e4bafb596b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<text style='font-size:20px'>Raw output</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([['11h_11p|12h_12p', '11h_21p|12h_22p'],\n",
       "       ['21h_11p|22h_12p', '21h_21p|22h_22p'],\n",
       "       ['31h_11p|32h_12p', '31h_21p|32h_22p']], dtype='<U15')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style='font-size:20px'>Interpretation</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history 1, predictions 1\n",
      "11h_11p|12h_12p\n",
      "history 1, predictions 2\n",
      "11h_21p|12h_22p\n",
      "history 2, predictions 1\n",
      "21h_11p|22h_12p\n",
      "history 2, predictions 2\n",
      "21h_21p|22h_22p\n",
      "history 3, predictions 1\n",
      "31h_11p|32h_12p\n",
      "history 3, predictions 2\n",
      "31h_21p|32h_22p\n"
     ]
    }
   ],
   "source": [
    "# history observations\n",
    "history = np.array([\n",
    "    [\"11h\", \"12h\"],\n",
    "    [\"21h\", \"22h\"],\n",
    "    [\"31h\", \"32h\"]\n",
    "])\n",
    "# observations that we'll\n",
    "# use for predicitons\n",
    "predict = np.array([\n",
    "    [\"11p\", \"12p\"],\n",
    "    [\"21p\", \"22p\"]\n",
    "])\n",
    "\n",
    "cf = CollaborativeFilter(\n",
    "    similarity=lambda a,b: \"|\".join([a+\"_\"+b for a,b in zip(a,b)])\n",
    ")\n",
    "cf.fit(history)\n",
    "ans = cf.get_similarities(predict)\n",
    "\n",
    "display(HTML(header_pattern.format(\"Raw output\")))\n",
    "display(ans)\n",
    "\n",
    "display(HTML(header_pattern.format(\"Interpretation\")))\n",
    "for hist_i, hist in enumerate(ans):\n",
    "    for pred_i, pred in enumerate(hist):\n",
    "        print(f\"history {hist_i + 1}, predictions {pred_i + 1}\")\n",
    "        print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffd5d1-f288-45aa-9699-cd0a1ce3da45",
   "metadata": {},
   "source": [
    "So as a result we'll have the matrix $[sim_{ij}]$ similarity of the $i$-th fit user to the $j$-th prediction user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca657749-0c65-43ea-b711-cb6fcdbfbc57",
   "metadata": {},
   "source": [
    "### Get collaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ad23bdf-eb24-4f40-a603-5005bec8e39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.58829171,  0.08276059, -0.4258411 , ...,  0.53354002,\n",
       "        -0.45328433, -0.91364277],\n",
       "       [-0.21633961, -0.13245324, -0.72969394, ...,  0.97336648,\n",
       "        -0.43185521, -0.77991383],\n",
       "       [-0.66560255, -0.01863067, -0.2192645 , ...,  0.23918729,\n",
       "        -0.48696592, -0.38150302],\n",
       "       ...,\n",
       "       [-0.3899503 , -0.36707203, -0.44233627, ...,  0.97574887,\n",
       "        -0.11202768, -0.64677417],\n",
       "       [ 0.00776151, -0.74330462,  0.92450033, ...,  0.40421051,\n",
       "         0.95807103,  0.93155164],\n",
       "       [ 0.04428005, -0.97302555,  0.91855865, ...,  0.27027781,\n",
       "         0.9647146 ,  0.91132238]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
