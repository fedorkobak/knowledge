{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01d4f65-fdbe-4546-9168-891beba49c89",
   "metadata": {},
   "source": [
    "# Confusion matrix\n",
    "\n",
    "Inaccuracy matrix is a very important concept for evaluating classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b82584-9b9d-4554-8334-6154d4f99dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6db2d0-a4e0-44a3-95dc-584a393d9033",
   "metadata": {},
   "source": [
    "## Example task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2636ffa5-f1cf-41fe-9564-3b5e66223952",
   "metadata": {},
   "source": [
    "Consider a binary classification problem. We have two classes, Positive and Negative.\n",
    "\n",
    "Let be:\n",
    "\n",
    "- $P$ is the number of positive observations in the sample;\n",
    "- $N$ is the number of negative observations in the sample.\n",
    "\n",
    "The following code generates possible outputs of the classification task:\n",
    "\n",
    "- $y$ - real targets, 0 corresponds to negative 1 to positive;\n",
    "- $t_i$ - score that indicates the probability that a particular object belongs to the positive class;\n",
    "- $\\hat{y}=\\left[t_i>T\\right]$ - final predicts that depends which depend on the cut-off threshold - $T$. You can choose different $T$ and it will fill the confusion matrix - it's discussed in the following sections. For the example below, $T$ is the mean of $t_i=\\overline{1,n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f93e88b-c423-4a05-b4de-497db68f33c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$$y$$</th>\n",
       "      <th>$$t_i$$</th>\n",
       "      <th>$$\\hat{y}$$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.644251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.162201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.624533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.033877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.012203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   $$y$$   $$t_i$$  $$\\hat{y}$$\n",
       "0      0 -0.644251            0\n",
       "1      0 -1.162201            0\n",
       "2      1 -0.624533            0\n",
       "3      1  2.033877            1\n",
       "4      1 -1.012203            0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, y = make_classification(\n",
    "    n_features=1,\n",
    "    n_informative=1,\n",
    "    n_redundant=0,\n",
    "    n_repeated=0,\n",
    "    n_clusters_per_class=1,\n",
    "    flip_y=0.3,\n",
    "    random_state=2\n",
    ")\n",
    "scores = scores.ravel()\n",
    "pd.DataFrame({\n",
    "    \"$$y$$\" : y, \n",
    "    \"$$t_i$$\" : scores, \n",
    "    \"$$\\hat{y}$$\":(scores>np.mean(scores)).astype(\"int\")\n",
    "}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12396198-f3de-4139-b424-36b2e9debedb",
   "metadata": {},
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3fc5f-2b74-4f1c-ac0b-8f1e621b5dcb",
   "metadata": {},
   "source": [
    "Now, suppose we have formed some classifier. We have the following groups of observations.\n",
    "\n",
    "- *True positive*: observations that were positive in the sample and we correctly predicted them as positive. We will denote their number as $TP$;\n",
    "- *True negative*: observations that were negative in the sample and we correcrly predicted then as negative. We will denote their number as $TN$;\n",
    "- *False positve*: observations that were negative in the sample, but which we then mistakenly predicted to be positive. We will denote their number as $FP$;\n",
    "- *False negative*: observations that were positive in the sample, but wich we then mistakenly predicted to be negative. We will denote their number as $FN$.\n",
    "\n",
    "So, if you put the actual value on the rows and the predicted value on the columns, you will get a confusion matrix.\n",
    "\n",
    "\n",
    "| | Predicted $N$ | Predicted $P$ |\n",
    "|:---|:---:|:---:|\n",
    "| Actual $N$ |$TN$|$FP$ |\n",
    "| Actual $P$ |$FN$|$TP$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8cbeaf-36e1-446f-819a-2c81b344bda2",
   "metadata": {},
   "source": [
    "Also valuable is the representation of the confusion matrix using relative values.\n",
    "\n",
    "Let be:\n",
    "\n",
    "- $P^* = TP + FP$ - number of observations from the sample predicted as positive;\n",
    "- $N^* = TN + FN$ - number of observations from the sample predicted as negative;\n",
    "- $TNR = TN/N^*$ - true negative rate, the proportion of correct predictions among observations that are predicted negative;\n",
    "- $FNR = FN/N^*$ - false negative rate, the proportion of incorrect predictions among observations that are predicted to be negative;\n",
    "- $TPR = TP/P^*$ - true positive rate, the proportion of correct predictions among observations that are predicted to be positive;\n",
    "- $FPR = FP/P^*$ - false positve rate, the proportion of incorrect predicitons among observations that are predicted to be negative.\n",
    "\n",
    "\n",
    "So using these notations the confusion matrix can also be written:\n",
    "\n",
    "| | Predicted $N$ | Predicted $P$ |\n",
    "|:---|:---:|:---:|\n",
    "| Actual $N$ |$TNR$|$FPR$ |\n",
    "| Actual $P$ |$FNR$|$TPR$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210887e-81b9-4832-a024-b49d981b6363",
   "metadata": {},
   "source": [
    "Here is an example of calculating the confusion matrix using `sklearn.metrics.confusion_matrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d475e43-c213-4c6f-b025-f2d098a023ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39,  7],\n",
       "       [17, 37]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "sklearn.metrics.confusion_matrix(y, scores > np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37552f-be87-4bce-b36e-1bb7d474f4d3",
   "metadata": {},
   "source": [
    "## Confusion table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c502da-4730-4218-a712-74df61d57499",
   "metadata": {},
   "source": [
    "### Idea\n",
    "\n",
    "Many classification models allow to return a score that indicates the probability that a particular object belongs to the positive class. You can select the threshold above which you consider the object under consideration to be positive. Different treshold values will consequently produce different confusion matrixes.\n",
    "\n",
    "The table that puts in correspondence to some selected threshold the table of contiguity will be called the confusion table.\n",
    "\n",
    "| $T$   | $TN$ | $FP$ | $FN$ | $TP$ |\n",
    "|:-----------|:-----:|:-----:|:-----:|:-----:|\n",
    "| $t_1$      | $TN_1$| $FP_1$| $FN_1$| $TP_1$|\n",
    "| $t_2$      | $TN_2$| $FP_2$| $FN_2$| $TP_2$|\n",
    "| ...        | ...    | ...    | ...    | ...    |\n",
    "| $t_i$      | $TN_i$| $FP_i$| $FN_i$| $TP_i$|\n",
    "| ...        | ...    | ...    | ...    | ...    |\n",
    "| $t_n$      | $TN_n$| $FP_n$| $FN_n$| $TP_n$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca36fa90-9159-4553-a18d-9997ee2ee8a0",
   "metadata": {},
   "source": [
    "### Realisation\n",
    "\n",
    "I didn't find ready realisation of the similar concept. So here is my own realisation.\n",
    "\n",
    "The first thing that comes to mind is to use `sklearn.metrix.confusion_matrix` for all needed $t_i$. But this solution is extremely slow - an estimate of the complexity of the algorithm is $O(nT')$, where $n$ number of samples $T'$ is the number of thresholds to check.\n",
    "\n",
    "The following is a description of the algorithm that will work with complexity $O(n)$ assuming that the observations are sorted in ascending order $s_i$ and all thresholds are sorted in asceding order:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadcb0d7-fe1f-487c-9f84-8adfb7b3be97",
   "metadata": {},
   "source": [
    "#### Text description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ee652-2f46-4537-bb93-13bab3d880c1",
   "metadata": {},
   "source": [
    "As input we have three arrays:\n",
    "\n",
    "- $\\left\\{y_1,y_2, ... , y_n\\right\\}$ - real classes of the observations, where:\n",
    "$$y_i = \\begin{cases}\n",
    "    0, \\text{if i-th observation negative};\\\\\n",
    "    1, \\text{if i-th observation positive}.\n",
    "\\end{cases}$$\n",
    "- $\\left\\{s_1,s_2, ..., s_n\\right\\}$ - scores of the observations;\n",
    "- $\\left\\{t_1, t_2, ..., t_{T'}\\right\\}$ - the thresholds we're interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c186c5-b14d-4f85-984a-9104c1ecd6ce",
   "metadata": {},
   "source": [
    "Let's introduce cursors for the values we are interested in, and setup them values for the smallest rational threshold for a given problem:\n",
    "\n",
    "- $TP'=P=\\sum_{i=1}^n{y_i}$ - with the lowest threshold, all positive outcomes are truly classified as positive;\n",
    "- $FP'=N = n -\\sum_{i=1}^n{y_i}$ - with the lowest threshold, all negative outcomes are mistaken classified as positive;\n",
    "- $TN'=0, FN'=0$ - with the lowest threshold there are no values that classified as negative;\n",
    "- $i=1$ indexes $y_i$ and $s_i$;\n",
    "- $j=1$ indexes $t_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3024d9a6-4bc4-40eb-a6c7-9b1751f637b0",
   "metadata": {},
   "source": [
    "Now let's talk about the iterative procedure:\n",
    "\n",
    "At each step we compare $s_i$ and $t_j$:\n",
    "\n",
    "- If $s_i < t_j$:\n",
    "    - If $y_i=1$, then we add one to $FN'$ and subtract one from $TP'$;\n",
    "    - If $y_i=0$, then we add one to $TN'$ and subtract one from $FP'$;\n",
    "    - Come the the next observation - add one to $i$;\n",
    "- If $s_i \\geq t_j$:\n",
    "    - Add the current values of $TP', FP', TN', FN'$ to the confusion table row corresponding to $t_j$;\n",
    "    - Come to the next threshold, - add one to $j$;\n",
    "- The algorithm stops when we've circled all thresholds $j>T'$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa5a40-2ee7-4f3e-bead-16d5cfc80355",
   "metadata": {},
   "source": [
    "#### Python realisaton\n",
    "\n",
    "In this section is a python function that implements the algorithm below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7b7a54-9b4e-4862-ab78-43311b40e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_sorted_by_scores(y_true, y_score):\n",
    "    '''\n",
    "    Get sort y_true and y_score which\n",
    "    elements corresponds to each other\n",
    "    sorted by y_score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : numpy.array\n",
    "        array of outcomes;\n",
    "    y_scores : numpy.array\n",
    "        array of scores that defines order\n",
    "        of the outputs.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    y_true : numpy.array\n",
    "        y_true sorted according to y_score\n",
    "    y_scores : numpy array\n",
    "        sorted y_score;\n",
    "    '''\n",
    "    sorting = np.argsort(y_score)\n",
    "    return y_true[sorting], y_score[sorting]\n",
    "\n",
    "\n",
    "def get_confusion_table(\n",
    "    y_true,\n",
    "    y_score,\n",
    "    thresholds=None\n",
    "):\n",
    "    '''\n",
    "    Get confusion table - set of confusion\n",
    "    matrixes for given set of thresholds.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : numpy.array\n",
    "        binary array that represents really classes of\n",
    "        observations;\n",
    "    y_score : numpy.array\n",
    "        array which elements corresponds to the y_true\n",
    "        and represents result scores of the classifier;\n",
    "    thresholds : numpy.array\n",
    "        set of thresholds. By default the same as y_score\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    out : numpy.array\n",
    "        where each row is confusion matrix for particular\n",
    "        threshold. Each row contains values \n",
    "        threshold, TN, FP, FN, TP.\n",
    "    '''\n",
    "    if thresholds is None:\n",
    "        thresholds = y_score\n",
    "\n",
    "    # it's crusial for y_true\n",
    "    # and y_score to have same size\n",
    "    n = len(y_score)\n",
    "    if n != len(y_true):\n",
    "        raise ValueError(\n",
    "            \"y_score and y_true must \"\n",
    "            \"have the same size. But got \"\n",
    "            f\"{n} and {len(y_true)}\"\n",
    "        )\n",
    "\n",
    "    y_true, y_score = get_sorted_by_scores(y_true, y_score)\n",
    "    thresholds = (y_score if (thresholds is None) else np.sort(thresholds)) \n",
    "    \n",
    "    T_len = len(thresholds)\n",
    "\n",
    "    # setting up initial values for cursors\n",
    "    TP = np.sum(y_true)\n",
    "    FP = n-TP\n",
    "    TN=0;FN=0;i=0;j=0\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    while True:\n",
    "        if y_score[i] < thresholds[j]:\n",
    "            if y_true[i]: FN+=1;TP-=1\n",
    "            else: TN+=1;FP-=1\n",
    "            i+=1\n",
    "        else:\n",
    "            res.append([thresholds[j],TN,FP,FN,TP])\n",
    "            j+=1            \n",
    "\n",
    "        if j >= T_len:\n",
    "            return np.array(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c896e56f-9477-45d7-91e4-8a435a90e4fa",
   "metadata": {},
   "source": [
    "So let's see how it works with the example we added earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3921d4-da4f-40ae-a7ef-de8b1d144f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$$TN$$</th>\n",
       "      <th>$$FP$$</th>\n",
       "      <th>$$FN$$</th>\n",
       "      <th>$$TP$$</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$T$$</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.528063</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.463307</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.405160</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.388968</th>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.308240</th>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.814459</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.834142</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.892121</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.917869</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.033877</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           $$TN$$  $$FP$$  $$FN$$  $$TP$$\n",
       "$$T$$                                    \n",
       "-1.528063       0      46       0      54\n",
       "-1.463307       0      46       1      53\n",
       "-1.405160       1      45       1      53\n",
       "-1.388968       2      44       1      53\n",
       "-1.308240       3      43       1      53\n",
       "...           ...     ...     ...     ...\n",
       " 1.814459      45       1      50       4\n",
       " 1.834142      45       1      51       3\n",
       " 1.892121      45       1      52       2\n",
       " 1.917869      46       0      52       2\n",
       " 2.033877      46       0      53       1\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = get_confusion_table(y, scores)\n",
    "\n",
    "pd.DataFrame(\n",
    "    result[:, 1:], \n",
    "    index=pd.Index(result[:,0], name=\"$$T$$\"),\n",
    "    columns=[\"$$TN$$\", \"$$FP$$\", \"$$FN$$\", \"$$TP$$\"]\n",
    ").astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0ba623-3853-4592-93e2-b151d455168f",
   "metadata": {},
   "source": [
    "#### Tests\n",
    "\n",
    "For the example under consideration, everything looks great, but it's good practice to make a simple example that can be easily handled in mind. Here's the set of unit tests described and implemented for the above function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad007ee-ccf1-424c-967e-89e2a9ed38c2",
   "metadata": {},
   "source": [
    "Consider case:\n",
    "\n",
    "- $y_i\\in \\left\\{1,0,0,1,0\\right\\}$ - real classes of the observations;\n",
    "- $s_i\\in \\left\\{4,1,1,2,3\\right\\}$ - scores of the observations;\n",
    "- $t_j \\in \\left\\{2,3\\right\\}$ - the thresholds we're interested in.\n",
    "\n",
    " Let us consider the specified cut-off thresholds and indicate which of them observations at a given threshold belong to such a sector of the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fdc2fe-88b9-42d2-8b37-26f6d4f7e8bb",
   "metadata": {},
   "source": [
    "For $t_1=2$:\n",
    "\n",
    "|$i$|$s_i$|$y_i$|$TN$|$FP$|$FN$|$TP$|\n",
    "|:--|:---:|:---:|:--:|:--:|:--:|:--:|\n",
    "|1|4|1|×|×|×|✓|\n",
    "|2|1|0|✓|×|×|×|\n",
    "|3|1|0|✓|×|×|×|\n",
    "|4|2|1|×|×|×|✓|\n",
    "|5|3|0|×|✓|×|×|\n",
    "|Total|||2|1|0|2|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c69eac-297c-4418-97bb-0ea111da0ea3",
   "metadata": {},
   "source": [
    "For $t_2=3$:\n",
    "\n",
    "|$i$|$s_i$|$y_i$|$TN$|$FP$|$FN$|$TP$|\n",
    "|-|-|-|-|-|-|-|\n",
    "|1|4|1|×|×|×|✓|\n",
    "|2|1|0|✓|×|×|×|\n",
    "|3|1|0|✓|×|×|×|\n",
    "|4|2|1|×|×|✓|×|\n",
    "|5|3|0|×|✓|×|×|\n",
    "|Total|||2|1|1|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1770072d-9233-4ca6-b594-1686fd85b112",
   "metadata": {},
   "source": [
    "So let's see if the results of our hand calculations are the same as the function's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1b52a93-150d-4ed2-a447-5628b25166d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$$TN$$</th>\n",
       "      <th>$$FP$$</th>\n",
       "      <th>$$FN$$</th>\n",
       "      <th>$$TP$$</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$$T$$</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       $$TN$$  $$FP$$  $$FN$$  $$TP$$\n",
       "$$T$$                                \n",
       "2           2       1       0       2\n",
       "3           2       1       1       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y =      np.array([1,0,0,1,0])\n",
    "test_scores = np.array([4,1,1,2,3])\n",
    "test_thresholds = np.array([2,3])\n",
    "\n",
    "result = get_confusion_table(test_y, test_scores, test_thresholds)\n",
    "\n",
    "pd.DataFrame(\n",
    "    result[:, 1:], \n",
    "    index=pd.Index(result[:,0], name=\"$$T$$\"),\n",
    "    columns=[\"$$TN$$\", \"$$FP$$\", \"$$FN$$\", \"$$TP$$\"]\n",
    ").astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfda0e3-ff6d-4591-9d1c-bad714d3b7a6",
   "metadata": {},
   "source": [
    "Here are automatic test cases for the cases discussed earlier and some additional ones. So you don't have to check everything yourself if you want to select something in the implementation of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c724a4c-c88c-4891-8d97-73c211d20ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_array_sizes (__main__.TestCounfusionTable)\n",
      "If y_true and y_score have different ... ok\n",
      "test_basic_output (__main__.TestCounfusionTable)\n",
      "This is basic case for wich ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestCounfusionTable(unittest.TestCase):\n",
    "    def test_array_sizes(self):\n",
    "        '''\n",
    "        If y_true and y_score have different\n",
    "        sizes if should raise ValueError.\n",
    "        '''\n",
    "        with self.assertRaises(ValueError):\n",
    "            get_confusion_table(\n",
    "                y_true=[1,2,3,4], \n",
    "                y_score=[3,2,1,4,3]\n",
    "            )\n",
    "\n",
    "    def test_basic_output(self):\n",
    "        '''\n",
    "        This is basic case for wich\n",
    "        we know actual answer.\n",
    "        '''\n",
    "        test_y = np.array([1,0,0,1,0])\n",
    "        test_scores = np.array([4,1,1,2,3])\n",
    "        test_thresholds = np.array([2,3])\n",
    "\n",
    "        exp_ans = np.array([\n",
    "            [2, 2, 1, 0, 2],\n",
    "            [3, 2, 1, 1, 1]\n",
    "        ])\n",
    "        act_ans = get_confusion_table(\n",
    "            test_y, test_scores, test_thresholds\n",
    "        )\n",
    "        self.assertTrue(\n",
    "            (act_ans == exp_ans).all()\n",
    "        )\n",
    "ans = unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}